==========================
How should we connect to your data?
==========================
ðŸ”˜ connector.class



	 - Type: true
	 - Default: STRING
	 - Importance: 
	 - Required: HIGH

ðŸ”˜ name



	 - Type: true
	 - Default: STRING
	 - Importance: Sets a name for your connector.
	 - Required: HIGH

==========================
Kafka Cluster credentials
==========================
ðŸ”˜ kafka.auth.mode

Kafka Authentication mode. It can be one of KAFKA_API_KEY or SERVICE_ACCOUNT. It defaults to KAFKA_API_KEY mode.

	 - Type: STRING
	 - Default: KAFKA_API_KEY
	 - Importance: HIGH
	 - Required: false

ðŸ”˜ kafka.service.account.id



	 - Type: false
	 - Default: STRING
	 - Importance: The Service Account that will be used to generate the API keys to communicate with Kafka Cluster.
	 - Required: HIGH

ðŸ”˜ kafka.api.key



	 - Type: false
	 - Default: STRING
	 - Importance: Kafka API Key. Required when kafka.auth.mode==KAFKA_API_KEY.
	 - Required: HIGH

ðŸ”˜ kafka.api.secret



	 - Type: false
	 - Default: PASSWORD
	 - Importance: Secret associated with Kafka API key. Required when kafka.auth.mode==KAFKA_API_KEY.
	 - Required: HIGH

ðŸ”˜ datapreview.schemas.enable

This config key only applies to data preview requests and governs whether the data preview output has record schema with it.

	 - Type: STRING
	 - Default: false
	 - Importance: LOW
	 - Required: false

==========================
Which topic do you want to send data to?
==========================
ðŸ”˜ kafka.topic



	 - Type: true
	 - Default: STRING
	 - Importance: Identifies the topic name to write the data to.
	 - Required: HIGH

==========================
Schema Config
==========================
ðŸ”˜ schema.context.name

Add a schema context name. A schema context represents an independent scope in Schema Registry. It is a separate sub-schema tied to topics in different Kafka clusters that share the same Schema Registry instance. If not used, the connector uses the default schema configured for Schema Registry in your Confluent Cloud environment.

	 - Type: STRING
	 - Default: default
	 - Importance: MEDIUM
	 - Required: false

==========================
Output messages
==========================
ðŸ”˜ output.data.format

Sets the output Kafka record value format. Valid entries are AVRO, JSON_SR, PROTOBUF, or JSON. Note that you need to have Confluent Cloud Schema Registry configured if using a schema-based message format like AVRO, JSON_SR, and PROTOBUF

	 - Type: STRING
	 - Default: JSON
	 - Importance: HIGH
	 - Required: true

==========================
ActiveMQ Connection
==========================
ðŸ”˜ activemq.url



	 - Type: true
	 - Default: STRING
	 - Importance: The URL of the ActiveMQ broker.
	 - Required: HIGH

ðŸ”˜ activemq.username



	 - Type: true
	 - Default: STRING
	 - Importance: The username to use when connecting to ActiveMQ.
	 - Required: HIGH

ðŸ”˜ activemq.password



	 - Type: true
	 - Default: PASSWORD
	 - Importance: The password to use when connecting to ActiveMQ.
	 - Required: HIGH

==========================
ActiveMQ Session
==========================
ðŸ”˜ jms.destination.name



	 - Type: true
	 - Default: STRING
	 - Importance: The name of the JMS destination (queue or topic) to read from.
	 - Required: HIGH

ðŸ”˜ jms.destination.type

The type of JMS destination, which is either `queue` or `topic`.

	 - Type: STRING
	 - Default: queue
	 - Importance: HIGH
	 - Required: false

ðŸ”˜ batch.size



	 - Type: false
	 - Default: INT
	 - Importance: The maximum number of records that a connector task may read from the JMS broker before writing to Kafka. The task holds these records until they are acknowledged in Kafka, so this may affect memory usage.
	 - Required: MEDIUM

ðŸ”˜ max.pending.messages



	 - Type: false
	 - Default: INT
	 - Importance: The maximum number of messages per task that can be received from JMS brokers and produced to Kafka before the task acknowledges the JMS session/messages. If the task fails and is restarted, this is the maximum number of JMS messages the task may duplicate in Kafka. This is typically set larger than ``batch.size``. A smaller value than ``batch.size`` limits the size of the batches.
	 - Required: MEDIUM

ðŸ”˜ max.poll.duration

The maximum amount of time each task can build a batch. The batch is closed and sent to Kafka if not enough messages are read during the time allotted. This helps limit connector lag when the JMS queue/topic has a lower throughput.

	 - Type: INT
	 - Default: 60000
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ character.encoding

The character encoding to use while receiving the message.

	 - Type: STRING
	 - Default: UTF-8
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ jms.subscription.durable

Whether the subscription of the connector tasks to a JMS topic is durable or not. Durable subscriptions require a subscription name to be set via ``jms.subscription.name``. 

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ jms.subscription.name



	 - Type: false
	 - Default: STRING
	 - Importance: The name of the JMS subscription. Supported only in durable subscriptions (``jms.subscription.durable = true``) and is applicable only to JMS topics.
	 - Required: MEDIUM

ðŸ”˜ jms.message.selector



	 - Type: false
	 - Default: STRING
	 - Importance: The message selector that should be applied to messages in the destination.
	 - Required: MEDIUM

==========================
Number of tasks for this connector
==========================
ðŸ”˜ tasks.max



	 - Type: true
	 - Default: INT
	 - Importance: Maximum number of tasks for the connector.
	 - Required: HIGH

==========================
Additional Configs
==========================
ðŸ”˜ value.converter.decimal.format

Specify the JSON/JSON_SR serialization format for Connect DECIMAL logical type values with two allowed literals:

	 - Type: STRING
	 - Default: BASE64
	 - Importance: LOW
	 - Required: false

ðŸ”˜ value.converter.replace.null.with.default

Whether to replace fields that have a default value and that are null to the default value. When set to true, the default value is used, otherwise null is used. Applicable for JSON Converter.

	 - Type: BOOLEAN
	 - Default: true
	 - Importance: LOW
	 - Required: false

ðŸ”˜ value.converter.reference.subject.name.strategy

Set the subject reference name strategy for value. Valid entries are DefaultReferenceSubjectNameStrategy or QualifiedReferenceSubjectNameStrategy. Note that the subject reference name strategy can be selected only for PROTOBUF format with the default strategy being DefaultReferenceSubjectNameStrategy.

	 - Type: STRING
	 - Default: DefaultReferenceSubjectNameStrategy
	 - Importance: LOW
	 - Required: false

ðŸ”˜ value.converter.schemas.enable

Include schemas within each of the serialized values. Input messages must contain `schema` and `payload` fields and may not contain additional fields. For plain JSON data, set this to `false`. Applicable for JSON Converter.

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: LOW
	 - Required: false

ðŸ”˜ errors.tolerance

Use this property if you would like to configure the connector's error handling behavior. WARNING: This property should be used with CAUTION for SOURCE CONNECTORS as it may lead to dataloss. If you set this property to 'all', the connector will not fail on errant records, but will instead log them (and send to DLQ for Sink Connectors) and continue processing. If you set this property to 'none', the connector task will fail on errant records.

	 - Type: STRING
	 - Default: none
	 - Importance: LOW
	 - Required: false

ðŸ”˜ value.converter.connect.meta.data



	 - Type: false
	 - Default: BOOLEAN
	 - Importance: Allow the Connect converter to add its metadata to the output schema. Applicable for Avro Converters.
	 - Required: LOW

ðŸ”˜ value.converter.value.subject.name.strategy

Determines how to construct the subject name under which the value schema is registered with Schema Registry.

	 - Type: STRING
	 - Default: TopicNameStrategy
	 - Importance: LOW
	 - Required: false

ðŸ”˜ key.converter.key.subject.name.strategy

How to construct the subject name for key schema registration.

	 - Type: STRING
	 - Default: TopicNameStrategy
	 - Importance: LOW
	 - Required: false

ðŸ”˜ value.converter.ignore.default.for.nullables

When set to true, this property ensures that the corresponding record in Kafka is NULL, instead of showing the default column value. Applicable for AVRO,PROTOBUF and JSON_SR Converters.

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: LOW
	 - Required: false

==========================
Auto-restart policy
==========================
ðŸ”˜ auto.restart.on.user.error

Enable connector to automatically restart on user-actionable errors.

	 - Type: BOOLEAN
	 - Default: true
	 - Importance: MEDIUM
	 - Required: false

==========================
Egress allowlist
==========================
ðŸ”˜ connector.egress.whitelist



	 - Type: false
	 - Default: STRING
	 - Importance: 
	 - Required: HIGH

