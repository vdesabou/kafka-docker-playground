==========================
Which topics do you want to get data from?
==========================
ðŸ”˜ topics



	 - Type: true
	 - Default: LIST
	 - Importance: Identifies the topic name or a comma-separated list of topic names.
	 - Required: HIGH

==========================
Schema Config
==========================
ðŸ”˜ schema.context.name

Add a schema context name. A schema context represents an independent scope in Schema Registry. It is a separate sub-schema tied to topics in different Kafka clusters that share the same Schema Registry instance. If not used, the connector uses the default schema configured for Schema Registry in your Confluent Cloud environment.

	 - Type: STRING
	 - Default: default
	 - Importance: MEDIUM
	 - Required: false

==========================
Input messages
==========================
ðŸ”˜ input.data.format

Sets the input Kafka record value format. Valid entries are AVRO, JSON_SR, PROTOBUF, JSON or BYTES. Note that you need to have Confluent Cloud Schema Registry configured if using a schema-based message format like AVRO, JSON_SR, and PROTOBUF.

	 - Type: STRING
	 - Default: JSON
	 - Importance: HIGH
	 - Required: true

ðŸ”˜ input.key.format

Sets the input Kafka record key format. Valid entries are BYTES or STRING.

	 - Type: STRING
	 - Default: BYTES
	 - Importance: HIGH
	 - Required: false

==========================
How should we connect to your data?
==========================
ðŸ”˜ connector.class



	 - Type: true
	 - Default: STRING
	 - Importance: 
	 - Required: HIGH

ðŸ”˜ name



	 - Type: true
	 - Default: STRING
	 - Importance: Sets a name for your connector.
	 - Required: HIGH

==========================
Kafka Cluster credentials
==========================
ðŸ”˜ kafka.auth.mode

Kafka Authentication mode. It can be one of KAFKA_API_KEY or SERVICE_ACCOUNT. It defaults to KAFKA_API_KEY mode.

	 - Type: STRING
	 - Default: KAFKA_API_KEY
	 - Importance: HIGH
	 - Required: false

ðŸ”˜ kafka.service.account.id



	 - Type: false
	 - Default: STRING
	 - Importance: The Service Account that will be used to generate the API keys to communicate with Kafka Cluster.
	 - Required: HIGH

ðŸ”˜ kafka.api.key



	 - Type: false
	 - Default: STRING
	 - Importance: Kafka API Key. Required when kafka.auth.mode==KAFKA_API_KEY.
	 - Required: HIGH

ðŸ”˜ kafka.api.secret



	 - Type: false
	 - Default: PASSWORD
	 - Importance: Secret associated with Kafka API key. Required when kafka.auth.mode==KAFKA_API_KEY.
	 - Required: HIGH

==========================
CSFLE
==========================
ðŸ”˜ csfle.enabled

Determines whether the connector honours CSFLE rules or not

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: HIGH
	 - Required: false

ðŸ”˜ sr.service.account.id



	 - Type: false
	 - Default: STRING
	 - Importance: Select the service account that has appropriate permissions to schemas and encryption keys in the Schema Registry.
	 - Required: HIGH

ðŸ”˜ csfle.onFailure

Configures the behavior for decryption failures. If set to ERROR, the connector will behave as configured for error behaviour. If set to NONE, the connector will ignore the decryption failure and proceed to write the data in its encrypted form.

	 - Type: STRING
	 - Default: ERROR
	 - Importance: MEDIUM
	 - Required: false

==========================
HTTP server details
==========================
ðŸ”˜ http.api.url



	 - Type: true
	 - Default: STRING
	 - Importance: Specifies the API endpoint to which connector should write to.
	 - Required: HIGH

ðŸ”˜ request.method

Specifies the HTTP request method (POST, PUT, PATCH) the connector should use for sending API request.

	 - Type: STRING
	 - Default: POST
	 - Importance: HIGH
	 - Required: false

ðŸ”˜ headers



	 - Type: false
	 - Default: STRING
	 - Importance: HTTP headers to be included in all requests. Individual headers should be separated by the Header Separator
	 - Required: HIGH

ðŸ”˜ header.separator



	 - Type: false
	 - Default: STRING
	 - Importance: Separator character used in headers
	 - Required: HIGH

ðŸ”˜ behavior.on.null.values

How to handle records with a non-null key and a null value (i.e. Kafka tombstone records). Valid options are ``ignore``, ``delete`` and ``fail``

	 - Type: STRING
	 - Default: ignore
	 - Importance: LOW
	 - Required: false

ðŸ”˜ sensitive.headers



	 - Type: false
	 - Default: PASSWORD
	 - Importance: Sensitive HTTP headers (eg: credentials) to be included in all requests. Individual headers should be separated by the Header Separator
	 - Required: HIGH

==========================
HTTP server error handling
==========================
ðŸ”˜ behavior.on.error

Describes the error handling behavior configuration for handling error responses from HTTP requests. Accepted values are ``ignore`` and ``fail``.

	 - Type: STRING
	 - Default: ignore
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ report.errors.as

Dictates the content of records produced to the error topic. Accepted values are ``error_string`` and ``http_response``. If set to ``error_string``, the value would be a human readable string describing the failure. The value will include some or all of the following information if available: http response code, reason phrase, submitted payload, url, response content, exception and error message. If set to ``http_response``, the value would be the plain response content for the request which failed to write the record. In both modes, any information about the failure will also be included in the error record's headers.

	 - Type: STRING
	 - Default: error_string
	 - Importance: MEDIUM
	 - Required: false

==========================
HTTP server batches
==========================
ðŸ”˜ request.body.format

Used to produce request body in either JSON or String format

	 - Type: STRING
	 - Default: string
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ batch.key.pattern



	 - Type: false
	 - Default: STRING
	 - Importance: Pattern used to build the key for a given batch. ${key} and ${topic} can be used to include message attributes here
	 - Required: HIGH

ðŸ”˜ batch.max.size

The number of records accumulated in a batch before the HTTP API is invoked

	 - Type: INT
	 - Default: 1
	 - Importance: HIGH
	 - Required: false

ðŸ”˜ batch.prefix



	 - Type: false
	 - Default: STRING
	 - Importance: Prefix added to record batches. This is applied once at the beginning of the batch of records
	 - Required: HIGH

ðŸ”˜ batch.suffix



	 - Type: false
	 - Default: STRING
	 - Importance: Suffix added to record batches. This is applied once at the end of the batch of records
	 - Required: HIGH

ðŸ”˜ batch.separator



	 - Type: false
	 - Default: STRING
	 - Importance: Separator for records in a batch
	 - Required: HIGH

ðŸ”˜ batch.json.as.array



	 - Type: false
	 - Default: BOOLEAN
	 - Importance: Whether or not to use an array to bundle json records. Only used when request.body.format is set to json. This can be disabled only when batch.max.size is set to 1.
	 - Required: HIGH

==========================
HTTP server authentication
==========================
ðŸ”˜ auth.type

Specifies the authentication type of the API endpoint. Valid values are ``NONE``, ``BASIC``, ``OAUTH2`` (Client Credentials grant type only).

	 - Type: STRING
	 - Default: NONE
	 - Importance: HIGH
	 - Required: false

ðŸ”˜ connection.user



	 - Type: false
	 - Default: STRING
	 - Importance: The username to be used with an endpoint requiring authentication
	 - Required: HIGH

ðŸ”˜ connection.password



	 - Type: false
	 - Default: PASSWORD
	 - Importance: The password to be used with an endpoint requiring authentication
	 - Required: HIGH

ðŸ”˜ oauth2.token.url



	 - Type: false
	 - Default: STRING
	 - Importance: The URL to be used for fetching OAuth2 token. Client Credentials is the only supported grant type.
	 - Required: HIGH

ðŸ”˜ oauth2.client.id



	 - Type: false
	 - Default: STRING
	 - Importance: The client id used when fetching OAuth2 token
	 - Required: HIGH

ðŸ”˜ oauth2.client.secret



	 - Type: false
	 - Default: PASSWORD
	 - Importance: The secret used when fetching OAuth2 token
	 - Required: HIGH

ðŸ”˜ oauth2.token.property

The name of the property containing the OAuth2 token returned by the http proxy.

	 - Type: STRING
	 - Default: access_token
	 - Importance: HIGH
	 - Required: false

ðŸ”˜ oauth2.client.auth.mode

Specifies how to encode ``client_id`` and ``client_secret`` in the OAuth2 authorization request. If set to 'header', the credentials are encoded as an ``'Authorization: Basic <base-64 encoded client_id:client_secret>'`` HTTP header. If set to 'url', then ``client_id`` and ``client_secret`` are sent in body as URL encoded parameters.

	 - Type: STRING
	 - Default: header
	 - Importance: LOW
	 - Required: false

ðŸ”˜ oauth2.client.scope

The scope used when fetching OAuth2 token. If empty, this parameter is not set in the authorization request

	 - Type: STRING
	 - Default: any
	 - Importance: LOW
	 - Required: false

ðŸ”˜ oauth2.jwt.enabled

Whether to generate and add JWT token to request. If selected, JWT token will be added as 'jwt_token' request param

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ oauth2.jwt.keystore.path



	 - Type: false
	 - Default: PASSWORD
	 - Importance: Keystore containing private key to use to sign JWT.
	 - Required: MEDIUM

ðŸ”˜ oauth2.jwt.keystore.password



	 - Type: false
	 - Default: PASSWORD
	 - Importance: Password to access keystore
	 - Required: MEDIUM

ðŸ”˜ oauth2.jwt.keystore.type

JWT keystore type

	 - Type: STRING
	 - Default: JKS
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ oauth2.jwt.claimset



	 - Type: false
	 - Default: STRING
	 - Importance: JSON containing JWT claims
	 - Required: MEDIUM

ðŸ”˜ oauth2.client.headers



	 - Type: false
	 - Default: STRING
	 - Importance: HTTP headers to be included in the OAuth2 client endpoint. Individual headers should be separated by OAuth2 Client Headers Separator
	 - Required: LOW

ðŸ”˜ oauth2.client.header.separator



	 - Type: false
	 - Default: STRING
	 - Importance: Separator character used in OAuth2 Client Headers
	 - Required: LOW

==========================
HTTP server retries
==========================
ðŸ”˜ retry.on.status.codes

The HTTP error codes to retry on. Comma-separated list of codes or range of codes to retry on. Ranges are specified with start and optional end code. Range boundaries are inclusive. For instance, '400-' includes all codes greater than or equal to 400. '400-500' includes codes from 400 to 500, including 500. Multiple ranges and single codes can be specified together to achieve fine grained control over retry behavior. For example, '404,408,500-' will retry on 404 NOT FOUND, 408 REQUEST TIMEOUT, and all 5xx error codes

	 - Type: STRING
	 - Default: 400-
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ max.retries

The maximum number of times to retry on errors before failing the task

	 - Type: INT
	 - Default: 3
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ retry.backoff.ms

The initial duration in milliseconds to wait following an error before a retry attempt is made. Subsequent backoff attempts will be exponentially larger than the first duration. Note that this value is the initial backoff before retrying. After that, the connector will retry using exponential jitter. Jitter adds randomness to the exponential backoff algorithm to prevent synchronized retries.

	 - Type: INT
	 - Default: 3000
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ http.connect.timeout.ms

The time in milliseconds to wait for a connection to be established

	 - Type: INT
	 - Default: 30000
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ http.request.timeout.ms

The time in milliseconds to wait for a request response from the server

	 - Type: INT
	 - Default: 30000
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ retry.backoff.policy

The backoff policy to use in terms of retry - CONSTANT_VALUE or EXPONENTIAL_WITH_JITTER

	 - Type: STRING
	 - Default: EXPONENTIAL_WITH_JITTER
	 - Importance: MEDIUM
	 - Required: false

==========================
HTTP server regular expressions
==========================
ðŸ”˜ regex.patterns



	 - Type: false
	 - Default: STRING
	 - Importance: Regular expression patterns used for replacements in the message sent to the HTTP service. Multiple regular expression patterns can be specified, but must be separated by ``regex.separator``
	 - Required: MEDIUM

ðŸ”˜ regex.replacements



	 - Type: false
	 - Default: STRING
	 - Importance: Regex replacements to use with the patterns in ``regex.patterns``.  Multiple replacements can be specified, but must be separated by ``regex.separator``. ``${key}`` and ``${topic}`` can be used here.
	 - Required: MEDIUM

ðŸ”˜ regex.separator



	 - Type: false
	 - Default: STRING
	 - Importance: Separator character used in ``regex.patterns`` and ``regex.replacements`` property.
	 - Required: MEDIUM

==========================
HTTP server SSL
==========================
ðŸ”˜ https.ssl.key.password



	 - Type: false
	 - Default: PASSWORD
	 - Importance: The password of the private key in the key store file. This is optional for client
	 - Required: HIGH

ðŸ”˜ https.ssl.keystorefile



	 - Type: false
	 - Default: PASSWORD
	 - Importance: The key store containing server certificate. Only required if using https
	 - Required: LOW

ðŸ”˜ https.ssl.keystore.password



	 - Type: false
	 - Default: PASSWORD
	 - Importance: The store password for the key store file. This is optional for a client and is only needed if https.ssl.keystore.location is configured
	 - Required: HIGH

ðŸ”˜ https.ssl.truststorefile



	 - Type: false
	 - Default: PASSWORD
	 - Importance: The trust store containing server CA certificate. Only required if using https
	 - Required: HIGH

ðŸ”˜ https.ssl.truststore.password



	 - Type: false
	 - Default: PASSWORD
	 - Importance: The trust store password containing server CA certificate. Only required if using https
	 - Required: HIGH

ðŸ”˜ https.ssl.protocol

The protocol to use for SSL connections

	 - Type: STRING
	 - Default: TLSv1.3
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ https.host.verifier.enabled

True if SSL host verification should be enabled

	 - Type: STRING
	 - Default: true
	 - Importance: MEDIUM
	 - Required: false

==========================
Consumer configuration
==========================
ðŸ”˜ max.poll.interval.ms

The maximum delay between subsequent consume requests to Kafka. This configuration property may be used to improve the performance of the connector, if the connector cannot send records to the sink system. Defaults to 300000 milliseconds (5 minutes).

	 - Type: LONG
	 - Default: 300000
	 - Importance: LOW
	 - Required: false

ðŸ”˜ max.poll.records

The maximum number of records to consume from Kafka in a single request. This configuration property may be used to improve the performance of the connector, if the connector cannot send records to the sink system. Defaults to 500 records.

	 - Type: LONG
	 - Default: 500
	 - Importance: LOW
	 - Required: false

==========================
Number of tasks for this connector
==========================
ðŸ”˜ tasks.max



	 - Type: true
	 - Default: INT
	 - Importance: Maximum number of tasks for the connector.
	 - Required: HIGH

==========================
Additional Configs
==========================
ðŸ”˜ value.converter.replace.null.with.default

Whether to replace fields that have a default value and that are null to the default value. When set to true, the default value is used, otherwise null is used. Applicable for JSON Converter.

	 - Type: BOOLEAN
	 - Default: true
	 - Importance: LOW
	 - Required: false

ðŸ”˜ value.converter.reference.subject.name.strategy

Set the subject reference name strategy for value. Valid entries are DefaultReferenceSubjectNameStrategy or QualifiedReferenceSubjectNameStrategy. Note that the subject reference name strategy can be selected only for PROTOBUF format with the default strategy being DefaultReferenceSubjectNameStrategy.

	 - Type: STRING
	 - Default: DefaultReferenceSubjectNameStrategy
	 - Importance: LOW
	 - Required: false

ðŸ”˜ value.converter.schemas.enable

Include schemas within each of the serialized values. Input messages must contain `schema` and `payload` fields and may not contain additional fields. For plain JSON data, set this to `false`. Applicable for JSON Converter.

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: LOW
	 - Required: false

ðŸ”˜ errors.tolerance

Use this property if you would like to configure the connector's error handling behavior. WARNING: This property should be used with CAUTION for SOURCE CONNECTORS as it may lead to dataloss. If you set this property to 'all', the connector will not fail on errant records, but will instead log them (and send to DLQ for Sink Connectors) and continue processing. If you set this property to 'none', the connector task will fail on errant records.

	 - Type: STRING
	 - Default: all
	 - Importance: LOW
	 - Required: false

ðŸ”˜ value.converter.ignore.default.for.nullables

When set to true, this property ensures that the corresponding record in Kafka is NULL, instead of showing the default column value. Applicable for AVRO,PROTOBUF and JSON_SR Converters.

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: LOW
	 - Required: false

ðŸ”˜ value.converter.decimal.format

Specify the JSON/JSON_SR serialization format for Connect DECIMAL logical type values with two allowed literals:

	 - Type: STRING
	 - Default: BASE64
	 - Importance: LOW
	 - Required: false

ðŸ”˜ value.converter.connect.meta.data



	 - Type: false
	 - Default: BOOLEAN
	 - Importance: Allow the Connect converter to add its metadata to the output schema. Applicable for Avro Converters.
	 - Required: LOW

ðŸ”˜ value.converter.value.subject.name.strategy

Determines how to construct the subject name under which the value schema is registered with Schema Registry.

	 - Type: STRING
	 - Default: TopicNameStrategy
	 - Importance: LOW
	 - Required: false

ðŸ”˜ key.converter.key.subject.name.strategy

How to construct the subject name for key schema registration.

	 - Type: STRING
	 - Default: TopicNameStrategy
	 - Importance: LOW
	 - Required: false

==========================
Auto-restart policy
==========================
ðŸ”˜ auto.restart.on.user.error

Enable connector to automatically restart on user-actionable errors.

	 - Type: BOOLEAN
	 - Default: true
	 - Importance: MEDIUM
	 - Required: false

==========================
Egress allowlist
==========================
ðŸ”˜ connector.egress.whitelist



	 - Type: false
	 - Default: STRING
	 - Importance: List a comma-separated list of FQDNs, IPs, or CIDR ranges for secure, restricted network egress.
	 - Required: HIGH

