==========================
How should we connect to your data?
==========================
ðŸ”˜ connector.class



	 - Type: true
	 - Default: STRING
	 - Importance: 
	 - Required: HIGH

ðŸ”˜ name



	 - Type: true
	 - Default: STRING
	 - Importance: Sets a name for your connector.
	 - Required: HIGH

==========================
Kafka Cluster credentials
==========================
ðŸ”˜ kafka.auth.mode

Kafka Authentication mode. It can be one of KAFKA_API_KEY or SERVICE_ACCOUNT. It defaults to KAFKA_API_KEY mode.

	 - Type: STRING
	 - Default: KAFKA_API_KEY
	 - Importance: HIGH
	 - Required: false

ðŸ”˜ kafka.service.account.id



	 - Type: false
	 - Default: STRING
	 - Importance: The Service Account that will be used to generate the API keys to communicate with Kafka Cluster.
	 - Required: HIGH

ðŸ”˜ kafka.api.key



	 - Type: false
	 - Default: STRING
	 - Importance: Kafka API Key. Required when kafka.auth.mode==KAFKA_API_KEY.
	 - Required: HIGH

ðŸ”˜ kafka.api.secret



	 - Type: false
	 - Default: PASSWORD
	 - Importance: Secret associated with Kafka API key. Required when kafka.auth.mode==KAFKA_API_KEY.
	 - Required: HIGH

ðŸ”˜ datapreview.schemas.enable

This config key only applies to data preview requests and governs whether the data preview output has record schema with it.

	 - Type: STRING
	 - Default: false
	 - Importance: LOW
	 - Required: false

==========================
Which topic name pattern do you want to send data to?
==========================
ðŸ”˜ topic.name.pattern

The pattern to use for the topic name, where the ``${resourceName}`` literal will be replaced with each resource name.

	 - Type: STRING
	 - Default: ${resourceName}
	 - Importance: HIGH
	 - Required: false

==========================
Schema Config
==========================
ðŸ”˜ schema.context.name

Add a schema context name. A schema context represents an independent scope in Schema Registry. It is a separate sub-schema tied to topics in different Kafka clusters that share the same Schema Registry instance. If not used, the connector uses the default schema configured for Schema Registry in your Confluent Cloud environment.

	 - Type: STRING
	 - Default: default
	 - Importance: MEDIUM
	 - Required: false

==========================
How should we connect to GitHub?
==========================
ðŸ”˜ github.service.url



	 - Type: true
	 - Default: STRING
	 - Importance: GitHub API Root Endpoint. Ex: https://api.github.com
	 - Required: MEDIUM

ðŸ”˜ github.access.token



	 - Type: true
	 - Default: PASSWORD
	 - Importance: The supplied token will be used as the value of 'Authorization' header in HTTP requests.
	 - Required: HIGH

ðŸ”˜ github.repositories



	 - Type: true
	 - Default: LIST
	 - Importance: The GitHub repositories to read from in the form of owner/repo-name. Ex: apache/kafka, apache/superset
	 - Required: HIGH

ðŸ”˜ github.resources



	 - Type: true
	 - Default: LIST
	 - Importance: The resources that are to be extracted and written to Kafka.
	 - Required: HIGH

ðŸ”˜ github.since



	 - Type: false
	 - Default: STRING
	 - Importance: Records created or updated after this time will be processed by the connector. If left blank, the default time will be set to the time this connector is launched. Expected format is `yyyy-MM-dd'T'HH:mm:ssX` or `yyyy-MM-dd`
	 - Required: HIGH

==========================
Connection details
==========================
ðŸ”˜ max.batch.size

The maximum number of records that should be returned and written to Kafka at one time.

	 - Type: INT
	 - Default: 100
	 - Importance: LOW
	 - Required: false

ðŸ”˜ max.in.flight.requests

The maximum number of requests that may be in-flight at once.

	 - Type: INT
	 - Default: 10
	 - Importance: LOW
	 - Required: false

ðŸ”˜ max.poll.interval.ms

The time in milliseconds between requests to fetch changed or updated entities.

	 - Type: LONG
	 - Default: 3000
	 - Importance: LOW
	 - Required: false

ðŸ”˜ request.interval.ms

The time in milliseconds to wait before checking for updated records.

	 - Type: LONG
	 - Default: 15000
	 - Importance: LOW
	 - Required: false

ðŸ”˜ max.retries

The maximum number of times to retry on errors before failing the task.

	 - Type: INT
	 - Default: 10
	 - Importance: LOW
	 - Required: false

ðŸ”˜ retry.backoff.ms

The time in milliseconds to wait following an error before a retry attempt is made.

	 - Type: LONG
	 - Default: 3000
	 - Importance: LOW
	 - Required: false

==========================
Output messages
==========================
ðŸ”˜ output.data.format



	 - Type: true
	 - Default: STRING
	 - Importance: Sets the output Kafka record value format. Valid entries are AVRO, JSON_SR, PROTOBUF, or JSON. Note that you need to have Confluent Cloud Schema Registry configured if using a schema-based message format like AVRO, JSON_SR, and PROTOBUF
	 - Required: HIGH

==========================
Number of tasks for this connector
==========================
ðŸ”˜ tasks.max



	 - Type: true
	 - Default: INT
	 - Importance: Maximum number of tasks for the connector.
	 - Required: HIGH

==========================
Auto-restart policy
==========================
ðŸ”˜ auto.restart.on.user.error

Enable connector to automatically restart on user-actionable errors.

	 - Type: BOOLEAN
	 - Default: true
	 - Importance: MEDIUM
	 - Required: false

==========================
Additional Configs
==========================
ðŸ”˜ value.converter.decimal.format

Specify the JSON/JSON_SR serialization format for Connect DECIMAL logical type values with two allowed literals:

	 - Type: STRING
	 - Default: BASE64
	 - Importance: LOW
	 - Required: false

ðŸ”˜ value.converter.reference.subject.name.strategy

Set the subject reference name strategy for value. Valid entries are DefaultReferenceSubjectNameStrategy or QualifiedReferenceSubjectNameStrategy. Note that the subject reference name strategy can be selected only for PROTOBUF format with the default strategy being DefaultReferenceSubjectNameStrategy.

	 - Type: STRING
	 - Default: DefaultReferenceSubjectNameStrategy
	 - Importance: LOW
	 - Required: false

ðŸ”˜ value.converter.connect.meta.data



	 - Type: false
	 - Default: BOOLEAN
	 - Importance: Allow the Connect converter to add its metadata to the output schema. Applicable for Avro Converters.
	 - Required: LOW

ðŸ”˜ value.converter.value.subject.name.strategy

Determines how to construct the subject name under which the value schema is registered with Schema Registry.

	 - Type: STRING
	 - Default: TopicNameStrategy
	 - Importance: LOW
	 - Required: false

ðŸ”˜ key.converter.key.subject.name.strategy

How to construct the subject name for key schema registration.

	 - Type: STRING
	 - Default: TopicNameStrategy
	 - Importance: LOW
	 - Required: false

