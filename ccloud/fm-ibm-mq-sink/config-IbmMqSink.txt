==========================
How should we connect to your data?
==========================
ðŸ”˜ connector.class



	 - Type: true
	 - Default: STRING
	 - Importance: 
	 - Required: HIGH

ðŸ”˜ name



	 - Type: true
	 - Default: STRING
	 - Importance: Sets a name for your connector.
	 - Required: HIGH

==========================
Which topics do you want to get data from?
==========================
ðŸ”˜ topics.regex



	 - Type: false
	 - Default: STRING
	 - Importance: A regular expression that matches the names of the topics to consume from. This is useful when you want to consume from multiple topics that match a certain pattern without having to list them all individually.
	 - Required: LOW

ðŸ”˜ topics



	 - Type: true
	 - Default: LIST
	 - Importance: Identifies the topic name or a comma-separated list of topic names.
	 - Required: HIGH

ðŸ”˜ errors.deadletterqueue.topic.name

The name of the topic to be used as the dead letter queue (DLQ) for messages that result in an error when processed by this sink connector, or its transformations or converters. Defaults to 'dlq-${connector}' if not set. The DLQ topic will be created automatically if it does not exist. You can provide ``${connector}`` in the value to use it as a placeholder for the logical cluster ID.

	 - Type: STRING
	 - Default: dlq-${connector}
	 - Importance: LOW
	 - Required: false

==========================
Schema Config
==========================
ðŸ”˜ schema.context.name

Add a schema context name. A schema context represents an independent scope in Schema Registry. It is a separate sub-schema tied to topics in different Kafka clusters that share the same Schema Registry instance. If not used, the connector uses the default schema configured for Schema Registry in your Confluent Cloud environment.

	 - Type: STRING
	 - Default: default
	 - Importance: MEDIUM
	 - Required: false

==========================
CSFLE
==========================
ðŸ”˜ csfle.enabled

Determines whether the connector honours CSFLE rules or not

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: HIGH
	 - Required: false

ðŸ”˜ sr.service.account.id



	 - Type: false
	 - Default: STRING
	 - Importance: Select the service account that has appropriate permissions to schemas and encryption keys in the Schema Registry.
	 - Required: HIGH

ðŸ”˜ csfle.onFailure

Configures the behavior for decryption failures. If set to ERROR, the connector will behave as configured for error behaviour. If set to NONE, the connector will ignore the decryption failure and proceed to write the data in its encrypted form.

	 - Type: STRING
	 - Default: ERROR
	 - Importance: MEDIUM
	 - Required: false

==========================
Input messages
==========================
ðŸ”˜ input.data.format

Sets the input Kafka record value format. Valid entries are AVRO, JSON_SR, PROTOBUF, JSON, BYTES or STRING. Note that you need to have Confluent Cloud Schema Registry configured if using a schema-based message format like AVRO, JSON_SR, and PROTOBUF.

	 - Type: STRING
	 - Default: JSON
	 - Importance: HIGH
	 - Required: true

==========================
Kafka Cluster credentials
==========================
ðŸ”˜ kafka.auth.mode

Kafka Authentication mode. It can be one of KAFKA_API_KEY or SERVICE_ACCOUNT. It defaults to KAFKA_API_KEY mode, whenever possible.

	 - Type: STRING
	 - Default: ${connect.regional.connector}
	 - Importance: HIGH
	 - Required: false

ðŸ”˜ kafka.service.account.id



	 - Type: false
	 - Default: STRING
	 - Importance: The Service Account that will be used to generate the API keys to communicate with Kafka Cluster.
	 - Required: HIGH

ðŸ”˜ kafka.api.key



	 - Type: false
	 - Default: STRING
	 - Importance: Kafka API Key. Required when kafka.auth.mode==KAFKA_API_KEY.
	 - Required: HIGH

ðŸ”˜ kafka.api.secret



	 - Type: false
	 - Default: PASSWORD
	 - Importance: Secret associated with Kafka API key. Required when kafka.auth.mode==KAFKA_API_KEY.
	 - Required: HIGH

==========================
IBM MQ Connection
==========================
ðŸ”˜ mq.username



	 - Type: true
	 - Default: STRING
	 - Importance: The username to use when connecting to IBM MQ.
	 - Required: HIGH

ðŸ”˜ mq.password



	 - Type: false
	 - Default: PASSWORD
	 - Importance: The password to use when connecting to IBM MQ.
	 - Required: HIGH

ðŸ”˜ mq.hostname



	 - Type: true
	 - Default: STRING
	 - Importance: IBM MQ broker host
	 - Required: HIGH

ðŸ”˜ mq.port

IBM MQ broker port

	 - Type: INT
	 - Default: 1414
	 - Importance: HIGH
	 - Required: false

ðŸ”˜ mq.queue.manager



	 - Type: true
	 - Default: STRING
	 - Importance: The name of the queue manager.
	 - Required: HIGH

ðŸ”˜ mq.channel



	 - Type: true
	 - Default: STRING
	 - Importance: The channel for client connections.
	 - Required: HIGH

ðŸ”˜ jms.destination.name



	 - Type: true
	 - Default: STRING
	 - Importance: The name of the JMS destination that messages are written to.
	 - Required: HIGH

ðŸ”˜ jms.destination.type

The type of JMS destination.

	 - Type: STRING
	 - Default: queue
	 - Importance: HIGH
	 - Required: false

==========================
IBM MQ Secure Connection
==========================
ðŸ”˜ mq.ssl.cipher.suite



	 - Type: false
	 - Default: STRING
	 - Importance: The CipherSuite for SSL connections.
	 - Required: HIGH

ðŸ”˜ mq.ssl.fips.required



	 - Type: false
	 - Default: BOOLEAN
	 - Importance: Whether SSL FIPS is required.
	 - Required: HIGH

ðŸ”˜ mq.ssl.peer.name



	 - Type: false
	 - Default: STRING
	 - Importance: Sets a distinguished name (DN) pattern. If sslCipherSuite is set, this pattern can ensure that the correct queue manager is used. The connection attempt fails if the distinguished name provided by the queue manager does not match this pattern.
	 - Required: HIGH

ðŸ”˜ mq.tls.protocol

The TLS protocol version for secure connections to IBM MQ.

	 - Type: STRING
	 - Default: TLSv1.2
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ mq.tls.keystore.type

The file format of the key store file. This is required only when using secure TLS communication with IBM MQ.

	 - Type: STRING
	 - Default: JKS
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ mq.tls.keystore.location



	 - Type: false
	 - Default: PASSWORD
	 - Importance: The key store file. This is required only when using secure TLS communication with IBM MQ.
	 - Required: HIGH

ðŸ”˜ mq.tls.keystore.password



	 - Type: false
	 - Default: PASSWORD
	 - Importance: The store password for the key store file. This is optional for client and only needed if ``TLS Keystore file`` is configured.
	 - Required: HIGH

ðŸ”˜ mq.tls.key.password



	 - Type: false
	 - Default: PASSWORD
	 - Importance: The password of the private key used for secure TLS communication with IBM MQ.
	 - Required: HIGH

ðŸ”˜ mq.tls.truststore.type

The file format of the trust store file. This is required when using TLS and secure communication with IBM MQ.

	 - Type: STRING
	 - Default: JKS
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ mq.tls.truststore.location



	 - Type: false
	 - Default: PASSWORD
	 - Importance: The trust store file. This is required only when using secure TLS communication with IBM MQ.
	 - Required: HIGH

ðŸ”˜ mq.tls.truststore.password



	 - Type: false
	 - Default: PASSWORD
	 - Importance: The password for the trust store file.
	 - Required: HIGH

ðŸ”˜ mq.tls.keymanager.algorithm

The algorithm used by key manager factory for SSL connections. This is required only when using secure TLS communication with IBM MQ.

	 - Type: STRING
	 - Default: SunX509
	 - Importance: LOW
	 - Required: false

ðŸ”˜ mq.tls.trustmanager.algorithm

The algorithm used by trust manager factory for SSL connections. This is required only when using secure TLS communication with IBM MQ.

	 - Type: STRING
	 - Default: PKIX
	 - Importance: LOW
	 - Required: false

ðŸ”˜ mq.tls.secure.random.implementation



	 - Type: false
	 - Default: STRING
	 - Importance: The SecureRandom PRNG implementation to use for SSL cryptography operations.
	 - Required: LOW

==========================
JMS details
==========================
ðŸ”˜ jms.forward.kafka.key

Convert the Kafka record key to a string and forward it on the JMS Message property JMSCorrelationID.

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: LOW
	 - Required: false

ðŸ”˜ jms.forward.kafka.metadata

Forward the Kafka record metadata on the JMS Message properties. This includes the record topic, partition, and offset.

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: LOW
	 - Required: false

ðŸ”˜ jms.forward.kafka.headers

Add the Kafka record headers to the JMS Message as string properties.

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: LOW
	 - Required: false

ðŸ”˜ jms.connection.max.retries

Connecting to a JMS broker may fail for multiple reasons. This determines the maximum number of times a task attempts to connect to the JMS broker.

	 - Type: INT
	 - Default: 5
	 - Importance: MEDIUM
	 - Required: false

ðŸ”˜ jms.connection.backoff.ms

Following a connection failure, this configuration parameter is the amount of time in milliseconds to wait before attempting to reconnect to the JMS broker.

	 - Type: LONG
	 - Default: 2000
	 - Importance: MEDIUM
	 - Required: false

==========================
Exactly-once delivery
==========================
ðŸ”˜ exactly.once.enabled

When enabled, uses transacted JMS sessions and stores Kafka offsets in IBM MQ to provide exactly-once delivery semantics. Requires mq.offsets.queue.name to be configured.

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: HIGH
	 - Required: false

ðŸ”˜ mq.offsets.queue.name



	 - Type: false
	 - Default: STRING
	 - Importance: The name of the IBM MQ queue used to store Kafka offsets for exactly-once delivery. Required when exactly.once.enabled is set to true.
	 - Required: HIGH

==========================
JMS formatter
==========================
ðŸ”˜ jms.message.format

The format of JMS message values.

	 - Type: STRING
	 - Default: string
	 - Importance: HIGH
	 - Required: false

ðŸ”˜ character.encoding

The character encoding to use while writing the message.

	 - Type: STRING
	 - Default: UTF-8
	 - Importance: LOW
	 - Required: false

ðŸ”˜ jms.message.format.schemas.enable

Include schemas within each of the serialized values and keys.

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: MEDIUM
	 - Required: false

==========================
JMS MessageProducer
==========================
ðŸ”˜ jms.producer.time.to.live.ms

Time to live (TTL) in milliseconds for messages sent to the JMS broker.

	 - Type: LONG
	 - Default: 0
	 - Importance: LOW
	 - Required: false

ðŸ”˜ jms.producer.delivery.mode

The ``PERSISTENT`` delivery mode (the default) instructs the JMS provider to take extra care to ensure that a message is not lost in transit in case of a JMS provider failure. The ``NON_PERSISTENT`` delivery mode does not require the JMS provider to store the message or otherwise guarantee that it is not lost if the provider fails.

	 - Type: STRING
	 - Default: persistent
	 - Importance: LOW
	 - Required: false

ðŸ”˜ jms.producer.disable.message.timestamp

Sets whether message timestamps are disabled in IBM MQ.

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: LOW
	 - Required: false

ðŸ”˜ mq.destination.suppress.rfh2

Whether to suppress or allow the inclusion of RFH2 Header. When set to true, IBM MQ uses native MQ message format instead of JMS/RFH2 format. Note: If ``jms.forward.kafka.headers`` is set to true while this property is enabled, all Kafka header names must be valid Java identifiers and it cannot contain dots or special characters. For example, a header with name ``task.generation`` will cause failures as they are not valid Java identifiers per the JMS specification.

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: LOW
	 - Required: false

==========================
Consumer configuration
==========================
ðŸ”˜ max.poll.interval.ms

The maximum delay between subsequent consume requests to Kafka. This configuration property may be used to improve the performance of the connector, if the connector cannot send records to the sink system. Defaults to 300000 milliseconds (5 minutes).

	 - Type: LONG
	 - Default: 300000
	 - Importance: LOW
	 - Required: false

ðŸ”˜ max.poll.records

The maximum number of records to consume from Kafka in a single request. This configuration property may be used to improve the performance of the connector, if the connector cannot send records to the sink system. Defaults to 500 records.

	 - Type: LONG
	 - Default: 500
	 - Importance: LOW
	 - Required: false

==========================
Number of tasks for this connector
==========================
ðŸ”˜ tasks.max



	 - Type: true
	 - Default: INT
	 - Importance: Maximum number of tasks for the connector.
	 - Required: HIGH

==========================
Additional Configs
==========================
ðŸ”˜ value.converter.replace.null.with.default

Whether to replace fields that have a default value and that are null to the default value. When set to true, the default value is used, otherwise null is used. Applicable for JSON Converter.

	 - Type: BOOLEAN
	 - Default: true
	 - Importance: LOW
	 - Required: false

ðŸ”˜ value.converter.reference.subject.name.strategy

Set the subject reference name strategy for value. Valid entries are DefaultReferenceSubjectNameStrategy or QualifiedReferenceSubjectNameStrategy. Note that the subject reference name strategy can be selected only for PROTOBUF format with the default strategy being DefaultReferenceSubjectNameStrategy.

	 - Type: STRING
	 - Default: DefaultReferenceSubjectNameStrategy
	 - Importance: LOW
	 - Required: false

ðŸ”˜ value.converter.schemas.enable

Include schemas within each of the serialized values. Input messages must contain `schema` and `payload` fields and may not contain additional fields. For plain JSON data, set this to `false`. Applicable for JSON Converter.

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: LOW
	 - Required: false

ðŸ”˜ errors.tolerance

Use this property if you would like to configure the connector's error handling behavior. WARNING: This property should be used with CAUTION for SOURCE CONNECTORS as it may lead to dataloss. If you set this property to 'all', the connector will not fail on errant records, but will instead log them (and send to DLQ for Sink Connectors) and continue processing. If you set this property to 'none', the connector task will fail on errant records.

	 - Type: STRING
	 - Default: all
	 - Importance: LOW
	 - Required: false

ðŸ”˜ value.converter.ignore.default.for.nullables

When set to true, this property ensures that the corresponding record in Kafka is NULL, instead of showing the default column value. Applicable for AVRO,PROTOBUF and JSON_SR Converters.

	 - Type: BOOLEAN
	 - Default: false
	 - Importance: LOW
	 - Required: false

ðŸ”˜ value.converter.decimal.format

Specify the JSON/JSON_SR serialization format for Connect DECIMAL logical type values with two allowed literals:

	 - Type: STRING
	 - Default: BASE64
	 - Importance: LOW
	 - Required: false

ðŸ”˜ value.converter.connect.meta.data



	 - Type: false
	 - Default: BOOLEAN
	 - Importance: Allow the Connect converter to add its metadata to the output schema. Applicable for Avro Converters.
	 - Required: LOW

ðŸ”˜ value.converter.value.subject.name.strategy

Determines how to construct the subject name under which the value schema is registered with Schema Registry.

	 - Type: STRING
	 - Default: TopicNameStrategy
	 - Importance: LOW
	 - Required: false

ðŸ”˜ key.converter.key.subject.name.strategy

How to construct the subject name for key schema registration.

	 - Type: STRING
	 - Default: TopicNameStrategy
	 - Importance: LOW
	 - Required: false

==========================
Auto-restart policy
==========================
ðŸ”˜ auto.restart.on.user.error

Enable connector to automatically restart on user-actionable errors.

	 - Type: BOOLEAN
	 - Default: true
	 - Importance: MEDIUM
	 - Required: false

==========================
Egress allowlist
==========================
ðŸ”˜ connector.egress.whitelist



	 - Type: false
	 - Default: STRING
	 - Importance: List a comma-separated list of FQDNs, IPs, or CIDR ranges for secure, restricted network egress.
	 - Required: HIGH

