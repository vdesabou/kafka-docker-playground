---
services:

  zookeeper:
    image: ${CP_ZOOKEEPER_IMAGE}:${CP_ZOOKEEPER_TAG}
    hostname: zookeeper
    container_name: zookeeper
    restart: always
    profiles:
    - zookeeper
    volumes:
      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/
    ports:
      - "9999:9999"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      KAFKA_JMX_PORT: 9999
      EXTRA_ARGS: ${GRAFANA_AGENT_ZK}
      KAFKA_JMX_HOSTNAME: localhost
      # for 5.4.x:
      KAFKA_OPTS: -Dzookeeper.4lw.commands.whitelist=*
      PYROSCOPE_APPLICATION_NAME: "zookeeper"
      PYROSCOPE_SERVER_ADDRESS: "http://pyroscope:4040"
  broker:
    image: ${CP_KAFKA_IMAGE}:${CP_KAFKA_TAG}
    hostname: broker
    container_name: broker
    restart: always
    ports:
      - "9092:9092"
      - "29092:29092"
      - "10000:10000"
    environment:
      KAFKA_JMX_PORT: 10000
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: BROKER:PLAINTEXT,HOST:PLAINTEXT
      KAFKA_LISTENERS: BROKER://:9092,HOST://:29092
      KAFKA_ADVERTISED_LISTENERS: BROKER://broker:9092,HOST://localhost:29092
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
      # Confluent Metrics Reporter for Control Center Cluster Monitoring
      KAFKA_METRIC_REPORTERS: $KAFKA_METRIC_REPORTERS
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker:9092
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: 'true'
      # for 5.4.x:
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      # for 6.0.0
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_CLUSTER_LINK_METADATA_TOPIC_REPLICATION_FACTOR: 1
      # # For Confluent Telemetry Reporter (proactive support)
      # KAFKA_CONFLUENT_TELEMETRY_ENABLED: 'true'
      # KAFKA_CONFLUENT_TELEMETRY_API_KEY: 'CLOUD_API_KEY'
      # KAFKA_CONFLUENT_TELEMETRY_API_SECRET: 'CLOUD_API_SECRET'
      EXTRA_ARGS: ${GRAFANA_AGENT_BROKER}
      PYROSCOPE_APPLICATION_NAME: "broker"
      PYROSCOPE_SERVER_ADDRESS: "http://pyroscope:4040"

      # Control Center 2.0
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_TYPE: "http"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_ENABLED: "true"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_METRICS_INCLUDE: "io.confluent.kafka.server.request.(?!.*delta).*|io.confluent.kafka.server.server.broker.state|io.confluent.kafka.server.replica.manager.leader.count|io.confluent.kafka.server.request.queue.size|io.confluent.kafka.server.broker.topic.failed.produce.requests.rate.1.min|io.confluent.kafka.server.tier.archiver.total.lag|io.confluent.kafka.server.request.total.time.ms.p99|io.confluent.kafka.server.broker.topic.failed.fetch.requests.rate.1.min|io.confluent.kafka.server.broker.topic.total.fetch.requests.rate.1.min|io.confluent.kafka.server.partition.caught.up.replicas.count|io.confluent.kafka.server.partition.observer.replicas.count|io.confluent.kafka.server.tier.tasks.num.partitions.in.error|io.confluent.kafka.server.broker.topic.bytes.out.rate.1.min|io.confluent.kafka.server.request.total.time.ms.p95|io.confluent.kafka.server.controller.active.controller.count|io.confluent.kafka.server.session.expire.listener.zookeeper.disconnects.total|io.confluent.kafka.server.request.total.time.ms.p999|io.confluent.kafka.server.controller.active.broker.count|io.confluent.kafka.server.request.handler.pool.request.handler.avg.idle.percent.rate.1.min|io.confluent.kafka.server.session.expire.listener.zookeeper.disconnects.rate.1.min|io.confluent.kafka.server.controller.unclean.leader.elections.rate.1.min|io.confluent.kafka.server.replica.manager.partition.count|io.confluent.kafka.server.controller.unclean.leader.elections.total|io.confluent.kafka.server.partition.replicas.count|io.confluent.kafka.server.broker.topic.total.produce.requests.rate.1.min|io.confluent.kafka.server.controller.offline.partitions.count|io.confluent.kafka.server.socket.server.network.processor.avg.idle.percent|io.confluent.kafka.server.partition.under.replicated|io.confluent.kafka.server.log.log.start.offset|io.confluent.kafka.server.log.tier.size|io.confluent.kafka.server.log.size|io.confluent.kafka.server.tier.fetcher.bytes.fetched.total|io.confluent.kafka.server.request.total.time.ms.p50|io.confluent.kafka.server.tenant.consumer.lag.offsets|io.confluent.kafka.server.session.expire.listener.zookeeper.expires.rate.1.min|io.confluent.kafka.server.log.log.end.offset|io.confluent.kafka.server.broker.topic.bytes.in.rate.1.min|io.confluent.kafka.server.partition.under.min.isr|io.confluent.kafka.server.partition.in.sync.replicas.count|io.confluent.telemetry.http.exporter.batches.dropped|io.confluent.telemetry.http.exporter.items.total|io.confluent.telemetry.http.exporter.items.succeeded|io.confluent.telemetry.http.exporter.send.time.total.millis|io.confluent.kafka.server.controller.leader.election.rate.(?!.*delta).*|io.confluent.telemetry.http.exporter.batches.failed"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_CLIENT_BASE_URL: "http://prometheus-c3-v2:9090/api/v1/otlp"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_CLIENT_COMPRESSION: "gzip"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_API_KEY: "dummy"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_API_SECRET: "dummy"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_BUFFER_PENDING_BATCHES_MAX: "80"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_BUFFER_BATCH_ITEMS_MAX: "4000"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_BUFFER_INFLIGHT_SUBMISSIONS_MAX: "10"
      KAFKA_CONFLUENT_TELEMETRY_METRICS_COLLECTOR_INTERVAL_MS: "60000"
      KAFKA_CONFLUENT_TELEMETRY_REMOTECONFIG_CONFLUENT_ENABLED: "false"
      KAFKA_CONFLUENT_CONSUMER_LAG_EMITTER_ENABLED: "true"
      # https://support.confluent.io/hc/en-us/articles/38120641503380--Action-required-Confluent-Platform-7-9-x-Important-Note-on-Group-Coordinator-in-Confluent-Platform-7-9-x
      KAFKA_GROUP_COORDINATOR_NEW_ENABLE: "false"
    volumes:
      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/

  broker2:
    image: ${CP_KAFKA_IMAGE}:${CP_KAFKA_TAG}
    hostname: broker2
    container_name: broker2
    restart: always
    profiles:
      - "kafka_nodes"
    ports:
      - "29292:29292"
      - "12000:12000"
    environment:
      KAFKA_JMX_PORT: 12000
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: BROKER:PLAINTEXT,HOST:PLAINTEXT
      KAFKA_LISTENERS: BROKER://:9092,HOST://:29292
      KAFKA_ADVERTISED_LISTENERS: BROKER://broker2:9092,HOST://localhost:29292
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
      # Confluent Metrics Reporter for Control Center Cluster Monitoring
      KAFKA_METRIC_REPORTERS: $KAFKA_METRIC_REPORTERS
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker2:9092
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: 'true'
      # for 5.4.x:
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      # for 6.0.0
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_CLUSTER_LINK_METADATA_TOPIC_REPLICATION_FACTOR: 1
      # # For Confluent Telemetry Reporter (proactive support)
      # KAFKA_CONFLUENT_TELEMETRY_ENABLED: 'true'
      # KAFKA_CONFLUENT_TELEMETRY_API_KEY: 'CLOUD_API_KEY'
      # KAFKA_CONFLUENT_TELEMETRY_API_SECRET: 'CLOUD_API_SECRET'
      EXTRA_ARGS: ${GRAFANA_AGENT_BROKER}
      PYROSCOPE_APPLICATION_NAME: "broker2"
      PYROSCOPE_SERVER_ADDRESS: "http://pyroscope:4040"

      # Control Center 2.0
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_TYPE: "http"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_ENABLED: "true"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_METRICS_INCLUDE: "io.confluent.kafka.server.request.(?!.*delta).*|io.confluent.kafka.server.server.broker.state|io.confluent.kafka.server.replica.manager.leader.count|io.confluent.kafka.server.request.queue.size|io.confluent.kafka.server.broker.topic.failed.produce.requests.rate.1.min|io.confluent.kafka.server.tier.archiver.total.lag|io.confluent.kafka.server.request.total.time.ms.p99|io.confluent.kafka.server.broker.topic.failed.fetch.requests.rate.1.min|io.confluent.kafka.server.broker.topic.total.fetch.requests.rate.1.min|io.confluent.kafka.server.partition.caught.up.replicas.count|io.confluent.kafka.server.partition.observer.replicas.count|io.confluent.kafka.server.tier.tasks.num.partitions.in.error|io.confluent.kafka.server.broker.topic.bytes.out.rate.1.min|io.confluent.kafka.server.request.total.time.ms.p95|io.confluent.kafka.server.controller.active.controller.count|io.confluent.kafka.server.session.expire.listener.zookeeper.disconnects.total|io.confluent.kafka.server.request.total.time.ms.p999|io.confluent.kafka.server.controller.active.broker.count|io.confluent.kafka.server.request.handler.pool.request.handler.avg.idle.percent.rate.1.min|io.confluent.kafka.server.session.expire.listener.zookeeper.disconnects.rate.1.min|io.confluent.kafka.server.controller.unclean.leader.elections.rate.1.min|io.confluent.kafka.server.replica.manager.partition.count|io.confluent.kafka.server.controller.unclean.leader.elections.total|io.confluent.kafka.server.partition.replicas.count|io.confluent.kafka.server.broker.topic.total.produce.requests.rate.1.min|io.confluent.kafka.server.controller.offline.partitions.count|io.confluent.kafka.server.socket.server.network.processor.avg.idle.percent|io.confluent.kafka.server.partition.under.replicated|io.confluent.kafka.server.log.log.start.offset|io.confluent.kafka.server.log.tier.size|io.confluent.kafka.server.log.size|io.confluent.kafka.server.tier.fetcher.bytes.fetched.total|io.confluent.kafka.server.request.total.time.ms.p50|io.confluent.kafka.server.tenant.consumer.lag.offsets|io.confluent.kafka.server.session.expire.listener.zookeeper.expires.rate.1.min|io.confluent.kafka.server.log.log.end.offset|io.confluent.kafka.server.broker.topic.bytes.in.rate.1.min|io.confluent.kafka.server.partition.under.min.isr|io.confluent.kafka.server.partition.in.sync.replicas.count|io.confluent.telemetry.http.exporter.batches.dropped|io.confluent.telemetry.http.exporter.items.total|io.confluent.telemetry.http.exporter.items.succeeded|io.confluent.telemetry.http.exporter.send.time.total.millis|io.confluent.kafka.server.controller.leader.election.rate.(?!.*delta).*|io.confluent.telemetry.http.exporter.batches.failed"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_CLIENT_BASE_URL: "http://prometheus-c3-v2:9090/api/v1/otlp"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_CLIENT_COMPRESSION: "gzip"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_API_KEY: "dummy"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_API_SECRET: "dummy"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_BUFFER_PENDING_BATCHES_MAX: "80"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_BUFFER_BATCH_ITEMS_MAX: "4000"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_BUFFER_INFLIGHT_SUBMISSIONS_MAX: "10"
      KAFKA_CONFLUENT_TELEMETRY_METRICS_COLLECTOR_INTERVAL_MS: "60000"
      KAFKA_CONFLUENT_TELEMETRY_REMOTECONFIG_CONFLUENT_ENABLED: "false"
      KAFKA_CONFLUENT_CONSUMER_LAG_EMITTER_ENABLED: "true"
      # https://support.confluent.io/hc/en-us/articles/38120641503380--Action-required-Confluent-Platform-7-9-x-Important-Note-on-Group-Coordinator-in-Confluent-Platform-7-9-x
      KAFKA_GROUP_COORDINATOR_NEW_ENABLE: "false"
    volumes:
      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/

  broker3:
    image: ${CP_KAFKA_IMAGE}:${CP_KAFKA_TAG}
    hostname: broker3
    container_name: broker3
    restart: always
    profiles:
      - "kafka_nodes"
    ports:
      - "29392:29392"
      - "13000:13000"
    environment:
      KAFKA_JMX_PORT: 13000
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: BROKER:PLAINTEXT,HOST:PLAINTEXT
      KAFKA_LISTENERS: BROKER://:9092,HOST://:29392
      KAFKA_ADVERTISED_LISTENERS: BROKER://broker3:9092,HOST://localhost:29392
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
      # Confluent Metrics Reporter for Control Center Cluster Monitoring
      KAFKA_METRIC_REPORTERS: $KAFKA_METRIC_REPORTERS
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker3:9092
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: 'true'
      # for 5.4.x:
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      # for 6.0.0
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_CLUSTER_LINK_METADATA_TOPIC_REPLICATION_FACTOR: 1
      # # For Confluent Telemetry Reporter (proactive support)
      # KAFKA_CONFLUENT_TELEMETRY_ENABLED: 'true'
      # KAFKA_CONFLUENT_TELEMETRY_API_KEY: 'CLOUD_API_KEY'
      # KAFKA_CONFLUENT_TELEMETRY_API_SECRET: 'CLOUD_API_SECRET'
      EXTRA_ARGS: ${GRAFANA_AGENT_BROKER}
      PYROSCOPE_APPLICATION_NAME: "broker3"
      PYROSCOPE_SERVER_ADDRESS: "http://pyroscope:4040"

      # Control Center 2.0
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_TYPE: "http"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_ENABLED: "true"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_METRICS_INCLUDE: "io.confluent.kafka.server.request.(?!.*delta).*|io.confluent.kafka.server.server.broker.state|io.confluent.kafka.server.replica.manager.leader.count|io.confluent.kafka.server.request.queue.size|io.confluent.kafka.server.broker.topic.failed.produce.requests.rate.1.min|io.confluent.kafka.server.tier.archiver.total.lag|io.confluent.kafka.server.request.total.time.ms.p99|io.confluent.kafka.server.broker.topic.failed.fetch.requests.rate.1.min|io.confluent.kafka.server.broker.topic.total.fetch.requests.rate.1.min|io.confluent.kafka.server.partition.caught.up.replicas.count|io.confluent.kafka.server.partition.observer.replicas.count|io.confluent.kafka.server.tier.tasks.num.partitions.in.error|io.confluent.kafka.server.broker.topic.bytes.out.rate.1.min|io.confluent.kafka.server.request.total.time.ms.p95|io.confluent.kafka.server.controller.active.controller.count|io.confluent.kafka.server.session.expire.listener.zookeeper.disconnects.total|io.confluent.kafka.server.request.total.time.ms.p999|io.confluent.kafka.server.controller.active.broker.count|io.confluent.kafka.server.request.handler.pool.request.handler.avg.idle.percent.rate.1.min|io.confluent.kafka.server.session.expire.listener.zookeeper.disconnects.rate.1.min|io.confluent.kafka.server.controller.unclean.leader.elections.rate.1.min|io.confluent.kafka.server.replica.manager.partition.count|io.confluent.kafka.server.controller.unclean.leader.elections.total|io.confluent.kafka.server.partition.replicas.count|io.confluent.kafka.server.broker.topic.total.produce.requests.rate.1.min|io.confluent.kafka.server.controller.offline.partitions.count|io.confluent.kafka.server.socket.server.network.processor.avg.idle.percent|io.confluent.kafka.server.partition.under.replicated|io.confluent.kafka.server.log.log.start.offset|io.confluent.kafka.server.log.tier.size|io.confluent.kafka.server.log.size|io.confluent.kafka.server.tier.fetcher.bytes.fetched.total|io.confluent.kafka.server.request.total.time.ms.p50|io.confluent.kafka.server.tenant.consumer.lag.offsets|io.confluent.kafka.server.session.expire.listener.zookeeper.expires.rate.1.min|io.confluent.kafka.server.log.log.end.offset|io.confluent.kafka.server.broker.topic.bytes.in.rate.1.min|io.confluent.kafka.server.partition.under.min.isr|io.confluent.kafka.server.partition.in.sync.replicas.count|io.confluent.telemetry.http.exporter.batches.dropped|io.confluent.telemetry.http.exporter.items.total|io.confluent.telemetry.http.exporter.items.succeeded|io.confluent.telemetry.http.exporter.send.time.total.millis|io.confluent.kafka.server.controller.leader.election.rate.(?!.*delta).*|io.confluent.telemetry.http.exporter.batches.failed"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_CLIENT_BASE_URL: "http://prometheus-c3-v2:9090/api/v1/otlp"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_CLIENT_COMPRESSION: "gzip"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_API_KEY: "dummy"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_API_SECRET: "dummy"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_BUFFER_PENDING_BATCHES_MAX: "80"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_BUFFER_BATCH_ITEMS_MAX: "4000"
      KAFKA_CONFLUENT_TELEMETRY_EXPORTER_C3PLUSPLUS_BUFFER_INFLIGHT_SUBMISSIONS_MAX: "10"
      KAFKA_CONFLUENT_TELEMETRY_METRICS_COLLECTOR_INTERVAL_MS: "60000"
      KAFKA_CONFLUENT_TELEMETRY_REMOTECONFIG_CONFLUENT_ENABLED: "false"
      KAFKA_CONFLUENT_CONSUMER_LAG_EMITTER_ENABLED: "true"
      # https://support.confluent.io/hc/en-us/articles/38120641503380--Action-required-Confluent-Platform-7-9-x-Important-Note-on-Group-Coordinator-in-Confluent-Platform-7-9-x
      KAFKA_GROUP_COORDINATOR_NEW_ENABLE: "false"
    volumes:
      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/



  schema-registry:
    image: ${CP_SCHEMA_REGISTRY_IMAGE}:${CP_SCHEMA_REGISTRY_TAG}
    hostname: schema-registry
    container_name: schema-registry
    restart: always
    depends_on:
      - broker
    ports:
      - "8081:8081"
      - "10001:10001"
    volumes:
      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/
    environment:
      SCHEMA_REGISTRY_JMX_PORT: 10001
      SCHEMA_REGISTRY_JMX_HOSTNAME: localhost
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: broker:9092
      # SCHEMA_REGISTRY_METRIC_REPORTERS: io.confluent.telemetry.reporter.TelemetryReporter
      # SCHEMA_REGISTRY_CONFLUENT_TELEMETRY_ENABLED: 'true'
      # SCHEMA_REGISTRY_CONFLUENT_TELEMETRY_API_KEY: 'CLOUD_API_KEY'
      # SCHEMA_REGISTRY_CONFLUENT_TELEMETRY_API_SECRET: 'CLOUD_API_SECRET'
      # https://github.com/confluentinc/schema-registry/issues/2213
      SCHEMA_REGISTRY_SCHEMA_PROVIDERS_AVRO_VALIDATE_DEFAULTS: "true"
      EXTRA_ARGS: ${GRAFANA_AGENT_SR}
      PYROSCOPE_APPLICATION_NAME: "schema-registry"
      PYROSCOPE_SERVER_ADDRESS: "http://pyroscope:4040"

  connect:
    image: ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG}
    hostname: connect
    container_name: connect
    restart: always
    depends_on:
      - broker
      - schema-registry
    ports:
      - "5005:5005"
      - "8083:8083"
      - "10002:10002"
    volumes:
      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/
      - ../../confluent-hub:/usr/share/confluent-hub-components
    environment:
      KAFKA_JMX_PORT: 10002
      KAFKA_JMX_HOSTNAME: localhost
      CONNECT_BOOTSTRAP_SERVERS: 'broker:9092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_GROUP_ID: "connect-cluster"
      CONNECT_PRODUCER_CLIENT_ID: "connect-worker-producer"
      CONNECT_CLIENT_ID: "connect-adminclient-producer"
      CONNECT_CONFIG_STORAGE_TOPIC: connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: connect-status
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      CONNECT_VALUE_CONVERTER: "io.confluent.connect.avro.AvroConverter"
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_PLUGIN_PATH: /usr/share/confluent-hub-components/confluentinc-kafka-connect-s3 # only load one connector to speed up deployment (it is overidden in connect tests)
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR,org.apache.kafka.connect.runtime.rest.RestServer=ERROR
      # Confluent Monitoring Interceptors for Control Center Streams Monitoring
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: $CONNECT_PRODUCER_INTERCEPTOR_CLASSES
      CONNECT_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_BOOTSTRAP_SERVERS: broker:9092
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: $CONNECT_CONSUMER_INTERCEPTOR_CLASSES
      CONNECT_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_BOOTSTRAP_SERVERS: broker:9092
      # Externalizing Secrets
      CONNECT_CONFIG_PROVIDERS: 'file'
      CONNECT_CONFIG_PROVIDERS_FILE_CLASS: 'org.apache.kafka.common.config.provider.FileConfigProvider'
      # CONNECT_LOG4J_ROOT_LOGLEVEL: DEBUG
      # KIP-158 https://cwiki.apache.org/confluence/display/KAFKA/KIP-158%3A+Kafka+Connect+should+allow+source+connectors+to+set+topic-specific+settings+for+new+topics (6.x only)
      CONNECT_TOPIC_CREATION_ENABLE: 'true'
      # CONNECT_METRIC_REPORTERS: io.confluent.telemetry.reporter.TelemetryReporter
      # CONNECT_CONFLUENT_TELEMETRY_ENABLED: 'true'
      # CONNECT_CONFLUENT_TELEMETRY_API_KEY: 'CLOUD_API_KEY'
      # CONNECT_CONFLUENT_TELEMETRY_API_SECRET: 'CLOUD_API_SECRET'
      CONNECT_CONNECTOR_CLIENT_CONFIG_OVERRIDE_POLICY: All
      CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
      # # https://kafka-docker-playground.io/#/reusables?id=✨-remote-debugging
      # KAFKA_DEBUG: 'true'
      # # With JDK9+, need to specify address=*:5005, see https://www.baeldung.com/java-application-remote-debugging#from-java9
      # JAVA_DEBUG_OPTS: '-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=0.0.0.0:5005'
      # uncomment when investigating class not found issue, see https://kafka-docker-playground.io/#/reusables?id=🔬-class-loading
      # KAFKA_OPTS: '-verbose:class'
      KAFKA_OPTS: -Ddynamic.worker.config.file=/dev/null
      # Reduce Connect memory utilization
      EXTRA_ARGS: ${GRAFANA_AGENT_CONNECT}
      # KAFKA_JVM_PERFORMANCE_OPTS: -server -XX:+UseG1GC -XX:GCTimeRatio=1
                  # -XX:MinHeapFreeRatio=10 -XX:MaxHeapFreeRatio=20
                  # -XX:MaxGCPauseMillis=10000 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent
                  # -XX:MaxInlineLevel=15 -Djava.awt.headless=true
      PYROSCOPE_APPLICATION_NAME: "connect"
      PYROSCOPE_SERVER_ADDRESS: "http://pyroscope:4040"
      # centralized license is needed with CP 8.1+
      # https://docs.confluent.io/operator/current/co-manage-connectors.html#authenticate-to-kconnect-cluster
      CONNECT_CONFLUENT_TOPIC_BOOTSTRAP_SERVERS: 'broker:9092'
      CONNECT_CONFLUENT_TOPIC_REPLICATION_FACTOR: "1"
      
  connect2:
    image: ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG}
    hostname: connect2
    container_name: connect2
    restart: always
    depends_on:
      - broker
      - schema-registry
    ports:
      - "5205:5005"
      - "8283:8283"
      - "10022:10022"
    profiles:
      - "connect_nodes"
    volumes:
      - ./jmx-exporter:/usr/share/jmx_exporter/
      - ../../confluent-hub:/usr/share/confluent-hub-components
    environment:
      KAFKA_JMX_PORT: 10022
      KAFKA_JMX_HOSTNAME: localhost
      CONNECT_LISTENERS: http://:8283
      CONNECT_BOOTSTRAP_SERVERS: 'broker:9092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect2
      CONNECT_GROUP_ID: "connect-cluster"
      CONNECT_PRODUCER_CLIENT_ID: "connect-worker-producer"
      CONNECT_CONFIG_STORAGE_TOPIC: connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: connect-status
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      CONNECT_VALUE_CONVERTER: "io.confluent.connect.avro.AvroConverter"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_PLUGIN_PATH: /usr/share/confluent-hub-components
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR,org.apache.kafka.connect.runtime.rest.RestServer=ERROR
      # Confluent Monitoring Interceptors for Control Center Streams Monitoring
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: $CONNECT_PRODUCER_INTERCEPTOR_CLASSES
      CONNECT_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_BOOTSTRAP_SERVERS: broker:9092
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: $CONNECT_CONSUMER_INTERCEPTOR_CLASSES
      CONNECT_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_BOOTSTRAP_SERVERS: broker:9092
      # Externalizing Secrets
      CONNECT_CONFIG_PROVIDERS: 'file'
      CONNECT_CONFIG_PROVIDERS_FILE_CLASS: 'org.apache.kafka.common.config.provider.FileConfigProvider'
      # CONNECT_LOG4J_ROOT_LOGLEVEL: DEBUG
      # KIP-158 https://cwiki.apache.org/confluence/display/KAFKA/KIP-158%3A+Kafka+Connect+should+allow+source+connectors+to+set+topic-specific+settings+for+new+topics (6.x only)
      CONNECT_TOPIC_CREATION_ENABLE: 'true'
      # CONNECT_METRIC_REPORTERS: io.confluent.telemetry.reporter.TelemetryReporter
      # CONNECT_CONFLUENT_TELEMETRY_ENABLED: 'true'
      # CONNECT_CONFLUENT_TELEMETRY_API_KEY: 'CLOUD_API_KEY'
      # CONNECT_CONFLUENT_TELEMETRY_API_SECRET: 'CLOUD_API_SECRET'
      CONNECT_CONNECTOR_CLIENT_CONFIG_OVERRIDE_POLICY: All
      CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
      # # https://kafka-docker-playground.io/#/reusables?id=✨-remote-debugging
      # KAFKA_DEBUG: 'true'
      # # With JDK9+, need to specify address=*:5005, see https://www.baeldung.com/java-application-remote-debugging#from-java9
      # JAVA_DEBUG_OPTS: '-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=0.0.0.0:5005'
      # uncomment when investigating class not found issue, see https://kafka-docker-playground.io/#/reusables?id=🔬-class-loading
      # KAFKA_OPTS: '-verbose:class'
      KAFKA_OPTS: -Ddynamic.worker.config.file=/dev/null
      # Reduce Connect memory utilization
      EXTRA_ARGS: ${GRAFANA_AGENT_CONNECT}
      # KAFKA_JVM_PERFORMANCE_OPTS: -server -XX:+UseG1GC -XX:GCTimeRatio=1
                  # -XX:MinHeapFreeRatio=10 -XX:MaxHeapFreeRatio=20
                  # -XX:MaxGCPauseMillis=10000 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent
                  # -XX:MaxInlineLevel=15 -Djava.awt.headless=true
      PYROSCOPE_APPLICATION_NAME: "connect2"
      PYROSCOPE_SERVER_ADDRESS: "http://pyroscope:4040"
      # centralized license is needed with CP 8.1+
      # https://docs.confluent.io/operator/current/co-manage-connectors.html#authenticate-to-kconnect-cluster
      CONNECT_CONFLUENT_TOPIC_BOOTSTRAP_SERVERS: 'broker:9092'
      CONNECT_CONFLUENT_TOPIC_REPLICATION_FACTOR: "1"

  connect3:
    image: ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG}
    hostname: connect3
    container_name: connect3
    restart: always
    depends_on:
      - broker
      - schema-registry
    ports:
      - "5305:5005"
      - "8383:8383"
      - "10032:10032"
    profiles:
      - "connect_nodes"
    volumes:
      - ./jmx-exporter:/usr/share/jmx_exporter/
      - ../../confluent-hub:/usr/share/confluent-hub-components
    environment:
      KAFKA_JMX_PORT: 10032
      KAFKA_JMX_HOSTNAME: localhost
      CONNECT_LISTENERS: http://:8383
      CONNECT_BOOTSTRAP_SERVERS: 'broker:9092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect3
      CONNECT_GROUP_ID: "connect-cluster"
      CONNECT_PRODUCER_CLIENT_ID: "connect-worker-producer"
      CONNECT_CONFIG_STORAGE_TOPIC: connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: connect-status
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      CONNECT_VALUE_CONVERTER: "io.confluent.connect.avro.AvroConverter"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_PLUGIN_PATH: /usr/share/confluent-hub-components # to avoid overwriting all docker-compose in each directory, we base this path from the source command being issued when the environment starts. See start.sh in plain
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR,org.apache.kafka.connect.runtime.rest.RestServer=ERROR
      # Confluent Monitoring Interceptors for Control Center Streams Monitoring
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: $CONNECT_PRODUCER_INTERCEPTOR_CLASSES
      CONNECT_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_BOOTSTRAP_SERVERS: broker:9092
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: $CONNECT_CONSUMER_INTERCEPTOR_CLASSES
      CONNECT_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_BOOTSTRAP_SERVERS: broker:9092
      # Externalizing Secrets
      CONNECT_CONFIG_PROVIDERS: 'file'
      CONNECT_CONFIG_PROVIDERS_FILE_CLASS: 'org.apache.kafka.common.config.provider.FileConfigProvider'
      # CONNECT_LOG4J_ROOT_LOGLEVEL: DEBUG
      # KIP-158 https://cwiki.apache.org/confluence/display/KAFKA/KIP-158%3A+Kafka+Connect+should+allow+source+connectors+to+set+topic-specific+settings+for+new+topics (6.x only)
      CONNECT_TOPIC_CREATION_ENABLE: 'true'
      # CONNECT_METRIC_REPORTERS: io.confluent.telemetry.reporter.TelemetryReporter
      # CONNECT_CONFLUENT_TELEMETRY_ENABLED: 'true'
      # CONNECT_CONFLUENT_TELEMETRY_API_KEY: 'CLOUD_API_KEY'
      # CONNECT_CONFLUENT_TELEMETRY_API_SECRET: 'CLOUD_API_SECRET'
      CONNECT_CONNECTOR_CLIENT_CONFIG_OVERRIDE_POLICY: All
      CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
      # # https://kafka-docker-playground.io/#/reusables?id=✨-remote-debugging
      # KAFKA_DEBUG: 'true'
      # # With JDK9+, need to specify address=*:5005, see https://www.baeldung.com/java-application-remote-debugging#from-java9
      # JAVA_DEBUG_OPTS: '-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=0.0.0.0:5005'
      # uncomment when investigating class not found issue, see https://kafka-docker-playground.io/#/reusables?id=🔬-class-loading
      # KAFKA_OPTS: '-verbose:class'
      KAFKA_OPTS: -Ddynamic.worker.config.file=/dev/null
      # Reduce Connect memory utilization
      EXTRA_ARGS: ${GRAFANA_AGENT_CONNECT}
      # KAFKA_JVM_PERFORMANCE_OPTS: -server -XX:+UseG1GC -XX:GCTimeRatio=1
                  # -XX:MinHeapFreeRatio=10 -XX:MaxHeapFreeRatio=20
                  # -XX:MaxGCPauseMillis=10000 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent
                  # -XX:MaxInlineLevel=15 -Djava.awt.headless=true
      PYROSCOPE_APPLICATION_NAME: "connect3"
      PYROSCOPE_SERVER_ADDRESS: "http://pyroscope:4040"
      # centralized license is needed with CP 8.1+
      # https://docs.confluent.io/operator/current/co-manage-connectors.html#authenticate-to-kconnect-cluster
      CONNECT_CONFLUENT_TOPIC_BOOTSTRAP_SERVERS: 'broker:9092'
      CONNECT_CONFLUENT_TOPIC_REPLICATION_FACTOR: "1"

  ksqldb-server:
    image: ${CP_KSQL_IMAGE}:${CP_KSQL_TAG}
    hostname: ksqldb-server
    container_name: ksqldb-server
    depends_on:
      - broker
      - connect
    ports:
      - "8088:8088"
      - "10003:10003"
    volumes:
      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/
    profiles:
    - ksqldb
    environment:
      KSQL_JMX_PORT: 10003
      KSQL_JMX_HOSTNAME: localhost
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_BOOTSTRAP_SERVERS: broker:9092
      KSQL_CACHE_MAX_BYTES_BUFFERING: 0
      KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      KSQL_KSQL_CONNECT_URL: "http://connect:8083"
      # KSQL_KSQL_STREAMS_PROCESSING_GUARANTEE=exactly_once
      # --- ksqlDB Server log config ---
      KSQL_LOG4J_ROOT_LOGLEVEL: "INFO"
      KSQL_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
      # --- ksqlDB processing log config ---
      # KSQL_LOG4J_PROCESSING_LOG_BROKERLIST: broker:9092
      # KSQL_LOG4J_PROCESSING_LOG_TOPIC: ksql_processing_log
      # KSQL_KSQL_LOGGING_PROCESSING_TOPIC_NAME: ksql_processing_log
      # KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
      # KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      # KSQL_KSQL_LOGGING_PROCESSING_ROWS_INCLUDE: 'true'
      # KSQL_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      # KSQL_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      # KSQL_METRIC_REPORTERS: io.confluent.telemetry.reporter.TelemetryReporter
      # KSQL_CONFLUENT_TELEMETRY_ENABLED: 'true'
      # KSQL_CONFLUENT_TELEMETRY_API_KEY: 'CLOUD_API_KEY'
      # KSQL_CONFLUENT_TELEMETRY_API_SECRET: 'CLOUD_API_SECRET'
      EXTRA_ARGS: ${GRAFANA_AGENT_KSQLDB}
      PYROSCOPE_APPLICATION_NAME: "ksqldb-server"
      PYROSCOPE_SERVER_ADDRESS: "http://pyroscope:4040"

  ksqldb-cli:
    image: ${CP_KSQL_CLI_IMAGE}:${CP_KSQL_CLI_TAG}
    container_name: ksqldb-cli
    depends_on:
      - broker
      - connect
      - ksqldb-server
    entrypoint: /bin/sh
    profiles:
    - ksqldb
    tty: true

  control-center:
    image: ${CP_CONTROL_CENTER_IMAGE}:${CP_CONTROL_CENTER_TAG}
    hostname: control-center
    container_name: control-center
    restart: always
    depends_on:
      - broker
      - schema-registry
      - connect
    ports:
      - "${C3_PORT:-9021}:9021"
    profiles:
    - control-center
    volumes:
      - ../../environment/plaintext/control-center-v2-config:/mnt/config

    # needed for c3 next gen
    command: "bash -c 'dub template /etc/confluent/docker/control-center.properties.template /etc/confluent-control-center/control-center.properties && \
                          /etc/confluent/docker/run'"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker:9092'
      CONTROL_CENTER_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      CONTROL_CENTER_CONNECT_CLUSTER: http://connect:8083 # deprecated
      CONTROL_CENTER_CONNECT_MYCONNECT_CLUSTER: http://connect:8083
      CONTROL_CENTER_KAFKA_BOOTSTRAP_SERVERS: 'broker:9092'
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      CONTROL_CENTER_KAFKA_MYCLUSTER_BOOTSTRAP_SERVERS: 'broker:9092'
      CONTROL_CENTER_UI_AUTOUPDATE_ENABLE: "false"
      CONTROL_CENTER_KSQL_URL: "http://ksqldb-server:8088" # deprecated
      CONTROL_CENTER_KSQL_ADVERTISED_URL: "http://127.0.0.1:8088" # deprecated
      CONTROL_CENTER_KSQL_MYKSQL_URL: "http://ksqldb-server:8088"
      CONTROL_CENTER_KSQL_MYKSQL_ADVERTISED_URL: "http://127.0.0.1:8088"
      CONTROL_CENTER_COMMAND_TOPIC_REPLICATION: 1
      CONTROL_CENTER_METRICS_TOPIC_REPLICATION: 1
      # METRIC_REPORTERS: io.confluent.telemetry.reporter.TelemetryReporter
      # CONFLUENT_TELEMETRY_ENABLED: 'true'
      # CONFLUENT_TELEMETRY_API_KEY: 'CLOUD_API_KEY'
      # CONFLUENT_TELEMETRY_API_SECRET: 'CLOUD_API_SECRET'
      # starting from 7.0
      #CONTROL_CENTER_MODE_ENABLE: management
      # CONTROL_CENTER_ID: 32

      # https://docs.confluent.io/control-center/2.0/installation/overview.html
      # https://github.com/confluentinc/cp-all-in-one/blob/f062fd7f11134a13c17634f58d592a436f56a11e/cp-all-in-one/docker-compose.yml
      CONTROL_CENTER_PROMETHEUS_ENABLE: true
      CONTROL_CENTER_PROMETHEUS_URL: http://prometheus-c3-v2:9090
      CONTROL_CENTER_PROMETHEUS_RULES_FILE: /mnt/config/trigger_rules-generated.yml
      CONTROL_CENTER_ALERTMANAGER_URL: http://alertmanager-c3-v2:9093
      CONTROL_CENTER_ALERTMANAGER_CONFIG_FILE: /mnt/config/alertmanager.yml

  prometheus-c3-v2:
    image: confluentinc/cp-enterprise-prometheus:2.0.0
    hostname: prometheus-c3-v2
    container_name: prometheus-c3-v2
    volumes:
      - ../../environment/plaintext/control-center-v2-config:/mnt/config
    command: "--config.file=/mnt/config/prometheus.yml --enable-feature=otlp-write-receiver --web.enable-lifecycle"

  alertmanager-c3-v2:
    image: confluentinc/cp-enterprise-alertmanager:2.0.0
    hostname: alertmanager-c3-v2
    container_name: alertmanager-c3-v2
    depends_on:
      - prometheus-c3-v2
    volumes:
      - ../../environment/plaintext/control-center-v2-config:/mnt/config
    command: "--web.external-url=http://localhost --config.file=/etc/alertmanager/alertmanager.yml"

  rest-proxy:
    image: ${CP_REST_PROXY_IMAGE}:${CP_REST_PROXY_TAG}
    hostname: rest-proxy
    container_name: rest-proxy
    restart: always
    depends_on:
      - broker
      - schema-registry
    ports:
      - "8082:8082"
    profiles:
    - rest-proxy
    environment:
      KAFKA_REST_HOST_NAME: rest-proxy
      KAFKA_REST_BOOTSTRAP_SERVERS: 'broker:9092'
      KAFKA_REST_LISTENERS: "http://0.0.0.0:8082"
      KAFKA_REST_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'

  kafka-lag-exporter:
    image: seglo/kafka-lag-exporter:0.7.1
    hostname: kafka-lag-exporter
    container_name: kafka-lag-exporter
    profiles:
      - "grafana"
    restart: always
    ports:
      - 9998:9998
    volumes:
      - ./kafka-lag-exporter/application.conf:/opt/docker/conf/application.conf
      - ./kafka-lag-exporter/logback.xml:/opt/docker/conf/logback.xml

  alertmanager:
    image: prom/alertmanager:latest
    hostname: alertmanager
    container_name: alertmanager
    profiles:
      - "grafana"
    ports:
      - 9093:9093

  node-exporter:
    image: prom/node-exporter:v1.2.2
    hostname: node-exporter
    container_name: node-exporter
    profiles:
      - "grafana"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - "--path.procfs=/host/proc"
      - "--path.sysfs=/host/sys"
      - "--collector.filesystem.ignored-mount-points"
      - "^(aufs|proc|nsfs|shm|cgroup|tmpfs|binfmt_misc|debugfs|devpts|fusectl|hugetlbfs|fuse.lxcfs|mqueue|pstore|securityfs|sysfs|autofs|devtmpfs|configfs)"

  prometheus:
    image: prom/prometheus:v2.29.2
    hostname: prometheus
    container_name: prometheus
    profiles:
      - "grafana"
    ports:
      - 9090:9090
    volumes:
      - ./prometheus/:/etc/prometheus/
    depends_on:
      - node-exporter
      - kafka-lag-exporter
      - alertmanager

  grafana:
    image: grafana/grafana:8.5.27
    hostname: grafana
    container_name: grafana
    profiles:
      - "grafana"
    environment:
      - "GF_SECURITY_ADMIN_USER=admin"
      - "GF_SECURITY_ADMIN_PASSWORD=password"
      - "GF_USERS_ALLOW_SIGN_UP=false"
    ports:
      - 3000:3000
    volumes:
      - ./grafana/provisioning/:/etc/grafana/provisioning/
      - ./grafana/config/grafana.ini:/etc/grafana/grafana.ini
    depends_on:
      - prometheus

  kcat:
    image: confluentinc/cp-kcat:latest
    hostname: kcat
    container_name: kcat
    depends_on:
      - broker
    entrypoint: [ "sh", "-c", "sleep infinity" ]
    profiles:
      - "kcat"

  conduktor-postgresql:
    image: postgres:14
    hostname: conduktor-postgresql
    container_name: conduktor-postgresql
    environment:
      POSTGRES_DB: "conduktor"
      POSTGRES_USER: "conduktor"
      POSTGRES_PASSWORD: "change_me"
    profiles:
      - "conduktor"

  conduktor-console:
    image: conduktor/conduktor-console:1.30.0
    hostname: conduktor-console
    container_name: conduktor-console
    depends_on:
      - conduktor-postgresql
    ports:
      - "8080:8080"
    volumes:
      - ../../environment/plaintext/conduktor/platform-config.yaml:/tmp/platform-config.yaml
    environment:
      CDK_IN_CONF_FILE: /tmp/platform-config.yaml
    profiles:
      - "conduktor"

  conduktor-monitoring:
    image: conduktor/conduktor-console-cortex:1.30.0
    hostname: conduktor-monitoring
    container_name: conduktor-monitoring
    environment:
      # Connection to the Console container
      CDK_CONSOLE-URL: "http://conduktor-console:8080"
    profiles:
      - "conduktor"

  pyroscope:
    hostname: pyroscope
    container_name: pyroscope
    image: pyroscope/pyroscope:0.37.2
    profiles:
      - "grafana"
    ports:
      - '4040:4040'
    command:
      - "server"
      - "-no-self-profiling"

  # Flink JobManager
  jobmanager:
    image: flink:${FLINK_TAG}
    hostname: jobmanager
    container_name: jobmanager
    profiles:
      - flink
    ports:
      - "18081:18081"  # REST API and Web UI
      - "9091:9090"    # Prometheus metrics
    entrypoint: >
      sh -c "$flink_connectors exec /docker-entrypoint.sh jobmanager"
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        rest.port: 18081
        taskmanager.numberOfTaskSlots: 4
        ${GRAFANA_FLINK}
  
  # Flink TaskManager
  taskmanager:
    image: flink:${FLINK_TAG}
    hostname: taskmanager
    container_name: taskmanager
    profiles:
      - flink
    depends_on:
      - jobmanager
    entrypoint: >
      sh -c "$flink_connectors exec /docker-entrypoint.sh taskmanager"
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        rest.address: jobmanager
        rest.port: 18081
        taskmanager.numberOfTaskSlots: 4
        ${GRAFANA_FLINK}
  # Flink SQL Client
  sql-client:
    image: flink:${FLINK_TAG}
    hostname: sql-client
    container_name: sql-client
    profiles:
      - flink
    depends_on:
      - jobmanager
    stdin_open: true
    tty: true
    entrypoint: >
      sh -c "$flink_connectors exec /docker-entrypoint.sh bin/sql-client.sh"
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        rest.address: jobmanager
        rest.port: 18081
        deployment.gateway-address: jobmanager
        deployment.gateway-port: 18081