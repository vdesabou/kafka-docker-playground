---
version: '3.5'
services:

  zookeeper:
    image: confluentinc/cp-zookeeper:${TAG}
    hostname: zookeeper
    container_name: zookeeper
    restart: always
    volumes:
      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/
    ports:
      - "9999:9999"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      KAFKA_JMX_PORT: 9999
      EXTRA_ARGS: ${GRAFANA_AGENT_ZK}
      KAFKA_JMX_HOSTNAME: localhost
      # for 5.4.x:
      KAFKA_OPTS: -Dzookeeper.4lw.commands.whitelist=*
      PYROSCOPE_APPLICATION_NAME: "zookeeper"
      PYROSCOPE_SERVER_ADDRESS: "http://pyroscope:4040"
  broker:
    image: ${CP_KAFKA_IMAGE}:${TAG}
    hostname: broker
    container_name: broker
    restart: always
    ports:
      - "9092:9092"
      - "29092:29092"
      - "10000:10000"
    environment:
      KAFKA_JMX_PORT: 10000
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: BROKER:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_LISTENERS: BROKER://:9092,PLAINTEXT_HOST://:29092
      KAFKA_ADVERTISED_LISTENERS: BROKER://broker:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
      # Confluent Metrics Reporter for Control Center Cluster Monitoring
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker:9092
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: 'true'
      # for 5.4.x:
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      # for 6.0.0
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      # # For Confluent Telemetry Reporter (proactive support)
      # KAFKA_CONFLUENT_TELEMETRY_ENABLED: 'true'
      # KAFKA_CONFLUENT_TELEMETRY_API_KEY: 'CLOUD_API_KEY'
      # KAFKA_CONFLUENT_TELEMETRY_API_SECRET: 'CLOUD_API_SECRET'
      EXTRA_ARGS: ${GRAFANA_AGENT_BROKER}
      PYROSCOPE_APPLICATION_NAME: "broker"
      PYROSCOPE_SERVER_ADDRESS: "http://pyroscope:4040"
    volumes:
      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/

  broker2:
    image: ${CP_KAFKA_IMAGE}:${TAG}
    hostname: broker2
    container_name: broker2
    restart: always
    profiles:
      - "kafka_nodes"
    ports:
      - "9292:9292"
      - "29292:29292"
      - "12000:12000"
    environment:
      KAFKA_JMX_PORT: 12000
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: BROKER:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_LISTENERS: BROKER://:9292,PLAINTEXT_HOST://:29292
      KAFKA_ADVERTISED_LISTENERS: BROKER://broker2:9292,PLAINTEXT_HOST://localhost:29292
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
      # Confluent Metrics Reporter for Control Center Cluster Monitoring
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker2:9292
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: 'true'
      # for 5.4.x:
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      # for 6.0.0
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      # # For Confluent Telemetry Reporter (proactive support)
      # KAFKA_CONFLUENT_TELEMETRY_ENABLED: 'true'
      # KAFKA_CONFLUENT_TELEMETRY_API_KEY: 'CLOUD_API_KEY'
      # KAFKA_CONFLUENT_TELEMETRY_API_SECRET: 'CLOUD_API_SECRET'
      EXTRA_ARGS: ${GRAFANA_AGENT_BROKER}
      PYROSCOPE_APPLICATION_NAME: "broker2"
      PYROSCOPE_SERVER_ADDRESS: "http://pyroscope:4040"
    volumes:
      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/  

  broker3:
    image: ${CP_KAFKA_IMAGE}:${TAG}
    hostname: broker3
    container_name: broker3
    restart: always
    profiles:
      - "kafka_nodes"
    ports:
      - "9392:9392"
      - "29392:29392"
      - "13000:13000"
    environment:
      KAFKA_JMX_PORT: 13000
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: BROKER:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_LISTENERS: BROKER://:9392,PLAINTEXT_HOST://:29392
      KAFKA_ADVERTISED_LISTENERS: BROKER://broker3:9392,PLAINTEXT_HOST://localhost:29392
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
      # Confluent Metrics Reporter for Control Center Cluster Monitoring
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker3:9392
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: 'true'
      # for 5.4.x:
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      # for 6.0.0
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      # # For Confluent Telemetry Reporter (proactive support)
      # KAFKA_CONFLUENT_TELEMETRY_ENABLED: 'true'
      # KAFKA_CONFLUENT_TELEMETRY_API_KEY: 'CLOUD_API_KEY'
      # KAFKA_CONFLUENT_TELEMETRY_API_SECRET: 'CLOUD_API_SECRET'
      EXTRA_ARGS: ${GRAFANA_AGENT_BROKER}
      PYROSCOPE_APPLICATION_NAME: "broker3"
      PYROSCOPE_SERVER_ADDRESS: "http://pyroscope:4040"
    volumes:
      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/



  schema-registry:
    image: confluentinc/cp-schema-registry:${TAG}
    hostname: schema-registry
    container_name: schema-registry
    restart: always
    depends_on:
      - broker
    ports:
      - "8081:8081"
      - "10001:10001"
    volumes:
      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/
    environment:
      SCHEMA_REGISTRY_JMX_PORT: 10001
      SCHEMA_REGISTRY_JMX_HOSTNAME: localhost
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: broker:9092
      # SCHEMA_REGISTRY_METRIC_REPORTERS: io.confluent.telemetry.reporter.TelemetryReporter
      # SCHEMA_REGISTRY_CONFLUENT_TELEMETRY_ENABLED: 'true'
      # SCHEMA_REGISTRY_CONFLUENT_TELEMETRY_API_KEY: 'CLOUD_API_KEY'
      # SCHEMA_REGISTRY_CONFLUENT_TELEMETRY_API_SECRET: 'CLOUD_API_SECRET'
      # https://github.com/confluentinc/schema-registry/issues/2213
      SCHEMA_REGISTRY_SCHEMA_PROVIDERS_AVRO_VALIDATE_DEFAULTS: "true"
      EXTRA_ARGS: ${GRAFANA_AGENT_SR}
      PYROSCOPE_APPLICATION_NAME: "schema-registry"
      PYROSCOPE_SERVER_ADDRESS: "http://pyroscope:4040"

  connect:
    image: ${CP_CONNECT_IMAGE}:${CONNECT_TAG}
    hostname: connect
    container_name: connect
    restart: always
    depends_on:
      - broker
      - schema-registry
    ports:
      - "5005:5005"
      - "8083:8083"
      - "10002:10002"
    volumes:
      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/
      - ../../confluent-hub:/usr/share/confluent-hub-components
    environment:
      KAFKA_JMX_PORT: 10002
      KAFKA_JMX_HOSTNAME: localhost
      CONNECT_BOOTSTRAP_SERVERS: 'broker:9092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_GROUP_ID: "connect-cluster"
      CONNECT_PRODUCER_CLIENT_ID: "connect-worker-producer"
      CONNECT_CLIENT_ID: "connect-adminclient-producer"
      CONNECT_CONFIG_STORAGE_TOPIC: connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: connect-status
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      CONNECT_VALUE_CONVERTER: "io.confluent.connect.avro.AvroConverter"
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_PLUGIN_PATH: /usr/share/confluent-hub-components/confluentinc-kafka-connect-s3 # only load one connector to speed up deployment (it is overidden in connect tests)
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR
      # Confluent Monitoring Interceptors for Control Center Streams Monitoring
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      CONNECT_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_BOOTSTRAP_SERVERS: broker:9092
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      CONNECT_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_BOOTSTRAP_SERVERS: broker:9092
      # Externalizing Secrets
      CONNECT_CONFIG_PROVIDERS: 'file'
      CONNECT_CONFIG_PROVIDERS_FILE_CLASS: 'org.apache.kafka.common.config.provider.FileConfigProvider'
      # CONNECT_LOG4J_ROOT_LOGLEVEL: DEBUG
      # KIP-158 https://cwiki.apache.org/confluence/display/KAFKA/KIP-158%3A+Kafka+Connect+should+allow+source+connectors+to+set+topic-specific+settings+for+new+topics (6.x only)
      CONNECT_TOPIC_CREATION_ENABLE: 'true'
      # CONNECT_METRIC_REPORTERS: io.confluent.telemetry.reporter.TelemetryReporter
      # CONNECT_CONFLUENT_TELEMETRY_ENABLED: 'true'
      # CONNECT_CONFLUENT_TELEMETRY_API_KEY: 'CLOUD_API_KEY'
      # CONNECT_CONFLUENT_TELEMETRY_API_SECRET: 'CLOUD_API_SECRET'
      CONNECT_CONNECTOR_CLIENT_CONFIG_OVERRIDE_POLICY: All
      CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
      # # https://kafka-docker-playground.io/#/reusables?id=âœ¨-remote-debugging
      # KAFKA_DEBUG: 'true'
      # # With JDK9+, need to specify address=*:5005, see https://www.baeldung.com/java-application-remote-debugging#from-java9
      # JAVA_DEBUG_OPTS: '-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=0.0.0.0:5005'
      # uncomment when investigating class not found issue, see https://kafka-docker-playground.io/#/reusables?id=ðŸ”¬-class-loading
      # KAFKA_OPTS: '-verbose:class'
      # Reduce Connect memory utilization
      EXTRA_ARGS: ${GRAFANA_AGENT_CONNECT}
      # KAFKA_JVM_PERFORMANCE_OPTS: -server -XX:+UseG1GC -XX:GCTimeRatio=1
                  # -XX:MinHeapFreeRatio=10 -XX:MaxHeapFreeRatio=20
                  # -XX:MaxGCPauseMillis=10000 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent
                  # -XX:MaxInlineLevel=15 -Djava.awt.headless=true
      PYROSCOPE_APPLICATION_NAME: "connect"
      PYROSCOPE_SERVER_ADDRESS: "http://pyroscope:4040"

  connect2:
    image: ${CP_CONNECT_IMAGE}:${CONNECT_TAG}
    hostname: connect2
    container_name: connect2
    restart: always
    depends_on:
      - broker
      - schema-registry
    ports:
      - "5205:5005"
      - "8283:8283"
      - "10022:10022"
    profiles:
      - "connect_nodes"
    volumes:
      - ./jmx-exporter:/usr/share/jmx_exporter/
      - ../../confluent-hub:/usr/share/confluent-hub-components
    environment:
      KAFKA_JMX_PORT: 10022
      KAFKA_JMX_HOSTNAME: localhost
      CONNECT_LISTENERS: http://:8283 
      CONNECT_BOOTSTRAP_SERVERS: 'broker:9092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect2
      CONNECT_GROUP_ID: "connect-cluster"
      CONNECT_PRODUCER_CLIENT_ID: "connect-worker-producer"
      CONNECT_CONFIG_STORAGE_TOPIC: connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: connect-status
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      CONNECT_VALUE_CONVERTER: "io.confluent.connect.avro.AvroConverter"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_PLUGIN_PATH: /usr/share/confluent-hub-components # to avoid overwriting all docker-compose in each directory, we base this path from the source command being issued when the environment starts. See start.sh in plain
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR
      # Confluent Monitoring Interceptors for Control Center Streams Monitoring
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      CONNECT_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_BOOTSTRAP_SERVERS: broker:9092
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      CONNECT_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_BOOTSTRAP_SERVERS: broker:9092
      # Externalizing Secrets
      CONNECT_CONFIG_PROVIDERS: 'file'
      CONNECT_CONFIG_PROVIDERS_FILE_CLASS: 'org.apache.kafka.common.config.provider.FileConfigProvider'
      # CONNECT_LOG4J_ROOT_LOGLEVEL: DEBUG
      # KIP-158 https://cwiki.apache.org/confluence/display/KAFKA/KIP-158%3A+Kafka+Connect+should+allow+source+connectors+to+set+topic-specific+settings+for+new+topics (6.x only)
      CONNECT_TOPIC_CREATION_ENABLE: 'true'
      # CONNECT_METRIC_REPORTERS: io.confluent.telemetry.reporter.TelemetryReporter
      # CONNECT_CONFLUENT_TELEMETRY_ENABLED: 'true'
      # CONNECT_CONFLUENT_TELEMETRY_API_KEY: 'CLOUD_API_KEY'
      # CONNECT_CONFLUENT_TELEMETRY_API_SECRET: 'CLOUD_API_SECRET'
      CONNECT_CONNECTOR_CLIENT_CONFIG_OVERRIDE_POLICY: All
      CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
      # # https://kafka-docker-playground.io/#/reusables?id=âœ¨-remote-debugging
      # KAFKA_DEBUG: 'true'
      # # With JDK9+, need to specify address=*:5005, see https://www.baeldung.com/java-application-remote-debugging#from-java9
      # JAVA_DEBUG_OPTS: '-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=0.0.0.0:5005'
      # uncomment when investigating class not found issue, see https://kafka-docker-playground.io/#/reusables?id=ðŸ”¬-class-loading
      # KAFKA_OPTS: '-verbose:class'
      # Reduce Connect memory utilization
      EXTRA_ARGS: ${GRAFANA_AGENT_CONNECT}
      # KAFKA_JVM_PERFORMANCE_OPTS: -server -XX:+UseG1GC -XX:GCTimeRatio=1
                  # -XX:MinHeapFreeRatio=10 -XX:MaxHeapFreeRatio=20
                  # -XX:MaxGCPauseMillis=10000 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent
                  # -XX:MaxInlineLevel=15 -Djava.awt.headless=true
      PYROSCOPE_APPLICATION_NAME: "connect2"
      PYROSCOPE_SERVER_ADDRESS: "http://pyroscope:4040"

  connect3:
    image: ${CP_CONNECT_IMAGE}:${CONNECT_TAG}
    hostname: connect3
    container_name: connect3
    restart: always
    depends_on:
      - broker
      - schema-registry
    ports:
      - "5305:5005"
      - "8383:8383"
      - "10032:10032"
    profiles:
      - "connect_nodes"
    volumes:
      - ./jmx-exporter:/usr/share/jmx_exporter/
      - ../../confluent-hub:/usr/share/confluent-hub-components
    environment:
      KAFKA_JMX_PORT: 10032
      KAFKA_JMX_HOSTNAME: localhost
      CONNECT_LISTENERS: http://:8383
      CONNECT_BOOTSTRAP_SERVERS: 'broker:9092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect3
      CONNECT_GROUP_ID: "connect-cluster"
      CONNECT_PRODUCER_CLIENT_ID: "connect-worker-producer"
      CONNECT_CONFIG_STORAGE_TOPIC: connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: connect-status
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.storage.StringConverter"
      CONNECT_VALUE_CONVERTER: "io.confluent.connect.avro.AvroConverter"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_PLUGIN_PATH: /usr/share/confluent-hub-components # to avoid overwriting all docker-compose in each directory, we base this path from the source command being issued when the environment starts. See start.sh in plain
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR
      # Confluent Monitoring Interceptors for Control Center Streams Monitoring
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      CONNECT_PRODUCER_CONFLUENT_MONITORING_INTERCEPTOR_BOOTSTRAP_SERVERS: broker:9092
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      CONNECT_CONSUMER_CONFLUENT_MONITORING_INTERCEPTOR_BOOTSTRAP_SERVERS: broker:9092
      # Externalizing Secrets
      CONNECT_CONFIG_PROVIDERS: 'file'
      CONNECT_CONFIG_PROVIDERS_FILE_CLASS: 'org.apache.kafka.common.config.provider.FileConfigProvider'
      # CONNECT_LOG4J_ROOT_LOGLEVEL: DEBUG
      # KIP-158 https://cwiki.apache.org/confluence/display/KAFKA/KIP-158%3A+Kafka+Connect+should+allow+source+connectors+to+set+topic-specific+settings+for+new+topics (6.x only)
      CONNECT_TOPIC_CREATION_ENABLE: 'true'
      # CONNECT_METRIC_REPORTERS: io.confluent.telemetry.reporter.TelemetryReporter
      # CONNECT_CONFLUENT_TELEMETRY_ENABLED: 'true'
      # CONNECT_CONFLUENT_TELEMETRY_API_KEY: 'CLOUD_API_KEY'
      # CONNECT_CONFLUENT_TELEMETRY_API_SECRET: 'CLOUD_API_SECRET'
      CONNECT_CONNECTOR_CLIENT_CONFIG_OVERRIDE_POLICY: All
      CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
      # # https://kafka-docker-playground.io/#/reusables?id=âœ¨-remote-debugging
      # KAFKA_DEBUG: 'true'
      # # With JDK9+, need to specify address=*:5005, see https://www.baeldung.com/java-application-remote-debugging#from-java9
      # JAVA_DEBUG_OPTS: '-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=0.0.0.0:5005'
      # uncomment when investigating class not found issue, see https://kafka-docker-playground.io/#/reusables?id=ðŸ”¬-class-loading
      # KAFKA_OPTS: '-verbose:class'
      # Reduce Connect memory utilization
      EXTRA_ARGS: ${GRAFANA_AGENT_CONNECT}
      # KAFKA_JVM_PERFORMANCE_OPTS: -server -XX:+UseG1GC -XX:GCTimeRatio=1
                  # -XX:MinHeapFreeRatio=10 -XX:MaxHeapFreeRatio=20
                  # -XX:MaxGCPauseMillis=10000 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent
                  # -XX:MaxInlineLevel=15 -Djava.awt.headless=true
      PYROSCOPE_APPLICATION_NAME: "connect3"
      PYROSCOPE_SERVER_ADDRESS: "http://pyroscope:4040"

  ksqldb-server:
    image: ${CP_KSQL_IMAGE}:${TAG}
    hostname: ksqldb-server
    container_name: ksqldb-server
    depends_on:
      - broker
      - connect
    ports:
      - "8088:8088"
      - "10003:10003"
    volumes:
      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/
    profiles:
    - ksqldb
    environment:
      KSQL_JMX_PORT: 10003
      KSQL_JMX_HOSTNAME: localhost
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_BOOTSTRAP_SERVERS: broker:9092
      KSQL_CACHE_MAX_BYTES_BUFFERING: 0
      KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      KSQL_KSQL_CONNECT_URL: "http://connect:8083"
      # KSQL_KSQL_STREAMS_PROCESSING_GUARANTEE=exactly_once
      # --- ksqlDB Server log config ---
      KSQL_LOG4J_ROOT_LOGLEVEL: "INFO"
      KSQL_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
      # --- ksqlDB processing log config ---
      # KSQL_LOG4J_PROCESSING_LOG_BROKERLIST: broker:9092
      # KSQL_LOG4J_PROCESSING_LOG_TOPIC: ksql_processing_log
      # KSQL_KSQL_LOGGING_PROCESSING_TOPIC_NAME: ksql_processing_log
      # KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
      # KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      # KSQL_KSQL_LOGGING_PROCESSING_ROWS_INCLUDE: 'true'
      KSQL_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      KSQL_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      # KSQL_METRIC_REPORTERS: io.confluent.telemetry.reporter.TelemetryReporter
      # KSQL_CONFLUENT_TELEMETRY_ENABLED: 'true'
      # KSQL_CONFLUENT_TELEMETRY_API_KEY: 'CLOUD_API_KEY'
      # KSQL_CONFLUENT_TELEMETRY_API_SECRET: 'CLOUD_API_SECRET'
      EXTRA_ARGS: ${GRAFANA_AGENT_KSQLDB}
      PYROSCOPE_APPLICATION_NAME: "ksqldb-server"
      PYROSCOPE_SERVER_ADDRESS: "http://pyroscope:4040"

  ksqldb-cli:
    image: ${CP_KSQL_CLI_IMAGE}
    container_name: ksqldb-cli
    depends_on:
      - broker
      - connect
      - ksqldb-server
    entrypoint: /bin/sh
    profiles:
    - ksqldb
    tty: true

  control-center:
    image: confluentinc/cp-enterprise-control-center:${TAG}
    hostname: control-center
    container_name: control-center
    restart: always
    depends_on:
      - broker
      - schema-registry
      - connect
    ports:
      - "${C3_PORT:-9021}:9021"
    profiles:
    - control-center
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker:9092'
      CONTROL_CENTER_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      CONTROL_CENTER_CONNECT_CLUSTER: http://connect:8083 # deprecated
      CONTROL_CENTER_CONNECT_MYCONNECT_CLUSTER: http://connect:8083
      CONTROL_CENTER_KAFKA_BOOTSTRAP_SERVERS: 'broker:9092'
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      CONTROL_CENTER_KAFKA_MYCLUSTER_BOOTSTRAP_SERVERS: 'broker:9092'
      CONTROL_CENTER_UI_AUTOUPDATE_ENABLE: "false"
      CONTROL_CENTER_KSQL_URL: "http://ksqldb-server:8088" # deprecated
      CONTROL_CENTER_KSQL_ADVERTISED_URL: "http://127.0.0.1:8088" # deprecated
      CONTROL_CENTER_KSQL_MYKSQL_URL: "http://ksqldb-server:8088"
      CONTROL_CENTER_KSQL_MYKSQL_ADVERTISED_URL: "http://127.0.0.1:8088"
      CONTROL_CENTER_COMMAND_TOPIC_REPLICATION: 1
      CONTROL_CENTER_METRICS_TOPIC_REPLICATION: 1
      # METRIC_REPORTERS: io.confluent.telemetry.reporter.TelemetryReporter
      # CONFLUENT_TELEMETRY_ENABLED: 'true'
      # CONFLUENT_TELEMETRY_API_KEY: 'CLOUD_API_KEY'
      # CONFLUENT_TELEMETRY_API_SECRET: 'CLOUD_API_SECRET'
      # starting from 7.0
      #CONTROL_CENTER_MODE_ENABLE: management
      # CONTROL_CENTER_ID: 32

  kafka-lag-exporter:
    image: seglo/kafka-lag-exporter:0.7.1
    hostname: kafka-lag-exporter
    container_name: kafka-lag-exporter
    profiles:
      - "grafana"
    restart: always
    ports:
      - 9998:9998
    volumes:
      - ./kafka-lag-exporter/application.conf:/opt/docker/conf/application.conf
      - ./kafka-lag-exporter/logback.xml:/opt/docker/conf/logback.xml

  alertmanager:
    image: prom/alertmanager:latest
    hostname: alertmanager
    container_name: alertmanager
    profiles:
      - "grafana"
    ports:
      - 9093:9093

  node-exporter:
    image: prom/node-exporter:v1.2.2
    hostname: node-exporter
    container_name: node-exporter
    profiles:
      - "grafana"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - "--path.procfs=/host/proc"
      - "--path.sysfs=/host/sys"
      - "--collector.filesystem.ignored-mount-points"
      - "^(aufs|proc|nsfs|shm|cgroup|tmpfs|binfmt_misc|debugfs|devpts|fusectl|hugetlbfs|fuse.lxcfs|mqueue|pstore|securityfs|sysfs|autofs|devtmpfs|configfs)"

  prometheus:
    image: prom/prometheus:v2.29.2
    hostname: prometheus
    container_name: prometheus
    profiles:
      - "grafana"
    ports:
      - 9090:9090
    volumes:
      - ./prometheus/:/etc/prometheus/
    depends_on:
      - node-exporter
      - kafka-lag-exporter
      - alertmanager

  grafana:
    image: grafana/grafana:8.1.3
    hostname: grafana
    container_name: grafana
    profiles:
      - "grafana"
    environment:
      - "GF_SECURITY_ADMIN_USER=admin"
      - "GF_SECURITY_ADMIN_PASSWORD=password"
      - "GF_USERS_ALLOW_SIGN_UP=false"
    ports:
      - 3000:3000
    volumes:
      - ./grafana/provisioning/:/etc/grafana/provisioning/
      - ./grafana/config/grafana.ini:/etc/grafana/grafana.ini
    depends_on:
      - prometheus

  kcat:
    image: confluentinc/cp-kcat:latest
    hostname: kcat
    container_name: kcat
    depends_on:
      - broker
    entrypoint: [ "sh", "-c", "sleep infinity" ]
    profiles:
      - "kcat"

  # https://github.com/conduktor/conduktor-platform/blob/main/doc/Configuration.md
  conduktor:
    image: conduktor/conduktor-platform:latest
    hostname: conduktor
    container_name: conduktor
    depends_on:
      - broker
    ports:
      - 8080:80
    volumes:
      - ../../environment/plaintext/conduktor/platform-config.yaml:/tmp/platform-config.yaml
    environment:
      CDK_IN_CONF_FILE: /tmp/platform-config.yaml
      RUN_MODE: "nano"
    profiles:
      - "conduktor"

  sr_plugins:
    image: cdpop001/sr_plugins:latest
    hostname: sr_plugins
    container_name: sr_plugins
    depends_on:
      - broker
    ports:
      - 8080:8080
    profiles:
      - "sr_plugin_app"

  pyroscope:
    hostname: pyroscope
    image: pyroscope/pyroscope:0.37.2
    profiles:
      - "grafana"
    ports:
      - '4040:4040'
    command:
      - "server"
      - "-no-self-profiling"