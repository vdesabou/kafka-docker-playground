#!/usr/bin/env bash
# This script was generated by bashly 1.0.1 (https://bashly.dannyb.co)
# Modifying it manually is not recommended

# :wrapper.bash3_bouncer
if [[ "${BASH_VERSINFO:-0}" -lt 4 ]]; then
  printf "bash version 4 or higher is required\n" >&2
  exit 1
fi

# :command.master_script

# :command.version_command
version_command() {
  echo "$version"
}

# :command.usage
playground_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground - üß† CLI for Kafka Docker Playground üê≥\n"
    echo

  else
    printf "playground - üß† CLI for Kafka Docker Playground üê≥\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground COMMAND\n"
  printf "  playground [COMMAND] --help | -h\n"
  printf "  playground --version | -v\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "Run commands:")"
  printf "  %s   üöÄ  Run example.\n" "$(green "run")                           "
  printf "  %s   üõ∏  Re-run last example.\n" "$(green "re-run")                        "
  echo
  printf "%s\n" "$(bold "Bootstrap commands:")"
  printf "  %s   üõ†  Bootstrap reproduction model.\n" "$(green "bootstrap-reproduction-model")  "
  echo
  printf "%s\n" "$(bold "Kafka commands:")"
  printf "  %s   üìù Get properties file from a container.\n" "$(green "get-properties")                "
  printf "  %s   üî∞ Get all schemas versions for all subjects.\n" "$(green "get-all-schemas")               "
  printf "  %s   üî¢ Get JMX metrics from a component.\n" "$(green "get-jmx-metrics")               "
  echo
  printf "%s\n" "$(bold "Debug commands:")"
  printf "  %s   ‚ú® Enable java remote debugging for container.\n" "$(green "enable-remote-debugging")       "
  echo
  printf "%s\n" "$(bold "Container commands:")"
  printf "  %s   üê≥ Container commands.\n" "$(green "container")                     "
  [[ -n $long_usage ]] && printf "  %s   üí´ Recreate container(s).\n" "$(green "container recreate")            "
  [[ -n $long_usage ]] && printf "  %s   üñ•Ô∏è  Get IP address of running containers.\n" "$(green "container get-ip-addresses")    "
  [[ -n $long_usage ]] && printf "  %s   üíÄ Kill all containers.\n" "$(green "container kill-all")            "
  [[ -n $long_usage ]] && printf "  %s   üïµÔ∏è  Tail and follow container logs.\n" "$(green "container logs")                "
  [[ -n $long_usage ]] && printf "  %s   üöÄ SSH into container.\n" "$(green "container ssh")                 "
  [[ -n $long_usage ]] && printf "  %s   ü™Ñ  Execute command in a container.\n" "$(green "container exec")                "
  [[ -n $long_usage ]] && printf "  %s   üîÅ Restart a container.\n" "$(green "container restart")             "
  [[ -n $long_usage ]] && printf "  %s   ‚è∏Ô∏è  Pause a container.\n" "$(green "container pause")               "
  [[ -n $long_usage ]] && printf "  %s   ‚èØÔ∏è  Resume a container.\n" "$(green "container resume")              "
  [[ -n $long_usage ]] && printf "  %s   üî´ Kill a container.\n" "$(green "container kill")                "
  echo
  printf "%s\n" "$(bold "Topic commands:")"
  printf "  %s   üìÅ Topic commands.\n" "$(green "topic")                         "
  [[ -n $long_usage ]] && printf "  %s   üíØ Get number of records in a topic.\n" "$(green "topic get-number-records")      "
  [[ -n $long_usage ]] && printf "  %s   üî∫ Display content of connect offsets topic.\n" "$(green "topic display-connect-offsets") "
  [[ -n $long_usage ]] && printf "  %s   üîª Display content of __consumer_offsets topic.\n" "$(green "topic display-consumer-offsets")"
  [[ -n $long_usage ]] && printf "  %s   üîé Describe topic.\n" "$(green "topic describe")                "
  [[ -n $long_usage ]] && printf "  %s   ‚ÜòÔ∏è Consumer topic(s) from current running examples\n" "$(green "topic consume")                 "
  echo
  printf "%s\n" "$(bold "Connector commands:")"
  printf "  %s   üîó Connector commands.\n" "$(green "connector")                     "
  [[ -n $long_usage ]] && printf "  %s   ‚ÑπÔ∏è  Show status of all connectors.\n" "$(green "connector status")              "
  [[ -n $long_usage ]] && printf "  %s   üîñ Show all plugins installed.\n" "$(green "connector plugins")             "
  [[ -n $long_usage ]] && printf "  %s   ‚è∏Ô∏è  Pause connector\n" "$(green "connector pause")               "
  [[ -n $long_usage ]] && printf "  %s   ‚ôªÔ∏è  Restart connector\n" "$(green "connector restart")             "
  [[ -n $long_usage ]] && printf "  %s   ‚èØÔ∏è  Resume connector\n" "$(green "connector resume")              "
  [[ -n $long_usage ]] && printf "  %s   üóëÔ∏è  Delete connector\n" "$(green "connector delete")              "
  [[ -n $long_usage ]] && printf "  %s   üê¢ Show lag of sink connector\n" "$(green "connector show-lag")            "
  [[ -n $long_usage ]] && printf "  %s   üß¨ Set connect log level.\n" "$(green "connector log-level")           "
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo
    printf "  %s\n" "$(magenta "--version, -v")"
    printf "    Show version number\n"
    echo

  fi
}

# :command.usage
playground_get_connector_list_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-connector-list - Return some completion for connector list\n"
    echo

  else
    printf "playground get-connector-list - Return some completion for connector list\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-connector-list\n"
  printf "  playground get-connector-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_topic_list_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-topic-list - Return some completion for topic list\n"
    echo

  else
    printf "playground get-topic-list - Return some completion for topic list\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-topic-list\n"
  printf "  playground get-topic-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_examples_list_with_fzf_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-examples-list-with-fzf - Return some completion for examples list\n"
    echo

  else
    printf "playground get-examples-list-with-fzf - Return some completion for examples list\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-examples-list-with-fzf [CUR] [OPTIONS]\n"
  printf "  playground get-examples-list-with-fzf --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--without-repro")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--sink-only")"
    printf "\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_run_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground run\n"
    echo

    printf "  üöÄ  Run example.\n  \n  üëâ Check documentation https://tinyurl.com/yx3vbwu5\n"
    echo

  else
    printf "playground run - üöÄ  Run example.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground run [OPTIONS]\n"
  printf "  playground run --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--file, -f FILE (required)")"
    printf "    Example file to run.\n    It must be absolute full path. \n    \n    üéì Tip: use <tab> completion to trigger fzf completion.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--skip-editor, -s")"
    printf "    Skip opening example file with text editor\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--tag TAG")"
    printf "    CP version to use\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-tag CONNECTOR_TAG")"
    printf "    Connector version to use\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-zip CONNECTOR_ZIP")"
    printf "    Connector zip to use\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-jar CONNECTOR_JAR")"
    printf "    Connector jar to use\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--disable-ksqldb")"
    printf "    Disable ksqlDB\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--disable-control-center")"
    printf "    Disable Control Center\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-conduktor")"
    printf "    Enable Conduktor\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-multiple-brokers")"
    printf "    Enable Multiple brokers\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-multiple-connect-workers")"
    printf "    Enable Multiple Connect Workers\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-jmx-grafana")"
    printf "    Enable Grafana\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-kcat")"
    printf "    Enable kcat\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-sr-maven-plugin-app")"
    printf "    Enable Schema Registry Maven plugin App\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_environment_variables
    printf "%s\n" "$(bold "Environment Variables:")"

    # :environment_variable.usage
    printf "  %s\n" "$(cyan "EDITOR")"
    printf "    üîñ Editor to use to open the example file.\n"
    echo

  fi
}

# :command.usage
playground_re_run_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground re-run - üõ∏  Re-run last example.\n"
    echo

  else
    printf "playground re-run - üõ∏  Re-run last example.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground re-run\n"
  printf "  playground re-run --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_environment_variables
    printf "%s\n" "$(bold "Environment Variables:")"

    # :environment_variable.usage
    printf "  %s\n" "$(cyan "EDITOR")"
    printf "    üîñ Editor to use to open the example file.\n"
    echo

  fi
}

# :command.usage
playground_bootstrap_reproduction_model_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground bootstrap-reproduction-model\n"
    echo

    printf "  üõ†  Bootstrap reproduction model.\n  \n  üëâ Check documentation https://tinyurl.com/bdfs25my\n"
    echo

  else
    printf "playground bootstrap-reproduction-model - üõ†  Bootstrap reproduction model.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground bootstrap-reproduction-model [OPTIONS]\n"
  printf "  playground bootstrap-reproduction-model --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--file, -f FILE (required)")"
    printf "    Example file to use as basis.\n    It must be absolute full path. \n    \n    üéì Tip: use <tab> completion to trigger fzf completion.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--description, -d DESCRIPTION (required)")"
    printf "    Description.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--producer, -p PRODUCER-TYPE")"
    printf "    Java producer type to use. \n    One of avro, avro-with-key, protobuf, protobuf-with-key, json-schema,\n    json-schema-with-key.\n    \n    Note: 'with-key' will also produce key with selected converter, otherwise\n    LongConverter is used.\n"
    printf "    Allowed: none, avro, avro-with-key, protobuf, protobuf-with-key, json-schema, json-schema-with-key\n"
    printf "    Default: none\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--nb-producers, -n NB-PRODUCERS")"
    printf "    Number of java producers to generate.\n"
    printf "    Default: \n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--custom-smt")"
    printf "    Add a custom SMT (no-op).\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--pipeline SINK_FILE")"
    printf "    Sink example file to use for creating a pipeline.\n    It must be absolute full path. \n    \n    üéì Tip: use <tab> completion to trigger fzf completion.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_environment_variables
    printf "%s\n" "$(bold "Environment Variables:")"

    # :environment_variable.usage
    printf "  %s\n" "$(cyan "OUTPUT_FOLDER")"
    printf "    üìÅ Output folder where to generate bootstrapped files.\n"
    printf "    Default: reproduction-models\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground bootstrap-reproduction-model -f hdfs2<tab> -d \"simple test\"\n"
    printf "  playground bootstrap-reproduction-model -f /full/path/hdfs2-sink.sh -d\n  \"testing with avro producer\" --producer avro\n"
    printf "  playground bootstrap-reproduction-model -f hdfs2<tab> -d \"testing with 2\n  protobuf producers\" --producer protobuf --nb-producers 2\n"
    printf "  playground bootstrap-reproduction-model -f hdfs2<tab> -d \"testing custom smt\"\n  --custom-smt\n"
    printf "  playground bootstrap-reproduction-model -f debeziumpostgres<tab> -d \"create\n  pipeline\" --pipeline jdbcsink<tab>\n"
    echo

  fi
}

# :command.usage
playground_get_properties_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-properties\n"
    echo

    printf "  üìù Get properties file from a container.\n  \n  üëâ Check documentation https://tinyurl.com/4vj7tm2b\n"
    echo

  else
    printf "playground get-properties - üìù Get properties file from a container.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-properties [OPTIONS]\n"
  printf "  playground get-properties --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    Container name.\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground get-properties\n"
    printf "  playground get-properties --container broker\n"
    printf "  playground get-properties -c broker\n"
    echo

  fi
}

# :command.usage
playground_get_all_schemas_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-all-schemas\n"
    echo

    printf "  üî∞ Get all schemas versions for all subjects.\n  \n  üëâ Check documentation xxxx\n"
    echo

  else
    printf "playground get-all-schemas - üî∞ Get all schemas versions for all subjects.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-all-schemas\n"
  printf "  playground get-all-schemas --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground get-all-schemas\n"
    echo

  fi
}

# :command.usage
playground_enable_remote_debugging_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground enable-remote-debugging\n"
    echo

    printf "  ‚ú® Enable java remote debugging for container.\n  \n  üëâ Check documentation https://tinyurl.com/bdz843d4\n"
    echo

  else
    printf "playground enable-remote-debugging - ‚ú® Enable java remote debugging for container.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground enable-remote-debugging [OPTIONS]\n"
  printf "  playground enable-remote-debugging --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    Container name.\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground enable-remote-debugging\n"
    printf "  playground enable-remote-debugging --container broker\n"
    printf "  playground enable-remote-debugging -c broker\n"
    echo

  fi
}

# :command.usage
playground_get_jmx_metrics_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-jmx-metrics\n"
    echo

    printf "  üî¢ Get JMX metrics from a component.\n  \n  üëâ Check documentation https://tinyurl.com/yc2myws9\n"
    echo

  else
    printf "playground get-jmx-metrics - üî¢ Get JMX metrics from a component.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-jmx-metrics [OPTIONS]\n"
  printf "  playground get-jmx-metrics --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--component, -c COMPONENT")"
    printf "    Component name.\n"
    printf "    Allowed: zookeeper, broker, connect, schema-registry\n"
    printf "    Default: connect\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--domain, -d DOMAIN")"
    printf "    Domain name.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground get-jmx-metrics --component connect\n"
    printf "  playground get-jmx-metrics --component connect --domain \"kafka.connect\n  kafka.consumer kafka.producer\"\n"
    printf "  playground get-jmx-metrics -c broker\n"
    echo

  fi
}

# :command.usage
playground_container_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container - üê≥ Container commands.\n"
    echo

  else
    printf "playground container - üê≥ Container commands.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container COMMAND\n"
  printf "  playground container [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "Container commands:")"
  printf "  %s   üí´ Recreate container(s).\n" "$(green "recreate")        "
  printf "  %s   üñ•Ô∏è  Get IP address of running containers.\n" "$(green "get-ip-addresses")"
  printf "  %s   üíÄ Kill all containers.\n" "$(green "kill-all")        "
  printf "  %s   üïµÔ∏è  Tail and follow container logs.\n" "$(green "logs")            "
  printf "  %s   üöÄ SSH into container.\n" "$(green "ssh")             "
  printf "  %s   ü™Ñ  Execute command in a container.\n" "$(green "exec")            "
  printf "  %s   üîÅ Restart a container.\n" "$(green "restart")         "
  printf "  %s   ‚è∏Ô∏è  Pause a container.\n" "$(green "pause")           "
  printf "  %s   ‚èØÔ∏è  Resume a container.\n" "$(green "resume")          "
  printf "  %s   üî´ Kill a container.\n" "$(green "kill")            "
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_recreate_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container recreate\n"
    echo

    printf "  üí´ Recreate container(s).\n  \n  üëâ Check documentation https://tinyurl.com/3rhjxfbs\n"
    echo

  else
    printf "playground container recreate - üí´ Recreate container(s).\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container recreate\n"
  printf "  playground container recreate --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_get_ip_addresses_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container get-ip-addresses - üñ•Ô∏è  Get IP address of running containers.\n"
    echo

  else
    printf "playground container get-ip-addresses - üñ•Ô∏è  Get IP address of running containers.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container get-ip-addresses\n"
  printf "  playground container get-ip-addresses --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground get-ip-address-container\n"
    echo

  fi
}

# :command.usage
playground_container_kill_all_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container kill-all - üíÄ Kill all containers.\n"
    echo

  else
    printf "playground container kill-all - üíÄ Kill all containers.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container kill-all\n"
  printf "  playground container kill-all --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_logs_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container logs - üïµÔ∏è  Tail and follow container logs.\n"
    echo

  else
    printf "playground container logs - üïµÔ∏è  Tail and follow container logs.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container logs [OPTIONS]\n"
  printf "  playground container logs --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    Container name.\n"
    printf "    Default: connect\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--open, -o EDITOR")"
    printf "    Save output to a file and open with editor passed as argument (default is\n    code).\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--wait-for-log, -w LOG")"
    printf "    Wait until log appears.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--max-wait, -m MAX_WAIT")"
    printf "    Max time in seconds to wait when using --wait-for-log (default 600s).\n"
    printf "    Default: 600\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground logs --container connect\n"
    printf "  playground logs -c connect -o code\n"
    printf "  playground logs -c connect -o vim\n"
    echo

  fi
}

# :command.usage
playground_container_ssh_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container ssh - üöÄ SSH into container.\n"
    echo

  else
    printf "playground container ssh - üöÄ SSH into container.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container ssh [OPTIONS]\n"
  printf "  playground container ssh --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    Container name.\n"
    printf "    Default: connect\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--shell, -s SHELL")"
    printf "    Shell to use (default is bash).\n"
    printf "    Allowed: bash, sh, ksh, zsh\n"
    printf "    Default: bash\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground ssh -c connect\n"
    printf "  playground ssh -c connect -s sh\n"
    printf "  playground ssh --container connect --shell sh\n"
    echo

  fi
}

# :command.usage
playground_container_exec_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container exec - ü™Ñ  Execute command in a container.\n"
    echo

  else
    printf "playground container exec - ü™Ñ  Execute command in a container.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container exec [OPTIONS]\n"
  printf "  playground container exec --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    Container name.\n"
    printf "    Default: connect\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--command, -d COMMAND (required)")"
    printf "    Command to execute.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--root")"
    printf "    Run command as root.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--shell SHELL")"
    printf "    Shell to use (default is bash).\n"
    printf "    Allowed: bash, sh, ksh, zsh\n"
    printf "    Default: bash\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground exec -c connect -d \"date\"\n"
    printf "  playground exec -c connect -d \"whoami\" --root\n"
    printf "  playground exec --container connect --command \"whoami\" --shell sh\n"
    echo

  fi
}

# :command.usage
playground_container_restart_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container restart - üîÅ Restart a container.\n"
    echo

  else
    printf "playground container restart - üîÅ Restart a container.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container restart [OPTIONS]\n"
  printf "  playground container restart --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    Container name.\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_pause_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container pause - ‚è∏Ô∏è  Pause a container.\n"
    echo

  else
    printf "playground container pause - ‚è∏Ô∏è  Pause a container.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container pause [OPTIONS]\n"
  printf "  playground container pause --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    Container name.\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_resume_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container resume - ‚èØÔ∏è  Resume a container.\n"
    echo

  else
    printf "playground container resume - ‚èØÔ∏è  Resume a container.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container resume [OPTIONS]\n"
  printf "  playground container resume --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    Container name.\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_kill_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container kill - üî´ Kill a container.\n"
    echo

  else
    printf "playground container kill - üî´ Kill a container.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container kill [OPTIONS]\n"
  printf "  playground container kill --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    Container name.\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic - üìÅ Topic commands.\n"
    echo

  else
    printf "playground topic - üìÅ Topic commands.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic COMMAND\n"
  printf "  playground topic [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "Topic commands:")"
  printf "  %s   üíØ Get number of records in a topic.\n" "$(green "get-number-records")      "
  printf "  %s   üî∫ Display content of connect offsets topic.\n" "$(green "display-connect-offsets") "
  printf "  %s   üîª Display content of __consumer_offsets topic.\n" "$(green "display-consumer-offsets")"
  printf "  %s   üîé Describe topic.\n" "$(green "describe")                "
  printf "  %s   ‚ÜòÔ∏è Consumer topic(s) from current running examples\n" "$(green "consume")                 "
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_get_number_records_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic get-number-records - üíØ Get number of records in a topic.\n"
    echo

  else
    printf "playground topic get-number-records - üíØ Get number of records in a topic.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic get-number-records [OPTIONS]\n"
  printf "  playground topic get-number-records --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC (required)")"
    printf "    Topic name.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground get-number-records --topic a-topic\n"
    printf "  playground get-number-records -t a-topic\n"
    echo

  fi
}

# :command.usage
playground_topic_display_connect_offsets_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic display-connect-offsets - üî∫ Display content of connect offsets topic.\n"
    echo

  else
    printf "playground topic display-connect-offsets - üî∫ Display content of connect offsets topic.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic display-connect-offsets\n"
  printf "  playground topic display-connect-offsets --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_display_consumer_offsets_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic display-consumer-offsets - üîª Display content of __consumer_offsets topic.\n"
    echo

  else
    printf "playground topic display-consumer-offsets - üîª Display content of __consumer_offsets topic.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic display-consumer-offsets\n"
  printf "  playground topic display-consumer-offsets --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_describe_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic describe - üîé Describe topic.\n"
    echo

  else
    printf "playground topic describe - üîé Describe topic.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic describe [OPTIONS]\n"
  printf "  playground topic describe --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC (required)")"
    printf "    Topic name.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_consume_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic consume - ‚ÜòÔ∏è Consumer topic(s) from current running examples\n"
    echo

  else
    printf "playground topic consume - ‚ÜòÔ∏è Consumer topic(s) from current running examples\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic consume\n"
  printf "  playground topic consume --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector - üîó Connector commands.\n"
    echo

  else
    printf "playground connector - üîó Connector commands.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector COMMAND\n"
  printf "  playground connector [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   ‚ÑπÔ∏è  Show status of all connectors.\n" "$(green "status")   "
  printf "  %s   üîñ Show all plugins installed.\n" "$(green "plugins")  "
  printf "  %s   ‚è∏Ô∏è  Pause connector\n" "$(green "pause")    "
  printf "  %s   ‚ôªÔ∏è  Restart connector\n" "$(green "restart")  "
  printf "  %s   ‚èØÔ∏è  Resume connector\n" "$(green "resume")   "
  printf "  %s   üóëÔ∏è  Delete connector\n" "$(green "delete")   "
  printf "  %s   üê¢ Show lag of sink connector\n" "$(green "show-lag") "
  printf "  %s   üß¨ Set connect log level.\n" "$(green "log-level")"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground connector status\n"
    printf "  playground connector status --json\n"
    printf "  playground connector resume --connector <connector-name>\n"
    printf "  playground connector pause -c <connector-name>\n"
    printf "  playground connector delete -c <connector-name>\n"
    echo

  fi
}

# :command.usage
playground_connector_status_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector status - ‚ÑπÔ∏è  Show status of all connectors.\n"
    echo

  else
    printf "playground connector status - ‚ÑπÔ∏è  Show status of all connectors.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector status [OPTIONS]\n"
  printf "  playground connector status --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--json")"
    printf "    Show output as JSON.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_plugins_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector plugins - üîñ Show all plugins installed.\n"
    echo

  else
    printf "playground connector plugins - üîñ Show all plugins installed.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector plugins\n"
  printf "  playground connector plugins --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_pause_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector pause - ‚è∏Ô∏è  Pause connector\n"
    echo

  else
    printf "playground connector pause - ‚è∏Ô∏è  Pause connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector pause [OPTIONS]\n"
  printf "  playground connector pause --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR (required)")"
    printf "    Connector name.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_restart_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector restart - ‚ôªÔ∏è  Restart connector\n"
    echo

  else
    printf "playground connector restart - ‚ôªÔ∏è  Restart connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector restart [OPTIONS]\n"
  printf "  playground connector restart --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR (required)")"
    printf "    Connector name.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_resume_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector resume - ‚èØÔ∏è  Resume connector\n"
    echo

  else
    printf "playground connector resume - ‚èØÔ∏è  Resume connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector resume [OPTIONS]\n"
  printf "  playground connector resume --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR (required)")"
    printf "    Connector name.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_delete_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector delete - üóëÔ∏è  Delete connector\n"
    echo

  else
    printf "playground connector delete - üóëÔ∏è  Delete connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector delete [OPTIONS]\n"
  printf "  playground connector delete --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR (required)")"
    printf "    Connector name.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_show_lag_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector show-lag - üê¢ Show lag of sink connector\n"
    echo

  else
    printf "playground connector show-lag - üê¢ Show lag of sink connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector show-lag [OPTIONS]\n"
  printf "  playground connector show-lag --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR (required)")"
    printf "    Connector name.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_log_level_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector log-level\n"
    echo

    printf "  üß¨ Set connect log level.\n  \n  üëâ Check documentation https://tinyurl.com/yc78tr8a\n"
    echo

  else
    printf "playground connector log-level - üß¨ Set connect log level.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector log-level COMMAND\n"
  printf "  playground connector log-level [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   Get log levels.\n" "$(green "get")"
  printf "  %s   Set log level for specific logger.\n" "$(green "set")"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground connect-log-level get\n"
    printf "  playground connect-log-level get -p io.confluent.connect.oracle.cdc\n"
    printf "  playground connect-log-level get --package io.confluent.connect.oracle.cdc\n"
    printf "  playground connect-log-level set -p\n  io.confluent.connect.oracle.cdc.logging.LogUtils -l TRACE\n"
    echo

  fi
}

# :command.usage
playground_connector_log_level_get_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector log-level get - Get log levels.\n"
    echo

  else
    printf "playground connector log-level get - Get log levels.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector log-level get [OPTIONS]\n"
  printf "  playground connector log-level get --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--package, -p PACKAGE")"
    printf "    Package name.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_log_level_set_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector log-level set - Set log level for specific logger.\n"
    echo

  else
    printf "playground connector log-level set - Set log level for specific logger.\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector log-level set [OPTIONS]\n"
  printf "  playground connector log-level set --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--package, -p PACKAGE (required)")"
    printf "    Package name.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--level, -l LEVEL (required)")"
    printf "    Log level.\n"
    printf "    Allowed: INFO, WARN, DEBUG, TRACE\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.normalize_input
normalize_input() {
  local arg flags

  while [[ $# -gt 0 ]]; do
    arg="$1"
    if [[ $arg =~ ^(--[a-zA-Z0-9_\-]+)=(.+)$ ]]; then
      input+=("${BASH_REMATCH[1]}")
      input+=("${BASH_REMATCH[2]}")
    elif [[ $arg =~ ^(-[a-zA-Z0-9])=(.+)$ ]]; then
      input+=("${BASH_REMATCH[1]}")
      input+=("${BASH_REMATCH[2]}")
    elif [[ $arg =~ ^-([a-zA-Z0-9][a-zA-Z0-9]+)$ ]]; then
      flags="${BASH_REMATCH[1]}"
      for ((i = 0; i < ${#flags}; i++)); do
        input+=("-${flags:i:1}")
      done
    else
      input+=("$arg")
    fi

    shift
  done
}
# :command.inspect_args
inspect_args() {
  if ((${#args[@]})); then
    readarray -t sorted_keys < <(printf '%s\n' "${!args[@]}" | sort)
    echo args:
    for k in "${sorted_keys[@]}"; do echo "- \${args[$k]} = ${args[$k]}"; done
  else
    echo args: none
  fi

  if ((${#other_args[@]})); then
    echo
    echo other_args:
    echo "- \${other_args[*]} = ${other_args[*]}"
    for i in "${!other_args[@]}"; do
      echo "- \${other_args[$i]} = ${other_args[$i]}"
    done
  fi

  if ((${#deps[@]})); then
    readarray -t sorted_keys < <(printf '%s\n' "${!deps[@]}" | sort)
    echo
    echo deps:
    for k in "${sorted_keys[@]}"; do echo "- \${deps[$k]} = ${deps[$k]}"; done
  fi

}

# :command.user_lib
# src/lib/cli_function.sh
function get_environment_used() {
  if [ ! -f /tmp/playground-command ]
  then
    echo "error"
    return
  fi

  grep "environment/2way-ssl" /tmp/playground-command > /dev/null
  if [ $? = 0 ]
  then
    echo "2way-ssl"
    return
  fi

  grep "environment/sasl-ssl" /tmp/playground-command > /dev/null
  if [ $? = 0 ]
  then
    echo "sasl-ssl"
    return
  fi

  grep "environment/rbac-sasl-plain" /tmp/playground-command > /dev/null
  if [ $? = 0 ]
  then
    echo "rbac-sasl-plain"
    return
  fi

  echo "plaintext"
}

function get_connect_url_and_security() {
  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi
  connect_url="http://localhost:8083"
  security=""
  if [[ "$environment" == *"ssl"* ]]
  then
      connect_url="https://localhost:8083"
      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

      security="--cert $DIR_CLI/../../environment/$environment/security/connect.certificate.pem --key $DIR_CLI/../../environment/$environment/security/connect.key --tlsv1.2 --cacert $DIR_CLI/../../environment/$environment/security/snakeoil-ca-1.crt"
  elif [[ "$environment" == "rbac-sasl-plain" ]]
  then
      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

      security="-u connectorSubmitter:connectorSubmitter"
  fi

  echo "$connect_url@$security"
}

function get_sr_url_and_security() {
  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  sr_url="http://localhost:8081"
  security_sr=""

  if [[ "$environment" == *"ssl"* ]]
  then
      sr_url="https://localhost:8081"
      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

      security="--cert $DIR_CLI/../../environment/$environment/security/schema-registry.certificate.pem --key $DIR_CLI/../../environment/$environment/security/schema-registry.key --tlsv1.2 --cacert $DIR_CLI/../../environment/$environment/security/snakeoil-ca-1.crt"
  elif [[ "$environment" == "rbac-sasl-plain" ]]
  then
      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

      security="-u superUser:superUser"
  fi

  echo "$sr_url@$security"
}

function get_security_broker() {
  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  security_broker=""
  if [ "$environment" != "plaintext" ]
  then
      security_broker="--command-config /etc/kafka/secrets/client_without_interceptors.config"
  fi
  echo "$security_broker"
}

function get_connector_list() {
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  curl $security -s "$connect_url/connectors" | jq -r '.[]'
}

function get_examples_list_with_fzf() {
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  dir2=$(echo ${dir1%/*})

  cur="$1"
  if [[ $(type -f bat 2>&1) =~ "not found" ]]
  then
    res=$(find $dir2 -name \*.sh ! -name 'stop.sh' ! -path '*/scripts/*' ! -path '*/docs-examples/*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-setup-scripts/*' | fzf --query "$cur" --delimiter / --with-nth '-3,-2,-1' --preview 'cat {}');echo "$cur@$res"
  else
    res=$(find $dir2 -name \*.sh ! -name 'stop.sh' ! -path '*/scripts/*' ! -path '*/docs-examples/*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-setup-scripts/*' | fzf --query "$cur" --delimiter / --with-nth '-3,-2,-1' --preview 'bat --style=numbers --color=always --line-range :500 {}');echo "$cur@$res"
  fi
}

function get_examples_list_with_fzf_without_repro() {
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  dir2=$(echo ${dir1%/*})

  cur="$1"
  if [[ $(type -f bat 2>&1) =~ "not found" ]]
  then
    res=$(find $dir2 -name \*.sh ! -name 'stop.sh' ! -path '*/scripts/*' ! -path '*/docs-examples/*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-setup-scripts/*' ! -path '*/reproduction-models/*' | fzf --query "$cur" --delimiter / --with-nth '-3,-2,-1' --preview 'cat {}');echo "$cur@$res"
  else
    res=$(find $dir2 -name \*.sh ! -name 'stop.sh' ! -path '*/scripts/*' ! -path '*/docs-examples/*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-setup-scripts/*' ! -path '*/reproduction-models/*' | fzf --query "$cur" --delimiter / --with-nth '-3,-2,-1' --preview 'bat --style=numbers --color=always --line-range :500 {}');echo "$cur@$res"
  fi
}

function get_examples_list_with_fzf_without_repro_sink_only() {
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  dir2=$(echo ${dir1%/*})

  cur="$1"
  if [[ $(type -f bat 2>&1) =~ "not found" ]]
  then
    res=$(find $dir2 -name \*.sh ! -name 'stop.sh' -path '*/connect-*-sink/*' ! -path '*/scripts/*' ! -path '*/docs-examples/*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-setup-scripts/*' ! -path '*/reproduction-models/*' | fzf --query "$cur" --delimiter / --with-nth '-3,-2,-1' --preview 'cat {}');echo "$cur@$res"
  else
    res=$(find $dir2 -name \*.sh ! -name 'stop.sh' -path '*/connect-*-sink/*' ! -path '*/scripts/*' ! -path '*/docs-examples/*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-setup-scripts/*' ! -path '*/reproduction-models/*' | fzf --query "$cur" --delimiter / --with-nth '-3,-2,-1' --preview 'bat --style=numbers --color=always --line-range :500 {}');echo "$cur@$res"
  fi
}

# src/lib/colors.sh
print_in_color() {
  local color="$1"
  shift
  if [[ -z ${NO_COLOR+x} ]]; then
    printf "$color%b\e[0m\n" "$*"
  else
    printf "%b\n" "$*"
  fi
}

red() { print_in_color "\e[31m" "$*"; }
green() { print_in_color "\e[32m" "$*"; }
yellow() { print_in_color "\e[33m" "$*"; }
blue() { print_in_color "\e[34m" "$*"; }
magenta() { print_in_color "\e[35m" "$*"; }
cyan() { print_in_color "\e[36m" "$*"; }
bold() { print_in_color "\e[1m" "$*"; }
underlined() { print_in_color "\e[4m" "$*"; }
red_bold() { print_in_color "\e[1;31m" "$*"; }
green_bold() { print_in_color "\e[1;32m" "$*"; }
yellow_bold() { print_in_color "\e[1;33m" "$*"; }
blue_bold() { print_in_color "\e[1;34m" "$*"; }
magenta_bold() { print_in_color "\e[1;35m" "$*"; }
cyan_bold() { print_in_color "\e[1;36m" "$*"; }
red_underlined() { print_in_color "\e[4;31m" "$*"; }
green_underlined() { print_in_color "\e[4;32m" "$*"; }
yellow_underlined() { print_in_color "\e[4;33m" "$*"; }
blue_underlined() { print_in_color "\e[4;34m" "$*"; }
magenta_underlined() { print_in_color "\e[4;35m" "$*"; }
cyan_underlined() { print_in_color "\e[4;36m" "$*"; }

# src/lib/heredocs.sh
function get_properties_command_heredoc () {
docker exec -i "$1" sh << EOF
ps -ef | grep properties | grep java | grep -v grep | awk '{ print \$NF }' > /tmp/propertie_file
propertie_file=\$(cat /tmp/propertie_file)
if [ ! -f \$propertie_file ]
then
  logerror 'ERROR: Could not determine properties file!'
  exit 1
fi
cat \$propertie_file | grep -v None | grep . | sort
EOF
}

function get_producer_heredoc () {
        cat << EOF >> $tmp_dir/producer

  $producer_hostname:
    build:
      context: ../../$output_folder/$final_dir/$producer_hostname/
    hostname: producer
    container_name: $producer_hostname
    environment:
      KAFKA_BOOTSTRAP_SERVERS: broker:9092
      TOPIC: "$topic_name"
      REPLICATION_FACTOR: 1
      NUMBER_OF_PARTITIONS: 1
      NB_MESSAGES: 10 # -1 for MAX_VALUE
      MESSAGE_BACKOFF: 100 # Frequency of message injection
      KAFKA_ACKS: "all" # default: "1"
      KAFKA_REQUEST_TIMEOUT_MS: 20000
      KAFKA_RETRY_BACKOFF_MS: 500
      KAFKA_CLIENT_ID: "my-java-$producer_hostname"
      KAFKA_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      JAVA_OPTS: \${GRAFANA_AGENT_PRODUCER}
    volumes:
      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/

EOF
}

function get_producer_ccloud_heredoc () {
        cat << EOF >> $tmp_dir/producer

  $producer_hostname:
    build:
      context: ../../$output_folder/$final_dir/$producer_hostname/
    hostname: producer
    container_name: $producer_hostname
    environment:
      KAFKA_BOOTSTRAP_SERVERS: \$BOOTSTRAP_SERVERS
      KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: "https"
      KAFKA_SASL_MECHANISM: "PLAIN"
      KAFKA_SASL_JAAS_CONFIG: \$SASL_JAAS_CONFIG
      KAFKA_SECURITY_PROTOCOL: "SASL_SSL"
      TOPIC: "$topic_name"
      REPLICATION_FACTOR: 3
      NUMBER_OF_PARTITIONS: 1
      NB_MESSAGES: 10 # -1 for MAX_VALUE
      MESSAGE_BACKOFF: 100 # Frequency of message injection
      KAFKA_ACKS: "all" # default: "1"
      KAFKA_REQUEST_TIMEOUT_MS: 20000
      KAFKA_RETRY_BACKOFF_MS: 500
      KAFKA_CLIENT_ID: "my-java-$producer_hostname"
      KAFKA_SCHEMA_REGISTRY_URL: \$SCHEMA_REGISTRY_URL
      KAFKA_BASIC_AUTH_CREDENTIALS_SOURCE: \$BASIC_AUTH_CREDENTIALS_SOURCE
      KAFKA_SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO: \$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO
      JAVA_OPTS: \${GRAFANA_AGENT_PRODUCER}
      EXTRA_ARGS:

    volumes:
      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/

EOF
}

function get_producer_build_heredoc () {
    cat << EOF > $tmp_dir/build_producer
for component in $list
do
    set +e
    log "üèó Building jar for \${component}"
    docker run -i --rm -e KAFKA_CLIENT_TAG=\$KAFKA_CLIENT_TAG -e TAG=\$TAG_BASE -v "\${DIR}/\${component}":/usr/src/mymaven -v "\$HOME/.m2":/root/.m2 -v "\${DIR}/\${component}/target:/usr/src/mymaven/target" -w /usr/src/mymaven maven:3.6.1-jdk-11 mvn -Dkafka.tag=\$TAG -Dkafka.client.tag=\$KAFKA_CLIENT_TAG package > /tmp/result.log 2>&1
    if [ \$? != 0 ]
    then
        logerror "ERROR: failed to build java component $component"
        tail -500 /tmp/result.log
        exit 1
    fi
    set -e
done

EOF
}

function get_producer_fixthis_heredoc () {
    cat << EOF >> $tmp_dir/java_producer
# üö®üö®üö® FIXTHIS: move it to the correct place üö®üö®üö®
EOF
}

function get_producer_run_heredoc () {
    cat << EOF >> $tmp_dir/java_producer
log "‚ú® Run the $schema_format java producer v$i which produces to topic $topic_name"
docker exec $producer_hostname bash -c "java \${JAVA_OPTS} -jar producer-1.0.0-jar-with-dependencies.jar"
EOF
}

function get_producer_run_heredoc () {
    cat << EOF >> $tmp_dir/java_producer
log "‚ú® Run the $schema_format java producer v$i which produces to topic $topic_name"
docker exec $producer_hostname bash -c "java \${JAVA_OPTS} -jar producer-1.0.0-jar-with-dependencies.jar"
EOF
}

function get_number_records_topic_command_heredoc () {
docker exec -i broker bash << EOF
kafka-run-class kafka.tools.GetOffsetShell --broker-list broker:9092 --topic "$1" --time -1 | awk -F ":" '{sum += \$3} END {print sum}'
EOF
}

function get_number_records_topic_command_heredoc_with_security () {
docker exec -i broker bash << EOF
kafka-run-class kafka.tools.GetOffsetShell --broker-list broker:9092 --command-config /etc/kafka/secrets/client_without_interceptors.config --topic "$1" --time -1 | awk -F ":" '{sum += \$3} END {print sum}'
EOF
}

function get_remote_debugging_command_heredoc () {
tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)
cat << EOF > $tmp_dir/docker-compose-remote-debugging.yml
version: '3.5'
services:
  $1:
    environment:
      # https://kafka-docker-playground.io/#/reusables?id=‚ú®-remote-debugging
      KAFKA_DEBUG: 'true'
      # With JDK9+, need to specify address=*:5005, see https://www.baeldung.com/java-application-remote-debugging#from-java9
      JAVA_DEBUG_OPTS: '-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=0.0.0.0:5005'
EOF

sed -e "s|up -d|-f $tmp_dir/docker-compose-remote-debugging.yml up -d|g" \
    /tmp/playground-command > /tmp/playground-command-debugging
}

function get_custom_smt_build_heredoc () {
    cat << EOF > $tmp_dir/build_custom_smt
for component in $custom_smt_name
do
    set +e
    log "üèó Building jar for \${component}"
    docker run -i --rm -e KAFKA_CLIENT_TAG=\$KAFKA_CLIENT_TAG -e TAG=\$TAG_BASE -v "\${DIR}/\${component}":/usr/src/mymaven -v "\$HOME/.m2":/root/.m2 -v "\${DIR}/\${component}/target:/usr/src/mymaven/target" -w /usr/src/mymaven maven:3.6.1-jdk-11 mvn -Dkafka.tag=\$TAG -Dkafka.client.tag=\$KAFKA_CLIENT_TAG package > /tmp/result.log 2>&1
    if [ \$? != 0 ]
    then
        logerror "ERROR: failed to build java component $component"
        tail -500 /tmp/result.log
        exit 1
    fi
    set -e
done

EOF
}

# src/lib/send_completions.sh
send_completions() {
  echo $'# playground completion                                    -*- shell-script -*-'
  echo $''
  echo $'# This bash completions script was generated by'
  echo $'# completely (https://github.com/dannyben/completely)'
  echo $'# Modifying it manually is not recommended'
  echo $''
  echo $'_playground_completions_filter() {'
  echo $'  local words="$1"'
  echo $'  local cur=${COMP_WORDS[COMP_CWORD]}'
  echo $'  local result=()'
  echo $''
  echo $'  if [[ "${cur:0:1}" == "-" ]]; then'
  echo $'    echo "$words"'
  echo $'  '
  echo $'  else'
  echo $'    for word in $words; do'
  echo $'      [[ "${word:0:1}" != "-" ]] && result+=("$word")'
  echo $'    done'
  echo $''
  echo $'    echo "${result[*]}"'
  echo $''
  echo $'  fi'
  echo $'}'
  echo $''
  echo $'_playground_completions() {'
  echo $'  local cur=${COMP_WORDS[COMP_CWORD]}'
  echo $'  local compwords=("${COMP_WORDS[@]:1:$COMP_CWORD-1}")'
  echo $'  local compline="${compwords[*]}"'
  echo $''
  echo $'  case "$compline" in'
  echo $'    \'recreate-container\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'get-properties\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h broker.* connect.* schema-registry.* zookeeper.*")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'completions\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'properties\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h broker.* connect.* schema-registry.* zookeeper.*")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'bootstrap\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -A file -W "$(_playground_completions_filter "--help -h avro avro-with-key json-schema json-schema-with-key none protobuf protobuf-with-key")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'recreate\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'boot\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -A file -W "$(_playground_completions_filter "--help -h avro avro-with-key json-schema json-schema-with-key none protobuf protobuf-with-key")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'get\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h broker.* connect.* schema-registry.* zookeeper.*")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'b\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -A file -W "$(_playground_completions_filter "--help -h avro avro-with-key json-schema json-schema-with-key none protobuf protobuf-with-key")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'g\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h broker.* connect.* schema-registry.* zookeeper.*")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'r\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    *)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help --version -h -v b boot bootstrap completions g get get-properties properties r recreate recreate-container")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'  esac'
  echo $'} &&'
  echo $'complete -F _playground_completions playground'
  echo $''
  echo $'# ex: filetype=sh'
}

# src/lib/utils_function.sh
function log() {
  YELLOW='\033[0;33m'
  NC='\033[0m' # No Color
  echo -e "$YELLOW`date +"%H:%M:%S"` ‚ÑπÔ∏è $@$NC"
}

function logerror() {
  RED='\033[0;31m'
  NC='\033[0m' # No Color
  echo -e "$RED`date +"%H:%M:%S"` üî• $@$NC"
}

function logwarn() {
  PURPLE='\033[0;35m'
  NC='\033[0m' # No Color
  echo -e "$PURPLE`date +"%H:%M:%S"` ‚ùó $@$NC"
}

function urlencode() {
  # https://gist.github.com/cdown/1163649
  # urlencode <string>

  old_lc_collate=$LC_COLLATE
  LC_COLLATE=C

  local length="${#1}"
  for (( i = 0; i < length; i++ )); do
      local c="${1:$i:1}"
      case $c in
          [a-zA-Z0-9.~_-]) printf '%s' "$c" ;;
          *) printf '%%%02X' "'$c" ;;
      esac
  done

  LC_COLLATE=$old_lc_collate
}

function jq() {
    if [[ $(type -f jq 2>&1) =~ "not found" ]]
    then
      docker run --rm -i imega/jq "$@"
    else
      $(which jq) "$@"
    fi
}

function yq() {
    if [[ $(type -f yq 2>&1) =~ "not found" ]]
    then
      docker run -u0 -v /tmp:/tmp --rm -i mikefarah/yq "$@"
    else
      $(which yq) "$@"
    fi
}

# https://stackoverflow.com/a/24067243
function version_gt() {
  test "$(printf '%s\n' "$@" | sort -V | head -n 1)" != "$1";
}

function set_kafka_client_tag()
{
    if [[ $TAG_BASE = 7.3.* ]]
    then
      export KAFKA_CLIENT_TAG="3.3.0"
    fi

    if [[ $TAG_BASE = 7.2.* ]]
    then
      export KAFKA_CLIENT_TAG="3.2.0"
    fi

    if [[ $TAG_BASE = 7.1.* ]]
    then
      export KAFKA_CLIENT_TAG="3.1.0"
    fi

    if [[ $TAG_BASE = 7.0.* ]]
    then
      export KAFKA_CLIENT_TAG="3.0.0"
    fi

    if [[ $TAG_BASE = 6.2.* ]]
    then
      export KAFKA_CLIENT_TAG="2.8.0"
    fi

    if [[ $TAG_BASE = 6.1.* ]]
    then
      export KAFKA_CLIENT_TAG="2.7.0"
    fi

    if [[ $TAG_BASE = 6.0.* ]]
    then
      export KAFKA_CLIENT_TAG="2.6.0"
    fi

    if [[ $TAG_BASE = 5.5.* ]]
    then
      export KAFKA_CLIENT_TAG="2.5.0"
    fi

    if [[ $TAG_BASE = 5.4.* ]]
    then
      export KAFKA_CLIENT_TAG="2.4.0"
    fi

    if [[ $TAG_BASE = 5.3.* ]]
    then
      export KAFKA_CLIENT_TAG="2.3.0"
    fi

    if [[ $TAG_BASE = 5.2.* ]]
    then
      export KAFKA_CLIENT_TAG="2.2.0"
    fi

    if [[ $TAG_BASE = 5.1.* ]]
    then
      export KAFKA_CLIENT_TAG="2.1.0"
    fi

    if [[ $TAG_BASE = 5.0.* ]]
    then
      export KAFKA_CLIENT_TAG="2.0.0"
    fi
}

function displaytime {
  local T=$1
  local D=$((T/60/60/24))
  local H=$((T/60/60%24))
  local M=$((T/60%60))
  local S=$((T%60))
  (( $D > 0 )) && printf '%d days ' $D
  (( $H > 0 )) && printf '%d hours ' $H
  (( $M > 0 )) && printf '%d minutes ' $M
  (( $D > 0 || $H > 0 || $M > 0 )) && printf 'and '
  printf '%d seconds\n' $S
}

function choosejar()
{
  log "Select the jar to replace:"
  select jar
  do
    # Check the selected menu jar number
    if [ 1 -le "$REPLY" ] && [ "$REPLY" -le $# ];
    then
      break;
    else
      logwarn "Wrong selection: select any number from 1-$#"
    fi
  done
}

function verify_installed()
{
  local cmd="$1"
  if [[ $(type $cmd 2>&1) =~ "not found" ]]; then
    echo -e "\nERROR: This script requires '$cmd'. Please install '$cmd' and run again.\n"
    exit 1
  fi
}

function verify_docker_and_memory()
{
  set +e
  docker info > /dev/null 2>&1
  if [[ $? -ne 0 ]]
  then
    logerror "Cannot connect to the Docker daemon. Is the docker daemon running?"
    exit 1
  fi
  set -e
  # Check only with Mac OS
  # if [[ "$OSTYPE" == "darwin"* ]]
  # then
  #   # Verify Docker memory is increased to at least 8GB
  #   DOCKER_MEMORY=$(docker system info | grep Memory | grep -o "[0-9\.]\+")
  #   if (( $(echo "$DOCKER_MEMORY 7.0" | awk '{print ($1 < $2)}') )); then
  #       logerror "WARNING: Did you remember to increase the memory available to Docker to at least 8GB (default is 2GB)? Demo may otherwise not work properly"
  #       exit 1
  #   fi
  # fi
  return 0
}

function verify_confluent_login()
{
  local cmd="$1"
  set +e
  output=$($cmd 2>&1)
  set -e
  if [ "${output}" = "Error: You must login to run that command." ] || [ "${output}" = "Error: Your session has expired. Please login again." ]; then
    logerror "This script requires confluent CLI to be logged in. Please execute 'confluent login' and run again."
    exit 1
  fi
}

function verify_confluent_details()
{
    if [ "$(confluent prompt -f "%E")" = "(none)" ]
    then
        logerror "confluent command is badly configured: environment is not set"
        logerror "Example: confluent kafka environment list"
        logerror "then: confluent kafka environment use <environment id>"
        exit 1
    fi

    if [ "$(confluent prompt -f "%K")" = "(none)" ]
    then
        logerror "confluent command is badly configured: cluster is not set"
        logerror "Example: confluent kafka cluster list"
        logerror "then: confluent kafka cluster use <cluster id>"
        exit 1
    fi

    if [ "$(confluent prompt -f "%a")" = "(none)" ]
    then
        logerror "confluent command is badly configured: api key is not set"
        logerror "Example: confluent api-key store <api key> <password>"
        logerror "then: confluent api-key use <api key>"
        exit 1
    fi

    CCLOUD_PROMPT_FMT='You will be using Confluent Cloud cluster with user={{fgcolor "green" "%u"}}, environment={{fgcolor "red" "%E"}}, cluster={{fgcolor "cyan" "%K"}}, api key={{fgcolor "yellow" "%a"}}'
    confluent prompt -f "$CCLOUD_PROMPT_FMT"
}

function check_if_continue()
{
    if [ ! -z "$CI" ] || [ ! -z "$CLOUDFORMATION" ]
    then
        # running with github actions or cloudformation, continue
        return
    fi
    read -p "Continue (y/n)?" choice
    case "$choice" in
    y|Y ) ;;
    n|N ) exit 1;;
    * ) logerror "invalid response!";exit 1;;
    esac
}

function really_check_if_continue()
{
    read -p "Continue (y/n)?" choice
    case "$choice" in
    y|Y ) ;;
    n|N ) exit 1;;
    * ) logerror "invalid response!";exit 1;;
    esac
}

function create_topic()
{
  local topic="$1"
  log "Check if topic $topic exists"
  confluent kafka topic create "$topic" --partitions 1 --dry-run 2>/dev/null
  if [[ $? == 0 ]]; then
    log "Create topic $topic"
    log "confluent kafka topic create $topic --partitions 1"
    confluent kafka topic create "$topic" --partitions 1 || true
  else
    log "Topic $topic already exists"
  fi
}

function delete_topic()
{
  local topic="$1"
  log "Check if topic $topic exists"
  confluent kafka topic create "$topic" --partitions 1 --dry-run 2>/dev/null
  if [[ $? != 0 ]]; then
    log "Delete topic $topic"
    log "confluent kafka topic delete $topic --force"
    confluent kafka topic delete "$topic" --force || true
  else
    log "Topic $topic does not exist"
  fi
}

function version_gt() {
  test "$(printf '%s\n' "$@" | sort -V | head -n 1)" != "$1";
}

function get_docker_compose_version() {
  docker-compose version | grep "^docker-compose version" | cut -d' ' -f3 | cut -d',' -f1
}

function check_docker_compose_version() {
  REQUIRED_DOCKER_COMPOSE_VER=${1:-"1.28.0"}
  DOCKER_COMPOSE_VER=$(get_docker_compose_version)

  if version_gt $REQUIRED_DOCKER_COMPOSE_VER $DOCKER_COMPOSE_VER; then
    log "docker-compose version ${REQUIRED_DOCKER_COMPOSE_VER} or greater is required.  Current reported version: ${DOCKER_COMPOSE_VER}"
    exit 1
  fi
}

function get_confluent_version() {
  confluent version | grep "^Version:" | cut -d':' -f2 | cut -d'v' -f2
}

function get_ansible_version() {
  ansible --version | grep "core" | cut -d'[' -f2 | cut -d']' -f1 | cut -d' ' -f 2
}

function check_confluent_version() {
  REQUIRED_CONFLUENT_VER=${1:-"3.0.0"}
  CONFLUENT_VER=$(get_confluent_version)

  if version_gt $REQUIRED_CONFLUENT_VER $CONFLUENT_VER; then
    log "confluent version ${REQUIRED_CONFLUENT_VER} or greater is required.  Current reported version: ${CONFLUENT_VER}"
    echo 'To update run: confluent update'
    exit 1
  fi
}

function container_to_ip() {
    name=$1
    echo $(docker exec $name hostname -I)
}

function block_host() {
    name=$1
    shift 1

    # https://serverfault.com/a/906499
    docker exec --privileged -t $name bash -c "tc qdisc add dev eth0 root handle 1: prio" 2>&1

    for ip in $@; do
        docker exec --privileged -t $name bash -c "tc filter add dev eth0 protocol ip parent 1: prio 1 u32 match ip dst $ip flowid 1:1" 2>&1
    done

    docker exec --privileged -t $name bash -c "tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip dst 0.0.0.0/0 flowid 1:2" 2>&1
    docker exec --privileged -t $name bash -c "tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip protocol 1 0xff flowid 1:2" 2>&1
    docker exec --privileged -t $name bash -c "tc qdisc add dev eth0 parent 1:1 handle 10: netem loss 100%" 2>&1
    docker exec --privileged -t $name bash -c "tc qdisc add dev eth0 parent 1:2 handle 20: sfq" 2>&1
}

function remove_partition() {
    for name in $@; do
        docker exec --privileged -t $name bash -c "tc qdisc del dev eth0 root"
    done
}

function aws() {

    if [ -z "$AWS_ACCESS_KEY_ID" ] && [ -z "$AWS_SECRET_ACCESS_KEY" ] && [ ! -f $HOME/.aws/config ] && [ ! -f $HOME/.aws/credentials ]
    then
      logerror 'ERROR: Neither AWS_ACCESS_KEY_ID/AWS_SECRET_ACCESS_KEY or $HOME/.aws/credentials are set. AWS credentials must be set !'
      if [ -z "$AWS_ACCESS_KEY_ID" ]
      then
        log 'AWS_ACCESS_KEY_ID environment variable is not set.'
      fi
      if [ -z "$AWS_SECRET_ACCESS_KEY" ]
      then
        log 'AWS_SECRET_ACCESS_KEY environment variable is not set.'
      fi
      if [ ! -f $HOME/.aws/credentials ]
      then
        log '$HOME/.aws/credentials does not exist.'
      fi
      return 1
    fi

    if [ ! -f $HOME/.aws/config ]
    then
          tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
cat << EOF > $tmp_dir/config
[default]
region = $AWS_REGION
EOF
    fi

    if [ ! -f $HOME/.aws/credentials ]
    then
      #log "Using aws cli with environment variables AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY"
      docker run --rm -iv $tmp_dir/config:/root/.aws/config -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY -v $(pwd):/aws -v /tmp:/tmp amazon/aws-cli "$@"
      rm -rf $tmp_dir
    else
      #log "Using aws cli with credentials file"
      docker run --rm -iv $HOME/.aws:/root/.aws -v $(pwd):/aws -v /tmp:/tmp amazon/aws-cli "$@"
    fi
}

function timeout() {
  if [[ $(type -f timeout 2>&1) =~ "not found" ]]; then
    # ignore
    shift
    eval "$@"
  else
    $(which timeout) "$@"
  fi
}

function az() {
    docker run -v /tmp:/tmp -v $HOME/.azure:/home/az/.azure -e HOME=/home/az --rm -i mcr.microsoft.com/azure-cli az "$@"
}

function display_docker_container_error_log() {
  logerror "####################################################"
  logerror "üê≥ docker ps"
  docker ps
  logerror "####################################################"
  for container in $(docker ps  --format="{{.Names}}")
  do
      logerror "####################################################"
      logerror "$container logs"
      if [[ "$container" == "connect" ]] || [[ "$container" == "sap" ]]
      then
          # always show all logs for connect
          docker container logs --tail=100 $container | grep -v "was supplied but isn't a known config"
      else
          docker container logs $container | egrep "ERROR|FATAL"
      fi
      logwarn "####################################################"
  done
}

function retry() {
  local n=1
  local max_retriable=4
  local max_default_retry=2
  while true; do
    "$@"
    ret=$?
    if [ $ret -eq 0 ]
    then
      return 0
    elif [ $ret -eq 111 ] # skipped
    then
      return 111
    elif [ $ret -eq 107 ] # known issue https://github.com/vdesabou/kafka-docker-playground/issues/907
    then
      return 107
    else
      script=$(echo "$@" | cut -d " " -f 2)
      # check for retriable scripts in scripts/tests-retriable.txt
      grep "$script" ${DIR}/tests-retriable.txt > /dev/null
      if [ $? = 0 ]
      then
        if [[ $n -lt $max_retriable ]]; then
          ((n++))
          logwarn "####################################################"
          logwarn "üßü‚Äç‚ôÇÔ∏è The test $script (retriable) has failed. Retrying (attempt $n/$max_retriable)"
          logwarn "####################################################"
          display_docker_container_error_log
        else
          logerror "üíÄ The test $script (retriable) has failed after $n attempts."
          return 1
        fi
      else
        if [[ $n -lt $max_default_retry ]]; then
          ((n++))
          logwarn "####################################################"
          logwarn "üé∞ The test $script (default_retry) has failed. Retrying (attempt $n/$max_default_retry)"
          logwarn "####################################################"
          display_docker_container_error_log
        else
          logerror "üíÄ The test $script (default_retry) has failed after $n attempts."
          return 1
        fi
      fi
    fi
  done
}

retrycmd() {
    local -r -i max_attempts="$1"; shift
    local -r -i sleep_interval="$1"; shift
    local -r cmd="$@"
    local -i attempt_num=1

    until $cmd
    do
        if (( attempt_num == max_attempts ))
        then
            display_docker_container_error_log
            logerror "Failed after $attempt_num attempts. Please troubleshoot and run again."
            return 1
        else
            printf "."
            ((attempt_num++))
            sleep $sleep_interval
        fi
    done
    printf "\n"
}

# for RBAC, taken from cp-demo
function host_check_kafka_cluster_registered() {
  KAFKA_CLUSTER_ID=$(docker container exec zookeeper zookeeper-shell zookeeper:2181 get /cluster/id 2> /dev/null | grep \"version\" | jq -r .id)
  if [ -z "$KAFKA_CLUSTER_ID" ]; then
    return 1
  fi
  echo $KAFKA_CLUSTER_ID
  return 0
}

# for RBAC, taken from cp-demo
function host_check_mds_up() {
  docker container logs broker > /tmp/out.txt 2>&1
  FOUND=$(cat /tmp/out.txt | grep "Started NetworkTrafficServerConnector")
  if [ -z "$FOUND" ]; then
    return 1
  fi
  return 0
}

# for RBAC, taken from cp-demo
function mds_login() {
  MDS_URL=$1
  SUPER_USER=$2
  SUPER_USER_PASSWORD=$3

  # Log into MDS
  if [[ $(type expect 2>&1) =~ "not found" ]]; then
    echo "'expect' is not found. Install 'expect' and try again"
    exit 1
  fi
  echo -e "\n# Login"
  OUTPUT=$(
  expect <<END
    log_user 1
    spawn confluent login --url $MDS_URL
    expect "Username: "
    send "${SUPER_USER}\r";
    expect "Password: "
    send "${SUPER_USER_PASSWORD}\r";
    expect "Logged in as "
    set result $expect_out(buffer)
END
  )
  echo "$OUTPUT"
  if [[ ! "$OUTPUT" =~ "Logged in as" ]]; then
    echo "Failed to log into MDS.  Please check all parameters and run again"
    exit 1
  fi
}

# https://raw.githubusercontent.com/zlabjp/kubernetes-scripts/master/wait-until-pods-ready

function __is_pod_ready() {
  [[ "$(kubectl get po "$1" -n $namespace -o 'jsonpath={.status.conditions[?(@.type=="Ready")].status}')" == 'True' ]]
}

function __pods_ready() {
  local pod

  [[ "$#" == 0 ]] && return 0

  for pod in $pods; do
    __is_pod_ready "$pod" || return 1
  done

  return 0
}

function wait-until-pods-ready() {
  local period interval i pods

  if [[ $# != 3 ]]; then
    echo "Usage: wait-until-pods-ready PERIOD INTERVAL NAMESPACE" >&2
    echo "" >&2
    echo "This script waits for all pods to be ready in the current namespace." >&2

    return 1
  fi

  period="$1"
  interval="$2"
  namespace="$3"

  sleep 10

  for ((i=0; i<$period; i+=$interval)); do
    pods="$(kubectl get po -n $namespace -o 'jsonpath={.items[*].metadata.name}')"
    if __pods_ready $pods; then
      return 0
    fi

    echo "Waiting for pods to be ready..."
    sleep "$interval"
  done

  echo "Waited for $period seconds, but all pods are not ready yet."
  return 1
}

function wait_for_datagen_connector_to_inject_data () {
  sleep 3
  connector_name="$1"
  datagen_tasks="$2"
  prefix_cmd="$3"
  set +e
  # wait for all tasks to be FAILED with org.apache.kafka.connect.errors.ConnectException: Stopping connector: generated the configured xxx number of messages
  MAX_WAIT=3600
  CUR_WAIT=0
  log "‚åõ Waiting up to $MAX_WAIT seconds for connector $connector_name to finish injecting requested load"
  $prefix_cmd curl -s -X GET http://localhost:8083/connectors/datagen-${connector_name}/status | jq .tasks[].trace | grep "generated the configured" | wc -l > /tmp/out.txt 2>&1
  while [[ ! $(cat /tmp/out.txt) =~ "${datagen_tasks}" ]]; do
    sleep 5
    $prefix_cmd curl -s -X GET http://localhost:8083/connectors/datagen-${connector_name}/status | jq .tasks[].trace | grep "generated the configured" | wc -l > /tmp/out.txt 2>&1
    CUR_WAIT=$(( CUR_WAIT+10 ))
    if [[ "$CUR_WAIT" -gt "$MAX_WAIT" ]]; then
      echo -e "\nERROR: Please troubleshoot'.\n"
      $prefix_cmd curl -s -X GET http://localhost:8083/connectors/datagen-${connector_name}/status | jq
      exit 1
    fi
  done
  log "Connector $connector_name has finish injecting requested load"
  set -e
}

# https://gist.github.com/Fuxy22/da4b7ca3bcb0bfea2c582964eafeb4ed
# remove specified host from /etc/hosts
function removehost() {
    if [ ! -z "$1" ]
    then
        HOSTNAME=$1

        if [ -n "$(grep $HOSTNAME /etc/hosts)" ]
        then
            echo "$HOSTNAME Found in your /etc/hosts, Removing now...";
            sudo sed -i".bak" "/$HOSTNAME/d" /etc/hosts
        else
            echo "$HOSTNAME was not found in your /etc/hosts";
        fi
    else
        echo "Error: missing required parameters."
        echo "Usage: "
        echo "  removehost domain"
    fi
}

# https://gist.github.com/Fuxy22/da4b7ca3bcb0bfea2c582964eafeb4ed
#add new ip host pair to /etc/hosts
function addhost() {
    if [ $# -eq 2 ]
    then
        IP=$1
        HOSTNAME=$2

        if [ -n "$(grep $HOSTNAME /etc/hosts)" ]
            then
                echo "$HOSTNAME already exists:";
                echo $(grep $HOSTNAME /etc/hosts);
            else
                echo "Adding $HOSTNAME to your /etc/hosts";
                printf "%s\t%s\n" "$IP" "$HOSTNAME" | sudo tee -a /etc/hosts > /dev/null;

                if [ -n "$(grep $HOSTNAME /etc/hosts)" ]
                    then
                        echo "$HOSTNAME was added succesfully:";
                        echo $(grep $HOSTNAME /etc/hosts);
                    else
                        echo "Failed to Add $HOSTNAME, Try again!";
                fi
        fi
    else
        echo "Error: missing required parameters."
        echo "Usage: "
        echo "  addhost ip domain"
    fi
}

function stop_all() {
  current_dir="$1"
  cd ${current_dir}
  if ls docker-compose.* 1> /dev/null 2>&1;
  then
    for docker_compose_file in $(ls docker-compose.*)
    do
        environment=$(echo $docker_compose_file | cut -d "." -f 2)
        ${DIR}/../../environment/${environment}/stop.sh "${PWD}/${docker_compose_file}"
    done
  else
    ${DIR}/../../environment/plaintext/stop.sh
  fi
  cd -
}

function display_jmx_info() {
  if [ -z "$ENABLE_JMX_GRAFANA" ]
  then
    log "üìä JMX metrics are available locally on those ports:"
  else
    log "üìä Grafana is reachable at http://127.0.0.1:3000 or JMX metrics are available locally on those ports:"
  fi

  log "    - zookeeper       : 9999"
  log "    - broker          : 10000"
  log "    - schema-registry : 10001"
  log "    - connect         : 10002"

  if [ -z "$DISABLE_KSQLDB" ]
  then
    log "    - ksqldb-server   : 10003"
  fi

}
function get_jmx_metrics() {
  JMXTERM_VERSION="1.0.2"
  JMXTERM_UBER_JAR="/tmp/jmxterm-$JMXTERM_VERSION-uber.jar"
  if [ ! -f $JMXTERM_UBER_JAR ]
  then
    curl -L https://github.com/jiaqi/jmxterm/releases/download/v$JMXTERM_VERSION/jmxterm-$JMXTERM_VERSION-uber.jar -o $JMXTERM_UBER_JAR -s
  fi

  rm -f /tmp/commands
  rm -f /tmp/jmx_metrics.log

  component="$1"
  domains="$2"
  if [ "$domains" = "" ]
  then
    # non existing domain: all domains will be in output !
    logwarn "You did not specify a list of domains, all domains will be exported!"
    domains="ALL"
  fi

  case "$component" in
  zookeeper )
    port=9999
  ;;
  broker )
    port=10000
  ;;
  schema-registry )
    port=10001
  ;;
  connect )
    port=10002
  ;;
  n|N ) ;;
  * ) logerror "invalid component $component! it should be one of zookeeper, broker, schema-registry or connect";exit 1;;
  esac

  docker cp $JMXTERM_UBER_JAR $component:$JMXTERM_UBER_JAR
  if [ "$domains" = "ALL" ]
  then

log "This is the list of domains for component $component"
docker exec -i $component java -jar $JMXTERM_UBER_JAR  -l localhost:$port -n -v silent << EOF
domains
exit
EOF
  fi

for domain in `echo $domains`
do
docker exec -i $component java -jar $JMXTERM_UBER_JAR  -l localhost:$port -n -v silent > /tmp/beans.log << EOF
domain $domain
beans
exit
EOF
  while read line; do echo "get *"  -b $line; done < /tmp/beans.log >> /tmp/commands

  echo "####### domain $domain ########" >> /tmp/jmx_metrics.log
  docker exec -i $component java -jar $JMXTERM_UBER_JAR  -l localhost:$port -n < /tmp/commands >> /tmp/jmx_metrics.log 2>&1
done

  log "JMX metrics are available in /tmp/jmx_metrics.log file"
}

# https://www.linuxjournal.com/content/validating-ip-address-bash-script
function valid_ip()
{
    local  ip=$1
    local  stat=1

    if [[ $ip =~ ^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$ ]]; then
        OIFS=$IFS
        IFS='.'
        ip=($ip)
        IFS=$OIFS
        [[ ${ip[0]} -le 255 && ${ip[1]} -le 255 \
            && ${ip[2]} -le 255 && ${ip[3]} -le 255 ]]
        stat=$?
    fi
    return $stat
}

function container_to_name() {
    container=$1
    echo "${PWD##*/}_${container}_1"
}

function container_to_ip() {
    if [ $# -lt 1 ]; then
        echo "Usage: container_to_ip container"
    fi
    echo $(docker inspect $1 -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}')
}

function clear_traffic_control() {
    if [ $# -lt 1 ]; then
        echo "Usage: clear_traffic_control src_container"
    fi

    src_container=$1

    echo "Removing all traffic control settings on $src_container"

    # Delete the entry from the tc table so the changes made to tc do not persist
    docker exec --privileged -u0 -t $src_container tc qdisc del dev eth0 root
}

function get_latency() {
    if [ $# -lt 2 ]; then
        echo "Usage: get_latency src_container dst_container"
    fi
    src_container=$1
    dst_container=$2
    docker exec --privileged -u0 -t $src_container ping $dst_container -c 4 -W 80 | tail -1 | awk -F '/' '{print $5}'
}

# https://serverfault.com/a/906499
function add_latency() {
    if [ $# -lt 3 ]; then
        echo "Usage: add_latency src_container dst_container (or ip address) latency"
        echo "Example: add_latency container-1 container-2 100ms"
    fi

    src_container=$1
    if valid_ip $2
    then

      dst_ip=$2
    else

      dst_ip=$(container_to_ip $2)
    fi
    latency=$3

    set +e
    clear_traffic_control $src_container
    set -e

    echo "Adding $latency latency from $src_container to $2"

    # Add a classful priority queue which lets us differentiate messages.
    # This queue is named 1:.
    # Three children classes, 1:1, 1:2 and 1:3, are automatically created.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 root handle 1: prio

    # Add a filter to the parent queue 1: (also called 1:0). The filter has priority 1 (if we had more filters this would make a difference).
    # For all messages with the ip of dst_ip as their destination, it routes them to class 1:1, which
    # subsequently sends them to its only child, queue 10: (All messages need to  "end up" in a queue).
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol ip parent 1: prio 1 u32 match ip dst $dst_ip flowid 1:1

    # Route the rest of the of the packets without any control.
    # Add a filter to the parent queue 1:. The filter has priority 2.
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip dst 0.0.0.0/0 flowid 1:2
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip protocol 1 0xff flowid 1:2

    # Add a child queue named 10: under class 1:1. All outgoing packets that will be routed to 10: will have delay applied them.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:1 handle 10: netem delay $latency

    # Add a child queue named 20: under class 1:2
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:2 handle 20: sfq
}

function add_packet_corruption() {
    if [ $# -lt 3 ]; then
        echo "Usage: add_packet_corruption src_container dst_container (or ip address) corrupt"
        echo "Exemple: add_packet_corruption container-1 container-2 1%"
    fi

    src_container=$1
    if valid_ip $2
    then

      dst_ip=$2
    else

      dst_ip=$(container_to_ip $2)
    fi
    corruption=$3

    set +e
    clear_traffic_control $src_container
    set -e

    echo "Adding $corruption corruption from $src_container to $2"

    # Add a classful priority queue which lets us differentiate messages.
    # This queue is named 1:.
    # Three children classes, 1:1, 1:2 and 1:3, are automatically created.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 root handle 1: prio

    # Add a filter to the parent queue 1: (also called 1:0). The filter has priority 1 (if we had more filters this would make a difference).
    # For all messages with the ip of dst_ip as their destination, it routes them to class 1:1, which
    # subsequently sends them to its only child, queue 10: (All messages need to  "end up" in a queue).
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol ip parent 1: prio 1 u32 match ip dst $dst_ip flowid 1:1

    # Route the rest of the of the packets without any control.
    # Add a filter to the parent queue 1:. The filter has priority 2.
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip dst 0.0.0.0/0 flowid 1:2

    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip protocol 1 0xff flowid 1:2

    # Add a child queue named 10: under class 1:1. All outgoing packets that will be routed to 10: will have corrupt applied them.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:1 handle 10: netem corrupt $corruption

    # Add a child queue named 20: under class 1:2
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:2 handle 20: sfq

}

function add_packet_loss() {
    if [ $# -lt 3 ]; then
        echo "Usage: add_packet_loss src_container dst_container (or ip address) corrupt"
        echo "Exemple: add_packet_loss container-1 container-2 1%"
    fi

    src_container=$1
    if valid_ip $2
    then

      dst_ip=$2
    else

      dst_ip=$(container_to_ip $2)
    fi
    loss=$3

    set +e
    clear_traffic_control $src_container
    set -e

    echo "Adding $loss loss from $src_container to $2"

    # Add a classful priority queue which lets us differentiate messages.
    # This queue is named 1:.
    # Three children classes, 1:1, 1:2 and 1:3, are automatically created.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 root handle 1: prio

    # Add a filter to the parent queue 1: (also called 1:0). The filter has priority 1 (if we had more filters this would make a difference).
    # For all messages with the ip of dst_ip as their destination, it routes them to class 1:1, which
    # subsequently sends them to its only child, queue 10: (All messages need to  "end up" in a queue).
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol ip parent 1: prio 1 u32 match ip dst $dst_ip flowid 1:1

    # Route the rest of the of the packets without any control.
    # Add a filter to the parent queue 1:. The filter has priority 2.
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip dst 0.0.0.0/0 flowid 1:2

    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip protocol 1 0xff flowid 1:2

    # Add a child queue named 10: under class 1:1. All outgoing packets that will be routed to 10: will have loss applied them.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:1 handle 10: netem loss $loss

    # Add a child queue named 20: under class 1:2
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:2 handle 20: sfq

}

function get_3rdparty_file () {
  file="$1"

  if [ -f $file ]
  then
    log "$file already present, skipping"
    return
  fi

  folder="3rdparty"
  if [[ "$file" == *repro* ]]
  then
    folder="repro-files"
  fi
  set +e
  aws s3 ls s3://kafka-docker-playground/$folder/$file > /dev/null 2>&1
  if [ $? -eq 0 ]
  then
      log "Downloading <s3://kafka-docker-playground/$folder/$file> from S3 bucket"
      aws s3 cp --only-show-errors "s3://kafka-docker-playground/$folder/$file" .
      if [ $? -eq 0 ]; then
        log "üìÑ <s3://kafka-docker-playground/$folder/$file> was downloaded from S3 bucket"
      fi
      if [[ "$OSTYPE" == "darwin"* ]]
      then
          # workaround for issue on linux, see https://github.com/vdesabou/kafka-docker-playground/issues/851#issuecomment-821151962
          chmod a+rw $file
      else
          # on CI, docker is run as runneradmin user, need to use sudo
          sudo chmod a+rw $file
      fi
  fi
  set -e
}

function remove_cdb_oracle_image() {
  ZIP_FILE="$1"
  SETUP_FOLDER="$2"

  if [ "$ZIP_FILE" == "linuxx64_12201_database.zip" ]
  then
      ORACLE_VERSION="12.2.0.1-ee"
  elif [ "$ZIP_FILE" == "LINUX.X64_180000_db_home.zip" ]
  then
      ORACLE_VERSION="18.3.0-ee"
  elif [ "$ZIP_FILE" == "LINUX.X64_213000_db_home.zip" ]
  then
      ORACLE_VERSION="21.3.0-ee"
  else
      ORACLE_VERSION="19.3.0-ee"
  fi

  SETUP_FILE=${SETUP_FOLDER}/01_user-setup.sh
  SETUP_FILE_CKSUM=$(cksum $SETUP_FILE | awk '{ print $1 }')
  ORACLE_IMAGE="db-prebuilt-$SETUP_FILE_CKSUM:$ORACLE_VERSION"

  if ! test -z "$(docker images -q $ORACLE_IMAGE)"
  then
    log "üßπ Removing Oracle image $ORACLE_IMAGE"
    docker image rm $ORACLE_IMAGE
  fi
}

function create_or_get_oracle_image() {
  ZIP_FILE="$1"
  SETUP_FOLDER="$2"

  if [ "$ZIP_FILE" == "linuxx64_12201_database.zip" ]
  then
      ORACLE_VERSION="12.2.0.1-ee"
  elif [ "$ZIP_FILE" == "LINUX.X64_180000_db_home.zip" ]
  then
      ORACLE_VERSION="18.3.0-ee"
  elif [ "$ZIP_FILE" == "LINUX.X64_213000_db_home.zip" ]
  then
      ORACLE_VERSION="21.3.0-ee"
  else
      ORACLE_VERSION="19.3.0-ee"
  fi
  # used for docker-images repo
  DOCKERFILE_VERSION=$(echo "$ORACLE_VERSION" | cut -d "-" -f 1)

  # https://github.com/oracle/docker-images/tree/main/OracleDatabase/SingleInstance/samples/prebuiltdb
  SETUP_FILE=${SETUP_FOLDER}/01_user-setup.sh
  SETUP_FILE_CKSUM=$(cksum $SETUP_FILE | awk '{ print $1 }')
  export ORACLE_IMAGE="db-prebuilt-$SETUP_FILE_CKSUM:$ORACLE_VERSION"
  TEMP_CONTAINER="oracle-build-$ORACLE_VERSION-$(basename $SETUP_FOLDER)"

  if test -z "$(docker images -q $ORACLE_IMAGE)"
  then
    set +e
    aws s3 ls s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar > /dev/null 2>&1
    if [ $? -eq 0 ]
    then
        log "Downloading <s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar> from S3 bucket"
        aws s3 cp --only-show-errors "s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar" /tmp/
        if [ $? -eq 0 ]
        then
          log "üìÑ <s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar> was downloaded from S3 bucket"
          docker load -i /tmp/$ORACLE_IMAGE.tar
          if [ $? -eq 0 ]
          then
            log "üìÑ image $ORACLE_IMAGE has been installed locally"
          fi
          log "üßπ Removing /tmp/$ORACLE_IMAGE.tar"
          rm -f /tmp/$ORACLE_IMAGE.tar
        fi
    else
        logwarn "If you're a Confluent employee, please check this link https://confluent.slack.com/archives/C0116NM415F/p1636391410032900 and also here https://confluent.slack.com/archives/C0116NM415F/p1636389483030900."
    fi
    set -e
  fi

  if ! test -z "$(docker images -q $ORACLE_IMAGE)"
  then
    log "‚ú® Using Oracle prebuilt image $ORACLE_IMAGE (oracle version üî¢ $ORACLE_VERSION and üìÇ setup folder $SETUP_FOLDER)"
    return
  fi

  BASE_ORACLE_IMAGE="oracle/database:$ORACLE_VERSION"

  if test -z "$(docker images -q $BASE_ORACLE_IMAGE)"
  then
    set +e
    aws s3 ls s3://kafka-docker-playground/3rdparty/oracle_database_$ORACLE_VERSION.tar > /dev/null 2>&1
    if [ $? -eq 0 ]
    then
        log "Downloading <s3://kafka-docker-playground/3rdparty/oracle_database_$ORACLE_VERSION.tar> from S3 bucket"
        aws s3 cp --only-show-errors "s3://kafka-docker-playground/3rdparty/oracle_database_$ORACLE_VERSION.tar" /tmp/
        if [ $? -eq 0 ]
        then
          log "üìÑ <s3://kafka-docker-playground/3rdparty/oracle_database_$ORACLE_VERSION.tar> was downloaded from S3 bucket"
          docker load -i /tmp/oracle_database_$ORACLE_VERSION.tar
          if [ $? -eq 0 ]
          then
            log "üìÑ image $BASE_ORACLE_IMAGE has been installed locally"
          fi
          log "üßπ Removing /tmp/$ORACLE_IMAGE.tar"
          rm -f /tmp/oracle_database_$ORACLE_VERSION.tar
        fi
    fi
    set -e
  fi

  if test -z "$(docker images -q $BASE_ORACLE_IMAGE)"
  then
      if [ ! -f ${ZIP_FILE} ]
      then
          set +e
          aws s3 ls s3://kafka-docker-playground/3rdparty/${ZIP_FILE} > /dev/null 2>&1
          if [ $? -eq 0 ]
          then
              log "Downloading <s3://kafka-docker-playground/3rdparty/${ZIP_FILE}> from S3 bucket"
              aws s3 cp --only-show-errors "s3://kafka-docker-playground/3rdparty/${ZIP_FILE}" .
              if [ $? -eq 0 ]; then
                    log "üìÑ <s3://kafka-docker-playground/3rdparty/${ZIP_FILE}> was downloaded from S3 bucket"
              fi
          fi
          set -e
      fi
      if [ ! -f ${ZIP_FILE} ]
      then
          logerror "ERROR: ${ZIP_FILE} is missing. It must be downloaded manually in order to acknowledge user agreement"
          exit 1
      fi
      log "üë∑ Building $BASE_ORACLE_IMAGE docker image..it can take a while...(more than 15 minutes!)"
      OLDDIR=$PWD
      rm -rf docker-images
      git clone https://github.com/oracle/docker-images.git

      mv ${ZIP_FILE} docker-images/OracleDatabase/SingleInstance/dockerfiles/$DOCKERFILE_VERSION/${ZIP_FILE}
      cd docker-images/OracleDatabase/SingleInstance/dockerfiles
      ./buildContainerImage.sh -v $DOCKERFILE_VERSION -e
      rm -rf docker-images
      cd ${OLDDIR}
  fi

  export ORACLE_IMAGE="db-prebuilt-$SETUP_FILE_CKSUM:$ORACLE_VERSION"

  if test -z "$(docker images -q $ORACLE_IMAGE)"
  then
      log "üè≠ Prebuilt $ORACLE_IMAGE docker image does not exist, building it now..it can take a while..."
      log "üö¶ Startup a container ${TEMP_CONTAINER} with setup folder $SETUP_FOLDER and create the database"
      cd $SETUP_FOLDER
      docker run -d -e ORACLE_PWD=Admin123 -v $PWD:/opt/oracle/scripts/setup --name ${TEMP_CONTAINER} ${BASE_ORACLE_IMAGE}
      cd -

      MAX_WAIT=2500
      CUR_WAIT=0
      log "‚åõ Waiting up to $MAX_WAIT seconds for ${TEMP_CONTAINER} to start"
      docker container logs ${TEMP_CONTAINER} > /tmp/out.txt 2>&1
      while [[ ! $(cat /tmp/out.txt) =~ "DATABASE IS READY TO USE" ]]; do
      sleep 10
      docker container logs ${TEMP_CONTAINER} > /tmp/out.txt 2>&1
      CUR_WAIT=$(( CUR_WAIT+10 ))
      if [[ "$CUR_WAIT" -gt "$MAX_WAIT" ]]; then
            logerror "ERROR: The logs in ${TEMP_CONTAINER} container do not show 'DATABASE IS READY TO USE' after $MAX_WAIT seconds. Please troubleshoot with 'docker container ps' and 'docker container logs'.\n"
            exit 1
      fi
      done
      log "${TEMP_CONTAINER} has started! Check logs in /tmp/${TEMP_CONTAINER}.log"
      docker container logs ${TEMP_CONTAINER} > /tmp/${TEMP_CONTAINER}.log 2>&1
      log "üõë Stop the running container"
      docker stop -t 600 ${TEMP_CONTAINER}
      log "üõ† Create the image with the prebuilt database"
      docker commit -m "Image with prebuilt database" ${TEMP_CONTAINER} ${ORACLE_IMAGE}
      log "üßπ Clean up ${TEMP_CONTAINER}"
      docker rm ${TEMP_CONTAINER}

      if [ ! -z "$CI" ]
      then
          set +e
          aws s3 ls s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar > /dev/null 2>&1
          if [ $? -ne 0 ]
          then
              log "üìÑ Uploading </tmp/$ORACLE_IMAGE.tar> to S3 bucket"
              docker save -o /tmp/$ORACLE_IMAGE.tar $ORACLE_IMAGE
              aws s3 cp --only-show-errors "/tmp/$ORACLE_IMAGE.tar" "s3://kafka-docker-playground/3rdparty/"
              if [ $? -eq 0 ]; then
                    log "üìÑ </tmp/$ORACLE_IMAGE.tar> was uploaded to S3 bucket"
              fi
          fi
          set -e
      fi
  fi

  log "‚ú® Using Oracle prebuilt image $ORACLE_IMAGE (oracle version üî¢ $ORACLE_VERSION and üìÇ setup folder $SETUP_FOLDER)"
}

function print_code_pass() {
  local MESSAGE=""
	local CODE=""
  OPTIND=1
  while getopts ":c:m:" opt; do
    case ${opt} in
			c ) CODE=${OPTARG};;
      m ) MESSAGE=${OPTARG};;
		esac
	done
  shift $((OPTIND-1))
	printf "${PRETTY_PASS}${PRETTY_CODE}%s\e[0m\n" "${CODE}"
	[[ -z "$MESSAGE" ]] || printf "\t$MESSAGE\n"

}
function print_code_error() {
  local MESSAGE=""
	local CODE=""
  OPTIND=1
  while getopts ":c:m:" opt; do
    case ${opt} in
			c ) CODE=${OPTARG};;
      m ) MESSAGE=${OPTARG};;
		esac
	done
  shift $((OPTIND-1))
	printf "${PRETTY_ERROR}${PRETTY_CODE}%s\e[0m\n" "${CODE}"
	[[ -z "$MESSAGE" ]] || printf "\t$MESSAGE\n"

}

function exit_with_error()
{
  local USAGE="\nUsage: exit_with_error -c code -n name -m message -l line_number\n"
  local NAME=""
  local MESSAGE=""
  local CODE=$UNSPECIFIED_ERROR
  local LINE=
  OPTIND=1
  while getopts ":n:m:c:l:" opt; do
    case ${opt} in
      n ) NAME=${OPTARG};;
      m ) MESSAGE=${OPTARG};;
      c ) CODE=${OPTARG};;
      l ) LINE=${OPTARG};;
      ? ) printf $USAGE;return 1;;
    esac
  done
  shift $((OPTIND-1))
  print_error "error ${CODE} occurred in ${NAME} at line $LINE"
	printf "\t${MESSAGE}\n"
  exit $CODE
}

function maybe_delete_ccloud_environment () {
  DELTA_CONFIGS_ENV=/tmp/delta_configs/env.delta

  if [ -f $DELTA_CONFIGS_ENV ]
  then
    source $DELTA_CONFIGS_ENV
  else
    logerror "ERROR: $DELTA_CONFIGS_ENV has not been generated"
    exit 1
  fi

  if [ -z "$CLUSTER_NAME" ]
  then
    #

    # CLUSTER_NAME is not set
    #
    log "üßπ‚ùå Confluent Cloud cluster will be deleted..."
    verify_installed "confluent"
    check_confluent_version 2.0.0 || exit 1
    verify_confluent_login  "confluent kafka cluster list"

    export QUIET=true

    if [ ! -z "$ENVIRONMENT" ]
    then
      log "üåê ENVIRONMENT $ENVIRONMENT is set, it will not be deleted"
      export PRESERVE_ENVIRONMENT=true
    else
      export PRESERVE_ENVIRONMENT=false
    fi
    SERVICE_ACCOUNT_ID=$(ccloud:get_service_account_from_current_cluster_name)
    set +e
    ccloud::destroy_ccloud_stack $SERVICE_ACCOUNT_ID
    set -e
  fi
}

function bootstrap_ccloud_environment () {
  DELTA_CONFIGS_ENV=/tmp/delta_configs/env.delta

  if [ -z "$CI" ] && [ -z "$CLOUDFORMATION" ]
  then
    # not running with CI
    verify_installed "confluent"
    check_confluent_version 3.0.0 || exit 1
    verify_confluent_login  "confluent kafka cluster list"
  else
      log "Installing confluent CLI"
      curl -L --http1.1 https://cnfl.io/cli | sudo sh -s -- -b /usr/local/bin
      export PATH=$PATH:/usr/local/bin
      log "##################################################"
      log "Log in to Confluent Cloud"
      log "##################################################"
      confluent login --save
  fi

  if [ -z "$CLUSTER_NAME" ]
  then
    #

    # CLUSTER_NAME is not set
    #
    log "üõ†üë∑‚Äç‚ôÄÔ∏è CLUSTER_NAME is not set, a new Confluent Cloud cluster will be created..."
    log "üéì If you wanted to use an existing cluster, set CLUSTER_NAME, ENVIRONMENT, CLUSTER_CLOUD, CLUSTER_REGION and CLUSTER_CREDS (also optionnaly SCHEMA_REGISTRY_CREDS)"

    if [ -z "$CLUSTER_CLOUD" ] || [ -z "$CLUSTER_REGION" ]
    then
      logwarn "CLUSTER_CLOUD and/or CLUSTER_REGION are not set, the cluster will be created üå§ AWS provider and üó∫ eu-west-2 region"
      export CLUSTER_CLOUD=aws

      export CLUSTER_REGION=eu-west-2
    fi

    if [ ! -z $ENVIRONMENT ]
    then
      log "üåê ENVIRONMENT is set with $ENVIRONMENT and will be used"
    fi
    log "üå§  CLUSTER_CLOUD is set with $CLUSTER_CLOUD"
    log "üó∫  CLUSTER_REGION is set with $CLUSTER_REGION"

    export EXAMPLE=$(basename $PWD)
    export WARMUP_TIME=15
    export QUIET=true
  else
    #

    # CLUSTER_NAME is set
    #
    log "üå± CLUSTER_NAME is set, your existing Confluent Cloud cluster will be used..."
    if [ -z $ENVIRONMENT ] || [ -z $CLUSTER_CLOUD ] || [ -z $CLUSTER_CLOUD ] || [ -z $CLUSTER_REGION ] || [ -z $CLUSTER_CREDS ]
    then
      logerror "One mandatory environment variable to use your cluster is missing:"
      logerror "ENVIRONMENT=$ENVIRONMENT"
      logerror "CLUSTER_NAME=$CLUSTER_NAME"
      logerror "CLUSTER_CLOUD=$CLUSTER_CLOUD"
      logerror "CLUSTER_REGION=$CLUSTER_REGION"
      logerror "CLUSTER_CREDS=$CLUSTER_CREDS"
      exit 1
    fi

    log "üåê ENVIRONMENT is set with $ENVIRONMENT"
    log "üé∞ CLUSTER_NAME is set with $CLUSTER_NAME"
    log "üå§  CLUSTER_CLOUD is set with $CLUSTER_CLOUD"
    log "üó∫  CLUSTER_REGION is set with $CLUSTER_REGION"

    export WARMUP_TIME=0
  fi

  check_if_continue

  ccloud::create_ccloud_stack false  \
    && print_code_pass -c "ccloud::create_ccloud_stack false"

  CONFIG_FILE=/tmp/tmp.config
  export CONFIG_FILE=$CONFIG_FILE
  ccloud::validate_ccloud_config $CONFIG_FILE || exit 1

  ccloud::generate_configs $CONFIG_FILE \
    && print_code_pass -c "ccloud::generate_configs $CONFIG_FILE"

  if [ -f $DELTA_CONFIGS_ENV ]
  then
    source $DELTA_CONFIGS_ENV
  else
    logerror "ERROR: $DELTA_CONFIGS_ENV has not been generated"
    exit 1
  fi
}

function create_ccloud_connector() {
  file=$1

  log "Creating connector from $file"
  confluent connect cluster create --config-file $file
  if [[ $? != 0 ]]
  then
    logerror "Exit status was not 0 while creating connector from $file.  Please troubleshoot and try again"
  fi

  return 0
}

function validate_ccloud_connector_up() {
  confluent connect cluster list -o json | jq -e 'map(select(.name == "'"$1"'" and .status == "RUNNING")) | .[]' > /dev/null 2>&1
}

function get_ccloud_connector_lcc() {
  confluent connect cluster list -o json | jq -r -e 'map(select(.name == "'"$1"'")) | .[].id'
}

function ccloud::retry() {
    local -r -i max_wait="$1"; shift
    local -r cmd="$@"

    local -i sleep_interval=5
    local -i curr_wait=0

    until $cmd
    do
        if (( curr_wait >= max_wait ))
        then
            echo "ERROR: Failed after $curr_wait seconds. Please troubleshoot and run again."
            return 1
        else
            printf "."
            curr_wait=$((curr_wait+sleep_interval))
            sleep $sleep_interval
        fi
    done
    printf "\n"
}

function wait_for_ccloud_connector_up() {
  filename=$1
  maxWait=$2

  connectorName=$(cat $filename | jq -r .name)
  connectorId=$(get_ccloud_connector_lcc $connectorName)
  log "Waiting up to $maxWait seconds for connector $connectorName ($connectorId) to be RUNNING"
  ccloud::retry $maxWait validate_ccloud_connector_up $connectorName || exit 1
  log "Connector $connectorName ($connectorId) is RUNNING"

  return 0
}

function delete_ccloud_connector() {
  filename=$1
  connectorName=$(cat $filename | jq -r .name)
  connectorId=$(get_ccloud_connector_lcc $connectorName)

  log "Deleting connector $connectorName ($connectorId)"
  confluent connect cluster delete $connectorId --force
  return 0
}

function wait_for_log () {
     message="$1"
     container=${2:-connect}
     max_wait=${3:-600}
     cur_wait=0
     log "‚åõ Waiting up to $max_wait seconds for message $message to be present in $container container logs..."
     docker container logs connect > /tmp/out.txt 2>&1
     while ! grep "$message" /tmp/out.txt > /dev/null;
     do
          sleep 10
          docker container logs connect > /tmp/out.txt 2>&1
          cur_wait=$(( cur_wait+10 ))
          if [[ "$cur_wait" -gt "$max_wait" ]]; then
               logerror "The logs in $container container do not show '$message' after $max_wait seconds. Please troubleshoot with 'docker container ps' and 'docker container logs'."
               return 1
          fi
     done
     grep "$message" /tmp/out.txt
     log "The log is there !"
}


CLI_MIN_VERSION=${CLI_MIN_VERSION:-2.5.0}

# --------------------------------------------------------------
# Library
# --------------------------------------------------------------

function ccloud::validate_expect_installed() {
  if [[ $(type expect 2>&1) =~ "not found" ]]; then
    echo "'expect' is not found. Install 'expect' and try again"
    exit 1
  fi

  return 0
}
function ccloud::validate_cli_installed() {
  if [[ $(type confluent 2>&1) =~ "not found" ]]; then
    echo "'confluent' is not found. Install the Confluent CLI (https://docs.confluent.io/confluent-cli/current/install.html) and try again."
    exit 1
  fi
}

function ccloud::validate_cli_v2() {
  ccloud::validate_cli_installed || exit 1

  if [[ -z $(confluent version 2>&1 | grep "Go") ]]; then
    echo "This example requires the new Confluent CLI. Please update your version and try again."
    exit 1
  fi

  return 0
}

function ccloud::validate_logged_in_cli() {
  ccloud::validate_cli_v2 || exit 1

  if [[ "$(confluent kafka cluster list 2>&1)" =~ "confluent login" ]]; then
    echo
    echo "ERROR: Not logged into Confluent Cloud."
    echo "Log in with the command 'confluent login --save' before running the example. The '--save' argument saves your Confluent Cloud user login credentials or refresh token (in the case of SSO) to the local netrc file."
    exit 1
  fi

  return 0
}

function ccloud::get_version_cli() {
  confluent version | grep "^Version:" | cut -d':' -f2 | cut -d'v' -f2
}

function ccloud::validate_version_cli() {
  ccloud::validate_cli_installed || exit 1

  CLI_VERSION=$(ccloud::get_version_cli)

  if ccloud::version_gt $CLI_MIN_VERSION $CLI_VERSION; then
    echo "confluent version ${CLI_MIN_VERSION} or greater is required. Current version: ${CLI_VERSION}"
    echo "To update, follow: https://docs.confluent.io/confluent-cli/current/migrate.html"
    exit 1
  fi
}

function ccloud::validate_psql_installed() {
  if [[ $(type psql 2>&1) =~ "not found" ]]; then
    echo "psql is not found. Install psql and try again"
    exit 1
  fi

  return 0
}

function ccloud::validate_aws_cli_installed() {
  if [[ $(type aws 2>&1) =~ "not found" ]]; then
    echo "AWS CLI is not found. Install AWS CLI and try again"
    exit 1
  fi

  return 0
}

function ccloud::get_version_aws_cli() {
  version_major=$(aws --version 2>&1 | awk -F/ '{print $2;}' | head -c 1)
  if [[ "$version_major" -eq 2 ]]; then
    echo "2"
  else
    echo "1"
  fi
  return 0
}

function ccloud::validate_gsutil_installed() {
  if [[ $(type gsutil 2>&1) =~ "not found" ]]; then
    echo "Google Cloud gsutil is not found. Install Google Cloud gsutil and try again"
    exit 1
  fi

  return 0
}

function ccloud::validate_az_installed() {
  if [[ $(type az 2>&1) =~ "not found" ]]; then
    echo "Azure CLI is not found. Install Azure CLI and try again"
    exit 1
  fi

  return 0
}

function ccloud::validate_cloud_source() {
  config=$1

  source $config

  if [[ "$DATA_SOURCE" == "kinesis" ]]; then
    ccloud::validate_aws_cli_installed || exit 1
    if [[ -z "$KINESIS_REGION" || -z "$AWS_PROFILE" ]]; then
      echo "ERROR: DATA_SOURCE=kinesis, but KINESIS_REGION or AWS_PROFILE is not set.  Please set these parameters in config/demo.cfg and try again."
      exit 1
    fi
    aws kinesis list-streams --profile $AWS_PROFILE --region $KINESIS_REGION > /dev/null \
      || { echo "Could not run 'aws kinesis list-streams'.  Check credentials and run again." ; exit 1; }
  elif [[ "$DATA_SOURCE" == "rds" ]]; then
    ccloud::validate_aws_cli_installed || exit 1
    if [[ -z "$RDS_REGION" || -z "$AWS_PROFILE" ]]; then
      echo "ERROR: DATA_SOURCE=rds, but RDS_REGION or AWS_PROFILE is not set.  Please set these parameters in config/demo.cfg and try again."
      exit 1
    fi
    aws rds describe-db-instances --profile $AWS_PROFILE --region $RDS_REGION > /dev/null \
      || { echo "Could not run 'aws rds describe-db-instances'.  Check credentials and run again." ; exit 1; }
  else
    echo "Cloud source $cloudsource is not valid.  Must be one of [kinesis|rds]."
    exit 1
  fi

  return 0
}

function ccloud::validate_cloud_storage() {
  config=$1

  source $config
  storage=$DESTINATION_STORAGE

  if [[ "$storage" == "s3" ]]; then
    ccloud::validate_aws_cli_installed || exit 1
    ccloud::validate_credentials_s3 $S3_PROFILE $S3_BUCKET || exit 1
    aws s3api list-buckets --profile $S3_PROFILE --region $STORAGE_REGION > /dev/null \
      || { echo "Could not run 'aws s3api list-buckets'.  Check credentials and run again." ; exit 1; }
  elif [[ "$storage" == "gcs" ]]; then
    ccloud::validate_gsutil_installed || exit 1
    ccloud::validate_credentials_gcp $GCS_CREDENTIALS_FILE $GCS_BUCKET || exit 1
  elif [[ "$storage" == "az" ]]; then
    ccloud::validate_az_installed || exit 1
    ccloud::validate_credentials_az $AZBLOB_STORAGE_ACCOUNT $AZBLOB_CONTAINER || exit 1
  else
    echo "Storage destination $storage is not valid.  Must be one of [s3|gcs|az]."
    exit 1
  fi

  return 0
}

function ccloud::validate_credentials_gcp() {
  GCS_CREDENTIALS_FILE=$1
  GCS_BUCKET=$2

  if [[ -z "$GCS_CREDENTIALS_FILE" || -z "$GCS_BUCKET" ]]; then
    echo "ERROR: DESTINATION_STORAGE=gcs, but GCS_CREDENTIALS_FILE or GCS_BUCKET is not set.  Please set these parameters in config/demo.cfg and try again."
    exit 1
  fi

  gcloud auth activate-service-account --key-file $GCS_CREDENTIALS_FILE || {
    echo "ERROR: Cannot activate service account with key file $GCS_CREDENTIALS_FILE. Verify your credentials and try again."
    exit 1
  }

  # Create JSON-formatted string of the GCS credentials
  export GCS_CREDENTIALS=$(python ./stringify-gcp-credentials.py $GCS_CREDENTIALS_FILE)
  # Remove leading and trailing double quotes, otherwise connector creation from CLI fails
  GCS_CREDENTIALS=$(echo "${GCS_CREDENTIALS:1:${#GCS_CREDENTIALS}-2}")

  return 0
}

function ccloud::validate_credentials_az() {
  AZBLOB_STORAGE_ACCOUNT=$1
  AZBLOB_CONTAINER=$2

  if [[ -z "$AZBLOB_STORAGE_ACCOUNT" || -z "$AZBLOB_CONTAINER" ]]; then
    echo "ERROR: DESTINATION_STORAGE=az, but AZBLOB_STORAGE_ACCOUNT or AZBLOB_CONTAINER is not set.  Please set these parameters in config/demo.cfg and try again."
    exit 1
  fi

  if [[ "$AZBLOB_STORAGE_ACCOUNT" == "default" ]]; then
    echo "ERROR: Azure Blob storage account name cannot be 'default'. Verify the value of the storage account name (did you create one?) in config/demo.cfg, as specified by the parameter AZBLOB_STORAGE_ACCOUNT, and try again."
    exit 1
  fi

  exists=$(az storage account check-name --name $AZBLOB_STORAGE_ACCOUNT | jq -r .reason)
  if [[ "$exists" != "AlreadyExists" ]]; then
    echo "ERROR: Azure Blob storage account name $AZBLOB_STORAGE_ACCOUNT does not exist. Check the value of AZBLOB_STORAGE_ACCOUNT in config/demo.cfg and try again."
    exit 1
  fi
  export AZBLOB_ACCOUNT_KEY=$(az storage account keys list --account-name $AZBLOB_STORAGE_ACCOUNT | jq -r '.[0].value')
  if [[ "$AZBLOB_ACCOUNT_KEY" == "" ]]; then
    echo "ERROR: Cannot get the key for Azure Blob storage account name $AZBLOB_STORAGE_ACCOUNT. Check the value of AZBLOB_STORAGE_ACCOUNT in config/demo.cfg, and your key, and try again."
    exit 1
  fi

  return 0
}

function ccloud::validate_credentials_s3() {
  S3_PROFILE=$1
  S3_BUCKET=$2

  if [[ -z "$S3_PROFILE" || -z "$S3_BUCKET" ]]; then
    echo "ERROR: DESTINATION_STORAGE=s3, but S3_PROFILE or S3_BUCKET is not set.  Please set these parameters in config/demo.cfg and try again."
    exit 1
  fi

  aws configure get aws_access_key_id --profile $S3_PROFILE 1>/dev/null || {
    echo "ERROR: Cannot determine aws_access_key_id from S3_PROFILE=$S3_PROFILE.  Verify your credentials and try again."
    exit 1
  }
  aws configure get aws_secret_access_key --profile $S3_PROFILE 1>/dev/null || {
    echo "ERROR: Cannot determine aws_secret_access_key from S3_PROFILE=$S3_PROFILE.  Verify your credentials and try again."
    exit 1
  }
  return 0
}

function ccloud::validate_schema_registry_up() {
  auth=$1
  sr_endpoint=$2

  curl --silent -u $auth $sr_endpoint > /dev/null || {
    echo "ERROR: Could not validate credentials to Confluent Cloud Schema Registry. Please troubleshoot"
    exit 1
  }

  echo "Validated credentials to Confluent Cloud Schema Registry at $sr_endpoint"
  return 0
}

function ccloud::get_environment_id_from_service_id() {
  SERVICE_ACCOUNT_ID=$1

  ENVIRONMENT_NAME_PREFIX=${ENVIRONMENT_NAME_PREFIX:-"pg-$SERVICE_ACCOUNT_ID"}
  local environment_id=$(confluent environment list -o json | jq -r 'map(select(.name | startswith("'"$ENVIRONMENT_NAME_PREFIX"'"))) | .[].id')

  echo $environment_id

  return 0
}

function ccloud::create_and_use_environment() {
  ENVIRONMENT_NAME=$1

  OUTPUT=$(confluent environment create $ENVIRONMENT_NAME -o json)
  (($? != 0)) && { echo "ERROR: Failed to create environment $ENVIRONMENT_NAME. Please troubleshoot and run again"; exit 1; }
  ENVIRONMENT=$(echo "$OUTPUT" | jq -r ".id")
  confluent environment use $ENVIRONMENT &>/dev/null

  echo $ENVIRONMENT

  return 0
}

function ccloud::find_cluster() {
  CLUSTER_NAME=$1
  CLUSTER_CLOUD=$2
  CLUSTER_REGION=$3

  local FOUND_CLUSTER=$(confluent kafka cluster list -o json | jq -c -r '.[] | select((.name == "'"$CLUSTER_NAME"'") and (.provider == "'"$CLUSTER_CLOUD"'") and (.region == "'"$CLUSTER_REGION"'"))')
  [[ ! -z "$FOUND_CLUSTER" ]] && {
      echo "$FOUND_CLUSTER" | jq -r .id
      return 0

    } || {
      return 1
    }
}

function ccloud::create_and_use_cluster() {
  CLUSTER_NAME=$1
  CLUSTER_CLOUD=$2
  CLUSTER_REGION=$3
  CLUSTER_TYPE=$4

  OUTPUT=$(confluent kafka cluster create "$CLUSTER_NAME" --cloud $CLUSTER_CLOUD --region $CLUSTER_REGION --type $CLUSTER_TYPE --output json 2>&1)
  (($? != 0)) && { echo "$OUTPUT"; exit 1; }
  CLUSTER=$(echo "$OUTPUT" | jq -r .id)
  confluent kafka cluster use $CLUSTER 2>/dev/null
  echo $CLUSTER

  return 0
}

function ccloud::maybe_create_and_use_cluster() {
  CLUSTER_NAME=$1
  CLUSTER_CLOUD=$2
  CLUSTER_REGION=$3
  CLUSTER_TYPE=$4
  CLUSTER_ID=$(ccloud::find_cluster $CLUSTER_NAME $CLUSTER_CLOUD $CLUSTER_REGION)
  if [ $? -eq 0 ]
  then
    confluent kafka cluster use $CLUSTER_ID
    echo $CLUSTER_ID
  else

    # VINC: added
    if [[ ! -z "$CLUSTER_CREDS" ]]
    then
      echo "ERROR: Could not find your $CLUSTER_CLOUD cluster $CLUSTER_NAME in region $CLUSTER_REGION"
      echo "Make sure CLUSTER_CLOUD and CLUSTER_REGION are set with values that correspond to your cluster!"
      exit 1
    else
      OUTPUT=$(ccloud::create_and_use_cluster "$CLUSTER_NAME" "$CLUSTER_CLOUD" "$CLUSTER_REGION" "$CLUSTER_TYPE")
      (($? != 0)) && { echo "$OUTPUT"; exit 1; }
      echo "$OUTPUT"
    fi
  fi

  return 0
}

function ccloud::create_service_account() {
  SERVICE_NAME=$1

  CCLOUD_EMAIL=$(confluent prompt -f '%u')
  OUTPUT=$(confluent iam service-account create $SERVICE_NAME --description "SA for $EXAMPLE run by $CCLOUD_EMAIL"  -o json)
  SERVICE_ACCOUNT_ID=$(echo "$OUTPUT" | jq -r ".id")

  echo $SERVICE_ACCOUNT_ID

  return 0
}

function ccloud:get_service_account_from_current_cluster_name() {
  SERVICE_ACCOUNT_ID=$(confluent kafka cluster describe -o json | jq -r '.name' | awk -F'-' '{print $3 "-" $4;}')

  echo $SERVICE_ACCOUNT_ID

  return 0
}

function ccloud::enable_schema_registry() {
  SCHEMA_REGISTRY_CLOUD=$1
  SCHEMA_REGISTRY_GEO=$2

  OUTPUT=$(confluent schema-registry cluster enable --cloud $SCHEMA_REGISTRY_CLOUD --geo $SCHEMA_REGISTRY_GEO -o json)
  SCHEMA_REGISTRY=$(echo "$OUTPUT" | jq -r ".id")

  echo $SCHEMA_REGISTRY

  return 0
}

function ccloud::find_credentials_resource() {
  SERVICE_ACCOUNT_ID=$1
  RESOURCE=$2
  local FOUND_CRED=$(confluent api-key list -o json | jq -c -r 'map(select((.resource_id == "'"$RESOURCE"'") and (.owner_resource_id == "'"$SERVICE_ACCOUNT_ID"'")))')
  local FOUND_COUNT=$(echo "$FOUND_CRED" | jq 'length')
  [[ $FOUND_COUNT -ne 0 ]] && {
      echo "$FOUND_CRED" | jq -r '.[0].api_key'
      return 0

    } || {
      return 1
    }
}
function ccloud::create_credentials_resource() {
  SERVICE_ACCOUNT_ID=$1
  RESOURCE=$2

  OUTPUT=$(confluent api-key create --service-account $SERVICE_ACCOUNT_ID --resource $RESOURCE -o json)
  API_KEY_SA=$(echo "$OUTPUT" | jq -r ".api_key")
  API_SECRET_SA=$(echo "$OUTPUT" | jq -r ".api_secret")
  echo "${API_KEY_SA}:${API_SECRET_SA}"

  # vinc
  sleep 30
  return 0
}
# The return from this function will be a colon ':' delimited
#   list, if the api-key is created the second element of the
#   list will be the secret.  If the api-key is being reused
#   the second element of the list will be empty
function ccloud::maybe_create_credentials_resource() {
  SERVICE_ACCOUNT_ID=$1
  RESOURCE=$2

  local KEY=$(ccloud::find_credentials_resource $SERVICE_ACCOUNT_ID $RESOURCE)
  [[ -z $KEY ]] && {
    ccloud::create_credentials_resource $SERVICE_ACCOUNT_ID $RESOURCE
  } || {
    echo "$KEY:"; # the secret cannot be retrieved from a found key, caller needs to handle this
    return 0
  }
}

function ccloud::find_ksqldb_app() {
  KSQLDB_NAME=$1
  CLUSTER=$2

  local FOUND_APP=$(confluent ksql cluster list -o json | jq -c -r 'map(select((.name == "'"$KSQLDB_NAME"'") and (.kafka == "'"$CLUSTER"'")))')
  local FOUND_COUNT=$(echo "$FOUND_APP" | jq 'length')
  [[ $FOUND_COUNT -ne 0 ]] && {
      echo "$FOUND_APP" | jq -r '.[].id'
      return 0

    } || {
      return 1
    }
}

function ccloud::create_ksqldb_app() {
  KSQLDB_NAME=$1
  CLUSTER=$2
  # colon deliminated credentials (APIKEY:APISECRET)
  local ksqlDB_kafka_creds=$3
  local kafka_api_key=$(echo $ksqlDB_kafka_creds | cut -d':' -f1)
  local kafka_api_secret=$(echo $ksqlDB_kafka_creds | cut -d':' -f2)

  KSQLDB=$(confluent ksql cluster create --cluster $CLUSTER --api-key "$kafka_api_key" --api-secret "$kafka_api_secret" --csu 1 -o json "$KSQLDB_NAME" | jq -r ".id")
  echo $KSQLDB

  return 0
}
function ccloud::maybe_create_ksqldb_app() {
  KSQLDB_NAME=$1
  CLUSTER=$2
  # colon deliminated credentials (APIKEY:APISECRET)
  local ksqlDB_kafka_creds=$3

  APP_ID=$(ccloud::find_ksqldb_app $KSQLDB_NAME $CLUSTER)
  if [ $? -eq 0 ]
  then
    echo $APP_ID
  else
    ccloud::create_ksqldb_app "$KSQLDB_NAME" "$CLUSTER" "$ksqlDB_kafka_creds"
  fi

  return 0
}

function ccloud::create_acls_all_resources_full_access() {
  SERVICE_ACCOUNT_ID=$1
  # Setting default QUIET=false to surface potential errors
  QUIET="${QUIET:-false}"
  [[ $QUIET == "true" ]] &&
    local REDIRECT_TO="/dev/null" ||
    local REDIRECT_TO="/dev/tty"

  confluent kafka acl create --allow --service-account $SERVICE_ACCOUNT_ID --operations CREATE,DELETE,WRITE,READ,DESCRIBE,DESCRIBE_CONFIGS --topic '*' &>"$REDIRECT_TO"

  confluent kafka acl create --allow --service-account $SERVICE_ACCOUNT_ID --operations READ,WRITE,CREATE,DESCRIBE --consumer-group '*' &>"$REDIRECT_TO"

  confluent kafka acl create --allow --service-account $SERVICE_ACCOUNT_ID --operations DESCRIBE,WRITE --transactional-id '*' &>"$REDIRECT_TO"

  confluent kafka acl create --allow --service-account $SERVICE_ACCOUNT_ID --operations IDEMPOTENT-WRITE,DESCRIBE --cluster-scope &>"$REDIRECT_TO"

  return 0
}

function ccloud::delete_acls_ccloud_stack() {
  SERVICE_ACCOUNT_ID=$1
  # Setting default QUIET=false to surface potential errors
  QUIET="${QUIET:-false}"
  [[ $QUIET == "true" ]] &&
    local REDIRECT_TO="/dev/null" ||
    local REDIRECT_TO="/dev/tty"

  echo "Deleting ACLs for service account ID $SERVICE_ACCOUNT_ID"

  confluent kafka acl delete --allow --service-account $SERVICE_ACCOUNT_ID --operations CREATE,DELETE,WRITE,READ,DESCRIBE,DESCRIBE_CONFIGS --topic '*' &>"$REDIRECT_TO"

  confluent kafka acl delete --allow --service-account $SERVICE_ACCOUNT_ID --operations READ,WRITE,CREATE,DESCRIBE --consumer-group '*' &>"$REDIRECT_TO"

  confluent kafka acl delete --allow --service-account $SERVICE_ACCOUNT_ID --operations DESCRIBE,WRITE --transactional-id '*' &>"$REDIRECT_TO"

  confluent kafka acl delete --allow --service-account $SERVICE_ACCOUNT_ID --operations IDEMPOTENT-WRITE,DESCRIBE --cluster-scope &>"$REDIRECT_TO"

  return 0
}

function ccloud::validate_ccloud_config() {
  [ -z "$1" ] && {
    echo "ccloud::validate_ccloud_config expects one parameter (configuration file with Confluent Cloud connection information)"
    exit 1
  }

  local cfg_file="$1"
  local bootstrap=$(grep "bootstrap\.servers" "$cfg_file" | cut -d'=' -f2-)
  [ -z "$bootstrap" ] && {
    echo "ERROR: Cannot read the 'bootstrap.servers' key-value pair from $cfg_file."
    exit 1;
  }
  return 0;
}

function ccloud::validate_ksqldb_up() {
  [ -z "$1" ] && {
    echo "ccloud::validate_ksqldb_up expects one parameter (ksqldb endpoint)"
    exit 1
  }

  [ $# -gt 1 ] && echo "WARN: ccloud::validate_ksqldb_up function expects one parameter"

  local ksqldb_endpoint=$1

  ccloud::validate_logged_in_cli || exit 1

  local ksqldb_meta=$(confluent ksql cluster list -o json | jq -r 'map(select(.endpoint == "'"$ksqldb_endpoint"'")) | .[]')

  local ksqldb_appid=$(echo "$ksqldb_meta" | jq -r '.id')
  if [[ "$ksqldb_appid" == "" ]]; then
    echo "ERROR: Confluent Cloud ksqlDB endpoint $ksqldb_endpoint is not found. Provision a ksqlDB cluster via the Confluent Cloud UI and add the configuration parameter ksql.endpoint and ksql.basic.auth.user.info into your Confluent Cloud configuration file at $ccloud_config_file and try again."
    exit 1
  fi

  local ksqldb_status=$(echo "$ksqldb_meta" | jq -r '.status')
  if [[ $ksqldb_status != "UP" ]]; then
    echo "ERROR: Confluent Cloud ksqlDB endpoint $ksqldb_endpoint with id $ksqlDBAppId is not in UP state. Troubleshoot and try again."
    exit 1
  fi

  return 0
}

function ccloud::validate_azure_account() {
  AZBLOB_STORAGE_ACCOUNT=$1

  if [[ "$AZBLOB_STORAGE_ACCOUNT" == "default" ]]; then
    echo "ERROR: Azure Blob storage account name cannot be 'default'. Verify the value of the storage account name (did you create one?) in config/demo.cfg, as specified by the parameter AZBLOB_STORAGE_ACCOUNT, and try again."
    exit 1
  fi

  exists=$(az storage account check-name --name $AZBLOB_STORAGE_ACCOUNT | jq -r .reason)
  if [[ "$exists" != "AlreadyExists" ]]; then
    echo "ERROR: Azure Blob storage account name $AZBLOB_STORAGE_ACCOUNT does not exist. Check the value of STORAGE_PROFILE in config/demo.cfg and try again."
    exit 1
  fi
  export AZBLOB_ACCOUNT_KEY=$(az storage account keys list --account-name $AZBLOB_STORAGE_ACCOUNT | jq -r '.[0].value')
  if [[ "$AZBLOB_ACCOUNT_KEY" == "" ]]; then
    echo "ERROR: Cannot get the key for Azure Blob storage account name $AZBLOB_STORAGE_ACCOUNT. Check the value of STORAGE_PROFILE in config/demo.cfg, and your key, and try again."
    exit 1
  fi

  return 0
}

function ccloud::validate_credentials_ksqldb() {
  ksqldb_endpoint=$1
  ccloud_config_file=$2
  credentials=$3

  response=$(curl ${ksqldb_endpoint}/info \
             -H "Content-Type: application/vnd.ksql.v1+json; charset=utf-8" \
             --silent \
             -u $credentials)
  if [[ "$response" =~ "Unauthorized" ]]; then
    echo "ERROR: Authorization failed to the ksqlDB cluster. Check your ksqlDB credentials set in the configuration parameter ksql.basic.auth.user.info in your Confluent Cloud configuration file at $ccloud_config_file and try again."
    exit 1
  fi

  echo "Validated credentials to Confluent Cloud ksqlDB at $ksqldb_endpoint"
  return 0
}

function ccloud::create_connector() {
  file=$1

  echo -e "\nCreating connector from $file\n"

  # About the Confluent CLI command 'confluent connect cluster create':
  # - Typical usage of this CLI would be 'confluent connect cluster create --config-file <filename>'
  # - However, in this example, the connector's configuration file contains parameters that need to be first substituted
  #   so the CLI command includes eval and heredoc.
  # - The '-vvv' is added for verbose output
  confluent connect cluster create -vvv --config <(eval "cat <<EOF
$(<$file)
EOF
")
  if [[ $? != 0 ]]; then
    echo "ERROR: Exit status was not 0 while creating connector from $file.  Please troubleshoot and try again"
    exit 1
  fi

  return 0
}

function ccloud::validate_connector_up() {
  confluent connect cluster list -o json | jq -e 'map(select(.name == "'"$1"'" and .status == "RUNNING")) | .[]' > /dev/null 2>&1
}

function ccloud::wait_for_connector_up() {
  filename=$1
  maxWait=$2

  connectorName=$(cat $filename | jq -r .name)
  echo "Waiting up to $maxWait seconds for connector $filename ($connectorName) to be RUNNING"
  ccloud::retry $maxWait ccloud::validate_connector_up $connectorName || exit 1
  echo "Connector $filename ($connectorName) is RUNNING"

  return 0
}

function ccloud::validate_ccloud_ksqldb_endpoint_ready() {
  KSQLDB_ENDPOINT=$1

  STATUS=$(confluent ksql cluster list -o json | jq -r 'map(select(.endpoint == "'"$KSQLDB_ENDPOINT"'")) | .[].status' | grep UP)
  if [[ "$STATUS" == "" ]]; then
    return 1
  fi

  return 0
}

function ccloud::validate_ccloud_cluster_ready() {
  confluent kafka topic list &>/dev/null
  return $?
}

function ccloud::validate_topic_exists() {
  topic=$1

  confluent kafka topic describe $topic &>/dev/null
  return $?
}

function ccloud::validate_subject_exists() {
  subject=$1
  sr_url=$2
  sr_credentials=$3

  curl --silent -u $sr_credentials $sr_url/subjects/$subject/versions/latest | jq -r ".subject" | grep $subject > /dev/null
  return $?
}

function ccloud::login_cli(){
  URL=$1
  EMAIL=$2
  PASSWORD=$3

  ccloud::validate_expect_installed

  echo -e "\n# Login"
  OUTPUT=$(
  expect <<END
    log_user 1
    spawn confluent login --url $URL --prompt -vvvv
    expect "Email: "
    send "$EMAIL\r";
    expect "Password: "
    send "$PASSWORD\r";
    expect "Logged in as "
    set result $expect_out(buffer)
END
  )
  echo "$OUTPUT"
  if [[ ! "$OUTPUT" =~ "Logged in as" ]]; then
    echo "Failed to log into your cluster. Please check all parameters and run again."
  fi

  return 0
}

function ccloud::get_service_account() {

  [ -z "$1" ] && {
    echo "ccloud::get_service_account expects one parameter (API Key)"
    exit 1
  }

  [ $# -gt 1 ] && echo "WARN: ccloud::get_service_account function expects one parameter, received two"

  local key="$1"

  serviceAccount=$(confluent api-key list -o json | jq -r -c 'map(select((.api_key == "'"$key"'"))) | .[].owner_resource_id')
  if [[ "$serviceAccount" == "" ]]; then
    echo "ERROR: Could not associate key $key to a service account. Verify your credentials, ensure the API key has a set resource type, and try again."
    exit 1
  fi
  if ! [[ "$serviceAccount" =~ ^sa-[a-z0-9]+$ ]]; then
    echo "ERROR: $serviceAccount value is not a valid value for a service account. Verify your credentials, ensure the API key has a set resource type, and try again."
    exit 1
  fi

  echo "$serviceAccount"

  return 0
}

function ccloud::create_acls_connector() {
  serviceAccount=$1

  confluent kafka acl create --allow --service-account $serviceAccount --operations DESCRIBE --cluster-scope
  confluent kafka acl create --allow --service-account $serviceAccount --operations CREATE,WRITE --prefix --topic dlq-lcc
  confluent kafka acl create --allow --service-account $serviceAccount --operations READ --prefix --consumer-group connect-lcc

  return 0
}

function ccloud::create_acls_control_center() {
  serviceAccount=$1

  echo "Confluent Control Center: creating _confluent-command and ACLs for service account $serviceAccount"
  confluent kafka topic create _confluent-command --partitions 1

  confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ,CREATE --topic _confluent --prefix

  confluent kafka acl create --allow --service-account $serviceAccount --operations READ,WRITE,CREATE --consumer-group _confluent --prefix

  return 0
}

function ccloud::create_acls_replicator() {
  serviceAccount=$1
  topic=$2

  confluent kafka acl create --allow --service-account $serviceAccount --operations CREATE,WRITE,READ,DESCRIBE,DESCRIBE_CONFIGS,ALTER-CONFIGS,DESCRIBE --topic $topic

  return 0
}

function ccloud::create_acls_connect_topics() {
  serviceAccount=$1

  echo "Connect: creating topics and ACLs for service account $serviceAccount"

  TOPIC=connect-demo-configs
  confluent kafka topic create $TOPIC --partitions 1 --config "cleanup.policy=compact"
  confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ --topic $TOPIC --prefix

  TOPIC=connect-demo-offsets
  confluent kafka topic create $TOPIC --partitions 6 --config "cleanup.policy=compact"
  confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ --topic $TOPIC --prefix

  TOPIC=connect-demo-statuses

  confluent kafka topic create $TOPIC --partitions 3 --config "cleanup.policy=compact"
  confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ  --topic $TOPIC --prefix

  for TOPIC in _confluent-monitoring _confluent-command ; do
    confluent kafka topic create $TOPIC --partitions 1 &>/dev/null
    confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ  --topic $TOPIC --prefix
  done

  confluent kafka acl create --allow --service-account $serviceAccount --operations READ --consumer-group connect-cloud

  echo "Connectors: creating topics and ACLs for service account $serviceAccount"
  confluent kafka acl create --allow --service-account $serviceAccount --operations READ --consumer-group connect-replicator
  confluent kafka acl create --allow --service-account $serviceAccount --operations DESCRIBE --cluster-scope

  return 0
}

function ccloud::validate_ccloud_stack_up() {
  CLOUD_KEY=$1
  CONFIG_FILE=$2
  enable_ksqldb=$3

  if [ -z "$enable_ksqldb" ]; then
    enable_ksqldb=true
  fi

  ccloud::validate_environment_set || exit 1
  ccloud::set_kafka_cluster_use_from_api_key "$CLOUD_KEY" || exit 1
  ccloud::validate_schema_registry_up "$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" "$SCHEMA_REGISTRY_URL" || exit 1
  if $enable_ksqldb ; then
    ccloud::validate_ksqldb_up "$KSQLDB_ENDPOINT" || exit 1
    ccloud::validate_credentials_ksqldb "$KSQLDB_ENDPOINT" "$CONFIG_FILE" "$KSQLDB_BASIC_AUTH_USER_INFO" || exit 1
  fi
}

function ccloud::validate_environment_set() {
  confluent environment list | grep '*' &>/dev/null || {
    echo "ERROR: could not determine if environment is set. Run 'confluent environment list' and set 'confluent environment use' and try again"
    exit 1
  }

  return 0
}

function ccloud::set_kafka_cluster_use_from_api_key() {
  [ -z "$1" ] && {
    echo "ccloud::set_kafka_cluster_use_from_api_key expects one parameter (API Key)"
    exit 1
  }

  [ $# -gt 1 ] && echo "WARN: ccloud::set_kafka_cluster_use_from_api_key function expects one parameter, received two"

  local key="$1"

  local kafkaCluster=$(confluent api-key list -o json | jq -r -c 'map(select((.api_key == "'"$key"'" and .resource_type == "kafka"))) | .[].resource_id')
  if [[ "$kafkaCluster" == "" ]]; then
    echo "ERROR: Could not associate key $key to a Confluent Cloud Kafka cluster. Verify your credentials, ensure the API key has a set resource type, and try again."
    exit 1
  fi

  confluent kafka cluster use $kafkaCluster
  local endpoint=$(confluent kafka cluster describe $kafkaCluster -o json | jq -r ".endpoint" | cut -c 12-)
  echo -e "\nAssociated key $key to Confluent Cloud Kafka cluster $kafkaCluster at $endpoint"

  return 0
}

# Deprecated 10/28/2020, use ccloud::set_kafka_cluster_use_from_api_key
function ccloud::set_kafka_cluster_use() {
  echo "WARN: set_kafka_cluster_use is deprecated, use ccloud::set_kafka_cluster_use_from_api_key"
  ccloud::set_kafka_cluster_use_from_api_key "$@"
}

#
# ccloud-stack documentation:
# https://docs.confluent.io/platform/current/tutorials/examples/ccloud/docs/ccloud-stack.html
#
function ccloud::create_ccloud_stack() {
  #ccloud::validate_version_cli $CLI_MIN_VERSION || exit 1
  QUIET="${QUIET:-false}"
  REPLICATION_FACTOR=${REPLICATION_FACTOR:-3}
  enable_ksqldb=${1:-false}
  EXAMPLE=${EXAMPLE:-ccloud-stack-function}
  CHECK_CREDIT_CARD="${CHECK_CREDIT_CARD:-false}"

  # Check if credit card is on file, which is required for cluster creation
  if $CHECK_CREDIT_CARD && [[ $(confluent admin payment describe) =~ "not found" ]]; then
    echo "ERROR: No credit card on file. Add a payment method and try again."
    echo "If you are using a cloud provider's Marketplace, see documentation for a workaround: https://docs.confluent.io/platform/current/tutorials/examples/ccloud/docs/ccloud-stack.html#running-with-marketplace"
    exit 1
  fi

  # VINC: added
  if [[ -z "$CLUSTER_CREDS" ]]
  then
    if [[ -z "$SERVICE_ACCOUNT_ID" ]]; then
      # Service Account is not received so it will be created
      local RANDOM_NUM=$((1 + RANDOM % 1000000))
      SERVICE_NAME=${SERVICE_NAME:-"pg-app-$RANDOM_NUM"}
      SERVICE_ACCOUNT_ID=$(ccloud::create_service_account $SERVICE_NAME)
    fi

    if [[ "$SERVICE_NAME" == "" ]]; then
      echo "ERROR: SERVICE_NAME is not defined. If you are providing the SERVICE_ACCOUNT_ID to this function please also provide the SERVICE_NAME"
      exit 1
    fi

    echo "Creating Confluent Cloud stack for service account $SERVICE_NAME, ID: $SERVICE_ACCOUNT_ID."
  fi

  if [[ -z "$ENVIRONMENT" ]];

  then
    # Environment is not received so it will be created
    ENVIRONMENT_NAME=${ENVIRONMENT_NAME:-"pg-$SERVICE_ACCOUNT_ID-$EXAMPLE"}
    ENVIRONMENT=$(ccloud::create_and_use_environment $ENVIRONMENT_NAME)
    (($? != 0)) && { echo "$ENVIRONMENT"; exit 1; }
  else
    confluent environment use $ENVIRONMENT || exit 1
  fi

  CLUSTER_NAME=${CLUSTER_NAME:-"pg-cluster-$SERVICE_ACCOUNT_ID"}
  CLUSTER_CLOUD="${CLUSTER_CLOUD:-aws}"
  CLUSTER_REGION="${CLUSTER_REGION:-us-west-2}"
  CLUSTER_TYPE="${CLUSTER_TYPE:-basic}"
  CLUSTER=$(ccloud::maybe_create_and_use_cluster "$CLUSTER_NAME" $CLUSTER_CLOUD $CLUSTER_REGION $CLUSTER_TYPE)
  (($? != 0)) && { echo "$CLUSTER"; exit 1; }
  if [[ "$CLUSTER" == "" ]] ; then
    echo "Kafka cluster id is empty"
    echo "ERROR: Could not create cluster. Please troubleshoot."
    exit 1
  fi

  BOOTSTRAP_SERVERS=$(confluent kafka cluster describe $CLUSTER -o json | jq -r ".endpoint" | cut -c 12-)
  NEED_ACLS=0
  # VINC: added
  if [[ -z "$CLUSTER_CREDS" ]]
  then
    CLUSTER_CREDS=$(ccloud::maybe_create_credentials_resource $SERVICE_ACCOUNT_ID $CLUSTER)
    NEED_ACLS=1
  fi

  MAX_WAIT=720
  echo ""
  echo "Waiting up to $MAX_WAIT seconds for Confluent Cloud cluster to be ready"
  ccloud::retry $MAX_WAIT ccloud::validate_ccloud_cluster_ready || exit 1

  # VINC: added
  if [[ $NEED_ACLS -eq 1 ]]
  then
    # Estimating another 80s wait still sometimes required
    WARMUP_TIME=${WARMUP_TIME:-80}
    echo "Sleeping an additional ${WARMUP_TIME} seconds to ensure propagation of all metadata"
    sleep $WARMUP_TIME

    ccloud::create_acls_all_resources_full_access $SERVICE_ACCOUNT_ID
  fi

  SCHEMA_REGISTRY_GEO="${SCHEMA_REGISTRY_GEO:-us}"
  SCHEMA_REGISTRY=$(ccloud::enable_schema_registry $CLUSTER_CLOUD $SCHEMA_REGISTRY_GEO)
  SCHEMA_REGISTRY_ENDPOINT=$(confluent schema-registry cluster describe -o json | jq -r ".endpoint_url")
  # VINC: added
  if [[ -z "$SCHEMA_REGISTRY_CREDS" ]]
  then
    if [[ -z "$SERVICE_ACCOUNT_ID" ]]; then
      # Service Account is not received so it will be created
      local RANDOM_NUM=$((1 + RANDOM % 1000000))
      SERVICE_NAME=${SERVICE_NAME:-"pg-app-$RANDOM_NUM"}
      SERVICE_ACCOUNT_ID=$(ccloud::create_service_account $SERVICE_NAME)
    fi
    SCHEMA_REGISTRY_CREDS=$(ccloud::maybe_create_credentials_resource $SERVICE_ACCOUNT_ID $SCHEMA_REGISTRY)
  fi

  # VINC
  set +e
  #log "Adding ResourceOwner RBAC role for all subjects"
  confluent iam rbac role-binding create --principal User:$SERVICE_ACCOUNT_ID --role ResourceOwner --environment $ENVIRONMENT --schema-registry-cluster $SCHEMA_REGISTRY --resource Subject:* 2>/dev/null

  if $enable_ksqldb ; then
    KSQLDB_NAME=${KSQLDB_NAME:-"demo-ksqldb-$SERVICE_ACCOUNT_ID"}
    KSQLDB=$(ccloud::maybe_create_ksqldb_app "$KSQLDB_NAME" $CLUSTER "$CLUSTER_CREDS")
    KSQLDB_ENDPOINT=$(confluent ksql cluster describe $KSQLDB -o json | jq -r ".endpoint")
    KSQLDB_CREDS=$(ccloud::maybe_create_credentials_resource $SERVICE_ACCOUNT_ID $KSQLDB)
    confluent ksql cluster configure-acls $KSQLDB
  fi

  CLOUD_API_KEY=`echo $CLUSTER_CREDS | awk -F: '{print $1}'`
  CLOUD_API_SECRET=`echo $CLUSTER_CREDS | awk -F: '{print $2}'`
  # FIX THIS: added by me
  confluent api-key store "$CLOUD_API_KEY" "$CLOUD_API_SECRET" --resource ${CLUSTER} --force
  confluent api-key use $CLOUD_API_KEY --resource ${CLUSTER}

  if [[ -z "$SKIP_CONFIG_FILE_WRITE" ]]; then
    if [[ -z "$CONFIG_FILE" ]]; then
      CONFIG_FILE="/tmp/tmp.config"
    fi

    cat <<EOF > $CONFIG_FILE
# --------------------------------------
# Confluent Cloud connection information
# --------------------------------------
# ENVIRONMENT ID: ${ENVIRONMENT}
# SERVICE ACCOUNT ID: ${SERVICE_ACCOUNT_ID}
# KAFKA CLUSTER ID: ${CLUSTER}
# SCHEMA REGISTRY CLUSTER ID: ${SCHEMA_REGISTRY}
EOF
    if $enable_ksqldb ; then
      cat <<EOF >> $CONFIG_FILE
# KSQLDB APP ID: ${KSQLDB}
EOF
    fi
    cat <<EOF >> $CONFIG_FILE
# --------------------------------------
sasl.mechanism=PLAIN
security.protocol=SASL_SSL
bootstrap.servers=${BOOTSTRAP_SERVERS}
sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='${CLOUD_API_KEY}' password='${CLOUD_API_SECRET}';
basic.auth.credentials.source=USER_INFO
schema.registry.url=${SCHEMA_REGISTRY_ENDPOINT}
basic.auth.user.info=`echo $SCHEMA_REGISTRY_CREDS | awk -F: '{print $1}'`:`echo $SCHEMA_REGISTRY_CREDS | awk -F: '{print $2}'`
replication.factor=${REPLICATION_FACTOR}
EOF
    if $enable_ksqldb ; then
      cat <<EOF >> $CONFIG_FILE
ksql.endpoint=${KSQLDB_ENDPOINT}
ksql.basic.auth.user.info=`echo $KSQLDB_CREDS | awk -F: '{print $1}'`:`echo $KSQLDB_CREDS | awk -F: '{print $2}'`
EOF
    fi

    echo
    echo "Client configuration file saved to: $CONFIG_FILE"
  fi

  return 0
}

function ccloud::destroy_ccloud_stack() {
  if [ $# -eq 0 ];then
    echo "ccloud::destroy_ccloud_stack requires a single parameter, the service account id."
    exit 1
  fi

  SERVICE_ACCOUNT_ID=$1
  ENVIRONMENT=${ENVIRONMENT:-$(ccloud::get_environment_id_from_service_id $SERVICE_ACCOUNT_ID)}

  confluent environment use $ENVIRONMENT || exit 1

  PRESERVE_ENVIRONMENT="${PRESERVE_ENVIRONMENT:-false}"

  ENVIRONMENT_NAME_PREFIX=${ENVIRONMENT_NAME_PREFIX:-"pg-$SERVICE_ACCOUNT_ID"}
  CLUSTER_NAME=${CLUSTER_NAME:-"pg-cluster-$SERVICE_ACCOUNT_ID"}
  CONFIG_FILE=${CONFIG_FILE:-"/tmp/tmp.config"}
  KSQLDB_NAME=${KSQLDB_NAME:-"demo-ksqldb-$SERVICE_ACCOUNT_ID"}

  # Setting default QUIET=false to surface potential errors
  QUIET="${QUIET:-false}"
  [[ $QUIET == "true" ]] &&

    local REDIRECT_TO="/dev/null" ||
    local REDIRECT_TO="/dev/tty"

  echo "Destroying Confluent Cloud stack associated to service account id $SERVICE_ACCOUNT_ID"

  # Delete associated ACLs
  ccloud::delete_acls_ccloud_stack $SERVICE_ACCOUNT_ID

  ksqldb_id_found=$(confluent ksql cluster list -o json | jq -r 'map(select(.name == "'"$KSQLDB_NAME"'")) | .[].id')
  if [[ $ksqldb_id_found != "" ]]; then
    echo "Deleting KSQLDB: $KSQLDB_NAME : $ksqldb_id_found"
    confluent ksql cluster delete $ksqldb_id_found &> "$REDIRECT_TO"
  fi

  # Delete connectors associated to this Kafka cluster, otherwise cluster deletion fails
  local cluster_id=$(confluent kafka cluster list -o json | jq -r 'map(select(.name == "'"$CLUSTER_NAME"'")) | .[].id')
  confluent connect cluster list --cluster $cluster_id -o json | jq -r '.[].id' | xargs -I{} confluent connect cluster delete {} --force

  echo "Deleting CLUSTER: $CLUSTER_NAME : $cluster_id"
  confluent kafka cluster delete $cluster_id &> "$REDIRECT_TO"

  # Delete API keys associated to the service account
  confluent api-key list --service-account $SERVICE_ACCOUNT_ID -o json | jq -r '.[].api_key' | xargs -I{} confluent api-key delete {} --force

  # Delete service account
  confluent iam service-account delete $SERVICE_ACCOUNT_ID --force &>"$REDIRECT_TO"

  if [[ $PRESERVE_ENVIRONMENT == "false" ]]; then
    local environment_id=$(confluent environment list -o json | jq -r 'map(select(.name | startswith("'"$ENVIRONMENT_NAME_PREFIX"'"))) | .[].id')
    if [[ "$environment_id" == "" ]]; then
      echo "WARNING: Could not find environment with name that starts with $ENVIRONMENT_NAME_PREFIX (did you create this ccloud-stack reusing an existing environment?)"
    else
      echo "Deleting ENVIRONMENT: prefix $ENVIRONMENT_NAME_PREFIX : $environment_id"
      confluent environment delete $environment_id &> "$REDIRECT_TO"
    fi
  fi

  rm -f $CONFIG_FILE

  return 0
}

# Overview:
#
# This code reads a local Confluent Cloud configuration file
# and writes delta configuration files into ./delta_configs for
# Confluent Platform components and clients connecting to Confluent Cloud.
#
# Confluent Platform Components:
# - Confluent Schema Registry
# - KSQL Data Generator
# - ksqlDB server
# - Confluent Replicator (executable)
# - Confluent Control Center
# - Confluent Metrics Reporter
# - Confluent REST Proxy
# - Kafka Connect
# - Kafka connector
# - Kafka command line tools
#
# Kafka Clients:
# - Java (Producer/Consumer)
# - Java (Streams)
# - librdkafka config
# - Python
# - .NET
# - Go
# - Node.js (https://github.com/Blizzard/node-rdkafka)
# - C++
#
# Documentation for using this script:
#
#   https://docs.confluent.io/current/cloud/connect/auto-generate-configs.html
#
# Arguments:
#
#   CONFIG_FILE, defaults to ~/.ccloud/config
#
# Example CONFIG_FILE at ~/.ccloud/config
#
#   $ cat $HOME/.ccloud/config
#
#   bootstrap.servers=<BROKER ENDPOINT>
#   security.protocol=SASL_SSL
#   sasl.mechanism=PLAIN
#   sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='<API KEY>' password='<API SECRET>';
#
# If you are using Confluent Cloud Schema Registry, add the following configuration parameters
#
#   basic.auth.credentials.source=USER_INFO
#   basic.auth.user.info=<SR API KEY>:<SR API SECRET>
#   schema.registry.url=https://<SR ENDPOINT>
#
# If you are using Confluent Cloud ksqlDB, add the following configuration parameters
#
#   ksql.endpoint=<ksqlDB ENDPOINT>
#   ksql.basic.auth.user.info=<ksqlDB API KEY>:<ksqlDB API SECRET>
#
function ccloud::generate_configs() {
  CONFIG_FILE=$1
  if [[ -z "$CONFIG_FILE" ]]; then
    CONFIG_FILE=~/.ccloud/config
  fi
  if [[ ! -f "$CONFIG_FILE" ]]; then
    echo "File $CONFIG_FILE is not found.  Please create this properties file to connect to your Confluent Cloud cluster and then try again"
    echo "See https://docs.confluent.io/current/cloud/connect/auto-generate-configs.html for more information"
    return 1
  fi

  echo -e "\nGenerating component configurations from $CONFIG_FILE"
  echo -e "\n(If you want to run any of these components to talk to Confluent Cloud, these are the configurations to add to the properties file for each component)"

  # Set permissions
  PERM=600
  if ls --version 2>/dev/null | grep -q 'coreutils' ; then
    # GNU binutils
    PERM=$(stat -c "%a" $CONFIG_FILE)
  else
    # BSD
    PERM=$(stat -f "%OLp" $CONFIG_FILE)
  fi

  # Make destination
  DEST="/tmp/delta_configs"
  mkdir -p $DEST

  # Glean parameters from the Confluent Cloud configuration file

  # Kafka cluster
  BOOTSTRAP_SERVERS=$( grep "^bootstrap.server" $CONFIG_FILE | awk -F'=' '{print $2;}' )
  BOOTSTRAP_SERVERS=${BOOTSTRAP_SERVERS/\\/}
  SASL_JAAS_CONFIG=$( grep "^sasl.jaas.config" $CONFIG_FILE | cut -d'=' -f2- )
  SASL_JAAS_CONFIG_PROPERTY_FORMAT=${SASL_JAAS_CONFIG/username\\=/username=}
  SASL_JAAS_CONFIG_PROPERTY_FORMAT=${SASL_JAAS_CONFIG_PROPERTY_FORMAT/password\\=/password=}
  CLOUD_KEY=$( echo $SASL_JAAS_CONFIG | awk '{print $3}' | awk -F"'" '$0=$2' )
  CLOUD_SECRET=$( echo $SASL_JAAS_CONFIG | awk '{print $4}' | awk -F"'" '$0=$2' )

  # Schema Registry
  BASIC_AUTH_CREDENTIALS_SOURCE=$( grep "^basic.auth.credentials.source" $CONFIG_FILE | awk -F'=' '{print $2;}' )
  SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO=$( grep "^basic.auth.user.info" $CONFIG_FILE | awk -F'=' '{print $2;}' )
  SCHEMA_REGISTRY_URL=$( grep "^schema.registry.url" $CONFIG_FILE | awk -F'=' '{print $2;}' )

  # ksqlDB
  KSQLDB_ENDPOINT=$( grep "^ksql.endpoint" $CONFIG_FILE | awk -F'=' '{print $2;}' )
  KSQLDB_BASIC_AUTH_USER_INFO=$( grep "^ksql.basic.auth.user.info" $CONFIG_FILE | awk -F'=' '{print $2;}' )

  # Build configuration file with Confluent Cloud connection parameters and
  # Confluent Monitoring Interceptors for Streams Monitoring in Confluent Control Center
  INTERCEPTORS_CONFIG_FILE=$DEST/interceptors-ccloud.config
  rm -f $INTERCEPTORS_CONFIG_FILE
  echo "# Configuration derived from $CONFIG_FILE" > $INTERCEPTORS_CONFIG_FILE
  while read -r line
  do
    # Skip lines that are commented out
    if [[ ! -z $line && ${line:0:1} == '#' ]]; then
      continue
    fi
    # Skip lines that contain just whitespace
    if [[ -z "${line// }" ]]; then
      continue
    fi
    if [[ ${line:0:9} == 'bootstrap' ]]; then
      line=${line/\\/}
    fi
    echo $line >> $INTERCEPTORS_CONFIG_FILE
  done < "$CONFIG_FILE"
  echo -e "\n# Confluent Monitoring Interceptor specific configuration" >> $INTERCEPTORS_CONFIG_FILE
  while read -r line
  do
    # Skip lines that are commented out
    if [[ ! -z $line && ${line:0:1} == '#' ]]; then
      continue
    fi
    # Skip lines that contain just whitespace
    if [[ -z "${line// }" ]]; then
      continue
    fi
    if [[ ${line:0:9} == 'bootstrap' ]]; then
      line=${line/\\/}
    fi
    if [[ ${line:0:4} == 'sasl' ||
          ${line:0:3} == 'ssl' ||
          ${line:0:8} == 'security' ||
          ${line:0:9} == 'bootstrap' ]]; then
      echo "confluent.monitoring.interceptor.$line" >> $INTERCEPTORS_CONFIG_FILE
    fi
  done < "$CONFIG_FILE"
  chmod $PERM $INTERCEPTORS_CONFIG_FILE

  echo -e "\nConfluent Platform Components:"

  # Confluent Schema Registry instance (local) for Confluent Cloud
  SR_CONFIG_DELTA=$DEST/schema-registry-ccloud.delta
  echo "$SR_CONFIG_DELTA"
  rm -f $SR_CONFIG_DELTA
  while read -r line
  do
    if [[ ! -z $line && ${line:0:1} != '#' ]]; then
      if [[ ${line:0:29} != 'basic.auth.credentials.source' && ${line:0:15} != 'schema.registry' ]]; then
        echo "kafkastore.$line" >> $SR_CONFIG_DELTA
      fi
    fi
  done < "$CONFIG_FILE"
  chmod $PERM $SR_CONFIG_DELTA

  # Confluent Replicator (executable) for Confluent Cloud
  REPLICATOR_PRODUCER_DELTA=$DEST/replicator-to-ccloud-producer.delta
  echo "$REPLICATOR_PRODUCER_DELTA"
  rm -f $REPLICATOR_PRODUCER_DELTA
  cp $INTERCEPTORS_CONFIG_FILE $REPLICATOR_PRODUCER_DELTA
  echo -e "\n# Confluent Replicator (executable) specific configuration" >> $REPLICATOR_PRODUCER_DELTA
  echo "interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor" >> $REPLICATOR_PRODUCER_DELTA
  REPLICATOR_SASL_JAAS_CONFIG=$SASL_JAAS_CONFIG
  REPLICATOR_SASL_JAAS_CONFIG=${REPLICATOR_SASL_JAAS_CONFIG//\\=/=}
  REPLICATOR_SASL_JAAS_CONFIG=${REPLICATOR_SASL_JAAS_CONFIG//\"/\\\"}
  chmod $PERM $REPLICATOR_PRODUCER_DELTA

  # ksqlDB Server runs locally and connects to Confluent Cloud
  KSQLDB_SERVER_DELTA=$DEST/ksqldb-server-ccloud.delta
  echo "$KSQLDB_SERVER_DELTA"
  rm -f $KSQLDB_SERVER_DELTA
  cp $INTERCEPTORS_CONFIG_FILE $KSQLDB_SERVER_DELTA
  echo -e "\n# ksqlDB Server specific configuration" >> $KSQLDB_SERVER_DELTA
  echo "producer.interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor" >> $KSQLDB_SERVER_DELTA
  echo "consumer.interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor" >> $KSQLDB_SERVER_DELTA
  echo "ksql.streams.producer.retries=2147483647" >> $KSQLDB_SERVER_DELTA
  echo "ksql.streams.producer.confluent.batch.expiry.ms=9223372036854775807" >> $KSQLDB_SERVER_DELTA
  echo "ksql.streams.producer.request.timeout.ms=300000" >> $KSQLDB_SERVER_DELTA
  echo "ksql.streams.producer.max.block.ms=9223372036854775807" >> $KSQLDB_SERVER_DELTA
  echo "ksql.streams.replication.factor=3" >> $KSQLDB_SERVER_DELTA
  echo "ksql.internal.topic.replicas=3" >> $KSQLDB_SERVER_DELTA
  echo "ksql.sink.replicas=3" >> $KSQLDB_SERVER_DELTA
  echo -e "\n# Confluent Schema Registry configuration for ksqlDB Server" >> $KSQLDB_SERVER_DELTA
  while read -r line
  do
    if [[ ${line:0:29} == 'basic.auth.credentials.source' ]]; then
      echo "ksql.schema.registry.$line" >> $KSQLDB_SERVER_DELTA
    elif [[ ${line:0:15} == 'schema.registry' ]]; then
      echo "ksql.$line" >> $KSQLDB_SERVER_DELTA
    fi
  done < $CONFIG_FILE
  chmod $PERM $KSQLDB_SERVER_DELTA

  # KSQL DataGen for Confluent Cloud
  KSQL_DATAGEN_DELTA=$DEST/ksql-datagen.delta
  echo "$KSQL_DATAGEN_DELTA"
  rm -f $KSQL_DATAGEN_DELTA
  cp $INTERCEPTORS_CONFIG_FILE $KSQL_DATAGEN_DELTA
  echo -e "\n# KSQL DataGen specific configuration" >> $KSQL_DATAGEN_DELTA
  echo "interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor" >> $KSQL_DATAGEN_DELTA
  echo -e "\n# Confluent Schema Registry configuration for KSQL DataGen" >> $KSQL_DATAGEN_DELTA
  while read -r line
  do
    if [[ ${line:0:29} == 'basic.auth.credentials.source' ]]; then
      echo "ksql.schema.registry.$line" >> $KSQL_DATAGEN_DELTA
    elif [[ ${line:0:15} == 'schema.registry' ]]; then
      echo "ksql.$line" >> $KSQL_DATAGEN_DELTA
    fi
  done < $CONFIG_FILE
  chmod $PERM $KSQL_DATAGEN_DELTA

  # Confluent Control Center runs locally, monitors Confluent Cloud, and uses Confluent Cloud cluster as the backstore
  C3_DELTA=$DEST/control-center-ccloud.delta
  echo "$C3_DELTA"
  rm -f $C3_DELTA
  echo -e "\n# Confluent Control Center specific configuration" >> $C3_DELTA
  while read -r line
    do
    if [[ ! -z $line && ${line:0:1} != '#' ]]; then
      if [[ ${line:0:9} == 'bootstrap' ]]; then
        line=${line/\\/}
        echo "$line" >> $C3_DELTA
      fi
      if [[ ${line:0:4} == 'sasl' || ${line:0:3} == 'ssl' || ${line:0:8} == 'security' ]]; then
        echo "confluent.controlcenter.streams.$line" >> $C3_DELTA
      fi
    fi
  done < "$CONFIG_FILE"
  # max.message.bytes is enforced to 8MB in Confluent Cloud
  echo "confluent.metrics.topic.max.message.bytes=8388608" >> $C3_DELTA
  echo -e "\n# Confluent Schema Registry configuration for Confluent Control Center" >> $C3_DELTA
  while read -r line
  do
    if [[ ${line:0:29} == 'basic.auth.credentials.source' ]]; then
      echo "confluent.controlcenter.schema.registry.$line" >> $C3_DELTA
    elif [[ ${line:0:15} == 'schema.registry' ]]; then
      echo "confluent.controlcenter.$line" >> $C3_DELTA
    fi
  done < $CONFIG_FILE
  chmod $PERM $C3_DELTA

  # Confluent Metrics Reporter to Confluent Cloud
  METRICS_REPORTER_DELTA=$DEST/metrics-reporter.delta
  echo "$METRICS_REPORTER_DELTA"
  rm -f $METRICS_REPORTER_DELTA
  echo "metric.reporters=io.confluent.metrics.reporter.ConfluentMetricsReporter" >> $METRICS_REPORTER_DELTA
  echo "confluent.metrics.reporter.topic.replicas=3" >> $METRICS_REPORTER_DELTA
  while read -r line
    do
    if [[ ! -z $line && ${line:0:1} != '#' ]]; then
      if [[ ${line:0:9} == 'bootstrap' || ${line:0:4} == 'sasl' || ${line:0:3} == 'ssl' || ${line:0:8} == 'security' ]]; then
        echo "confluent.metrics.reporter.$line" >> $METRICS_REPORTER_DELTA
      fi
    fi
  done < "$CONFIG_FILE"
  chmod $PERM $METRICS_REPORTER_DELTA

  # Confluent REST Proxy to Confluent Cloud
  REST_PROXY_DELTA=$DEST/rest-proxy.delta
  echo "$REST_PROXY_DELTA"
  rm -f $REST_PROXY_DELTA
  while read -r line
    do
    if [[ ! -z $line && ${line:0:1} != '#' ]]; then
      if [[ ${line:0:9} == 'bootstrap' || ${line:0:4} == 'sasl' || ${line:0:3} == 'ssl' || ${line:0:8} == 'security' ]]; then
        echo "$line" >> $REST_PROXY_DELTA
        echo "client.$line" >> $REST_PROXY_DELTA
      fi
    fi
  done < "$CONFIG_FILE"
  echo -e "\n# Confluent Schema Registry configuration for REST Proxy" >> $REST_PROXY_DELTA
  while read -r line
  do
    if [[ ${line:0:29} == 'basic.auth.credentials.source' || ${line:0:36} == 'schema.registry.basic.auth.user.info' ]]; then
      echo "client.$line" >> $REST_PROXY_DELTA
    elif [[ ${line:0:19} == 'schema.registry.url' ]]; then
      echo "$line" >> $REST_PROXY_DELTA
    fi
  done < $CONFIG_FILE
  chmod $PERM $REST_PROXY_DELTA

  # Kafka Connect runs locally and connects to Confluent Cloud
  CONNECT_DELTA=$DEST/connect-ccloud.delta
  echo "$CONNECT_DELTA"
  rm -f $CONNECT_DELTA
  cat <<EOF > $CONNECT_DELTA
# Configuration for embedded admin client
replication.factor=3
config.storage.replication.factor=3
offset.storage.replication.factor=3
status.storage.replication.factor=3

EOF
  while read -r line
    do
    if [[ ! -z $line && ${line:0:1} != '#' ]]; then
      if [[ ${line:0:9} == 'bootstrap' ]]; then
        line=${line/\\/}
        echo "$line" >> $CONNECT_DELTA
      fi
      if [[ ${line:0:4} == 'sasl' || ${line:0:3} == 'ssl' || ${line:0:8} == 'security' ]]; then
        echo "$line" >> $CONNECT_DELTA
      fi
    fi
  done < "$CONFIG_FILE"

  for prefix in "producer" "consumer" "producer.confluent.monitoring.interceptor" "consumer.confluent.monitoring.interceptor" ; do

  echo -e "\n# Configuration for embedded $prefix" >> $CONNECT_DELTA
  while read -r line
    do
    if [[ ! -z $line && ${line:0:1} != '#' ]]; then
      if [[ ${line:0:9} == 'bootstrap' ]]; then
        line=${line/\\/}
      fi
      if [[ ${line:0:4} == 'sasl' || ${line:0:3} == 'ssl' || ${line:0:8} == 'security' ]]; then
        echo "${prefix}.$line" >> $CONNECT_DELTA
      fi
    fi
  done < "$CONFIG_FILE"

  done

  cat <<EOF >> $CONNECT_DELTA

# Confluent Schema Registry for Kafka Connect
value.converter=io.confluent.connect.avro.AvroConverter
value.converter.basic.auth.credentials.source=$BASIC_AUTH_CREDENTIALS_SOURCE
value.converter.schema.registry.basic.auth.user.info=$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO
value.converter.schema.registry.url=$SCHEMA_REGISTRY_URL
EOF
  chmod $PERM $CONNECT_DELTA

  # Kafka connector
  CONNECTOR_DELTA=$DEST/connector-ccloud.delta
  echo "$CONNECTOR_DELTA"
  rm -f $CONNECTOR_DELTA
  cat <<EOF >> $CONNECTOR_DELTA
// Confluent Schema Registry for Kafka connectors
value.converter=io.confluent.connect.avro.AvroConverter
value.converter.basic.auth.credentials.source=$BASIC_AUTH_CREDENTIALS_SOURCE
value.converter.schema.registry.basic.auth.user.info=$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO
value.converter.schema.registry.url=$SCHEMA_REGISTRY_URL
EOF
  chmod $PERM $CONNECTOR_DELTA

  # AK command line tools
  AK_TOOLS_DELTA=$DEST/ak-tools-ccloud.delta
  echo "$AK_TOOLS_DELTA"
  rm -f $AK_TOOLS_DELTA
  cp $CONFIG_FILE $AK_TOOLS_DELTA
  chmod $PERM $AK_TOOLS_DELTA

  echo -e "\nKafka Clients:"

  # Java (Producer/Consumer)
  JAVA_PC_CONFIG=$DEST/java_producer_consumer.delta
  echo "$JAVA_PC_CONFIG"
  rm -f $JAVA_PC_CONFIG

  cat <<EOF >> $JAVA_PC_CONFIG
import java.util.Properties;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ConsumerConfig;
import org.apache.kafka.common.config.SaslConfigs;

Properties props = new Properties();

// Basic Confluent Cloud Connectivity
props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "$BOOTSTRAP_SERVERS");
props.put(ProducerConfig.REPLICATION_FACTOR_CONFIG, 3);
props.put(ProducerConfig.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
props.put(SaslConfigs.SASL_MECHANISM, "PLAIN");
props.put(SaslConfigs.SASL_JAAS_CONFIG, "$SASL_JAAS_CONFIG");

// Confluent Schema Registry for Java
props.put("basic.auth.credentials.source", "$BASIC_AUTH_CREDENTIALS_SOURCE");
props.put("schema.registry.basic.auth.user.info", "$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO");
props.put("schema.registry.url", "$SCHEMA_REGISTRY_URL");

// Optimize Performance for Confluent Cloud
props.put(ProducerConfig.RETRIES_CONFIG, 2147483647);
props.put("producer.confluent.batch.expiry.ms", 9223372036854775807);
props.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, 300000);
props.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 9223372036854775807);

// Required for Streams Monitoring in Confluent Control Center
props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor");
props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, confluent.monitoring.interceptor.bootstrap.servers, "$BOOTSTRAP_SERVERS");
props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + ProducerConfig.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_MECHANISM, "PLAIN");
props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_JAAS_CONFIG, "$SASL_JAAS_CONFIG");
props.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG, "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor");
props.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, confluent.monitoring.interceptor.bootstrap.servers, "$BOOTSTRAP_SERVERS");
props.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + ProducerConfig.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
props.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_MECHANISM, "PLAIN");
props.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_JAAS_CONFIG, "$SASL_JAAS_CONFIG");

// .... additional configuration settings
EOF
  chmod $PERM $JAVA_PC_CONFIG

  # Java (Streams)
  JAVA_STREAMS_CONFIG=$DEST/java_streams.delta
  echo "$JAVA_STREAMS_CONFIG"
  rm -f $JAVA_STREAMS_CONFIG

  cat <<EOF >> $JAVA_STREAMS_CONFIG
import java.util.Properties;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ConsumerConfig;
import org.apache.kafka.common.config.SaslConfigs;
import org.apache.kafka.streams.StreamsConfig;

Properties props = new Properties();

// Basic Confluent Cloud Connectivity
props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "$BOOTSTRAP_SERVERS");
props.put(StreamsConfig.REPLICATION_FACTOR_CONFIG, 3);
props.put(StreamsConfig.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
props.put(SaslConfigs.SASL_MECHANISM, "PLAIN");
props.put(SaslConfigs.SASL_JAAS_CONFIG, "$SASL_JAAS_CONFIG");

// Confluent Schema Registry for Java
props.put("basic.auth.credentials.source", "$BASIC_AUTH_CREDENTIALS_SOURCE");
props.put("schema.registry.basic.auth.user.info", "$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO");
props.put("schema.registry.url", "$SCHEMA_REGISTRY_URL");

// Optimize Performance for Confluent Cloud
props.put(StreamsConfig.producerPrefix(ProducerConfig.RETRIES_CONFIG), 2147483647);
props.put("producer.confluent.batch.expiry.ms", 9223372036854775807);
props.put(StreamsConfig.producerPrefix(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG), 300000);
props.put(StreamsConfig.producerPrefix(ProducerConfig.MAX_BLOCK_MS_CONFIG), 9223372036854775807);

// Required for Streams Monitoring in Confluent Control Center
props.put(StreamsConfig.PRODUCER_PREFIX + ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor");
props.put(StreamsConfig.PRODUCER_PREFIX + ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, confluent.monitoring.interceptor.bootstrap.servers, "$BOOTSTRAP_SERVERS");
props.put(StreamsConfig.PRODUCER_PREFIX + ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + StreamsConfig.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
props.put(StreamsConfig.PRODUCER_PREFIX + ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_MECHANISM, "PLAIN");
props.put(StreamsConfig.PRODUCER_PREFIX + ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_JAAS_CONFIG, "$SASL_JAAS_CONFIG");
props.put(StreamsConfig.CONSUMER_PREFIX + ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG, "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor");
props.put(StreamsConfig.CONSUMER_PREFIX + ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, confluent.monitoring.interceptor.bootstrap.servers, "$BOOTSTRAP_SERVERS");
props.put(StreamsConfig.CONSUMER_PREFIX + ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + StreamsConfig.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
props.put(StreamsConfig.CONSUMER_PREFIX + ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_MECHANISM, "PLAIN");
props.put(StreamsConfig.CONSUMER_PREFIX + ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_JAAS_CONFIG, "$SASL_JAAS_CONFIG");

// .... additional configuration settings
EOF
  chmod $PERM $JAVA_STREAMS_CONFIG

  # librdkafka
  LIBRDKAFKA_CONFIG=$DEST/librdkafka.delta
  echo "$LIBRDKAFKA_CONFIG"
  rm -f $LIBRDKAFKA_CONFIG

  cat <<EOF >> $LIBRDKAFKA_CONFIG
bootstrap.servers="$BOOTSTRAP_SERVERS"
security.protocol=SASL_SSL
sasl.mechanisms=PLAIN
sasl.username="$CLOUD_KEY"
sasl.password="$CLOUD_SECRET"
schema.registry.url="$SCHEMA_REGISTRY_URL"
basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO"
EOF
  chmod $PERM $LIBRDKAFKA_CONFIG

  # Python
  PYTHON_CONFIG=$DEST/python.delta
  echo "$PYTHON_CONFIG"
  rm -f $PYTHON_CONFIG

  cat <<EOF >> $PYTHON_CONFIG
from confluent_kafka import Producer, Consumer, KafkaError

producer = Producer({
           'bootstrap.servers': '$BOOTSTRAP_SERVERS',
           'broker.version.fallback': '0.10.0.0',
           'api.version.fallback.ms': 0,
           'sasl.mechanisms': 'PLAIN',
           'security.protocol': 'SASL_SSL',
           'sasl.username': '$CLOUD_KEY',
           'sasl.password': '$CLOUD_SECRET',
           // 'ssl.ca.location': '/usr/local/etc/openssl/cert.pem', // varies by distro
           'plugin.library.paths': 'monitoring-interceptor',
           // .... additional configuration settings
})

consumer = Consumer({
           'bootstrap.servers': '$BOOTSTRAP_SERVERS',
           'broker.version.fallback': '0.10.0.0',
           'api.version.fallback.ms': 0,
           'sasl.mechanisms': 'PLAIN',
           'security.protocol': 'SASL_SSL',
           'sasl.username': '$CLOUD_KEY',
           'sasl.password': '$CLOUD_SECRET',
           // 'ssl.ca.location': '/usr/local/etc/openssl/cert.pem', // varies by distro
           'plugin.library.paths': 'monitoring-interceptor',
           // .... additional configuration settings
})
EOF
  chmod $PERM $PYTHON_CONFIG

  # .NET

  DOTNET_CONFIG=$DEST/dotnet.delta
  echo "$DOTNET_CONFIG"
  rm -f $DOTNET_CONFIG

  cat <<EOF >> $DOTNET_CONFIG
using Confluent.Kafka;

var producerConfig = new Dictionary<string, object>
{
    { "bootstrap.servers", "$BOOTSTRAP_SERVERS" },
    { "broker.version.fallback", "0.10.0.0" },
    { "api.version.fallback.ms", 0 },
    { "sasl.mechanisms", "PLAIN" },
    { "security.protocol", "SASL_SSL" },
    { "sasl.username", "$CLOUD_KEY" },
    { "sasl.password", "$CLOUD_SECRET" },
    // { "ssl.ca.location", "/usr/local/etc/openssl/cert.pem" }, // varies by distro
    { ‚Äúplugin.library.paths‚Äù, ‚Äúmonitoring-interceptor‚Äù},
    // .... additional configuration settings
};

var consumerConfig = new Dictionary<string, object>
{
    { "bootstrap.servers", "$BOOTSTRAP_SERVERS" },
    { "broker.version.fallback", "0.10.0.0" },
    { "api.version.fallback.ms", 0 },
    { "sasl.mechanisms", "PLAIN" },
    { "security.protocol", "SASL_SSL" },
    { "sasl.username", "$CLOUD_KEY" },
    { "sasl.password", "$CLOUD_SECRET" },
    // { "ssl.ca.location", "/usr/local/etc/openssl/cert.pem" }, // varies by distro
    { ‚Äúplugin.library.paths‚Äù, ‚Äúmonitoring-interceptor‚Äù},
    // .... additional configuration settings
};
EOF
  chmod $PERM $DOTNET_CONFIG

  # Go
  GO_CONFIG=$DEST/go.delta
  echo "$GO_CONFIG"
  rm -f $GO_CONFIG

  cat <<EOF >> $GO_CONFIG
import (
  "github.com/confluentinc/confluent-kafka-go/kafka"

producer, err := kafka.NewProducer(&kafka.ConfigMap{
           "bootstrap.servers": "$BOOTSTRAP_SERVERS",
          "broker.version.fallback": "0.10.0.0",
          "api.version.fallback.ms": 0,
          "sasl.mechanisms": "PLAIN",
          "security.protocol": "SASL_SSL",
          "sasl.username": "$CLOUD_KEY",
          "sasl.password": "$CLOUD_SECRET",
                 // "ssl.ca.location": "/usr/local/etc/openssl/cert.pem", // varies by distro
                 "plugin.library.paths": "monitoring-interceptor",
                 // .... additional configuration settings
                 })

consumer, err := kafka.NewConsumer(&kafka.ConfigMap{
     "bootstrap.servers": "$BOOTSTRAP_SERVERS",
       "broker.version.fallback": "0.10.0.0",
       "api.version.fallback.ms": 0,
       "sasl.mechanisms": "PLAIN",
       "security.protocol": "SASL_SSL",
       "sasl.username": "$CLOUD_KEY",
       "sasl.password": "$CLOUD_SECRET",
                 // "ssl.ca.location": "/usr/local/etc/openssl/cert.pem", // varies by distro
       "session.timeout.ms": 6000,
                 "plugin.library.paths": "monitoring-interceptor",
                 // .... additional configuration settings
                 })
EOF
  chmod $PERM $GO_CONFIG

  # Node.js
  NODE_CONFIG=$DEST/node.delta
  echo "$NODE_CONFIG"
  rm -f $NODE_CONFIG

  cat <<EOF >> $NODE_CONFIG
var Kafka = require('node-rdkafka');

var producer = new Kafka.Producer({
    'metadata.broker.list': '$BOOTSTRAP_SERVERS',
    'sasl.mechanisms': 'PLAIN',
    'security.protocol': 'SASL_SSL',
    'sasl.username': '$CLOUD_KEY',
    'sasl.password': '$CLOUD_SECRET',
     // 'ssl.ca.location': '/usr/local/etc/openssl/cert.pem', // varies by distro
    'plugin.library.paths': 'monitoring-interceptor',
    // .... additional configuration settings
  });

var consumer = Kafka.KafkaConsumer.createReadStream({
    'metadata.broker.list': '$BOOTSTRAP_SERVERS',
    'sasl.mechanisms': 'PLAIN',
    'security.protocol': 'SASL_SSL',
    'sasl.username': '$CLOUD_KEY',
    'sasl.password': '$CLOUD_SECRET',
     // 'ssl.ca.location': '/usr/local/etc/openssl/cert.pem', // varies by distro
    'plugin.library.paths': 'monitoring-interceptor',
    // .... additional configuration settings
  }, {}, {
    topics: '<topic name>',
    waitInterval: 0,
    objectMode: false
});
EOF
  chmod $PERM $NODE_CONFIG

  # C++
  CPP_CONFIG=$DEST/cpp.delta
  echo "$CPP_CONFIG"
  rm -f $CPP_CONFIG

  cat <<EOF >> $CPP_CONFIG
#include <librdkafka/rdkafkacpp.h>

RdKafka::Conf *producerConfig = RdKafka::Conf::create(RdKafka::Conf::CONF_GLOBAL);
if (producerConfig->set("metadata.broker.list", "$BOOTSTRAP_SERVERS", errstr) != RdKafka::Conf::CONF_OK ||
    producerConfig->set("sasl.mechanisms", "PLAIN", errstr) != RdKafka::Conf::CONF_OK ||
    producerConfig->set("security.protocol", "SASL_SSL", errstr) != RdKafka::Conf::CONF_OK ||
    producerConfig->set("sasl.username", "$CLOUD_KEY", errstr) != RdKafka::Conf::CONF_OK ||
    producerConfig->set("sasl.password", "$CLOUD_SECRET", errstr) != RdKafka::Conf::CONF_OK ||
    // producerConfig->set("ssl.ca.location", "/usr/local/etc/openssl/cert.pem", errstr) != RdKafka::Conf::CONF_OK || // varies by distro
    producerConfig->set("plugin.library.paths", "monitoring-interceptor", errstr) != RdKafka::Conf::CONF_OK ||
    // .... additional configuration settings
   ) {
        std::cerr << "Configuration failed: " << errstr << std::endl;
        exit(1);
}
RdKafka::Producer *producer = RdKafka::Producer::create(producerConfig, errstr);

RdKafka::Conf *consumerConfig = RdKafka::Conf::create(RdKafka::Conf::CONF_GLOBAL);
if (consumerConfig->set("metadata.broker.list", "$BOOTSTRAP_SERVERS", errstr) != RdKafka::Conf::CONF_OK ||
    consumerConfig->set("sasl.mechanisms", "PLAIN", errstr) != RdKafka::Conf::CONF_OK ||
    consumerConfig->set("security.protocol", "SASL_SSL", errstr) != RdKafka::Conf::CONF_OK ||
    consumerConfig->set("sasl.username", "$CLOUD_KEY", errstr) != RdKafka::Conf::CONF_OK ||
    consumerConfig->set("sasl.password", "$CLOUD_SECRET", errstr) != RdKafka::Conf::CONF_OK ||
    // consumerConfig->set("ssl.ca.location", "/usr/local/etc/openssl/cert.pem", errstr) != RdKafka::Conf::CONF_OK || // varies by distro
    consumerConfig->set("plugin.library.paths", "monitoring-interceptor", errstr) != RdKafka::Conf::CONF_OK ||
    // .... additional configuration settings
   ) {
        std::cerr << "Configuration failed: " << errstr << std::endl;
        exit(1);
}
RdKafka::Consumer *consumer = RdKafka::Consumer::create(consumerConfig, errstr);
EOF
  chmod $PERM $CPP_CONFIG

  # ENV
  ENV_CONFIG=$DEST/env.delta
  echo "$ENV_CONFIG"
  rm -f $ENV_CONFIG

  cat <<EOF >> $ENV_CONFIG
export BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS"
export SASL_JAAS_CONFIG="$SASL_JAAS_CONFIG"
export SASL_JAAS_CONFIG_PROPERTY_FORMAT="$SASL_JAAS_CONFIG_PROPERTY_FORMAT"
export REPLICATOR_SASL_JAAS_CONFIG="$REPLICATOR_SASL_JAAS_CONFIG"
export BASIC_AUTH_CREDENTIALS_SOURCE="$BASIC_AUTH_CREDENTIALS_SOURCE"
export SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO"
export SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL"
export CLOUD_KEY="$CLOUD_KEY"
export CLOUD_SECRET="$CLOUD_SECRET"
export KSQLDB_ENDPOINT="$KSQLDB_ENDPOINT"
export KSQLDB_BASIC_AUTH_USER_INFO="$KSQLDB_BASIC_AUTH_USER_INFO"
EOF
  chmod $PERM $ENV_CONFIG

  return 0
}

# These are some duplicate functions from

#  helper.sh to decouple the script files.  In

#  the future we can work to remove this

#  duplication if necessary
function ccloud::retry() {
    local -r -i max_wait="$1"; shift
    local -r cmd="$@"

    local -i sleep_interval=5
    local -i curr_wait=0

    until $cmd
    do
        if (( curr_wait >= max_wait ))
        then
            echo "ERROR: Failed after $curr_wait seconds. Please troubleshoot and run again."
            return 1
        else
            printf "."
            curr_wait=$((curr_wait+sleep_interval))
            sleep $sleep_interval
        fi
    done
    printf "\n"
}
function ccloud::version_gt() {

  test "$(printf '%s\n' "$@" | sort -V | head -n 1)" != "$1";
}


function check_arm64_support() {

  DIR="$1"
  DOCKER_COMPOSE_FILE="$2"
  set +e
  if [ `uname -m` = "arm64" ]
  then
    test=$(echo "$DOCKER_COMPOSE_FILE" | awk -F"/" '{ print $(NF-2)"/"$(NF-1) }')
    grep "${test}" ${DIR}/../../scripts/arm64-support-none.txt > /dev/null
    if [ $? = 0 ]
    then
        logerror "üñ•Ô∏è This example is not working with ARM64 !"
        log "Do you want to start test anyway ?"
        check_if_continue
    fi

    grep "${test}" ${DIR}/../../scripts/arm64-support-with-emulation.txt > /dev/null
    if [ $? = 0 ]
    then
        logwarn "üñ•Ô∏è This example is working with ARM64 but requires emulation."
    fi

    log "üñ•Ô∏è This example should work natively with ARM64."
  fi
  set -e
}

function playground() {
  if [[ $(type -f playground 2>&1) =~ "not found" ]]
  then
    ../../scripts/cli/playground "$@"
  else
    $(which playground) "$@"
  fi
}

# src/lib/validations/validate_dir_exists.sh
validate_dir_exists() {
  [[ -d "$1" ]] || echo "must be an existing directory"
}

# src/lib/validations/validate_editor_exists.sh
validate_editor_exists() {
  local cmd="$1"
  if [[ $(type $cmd 2>&1) =~ "not found" ]]; then
    echo -e "\nERROR: This script requires '$cmd'. Please install '$cmd' and run again.\n"
    exit 1
  fi
}

# src/lib/validations/validate_file_exists.sh
validate_file_exists() {
  [[ -f "$1" ]] || echo "must be an existing file"
}

# src/lib/validations/validate_file_exists_with_trick.sh
validate_file_exists_with_trick() {
  file="$1"

  real_file=$file
  if [[ $file == *"@"* ]]
  then
    real_file=$(echo "$file" | cut -d "@" -f 2)
  fi

  [[ -f "$real_file" ]] || echo "$real_file must be an existing file"
}

# src/lib/validations/validate_integer.sh
validate_integer() {
  [[ "$1" =~ ^[0-9]+$ ]] || echo "must be an integer"
}

# src/lib/validations/validate_not_empty.sh
validate_not_empty() {
  [[ -z "$1" ]] && echo "must not be empty"
}

# :command.command_functions
# :command.function
playground_get_connector_list_command() {
  # src/get_connector_list_command.sh
  get_connector_list
}

# :command.function
playground_get_topic_list_command() {
  # src/get_topic_list_command.sh
  #docker exec broker kafka-topics --bootstrap-server broker:9092 --list | grep -v "^_"
  # trick to be faster
  docker exec broker ls /var/lib/kafka/data | grep -v "checkpoint" | grep -v "meta.properties" | grep -v "^_" | sed 's/[^-]*$//' | sed 's/.$//' | sort | uniq
}

# :command.function
playground_get_examples_list_with_fzf_command() {
  # src/get_examples_list_with_fzf_command.sh
  without_repro="${args[--without-repro]}"
  sink_only="${args[--sink-only]}"
  cur="${args[cur]}"

  if [[ -n "$without_repro" ]] && [[ -n "$sink_only" ]]
  then
      get_examples_list_with_fzf_without_repro_sink_only "$cur"
      return
  fi

  if [[ -n "$without_repro" ]]
  then
      get_examples_list_with_fzf_without_repro "$cur"
      return
  fi

  get_examples_list_with_fzf "$cur"
}

# :command.function
playground_run_command() {
  # src/run_command.sh
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

  root_folder=${DIR_CLI}/../..

  test_file="${args[--file]}"
  skip_editor="${args[--skip-editor]}"
  tag="${args[--tag]}"
  connector_tag="${args[--connector-tag]}"
  connector_zip="${args[--connector-zip]}"
  connector_jar="${args[--connector-jar]}"
  connector_jar="${args[--connector-jar]}"
  disable_ksqldb="${args[--disable-ksqldb]}"
  disable_c3="${args[--disable-control-center]}"
  enable_conduktor="${args[--enable-conduktor]}"
  enable_multiple_brokers="${args[--enable-multiple-brokers]}"
  enable_multiple_connect_workers="${args[--enable-multiple-connect-workers]}"
  enable_jmx_grafana="${args[--enable-jmx-grafana]}"
  enable_kcat="${args[--enable-kcat]}"
  enable_sr_maven_plugin_app="${args[--enable-sr-maven-plugin-app]}"

  if [ "$test_file" = "" ]
  then
    logerror "ERROR: test_file is not provided as argument!"
    exit 1
  fi

  if [[ $test_file == *"@"* ]]
  then
    test_file=$(echo "$test_file" | cut -d "@" -f 2)
  fi

  if [ ! -f "$test_file" ]
  then
    logerror "ERROR: test_file $test_file does not exist!"
    exit 1
  fi

  if [[ "$test_file" != *".sh" ]]
  then
    logerror "ERROR: test_file $test_file is not a .sh file!"
    exit 1
  fi

  test_file_directory="$(dirname "${test_file}")"

  # determining the docker-compose file from from test_file
  docker_compose_file=$(grep "environment" "$test_file" | grep DIR | grep start.sh | cut -d "/" -f 7 | cut -d '"' -f 1 | tail -n1 | xargs)

  if [ "${docker_compose_file}" != "" ] && [ ! -f "${test_file_directory}/${docker_compose_file}" ]
  then
    docker_compose_file=""
    logwarn "üìÅ Could not determine docker-compose override file from $test_file !"
  fi

  filename=$(basename -- "$test_file")
  extension="${filename##*.}"

  base1="${test_file_directory##*/}" # connect-cdc-oracle12-source
  dir1="${test_file_directory%/*}" #connect
  dir2="${dir1##*/}/$base1" # connect/connect-cdc-oracle12-source
  final_dir=$(echo $dir2 | tr '/' '-') # connect-connect-cdc-oracle12-source

  environment_variables_list=""
  argument_list=""
  if [[ -n "$tag" ]]
  then
    environment_variables_list="TAG=$tag"
    argument_list="--tag=$tag"
    export TAG=$tag
  fi

  if [[ -n "$connector_tag" ]]
  then
    environment_variables_list="$environment_variables_list CONNECTOR_TAG=$connector_tag"
    argument_list="$argument_list --connector-tag=$connector_tag"
    export CONNECTOR_TAG=$connector_tag
  fi

  if [[ -n "$connector_zip" ]]
  then
    environment_variables_list="$environment_variables_list CONNECTOR_ZIP=$connector_zip"
    argument_list="$argument_list --connector-zip=$connector_zip"
    export CONNECTOR_ZIP=$connector_zip
  fi

  if [[ -n "$connector_jar" ]]
  then
    environment_variables_list="$environment_variables_list CONNECTOR_JAR=$connector_jar"
    argument_list="$argument_list --connector-jar=$connector_jar"
    export CONNECTOR_JAR=$connector_jar
  fi

  if [[ -n "$disable_ksqldb" ]]
  then
    environment_variables_list="$environment_variables_list DISABLE_KSQLDB=true"
    argument_list="$argument_list --disable-ksqldb"
    export DISABLE_KSQLDB=true
  fi

  if [[ -n "$disable_c3" ]]
  then
    environment_variables_list="$environment_variables_list DISABLE_CONTROL_CENTER=true"
    argument_list="$argument_list --disable-control-center"
    export DISABLE_CONTROL_CENTER=true
  fi

  if [[ -n "$enable_conduktor" ]]
  then
    environment_variables_list="$environment_variables_list ENABLE_CONDUKTOR=true"
    argument_list="$argument_list --enable-conduktor"
    export ENABLE_CONDUKTOR=true
  fi

  if [[ -n "$enable_multiple_brokers" ]]
  then
    environment_variables_list="$environment_variables_list ENABLE_KAFKA_NODES=true"
    argument_list="$argument_list --enable-multiple-broker"
    export ENABLE_KAFKA_NODES=true
  fi

  if [[ -n "$enable_multiple_connect_workers" ]]
  then
    environment_variables_list="$environment_variables_list ENABLE_CONNECT_NODES=true"
    argument_list="$argument_list --enable-multiple-connect-workers"
    export ENABLE_CONNECT_NODES=true
  fi

  if [[ -n "$enable_jmx_grafana" ]]
  then
    environment_variables_list="$environment_variables_list ENABLE_JMX_GRAFANA=true"
    argument_list="$argument_list --enable-jmx-grafana"
    export ENABLE_JMX_GRAFANA=true
  fi

  if [[ -n "$enable_kcat" ]]
  then
    environment_variables_list="$environment_variables_list ENABLE_KCAT=true"
    argument_list="$argument_list --enable-kcat"
    export ENABLE_KCAT=true
  fi

  if [[ -n "$enable_sr_maven_plugin_app" ]]
  then
    environment_variables_list="$environment_variables_list ENABLE_SR_MAVEN_PLUGIN_NODE=true"
    argument_list="$argument_list --enable-sr-maven-plugin-app"
    export ENABLE_SR_MAVEN_PLUGIN_NODE=true
  fi

  if [[ ! -n "$skip_editor" ]]
  then
    if [ ! -z $EDITOR ]
    then
      log "üìñ Opening ${test_file} using EDITOR environment variable"
      $EDITOR ${test_file}
    else
      if [[ $(type code 2>&1) =~ "not found" ]]
      then
        logerror "Could not determine an editor to use, you can set EDITOR environment variable with your preferred choice"
        exit 1
      else
        log "üìñ Opening ${test_file} with code (you can change editor by setting EDITOR environment variable)"
        code ${test_file}
      fi
    fi
  fi

  if [ "$environment_variables_list" != "" ]
  then
    log "üöÄ Running example with $environment_variables_list ?"
  else
    log "üöÄ Running example with all default values ?"
  fi
  really_check_if_continue
  echo "playground run -f $test_file $argument_list" > /tmp/playground-run
  log "####################################################"
  log "üöÄ Executing $filename in dir $test_file_directory"
  log "####################################################"
  SECONDS=0
  cd $test_file_directory
  bash $filename
  ret=$?
  ELAPSED="took: $((($SECONDS / 60) % 60))min $(($SECONDS % 60))sec"
  let ELAPSED_TOTAL+=$SECONDS
  if [ $ret -eq 0 ]
  then
      log "####################################################"
      log "‚úÖ RESULT: SUCCESS for $filename ($ELAPSED - $CUMULATED)"
      log "####################################################"
  else
      logerror "####################################################"
      logerror "üî• RESULT: FAILURE for $filename ($ELAPSED - $CUMULATED)"
      logerror "####################################################"

      display_docker_container_error_log
  fi
}

# :command.function
playground_re_run_command() {
  # src/re_run_command.sh
  if [ ! -f /tmp/playground-run ]
  then
    logerror "File containing re-run command /tmp/playground-run does not exist!"
    logerror "Make sure to run playground run command !"
    exit 1
  fi

  log "Run command again:"
  cat /tmp/playground-run
  bash /tmp/playground-run
}

# :command.function
playground_bootstrap_reproduction_model_command() {
  # src/bootstrap_reproduction_model_command.sh
  IGNORE_CHECK_FOR_DOCKER_COMPOSE=true

  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  root_folder=$(echo ${dir1%/*})

  test_file="${args[--file]}"
  description="${args[--description]}"
  producer="${args[--producer]}"
  nb_producers="${args[--nb-producers]}"
  add_custom_smt="${args[--custom-smt]}"
  sink_file="${args[--pipeline]}"

  if [[ $test_file == *"@"* ]]
  then
    test_file=$(echo "$test_file" | cut -d "@" -f 2)
  fi

  if [[ "$test_file" != *".sh" ]]
  then
    logerror "ERROR: test_file $test_file is not a .sh file!"
    exit 1
  fi

  if [[ "$(dirname $test_file)" != /* ]]
  then
    logerror "ERROR: do not use relative path for test file!"
    exit 1
  fi

  if [ "$description" = "" ]
  then
    logerror "ERROR: description is not provided as argument!"
    exit 1
  fi

  if [ "$nb_producers" == "" ]
  then
    nb_producers=1
  fi

  test_file_directory="$(dirname "${test_file}")"
  cd ${test_file_directory}

  # determining the docker-compose file from from test_file
  docker_compose_file=$(grep "environment" "$test_file" | grep DIR | grep start.sh | cut -d "/" -f 7 | cut -d '"' -f 1 | tail -n1 | xargs)
  docker_compose_file="${test_file_directory}/${docker_compose_file}"
  description_kebab_case="${description// /-}"
  description_kebab_case=$(echo "$description_kebab_case" | tr '[:upper:]' '[:lower:]')

  if [ "${docker_compose_file}" != "" ] && [ ! -f "${docker_compose_file}" ]
  then
    docker_compose_file=""
    logwarn "üìÅ Could not determine docker-compose override file from $test_file !"
  fi

  topic_name="customer-$producer"
  topic_name=$(echo $topic_name | tr '-' '_')
  filename=$(basename -- "$test_file")
  extension="${filename##*.}"
  filename="${filename%.*}"

  base1="${test_file_directory##*/}" # connect-cdc-oracle12-source
  dir1="${test_file_directory%/*}" #connect
  dir2="${dir1##*/}/$base1" # connect/connect-cdc-oracle12-source
  final_dir=$(echo $dir2 | tr '/' '-') # connect-connect-cdc-oracle12-source

  if [[ -n "$sink_file" ]]
  then
    if [[ "$base1" != *source ]]
    then
      logerror "ERROR: example <$base1> must be source connector example when building a pipeline !"
      exit 1
    fi
  fi

  if [ "$producer" != "none" ]
  then
    if [[ "$base1" != *sink ]]
    then
      logerror "ERROR: example <$base1> must be sink connector example when using a java producer !"
      exit 1
    fi
  fi

  if [ ! -z "$OUTPUT_FOLDER" ]
  then
    output_folder="$OUTPUT_FOLDER"
    log "üìÇ Output folder is $output_folder (set with OUTPUT_FOLDER environment variable)"
  else
    output_folder="reproduction-models"
    log "üìÇ Output folder is default $output_folder (you can change it by setting OUTPUT_FOLDER environment variable)"
  fi

  repro_dir=$root_folder/$output_folder/$final_dir
  mkdir -p $repro_dir

  repro_test_file="$repro_dir/$filename-repro-$description_kebab_case.$extension"

  if [ "${docker_compose_file}" != "" ] && [ -f "${docker_compose_file}" ]
  then
    filename=$(basename -- "${docker_compose_file}")
    extension="${filename##*.}"
    filename="${filename%.*}"

    docker_compose_test_file="$repro_dir/$filename.repro-$description_kebab_case.$extension"
    log "‚ú® Creating file $docker_compose_test_file"
    rm -f $docker_compose_test_file
    cp ${docker_compose_file} $docker_compose_test_file

    docker_compose_test_file_name=$(basename -- "$docker_compose_test_file")
  fi

  log "‚ú® Creating file $repro_test_file"
  rm -f $repro_test_file
  if [ "${docker_compose_file}" != "" ]
  then
    filename=$(basename -- "${docker_compose_file}")
    sed -e "s|$filename|$docker_compose_test_file_name|g" \
      $test_file > $repro_test_file
  else
    cp $test_file $repro_test_file
  fi

  for file in README.md docker-compose*.yml keyfile.json stop.sh .gitignore oracle-datagen
  do
    if [ -f $file ]
    then
      cd $repro_dir > /dev/null
      ln -sf ../../$dir2/$file .
      cd - > /dev/null
    fi
  done

  if [ "$producer" != "none" ]
  then
    tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)
    case "${producer}" in
      avro)
        echo "               \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\"," > $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.avro.AvroConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter

        log "Examples to consume:"
        log "1Ô∏è‚É£ Simplest"
        echo "docker exec connect kafka-avro-console-consumer -bootstrap-server broker:9092 --property schema.registry.url=http://schema-registry:8081 --topic a-topic --from-beginning --max-messages 1"
        log "2Ô∏è‚É£ Displaying key:"
        echo "docker exec connect kafka-avro-console-consumer -bootstrap-server broker:9092 --property schema.registry.url=http://schema-registry:8081 --topic a-topic --property print.key=true --property key.separator=, --from-beginning --max-messages 1"
      ;;
      avro-with-key)
        echo "               \"key.converter\": \"io.confluent.connect.avro.AvroConverter\"," > $tmp_dir/key_converter
        echo "               \"key.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.avro.AvroConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter

        log "Examples to consume:"
        log "1Ô∏è‚É£ Simplest"
        echo "docker exec connect kafka-avro-console-consumer -bootstrap-server broker:9092 --property schema.registry.url=http://schema-registry:8081 --topic a-topic --from-beginning --max-messages 1"
        log "2Ô∏è‚É£ Displaying key:"
        echo "docker exec connect kafka-avro-console-consumer -bootstrap-server broker:9092 --property schema.registry.url=http://schema-registry:8081 --topic a-topic --property print.key=true --property key.separator=, --from-beginning --max-messages 1"
      ;;
      json-schema)
        echo "               \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\"," > $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.json.JsonSchemaConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter

        log "Examples to consume:"
        log "1Ô∏è‚É£ Simplest"
        echo "docker exec connect kafka-json-schema-console-consumer -bootstrap-server broker:9092 --property schema.registry.url=http://schema-registry:8081 --topic a-topic --from-beginning --max-messages 1"
        log "2Ô∏è‚É£ Displaying key:"
        echo "docker exec connect kafka-json-schema-console-consumer -bootstrap-server broker:9092 --property schema.registry.url=http://schema-registry:8081 --topic a-topic --property print.key=true --property key.separator=, --from-beginning --max-messages 1"
      ;;
      json-schema-with-key)
        echo "               \"key.converter\": \"io.confluent.connect.json.JsonSchemaConverter\"," > $tmp_dir/key_converter
        echo "               \"key.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.json.JsonSchemaConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter

        log "Examples to consume:"
        log "1Ô∏è‚É£ Simplest"
        echo "docker exec connect kafka-json-schema-console-consumer -bootstrap-server broker:9092 --property schema.registry.url=http://schema-registry:8081 --topic a-topic --from-beginning --max-messages 1"
        log "2Ô∏è‚É£ Displaying key:"
        echo "docker exec connect kafka-json-schema-console-consumer -bootstrap-server broker:9092 --property schema.registry.url=http://schema-registry:8081 --topic a-topic --property print.key=true --property key.separator=, --from-beginning --max-messages 1"
      ;;
      protobuf)
        echo "               \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\"," > $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.protobuf.ProtobufConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter

        log "Examples to consume:"
        log "1Ô∏è‚É£ Simplest"
        echo "docker exec connect kafka-protobuf-console-consumer -bootstrap-server broker:9092 --property schema.registry.url=http://schema-registry:8081 --topic a-topic --from-beginning --max-messages 1"
        log "2Ô∏è‚É£ Displaying key:"
        echo "docker exec connect kafka-protobuf-console-consumer -bootstrap-server broker:9092 --property schema.registry.url=http://schema-registry:8081 --topic a-topic --property print.key=true --property key.separator=, --from-beginning --max-messages 1"
      ;;
      protobuf-with-key)
        echo "               \"key.converter\": \"io.confluent.connect.protobuf.ProtobufConverter\"," > $tmp_dir/key_converter
        echo "               \"key.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.protobuf.ProtobufConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter

        log "Examples to consume:"
        log "1Ô∏è‚É£ Simplest"
        echo "docker exec connect kafka-protobuf-console-consumer -bootstrap-server broker:9092 --property schema.registry.url=http://schema-registry:8081 --topic a-topic --from-beginning --max-messages 1"
        log "2Ô∏è‚É£ Displaying key:"
        echo "docker exec connect kafka-protobuf-console-consumer -bootstrap-server broker:9092 --property schema.registry.url=http://schema-registry:8081 --topic a-topic --property print.key=true --property key.separator=, --from-beginning --max-messages 1"
      ;;
      none)
      ;;
      *)
        logerror "ERROR: producer name not valid ! Should be one of avro, avro-with-key, json-schema, json-schema-with-key, protobuf or protobuf-with-key"
        exit 1
      ;;
    esac

    original_topic_name=$(grep "\"topics\"" $repro_test_file | cut -d "\"" -f 4 | head -1)
    if [ "$original_topic_name" != "" ]
    then
      tmp=$(echo $original_topic_name | tr '-' '\-')
      sed -e "s|$tmp|$topic_name|g" \
          $repro_test_file > /tmp/tmp

      mv /tmp/tmp $repro_test_file
      # log "‚ú® Replacing topic $original_topic_name with $topic_name"
    fi

    for((i=1;i<=$nb_producers;i++)); do
      # looks like there is a maximum size for hostname in docker (container init caused: sethostname: invalid argument: unknown)
      producer_hostname=""
      producer_hostname="producer-repro-$description_kebab_case"
      producer_hostname=${producer_hostname:0:21}
      if [ $nb_producers -eq 1 ]
      then
        producer_hostname="${producer_hostname}"
      else
        producer_hostname="${producer_hostname}$i"
      fi

      rm -rf $producer_hostname
      mkdir -p $repro_dir/$producer_hostname/
      cp -Ra ${test_file_directory}/../../other/schema-format-$producer/producer/* $repro_dir/$producer_hostname/

      # update docker compose with producer container
      if [[ "$dir1" = *connect ]]
      then
        get_producer_heredoc
      fi

      if [[ "$dir1" = *ccloud ]]
      then
        get_producer_ccloud_heredoc
      fi
    done

    if [ "${docker_compose_file}" != "" ]
    then
      cp $docker_compose_test_file $tmp_dir/tmp_file
      line=$(grep -n 'services:' $docker_compose_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/producer; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $docker_compose_test_file

    else

      logwarn "As docker-compose override file could not be determined, you will need to add this manually:"
      cat $tmp_dir/producer
    fi

    for((i=1;i<=$nb_producers;i++)); do
      log "‚ú® Adding Java $producer producer in $repro_dir/$producer_hostname"
      producer_hostname=""
      producer_hostname="producer-repro-$description_kebab_case"
      producer_hostname=${producer_hostname:0:21}

      if [ $nb_producers -eq 1 ]
      then
        producer_hostname="${producer_hostname}"
      else
        producer_hostname="${producer_hostname}$i"
      fi

      list="$list $producer_hostname"

    done
    get_producer_build_heredoc
    # log "‚ú® Adding command to build jar for $producer_hostname to $repro_test_file"
    cp $repro_test_file $tmp_dir/tmp_file
    line=$(grep -n '${DIR}/../../environment' $repro_test_file | cut -d ":" -f 1 | tail -n1)

    { head -n $(($line-1)) $tmp_dir/tmp_file; cat $tmp_dir/build_producer; tail -n +$line $tmp_dir/tmp_file; } > $repro_test_file

    kafka_cli_producer_error=0
    kafka_cli_producer_eof=0
    line_kafka_cli_producer=$(egrep -n "kafka-console-producer|kafka-avro-console-producer|kafka-json-schema-console-producer|kafka-protobuf-console-producer" $repro_test_file | cut -d ":" -f 1 | tail -n1)
    if [ $? != 0 ]
    then
        logwarn "Could not find kafka cli producer!"
        kafka_cli_producer_error=1
    fi
    set +e
    egrep "kafka-console-producer|kafka-avro-console-producer|kafka-json-schema-console-producer|kafka-protobuf-console-producer" $repro_test_file | grep EOF > /dev/null
    if [ $? = 0 ]
    then
        kafka_cli_producer_eof=1

        sed -n "$line_kafka_cli_producer,$(($line_kafka_cli_producer + 10))p" $repro_test_file > /tmp/tmp
        tmp=$(grep -n "^EOF" /tmp/tmp | cut -d ":" -f 1 | tail -n1)
        if [ $tmp == "" ]
        then
          logwarn "Could not determine EOF for kafka cli producer!"
          kafka_cli_producer_error=1
        fi
        line_kafka_cli_producer_end=$(($line_kafka_cli_producer + $tmp))
    fi
    set -e
    if [ $kafka_cli_producer_error = 1 ]
    then
      get_producer_fixthis_heredoc
    fi

    for((i=1;i<=$nb_producers;i++)); do
      producer_hostname=""
      producer_hostname="producer-repro-$description_kebab_case"
      producer_hostname=${producer_hostname:0:21}

      if [ $nb_producers -eq 1 ]
      then
        producer_hostname="${producer_hostname}"
      else
        producer_hostname="${producer_hostname}$i"
      fi
      get_producer_run_heredoc
    done
    if [ $kafka_cli_producer_error = 1 ]
    then
      get_producer_fixthis_heredoc
    fi
    # log "‚ú® Adding command to run producer to $repro_test_file"
    cp $repro_test_file $tmp_dir/tmp_file

    if [ $kafka_cli_producer_error == 1 ]
    then
        { head -n $(($line-1)) $tmp_dir/tmp_file; cat $tmp_dir/java_producer; tail -n +$line $tmp_dir/tmp_file; } > $repro_test_file
    else
      if [ $kafka_cli_producer_eof == 0 ]
      then
        line_kafka_cli_producer_end=$(($line_kafka_cli_producer + 1))
      fi
      { head -n $(($line_kafka_cli_producer - 2)) $tmp_dir/tmp_file; cat $tmp_dir/java_producer; tail -n +$line_kafka_cli_producer_end $tmp_dir/tmp_file; } > $repro_test_file
    fi

    # deal with converters

    sink_key_converter=$(grep "\"key.converter\"" $repro_test_file | cut -d '"' -f 4)
    if [ "$sink_key_converter" == "" ]
    then
      log "üí± Sink connector is using default key.converter, i.e org.apache.kafka.connect.storage.StringConverter"
    else
      if [ "$sink_key_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
      then
        # check schemas.enable
        sink_key_json_converter_schemas_enable=$(grep "\"key.converter.schemas.enable\"" $repro_test_file | cut -d '"' -f 4)
        if [ "$sink_key_json_converter_schemas_enable" == "" ]
        then
          log "üí± Sink connector is using key.converter $sink_key_converter with schemas.enable=true"
        else
          log "üí± Sink connector is using key.converter $sink_key_converter with schemas.enable=$sink_key_json_converter_schemas_enable"
        fi
      else
        log "üí± Sink connector is using key.converter $sink_key_converter"
      fi
    fi

    sink_value_converter=$(grep "\"value.converter\"" $repro_test_file | cut -d '"' -f 4)
    if [ "$sink_value_converter" == "" ]
    then
      log "üí± Sink connector is using default value.converter, i.e io.confluent.connect.avro.AvroConverter"
    else
      if [ "$sink_value_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
      then
        # check schemas.enable
        sink_value_json_converter_schemas_enable=$(grep "\"value.converter.schemas.enable\"" $repro_test_file | cut -d '"' -f 4)
        if [ "$sink_value_json_converter_schemas_enable" == "" ]
        then
          log "üí± Sink connector is using value.converter $sink_value_converter with schemas.enable=true"
        else
          log "üí± Sink connector is using value.converter $sink_value_converter with schemas.enable=$sink_value_json_converter_schemas_enable"
        fi
      else
        log "üí± Sink connector is using value.converter $sink_value_converter"
      fi
    fi

    if [ "$sink_value_converter" == "" ]
    then
      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $repro_test_file; cat $tmp_dir/value_converter; tail -n +$(($line+1)) $repro_test_file; } > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file
    else
      # remove existing value.converter
      grep -vwE "\"value.converter" $repro_test_file > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file

      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $repro_test_file; cat $tmp_dir/value_converter; tail -n +$(($line+1)) $repro_test_file; } > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file
    fi
    log "üîÆ Changing Sink connector value.converter to use same as producer:"
    cat $tmp_dir/value_converter

    if [ "$sink_key_converter" == "" ]
    then
      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $repro_test_file; cat $tmp_dir/key_converter; tail -n +$(($line+1)) $repro_test_file; } > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file
    else
      # remove existing key.converter
      grep -vwE "\"key.converter" $repro_test_file > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file

      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $repro_test_file; cat $tmp_dir/key_converter; tail -n +$(($line+1)) $repro_test_file; } > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file
    fi
    log "üîÆ Changing Sink connector key.converter to use same as producer:"
    cat $tmp_dir/key_converter
  fi

  if [[ -n "$add_custom_smt" ]]
  then
    custom_smt_name=""
    custom_smt_name="MyCustomSMT-$description_kebab_case"
    custom_smt_name=${custom_smt_name:0:18}
    mkdir -p $repro_dir/$custom_smt_name/
    cp -Ra ../../other/custom-smt/MyCustomSMT/* $repro_dir/$custom_smt_name/

    tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)

    get_custom_smt_build_heredoc
    # log "‚ú® Adding command to build jar for $custom_smt_name to $repro_test_file"
    cp $repro_test_file $tmp_dir/tmp_file
    line=$(grep -n '${DIR}/../../environment' $repro_test_file | cut -d ":" -f 1 | tail -n1)

    { head -n $(($line-1)) $tmp_dir/tmp_file; cat $tmp_dir/build_custom_smt; tail -n +$line $tmp_dir/tmp_file; } > $repro_test_file

    connector_paths=$(grep "CONNECT_PLUGIN_PATH" "${docker_compose_file}" | grep -v "KSQL_CONNECT_PLUGIN_PATH" | cut -d ":" -f 2  | tr -s " " | head -1)
    if [ "$connector_paths" == "" ]
    then
      logerror "ERROR: not a connector test"
      exit 1
    else
      #  Loop on all connectors in CONNECT_PLUGIN_PATH and install custom SMT jar in lib folder
      my_array_connector_tag=($(echo $CONNECTOR_TAG | tr "," "\n"))
      for connector_path in ${connector_paths//,/ }
      do
        echo "log \"üìÇ Copying custom jar to connector folder $connector_path/lib/\"" >> $tmp_dir/build_custom_docker_cp_smt
        echo "docker cp $repro_dir/$custom_smt_name/target/MyCustomSMT-1.0.0-SNAPSHOT-jar-with-dependencies.jar connect:$connector_path/lib/" >> $tmp_dir/build_custom_docker_cp_smt
      done
      echo "log \"‚ôªÔ∏è Restart connect worker to load\"" >> $tmp_dir/build_custom_docker_cp_smt
      echo "docker restart connect" >> $tmp_dir/build_custom_docker_cp_smt
      echo "sleep 45" >> $tmp_dir/build_custom_docker_cp_smt
    fi

    cp $repro_test_file $tmp_dir/tmp_file
    line=$(grep -n '${DIR}/../../environment' $repro_test_file | cut -d ":" -f 1 | tail -n1)

    { head -n $(($line+2)) $tmp_dir/tmp_file; cat $tmp_dir/build_custom_docker_cp_smt; tail -n +$(($line+2)) $tmp_dir/tmp_file; } > $repro_test_file

    existing_transforms=$(grep "\"transforms\"" $repro_test_file | cut -d '"' -f 4)
    if [ "$existing_transforms" == "" ]
    then
      echo "              \"transforms\": \"MyCustomSMT\"," >> $tmp_dir/build_custom_smt_json_config
      echo "              \"transforms.MyCustomSMT.type\": \"com.github.vdesabou.kafka.connect.transforms.MyCustomSMT\"," >> $tmp_dir/build_custom_smt_json_config

      cp $repro_test_file $tmp_dir/tmp_file
      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/build_custom_smt_json_config; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $repro_test_file
    else
      log "ü§ñ Connector is using existing transforms $existing_transforms, the new custom SMT will be added to the list."

      # remove existing transforms
      grep -vwE "\"transforms\"" $repro_test_file > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file

      echo "              \"transforms\": \"MyCustomSMT,$existing_transforms\"," >> $tmp_dir/build_custom_smt_json_config
      echo "              \"transforms.MyCustomSMT.type\": \"com.github.vdesabou.kafka.connect.transforms.MyCustomSMT\"," >> $tmp_dir/build_custom_smt_json_config

      cp $repro_test_file $tmp_dir/tmp_file
      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/build_custom_smt_json_config; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $repro_test_file
    fi

  fi
  if [[ -n "$sink_file" ]]
  then
    tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)
    sink_file=$(echo "$sink_file" | cut -d "@" -f 2)
    test_sink_file_directory="$(dirname "${sink_file}")"

    # docker-compose part
    # determining the docker-compose file from from test_file
    docker_compose_sink_file=$(grep "environment" "$sink_file" | grep DIR | grep start.sh | cut -d "/" -f 7 | cut -d '"' -f 1 | tail -n1 | xargs)
    docker_compose_sink_file="${test_sink_file_directory}/${docker_compose_sink_file}"
    cp $docker_compose_test_file /tmp/1.yml
    cp $docker_compose_sink_file /tmp/2.yml
    yq ". *= load(\"/tmp/1.yml\")" /tmp/2.yml > $docker_compose_test_file

    connector_paths=$(grep "CONNECT_PLUGIN_PATH" "${docker_compose_file}" | grep -v "KSQL_CONNECT_PLUGIN_PATH" | cut -d ":" -f 2  | tr -s " " | head -1)
    sink_connector_paths=$(grep "CONNECT_PLUGIN_PATH" "${docker_compose_sink_file}" | grep -v "KSQL_CONNECT_PLUGIN_PATH" | cut -d ":" -f 2  | tr -s " " | head -1)
    if [ "$sink_connector_paths" == "" ]
    then
      logerror "ERROR: cannot find CONNECT_PLUGIN_PATH in  ${docker_compose_sink_file}"
      exit 1
    else
      tmp_new_connector_paths="$connector_paths,$sink_connector_paths"
      new_connector_paths=$(echo "$tmp_new_connector_paths" | sed 's/ //g')
      cp $docker_compose_test_file /tmp/1.yml

      yq -i ".services.connect.environment.CONNECT_PLUGIN_PATH = \"$new_connector_paths\"" /tmp/1.yml
      cp /tmp/1.yml $docker_compose_test_file
    fi


    # sh part

    line_final_source=$(grep -n 'source ${DIR}/../../scripts/utils.sh' $repro_test_file | cut -d ":" -f 1 | tail -n1)
    line_final_environment=$(grep -n '${DIR}/../../environment' $repro_test_file | cut -d ":" -f 1 | tail -n1)
    line_sink_source=$(grep -n 'source ${DIR}/../../scripts/utils.sh' $sink_file | cut -d ":" -f 1 | tail -n1)

    line_sink_environment=$(grep -n '${DIR}/../../environment' $sink_file | cut -d ":" -f 1 | tail -n1)

    # get converter info
    source_key_converter=$(grep "\"key.converter\"" $repro_test_file | cut -d '"' -f 4)
    if [ "$source_key_converter" == "" ]
    then
      log "üí± Source connector is using default key.converter, i.e org.apache.kafka.connect.storage.StringConverter"
    else
      if [ "$source_key_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
      then
        # check schemas.enable
        source_key_json_converter_schemas_enable=$(grep "\"key.converter.schemas.enable\"" $repro_test_file | cut -d '"' -f 4)
        if [ "$source_key_json_converter_schemas_enable" == "" ]
        then
          log "üí± Source connector is using key.converter $source_key_converter with schemas.enable=true"
        else
          log "üí± Source connector is using key.converter $source_key_converter with schemas.enable=$source_key_json_converter_schemas_enable"
        fi
      else
        log "üí± Source connector is using key.converter $source_key_converter"
      fi
    fi

    source_value_converter=$(grep "\"value.converter\"" $repro_test_file | cut -d '"' -f 4)
    if [ "$source_value_converter" == "" ]
    then
      log "üí± Source connector is using default value.converter, i.e io.confluent.connect.avro.AvroConverter"
    else
      if [ "$source_value_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
      then
        # check schemas.enable
        source_value_json_converter_schemas_enable=$(grep "\"value.converter.schemas.enable\"" $repro_test_file | cut -d '"' -f 4)
        if [ "$source_value_json_converter_schemas_enable" == "" ]
        then
          log "üí± Source connector is using value.converter $source_value_converter with schemas.enable=true"
        else
          log "üí± Source connector is using value.converter $source_value_converter with schemas.enable=$source_value_json_converter_schemas_enable"
        fi
      else
        log "üí± Source connector is using value.converter $source_value_converter"
      fi
    fi

    sink_key_converter=$(grep "\"key.converter\"" $sink_file | cut -d '"' -f 4)
    if [ "$sink_key_converter" == "" ]
    then
      log "üí± Sink connector is using default key.converter, i.e org.apache.kafka.connect.storage.StringConverter"
    else
      if [ "$sink_key_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
      then
        # check schemas.enable
        sink_key_json_converter_schemas_enable=$(grep "\"key.converter.schemas.enable\"" $sink_file | cut -d '"' -f 4)
        if [ "$sink_key_json_converter_schemas_enable" == "" ]
        then
          log "üí± Sink connector is using key.converter $sink_key_converter with schemas.enable=true"
        else
          log "üí± Sink connector is using key.converter $sink_key_converter with schemas.enable=$sink_key_json_converter_schemas_enable"
        fi
      else
        log "üí± Sink connector is using key.converter $sink_key_converter"
      fi
    fi

    sink_value_converter=$(grep "\"value.converter\"" $sink_file | cut -d '"' -f 4)
    if [ "$sink_value_converter" == "" ]
    then
      log "üí± Sink connector is using default value.converter, i.e io.confluent.connect.avro.AvroConverter"
    else
      if [ "$sink_value_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
      then
        # check schemas.enable
        sink_value_json_converter_schemas_enable=$(grep "\"value.converter.schemas.enable\"" $sink_file | cut -d '"' -f 4)
        if [ "$sink_value_json_converter_schemas_enable" == "" ]
        then
          log "üí± Sink connector is using value.converter $sink_value_converter with schemas.enable=true"
        else
          log "üí± Sink connector is using value.converter $sink_value_converter with schemas.enable=$sink_value_json_converter_schemas_enable"
        fi
      else
        log "üí± Sink connector is using value.converter $sink_value_converter"
      fi
    fi

    sed -n "$(($line_sink_source+1)),$(($line_sink_environment-1))p" $sink_file > $tmp_dir/pre_sink
    cp $repro_test_file $tmp_dir/tmp_file

    { head -n $(($line_final_environment-1)) $tmp_dir/tmp_file; cat $tmp_dir/pre_sink; tail -n +$line_final_environment $tmp_dir/tmp_file; } > $repro_test_file

    sed -n "$(($line_sink_environment+1)),$ p" $sink_file > $tmp_dir/tmp_file

    # deal with converters
    set +e
    if [ "$source_value_converter" == "" ] && [ "$sink_value_converter" == "" ]
    then
      # do nothing
      :
    else
      grep "\"value.converter" $repro_test_file > $tmp_dir/source_value_converter
      if [ "$sink_value_converter" == "" ]
      then
        line=$(grep -n 'connector.class' $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)

        { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/source_value_converter; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $tmp_dir/tmp_file2
        cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file
      else
        # remove existing value.converter
        grep -vwE "\"value.converter" $tmp_dir/tmp_file > $tmp_dir/tmp_file2
        cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file

        line=$(grep -n 'connector.class' $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)

        { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/source_value_converter; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $tmp_dir/tmp_file2
        cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file
      fi
      log "üîÆ Changing Sink connector value.converter to use same as source:"
      cat $tmp_dir/source_value_converter
    fi
    if [ "$source_key_converter" == "" ] && [ "$sink_key_converter" == "" ]
    then
      # do nothing
      :
    else
      grep "\"key.converter" $repro_test_file > $tmp_dir/source_key_converter
      if [ "$sink_key_converter" == "" ]
      then
        line=$(grep -n 'connector.class' $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)

        { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/source_key_converter; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $tmp_dir/tmp_file2
        cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file
      else
        # remove existing key.converter
        grep -vwE "\"key.converter" $tmp_dir/tmp_file > $tmp_dir/tmp_file2
        cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file

        line=$(grep -n 'connector.class' $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)

        { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/source_key_converter; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $tmp_dir/tmp_file2
        cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file
      fi
      log "üîÆ Changing Sink connector key.converter to use same as source:"
      cat $tmp_dir/source_key_converter
    fi
    set -e
    # need to remove cli which produces and change topic
    kafka_cli_producer_error=0
    kafka_cli_producer_eof=0
    line_kafka_cli_producer=$(egrep -n "kafka-console-producer|kafka-avro-console-producer|kafka-json-schema-console-producer|kafka-protobuf-console-producer" $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)
    if [ $? != 0 ]
    then
        logwarn "Could not find kafka cli producer!"
        kafka_cli_producer_error=1
    fi
    set +e
    egrep "kafka-console-producer|kafka-avro-console-producer|kafka-json-schema-console-producer|kafka-protobuf-console-producer" $tmp_dir/tmp_file | grep EOF > /dev/null
    if [ $? = 0 ]
    then
        kafka_cli_producer_eof=1

        sed -n "$line_kafka_cli_producer,$(($line_kafka_cli_producer + 10))p" $tmp_dir/tmp_file > /tmp/tmp
        tmp=$(grep -n "^EOF" /tmp/tmp | cut -d ":" -f 1 | tail -n1)
        if [ $tmp == "" ]
        then
          logwarn "Could not determine EOF for kafka cli producer!"
          kafka_cli_producer_error=1
        fi
        line_kafka_cli_producer_end=$(($line_kafka_cli_producer + $tmp))
    fi

    if [ $kafka_cli_producer_error == 0 ]
    then
      if [ $kafka_cli_producer_eof == 0 ]
      then
        line_kafka_cli_producer_end=$(($line_kafka_cli_producer + 1))
      fi
      { head -n $(($line_kafka_cli_producer - 2)) $tmp_dir/tmp_file; tail -n +$line_kafka_cli_producer_end $tmp_dir/tmp_file; } >  $tmp_dir/tmp_file2
      cat  $tmp_dir/tmp_file2 >> $repro_test_file
    fi
    set -e

    awk -F'--topic ' '{print $2}' $repro_test_file > $tmp_dir/tmp
    sed '/^$/d' $tmp_dir/tmp > $tmp_dir/tmp2
    original_topic_name=$(head -1 $tmp_dir/tmp2 | cut -d " " -f1)

    if [ "$original_topic_name" != "" ]
    then
      cp $repro_test_file $tmp_dir/tmp_file
      line=$(grep -n '"topics"' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      echo "              \"topics\": \"$original_topic_name\"," > $tmp_dir/topic_line
      { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/topic_line; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $repro_test_file
    else

      logwarn "Could not find original topic name! "
      logwarn "You would need to change topics config for sink by yourself."
    fi
  fi

  chmod u+x $repro_test_file
  repro_test_filename=$(basename -- "$repro_test_file")

  log "üåü Command to run generated example"
  echo "playground run -f $repro_dir/$repro_test_filename"
  echo "playground run -f $repro_dir/$repro_test_filename" > /tmp/playground-run
  playground run -f $repro_dir/$repro_test_filename

}

# :command.function
playground_get_properties_command() {
  # src/get_properties_command.sh
  container="${args[--container]}"

  log "Displaying properties file for $container"
  # see heredocs.sh
  get_properties_command_heredoc "$container"
}

# :command.function
playground_get_all_schemas_command() {
  # src/get_all_schemas_command.sh
  ret=$(get_sr_url_and_security)

  sr_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  # Get a list of all subjects in the schema registry
  subjects=$(curl $security -s "${sr_url}/subjects")

  log "Displaying all subjects üî∞ and versions üíØ"
  # Loop through each subject and retrieve all its schema versions and definitions
  for subject in $(echo "${subjects}" | jq -r '.[]'); do
    # Get a list of all schema versions for the subject
    versions=$(curl $security -s "${sr_url}/subjects/${subject}/versions")

    # Loop through each version and retrieve the schema
    for version in $(echo "${versions}" | jq -r '.[]'); do
      schema=$(curl $security -s "${sr_url}/subjects/${subject}/versions/${version}/schema" | jq .)
      log "üî∞ ${subject} üíØ ${version}"
      echo "${schema}"
    done
  done
}

# :command.function
playground_enable_remote_debugging_command() {
  # src/enable_remote_debugging_command.sh
  IGNORE_CHECK_FOR_DOCKER_COMPOSE=true

  container="${args[--container]}"

  log "Enable remote debugging for $container"

  # For ccloud case
  if [ -f /tmp/delta_configs/env.delta ]
  then
       source /tmp/delta_configs/env.delta
  fi

  # keep CONNECT TAG
  export CONNECT_TAG=$(docker inspect -f '{{.Config.Image}}' connect | cut -d ":" -f 2)

  if [ ! -f /tmp/playground-command ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1
  fi

  # see heredocs.sh
  get_remote_debugging_command_heredoc "$container"

  bash /tmp/playground-command-debugging

  log "If you use Visual Studio Code:"
  log "Edit .vscode/launch.json with"

  log "
  {
      \"version\": \"0.2.0\",
      \"configurations\": [

          {
              \"type\": \"java\",
              \"name\": \"Debug $component container\",
              \"request\": \"attach\",
              \"hostName\": \"127.0.0.1\",
              \"port\": 5005,
              \"timeout\": 30000
          }
      ]
  }
  "

  log "See https://kafka-docker-playground.io/#/reusables?id=‚ú®-remote-debugging"
}

# :command.function
playground_get_jmx_metrics_command() {
  # src/get_jmx_metrics_command.sh
  IGNORE_CHECK_FOR_DOCKER_COMPOSE=true

  component="${args[--component]}"
  domain="${args[--domain]}"

  case "${component}" in
    zookeeper|broker|schema-registry|connect)
    ;;
    *)
      logerror "ERROR: component name not valid ! Should be one of zookeeper, broker, schema-registry or connect"
      exit 1
    ;;
  esac

  get_jmx_metrics "$component" "$domain"
}

# :command.function
playground_container_recreate_command() {
  # src/container_recreate_command.sh
  IGNORE_CHECK_FOR_DOCKER_COMPOSE=true

  # keep CONNECT TAG
  export CONNECT_TAG=$(docker inspect -f '{{.Config.Image}}' connect | cut -d ":" -f 2)

  if [ ! -f /tmp/playground-command ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1
  fi

  bash /tmp/playground-command
}

# :command.function
playground_container_get_ip_addresses_command() {
  # src/container_get_ip_addresses_command.sh
  log "Get IP address of running containers"
  docker inspect -f '{{.Name}} - {{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' $(docker ps -aq)
}

# :command.function
playground_container_kill_all_command() {
  # src/container_kill_all_command.sh
  log "Kill all docker containers"
  docker rm -f $(docker ps -qa)
}

# :command.function
playground_container_logs_command() {
  # src/container_logs_command.sh
  container="${args[--container]}"
  editor="${args[--open]}"
  log="${args[--wait-for-log]}"
  max_wait="${args[--max-wait]}"

  if [[ -n "$editor" ]]
  then
    filename="/tmp/${container}-`date '+%Y-%m-%d-%H-%M-%S'`.log"
    log "Opening $filename with editor $editor"
    docker container logs "$container" > "$filename" 2>&1
    if [ $? -eq 0 ]
    then
      $editor "$filename"
    fi
  elif [[ -n "$log" ]]
  then
    wait_for_log "$log" "$container" "$max_wait"
  else

    docker container logs --tail=200 -f "$container"
  fi
}

# :command.function
playground_container_ssh_command() {
  # src/container_ssh_command.sh
  container="${args[--container]}"
  shell="${args[--shell]}"

  docker exec -it "$container" "$shell"
}

# :command.function
playground_container_exec_command() {
  # src/container_exec_command.sh
  container="${args[--container]}"
  command="${args[--command]}"
  root="${args[--root]}"
  shell="${args[--shell]}"

  if [[ -n "$root" ]]
  then
    log "Executing command as root in container $container with $shell"
    docker exec --privileged --user root $container $shell -c "$command"
  else
    log "Executing command in container $container with $shell"
    docker exec $container $shell -c "$command"
  fi

}

# :command.function
playground_container_restart_command() {
  # src/container_restart_command.sh
  container="${args[--container]}"

  log "Restarting docker container ${container}"
  docker restart ${container}
}

# :command.function
playground_container_pause_command() {
  # src/container_pause_command.sh
  container="${args[--container]}"

  log "Pausing docker container ${container}"
  docker pause ${container}
}

# :command.function
playground_container_resume_command() {
  # src/container_resume_command.sh
  container="${args[--container]}"

  log "Resuming docker container ${container}"
  docker resume ${container}
}

# :command.function
playground_container_kill_command() {
  # src/container_kill_command.sh
  container="${args[--container]}"

  log "Killing docker container ${container}"
  docker kill ${container}
}

# :command.function
playground_topic_get_number_records_command() {
  # src/topic_get_number_records_command.sh
  topic="${args[--topic]}"

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  log "Get number of records in a topic $topic"
  if [ "$environment" != "plaintext" ]
  then
      # see heredocs.sh
      get_number_records_topic_command_heredoc_with_security "$topic"
  else
      # see heredocs.sh
      get_number_records_topic_command_heredoc "$topic"
  fi
}

# :command.function
playground_topic_display_connect_offsets_command() {
  # src/topic_display_connect_offsets_command.sh
  security_broker=$(get_security_broker)

  log "Display content of connect offsets topic, press crtl-c to stop..."
  docker exec connect kafka-console-consumer -bootstrap-server broker:9092 --topic connect-offsets --from-beginning --property print.key=true --property print.timestamp=true $security_broker
}

# :command.function
playground_topic_display_consumer_offsets_command() {
  # src/topic_display_consumer_offsets_command.sh
  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  log "Display content of __consumer_offsets topic, press crtl-c to stop..."
  if [ "$environment" != "plaintext" ]
  then
      docker exec -i broker bash -c 'kafka-console-consumer --bootstrap-server broker:9092 --topic __consumer_offsets --from-beginning --formatter "kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter" --consumer.config /etc/kafka/secrets/client_without_interceptors.config | grep -v "_confluent-controlcenter"'
  else
      docker exec -i broker bash -c 'kafka-console-consumer --bootstrap-server broker:9092 --topic __consumer_offsets --from-beginning --formatter "kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter" | grep -v "_confluent-controlcenter"'
  fi
}

# :command.function
playground_topic_describe_command() {
  # src/topic_describe_command.sh
  topic="${args[--topic]}"

  security_broker=$(get_security_broker)

  log "Describing topic $topic"
  docker exec broker kafka-topics --describe --topic $topic --bootstrap-server broker:9092 $security_broker
}

# :command.function
playground_topic_consume_command() {
  # src/topic_consume_command.sh
  if [ ! -f /tmp/playground-run ]
  then
    logerror "File containing re-run command /tmp/playground-run does not exist!"
    logerror "Make sure to run playground run command !"
    exit 1
  fi

  test_file=$(cat /tmp/playground-run |tr '\t' ' ' |cut -d' ' -f4)
  if [ ! -f $test_file ]
  then
    logerror "Could not find test file in /tmp/playground-run"
    cat /tmp/playground-run
    exit 1
  fi

  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  sr_url="http://schema-registry:8081"
  security=""
  if [[ "$environment" == *"ssl"* ]]
  then
      sr_url="https://schema-registry:8081"
      security="--property schema.registry.ssl.truststore.location=/etc/kafka/secrets/kafka.client.truststore.jks --property schema.registry.ssl.truststore.password=confluent --property schema.registry.ssl.keystore.location=/etc/kafka/secrets/kafka.client.keystore.jks --property schema.registry.ssl.keystore.password=confluent --consumer.config /etc/kafka/secrets/client_without_interceptors.config"
  elif [[ "$environment" == "rbac-sasl-plain" ]]
  then
      sr_url="http://schema-registry:8081"
      security="--property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info=clientAvroCli:clientAvroCli --consumer.config /etc/kafka/secrets/client_without_interceptors.config"
  fi

  tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)
  awk -F'--topic ' '{print $2}' $test_file > $tmp_dir/tmp
  sed '/^$/d' $tmp_dir/tmp > $tmp_dir/tmp2
  topic_name=$(head -1 $tmp_dir/tmp2 | cut -d " " -f1)

  if [ "$topic_name" != "" ]
  then
    key_converter=$(grep "\"key.converter\"" $test_file | cut -d '"' -f 4)
    if [ "$key_converter" == "" ]
    then
      log "üîÆ connector is using default key.converter, i.e org.apache.kafka.connect.storage.StringConverter"
      key_converter="io.confluent.connect.avro.AvroConverter"
    else
      log "üîÆ connector is using key.converter $key_converter"
    fi

    value_converter=$(grep "\"value.converter\"" $test_file | cut -d '"' -f 4)
    if [ "$value_converter" == "" ]
    then
      log "üîÆ connector is using default value.converter, i.e io.confluent.connect.avro.AvroConverter"
      value_converter="io.confluent.connect.avro.AvroConverter"
    else
      log "üîÆ connector is using value.converter $value_converter"
    fi
    log "‚ú® Display content of topic $topic_name, press crtl-c to stop..."
    type=""
    case "${value_converter}" in
      io.confluent.connect.json.JsonSchemaConverter)
          type="json-schema"
      ;;
      io.confluent.connect.protobuf.ProtobufConverter)
          type="protobuf"
      ;;
      io.confluent.connect.avro.AvroConverter)
          type="avro"
          ;;
      *)
      ;;
    esac

    fifo_path="$tmp_dir/kafka_output_fifo"
    mkfifo "$fifo_path"
    case "${type}" in
      avro|protobuf|json-schema)
          if [ "$key_converter" == "io.confluent.connect.avro.AvroConverter" ]
          then
              docker exec connect kafka-$type-console-consumer -bootstrap-server broker:9092 --property schema.registry.url=$sr_url --topic $topic_name --property print.partition=true --property print.offset=true --property print.headers=true --property print.timestamp=true --property print.key=true --property key.separator="|" $security --from-beginning > "$fifo_path" &
          else
              docker exec connect kafka-$type-console-consumer --bootstrap-server broker:9092 --property schema.registry.url=$sr_url --topic $topic_name --property print.partition=true --property print.offset=true --property print.headers=true --property print.timestamp=true --property print.key=true --property key.separator="|" --property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer $security --from-beginning > "$fifo_path" &
          fi
          ;;
      *)
          docker exec connect kafka-console-consumer --bootstrap-server broker:9092 --topic $topic_name --property print.partition=true --property print.offset=true --property print.headers=true --property print.timestamp=true --property print.key=true --property key.separator="|" $security --from-beginning > "$fifo_path" &
      ;;
    esac

    # Detect the platform (macOS or Linux) and set the date command accordingly
    if [[ "$(uname)" == "Darwin" ]]; then
      # macOS
      date_command="date -r"
    else
      # Linux
      date_command="date -d@"
    fi

    # Loop through each line in the named pipe
    while read -r line; do
      # Extract the timestamp from the line
      timestamp_ms=$(echo "$line" | cut -d ":" -f 2 | cut -d "|" -f 1)

      # Convert milliseconds to seconds
      timestamp_sec=$((timestamp_ms / 1000))
      milliseconds=$((timestamp_ms % 1000))

      readable_date="$($date_command ${timestamp_sec} "+%Y-%m-%d %H:%M:%S.${milliseconds}")"

      line_with_date=$(echo "$line" | sed -E "s/CreateTime:[0-9]{13}/CreateTime: ${readable_date}/")

      echo "$line_with_date"
    done < "$fifo_path"
  else

    logwarn "Could not find topic name !"
    exit 1
  fi
}

# :command.function
playground_connector_status_command() {
  # src/connector_status_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  json="${args[--json]}"

  if [[ -n "$json" ]]
  then
    curl $security -s "$connect_url/connectors?expand=status&expand=info" | jq .
  else
    curl $security -s "$connect_url/connectors?expand=info&expand=status" | jq '. | to_entries[] | [ .value.info.type, .key, .value.status.connector.state,.value.status.tasks[].state,.value.info.config."connector.class"]|join(":|:")' | column -s : -t| sed 's/\"//g'| sort
  fi
}

# :command.function
playground_connector_plugins_command() {
  # src/connector_plugins_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  curl $security -s -X GET -H "Content-Type: application/json" "$connect_url/connector-plugins" | jq .
}

# :command.function
playground_connector_pause_command() {
  # src/connector_pause_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  connector="${args[--connector]}"
  log "Pausing connector $connector"
  curl $security -s -X PUT -H "Content-Type: application/json" "$connect_url/connectors/$connector/pause" | jq .

  playground connector status
}

# :command.function
playground_connector_restart_command() {
  # src/connector_restart_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  connector="${args[--connector]}"
  log "Restarting connector $connector"
  curl $security -s -X POST -H "Content-Type: application/json" "$connect_url/connectors/$connector/restart?includeTasks=true&onlyFailed=false" | jq .
}

# :command.function
playground_connector_resume_command() {
  # src/connector_resume_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  connector="${args[--connector]}"
  log "Resuming connector $connector"
  curl $security -s -X PUT -H "Content-Type: application/json" "$connect_url/connectors/$connector/resume"  | jq .

  playground connector status
}

# :command.function
playground_connector_delete_command() {
  # src/connector_delete_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  connector="${args[--connector]}"
  log "Deleting connector $connector"
  curl $security -s -X DELETE "$connect_url/connectors/$connector" | jq .
}

# :command.function
playground_connector_show_lag_command() {
  # src/connector_show_lag_command.sh
  connector="${args[--connector]}"

  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  type=$(curl $security -s $connect_url/connectors\?expand\=status\&expand\=info | jq -r '. | to_entries[] | [ .value.info.type]|join(":|:")')
  if [ "$type" != "sink" ]
  then
    logerror "Connector $connector is a $type connector, it must be a sink to show the lag !"
    exit 1

  fi

  security_broker=$(get_security_broker)

  log "Show lag for sink connector $connector"
  docker exec broker kafka-consumer-groups --bootstrap-server broker:9092 --group connect-$connector --describe $security_broker
}

# :command.function
playground_connector_log_level_get_command() {
  # src/connector_log_level_get_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  package="${args[--package]}"

  if [[ -n "$package" ]]
  then
    log "Get log level for package $package"
    curl $security -s "$connect_url/admin/loggers/$package" | jq .
  else
    log "Get log level for all packages"
    curl $security -s "$connect_url/admin/loggers" | jq .
  fi
}

# :command.function
playground_connector_log_level_set_command() {
  # src/connector_log_level_set_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  package="${args[--package]}"
  level="${args[--level]}"

  log "Set log level for package $package to $level"
  curl $security -s --request PUT \
    --url "$connect_url/admin/loggers/$package" \
    --header 'Accept: application/json' \
    --header 'Content-Type: application/json' \
    --data "{
   \"level\": \"$level\"
  }" | jq .

  playground connector log-level get -p "$package"
}

# :command.parse_requirements
parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --version | -v)
        version_command
        exit
        ;;

      --help | -h)
        long_usage=yes
        playground_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v docker >/dev/null 2>&1; then
    deps['docker']="$(command -v docker | head -n1)"
  else
    printf "missing dependency: docker\n" >&2
    printf "%s\n" "üëâ Check documentation https://tinyurl.com/4rpcmpjj" >&2
    exit 1
  fi

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    get-connector-list)
      action="get-connector-list"
      shift
      playground_get_connector_list_parse_requirements "$@"
      shift $#
      ;;

    get-topic-list)
      action="get-topic-list"
      shift
      playground_get_topic_list_parse_requirements "$@"
      shift $#
      ;;

    get-examples-list-with-fzf)
      action="get-examples-list-with-fzf"
      shift
      playground_get_examples_list_with_fzf_parse_requirements "$@"
      shift $#
      ;;

    run)
      action="run"
      shift
      playground_run_parse_requirements "$@"
      shift $#
      ;;

    re-run)
      action="re-run"
      shift
      playground_re_run_parse_requirements "$@"
      shift $#
      ;;

    bootstrap-reproduction-model)
      action="bootstrap-reproduction-model"
      shift
      playground_bootstrap_reproduction_model_parse_requirements "$@"
      shift $#
      ;;

    get-properties)
      action="get-properties"
      shift
      playground_get_properties_parse_requirements "$@"
      shift $#
      ;;

    get-all-schemas)
      action="get-all-schemas"
      shift
      playground_get_all_schemas_parse_requirements "$@"
      shift $#
      ;;

    enable-remote-debugging)
      action="enable-remote-debugging"
      shift
      playground_enable_remote_debugging_parse_requirements "$@"
      shift $#
      ;;

    get-jmx-metrics)
      action="get-jmx-metrics"
      shift
      playground_get_jmx_metrics_parse_requirements "$@"
      shift $#
      ;;

    container)
      action="container"
      shift
      playground_container_parse_requirements "$@"
      shift $#
      ;;

    topic)
      action="topic"
      shift
      playground_topic_parse_requirements "$@"
      shift $#
      ;;

    connector)
      action="connector"
      shift
      playground_connector_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_connector_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_connector_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="get-connector-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_topic_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_topic_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="get-topic-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_examples_list_with_fzf_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_examples_list_with_fzf_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="get-examples-list-with-fzf"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --without-repro)

        # :flag.case_no_arg
        args['--without-repro']=1
        shift
        ;;

      # :flag.case
      --sink-only)

        # :flag.case_no_arg
        args['--sink-only']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        if [[ -z ${args['cur']+x} ]]; then

          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_run_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_run_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v fzf >/dev/null 2>&1; then
    deps['fzf']="$(command -v fzf | head -n1)"
  else
    printf "missing dependency: fzf\n" >&2
    exit 1
  fi

  # :command.command_filter
  action="run"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --file | -f)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--file, -f FILE" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--file']="$2"
          shift
          shift
        else
          printf "%s\n" "--file requires an argument: --file, -f FILE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --skip-editor | -s)

        # :flag.case_no_arg
        args['--skip-editor']=1
        shift
        ;;

      # :flag.case
      --tag)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--tag requires an argument: --tag TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-tag)
        # :flag.conflicts
        if [[ -n "${args['--connector-zip']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-zip" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector-tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-tag requires an argument: --connector-tag CONNECTOR_TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-zip)
        # :flag.conflicts
        if [[ -n "${args['--connector-tag']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-tag" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector-zip']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-zip requires an argument: --connector-zip CONNECTOR_ZIP" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-jar)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--connector-jar CONNECTOR_JAR" "$(validate_file_exists "$2")" >&2
            exit 1
          fi

          args['--connector-jar']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-jar requires an argument: --connector-jar CONNECTOR_JAR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --disable-ksqldb)

        # :flag.case_no_arg
        args['--disable-ksqldb']=1
        shift
        ;;

      # :flag.case
      --disable-control-center)

        # :flag.case_no_arg
        args['--disable-control-center']=1
        shift
        ;;

      # :flag.case
      --enable-conduktor)

        # :flag.case_no_arg
        args['--enable-conduktor']=1
        shift
        ;;

      # :flag.case
      --enable-multiple-brokers)

        # :flag.case_no_arg
        args['--enable-multiple-brokers']=1
        shift
        ;;

      # :flag.case
      --enable-multiple-connect-workers)

        # :flag.case_no_arg
        args['--enable-multiple-connect-workers']=1
        shift
        ;;

      # :flag.case
      --enable-jmx-grafana)

        # :flag.case_no_arg
        args['--enable-jmx-grafana']=1
        shift
        ;;

      # :flag.case
      --enable-kcat)

        # :flag.case_no_arg
        args['--enable-kcat']=1
        shift
        ;;

      # :flag.case
      --enable-sr-maven-plugin-app)

        # :flag.case_no_arg
        args['--enable-sr-maven-plugin-app']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--file']+x} ]]; then
    printf "missing required flag: --file, -f FILE\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_re_run_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_re_run_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="re-run"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_bootstrap_reproduction_model_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_bootstrap_reproduction_model_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.environment_variables_filter
  # :command.environment_variables_default
  export OUTPUT_FOLDER="${OUTPUT_FOLDER:-reproduction-models}"

  # :command.dependencies_filter
  if command -v fzf >/dev/null 2>&1; then
    deps['fzf']="$(command -v fzf | head -n1)"
  else
    printf "missing dependency: fzf\n" >&2
    exit 1
  fi

  # :command.command_filter
  action="bootstrap-reproduction-model"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --file | -f)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--file, -f FILE" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--file']="$2"
          shift
          shift
        else
          printf "%s\n" "--file requires an argument: --file, -f FILE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --description | -d)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--description, -d DESCRIPTION" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--description']="$2"
          shift
          shift
        else
          printf "%s\n" "--description requires an argument: --description, -d DESCRIPTION" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --producer | -p)
        # :flag.conflicts
        if [[ -n "${args['--pipeline']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--pipeline" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--producer']="$2"
          shift
          shift
        else
          printf "%s\n" "--producer requires an argument: --producer, -p PRODUCER-TYPE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --nb-producers | -n)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_integer "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--nb-producers, -n NB-PRODUCERS" "$(validate_integer "$2")" >&2
            exit 1
          fi

          args['--nb-producers']="$2"
          shift
          shift
        else
          printf "%s\n" "--nb-producers requires an argument: --nb-producers, -n NB-PRODUCERS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --custom-smt)

        # :flag.case_no_arg
        args['--custom-smt']=1
        shift
        ;;

      # :flag.case
      --pipeline)
        # :flag.conflicts
        if [[ -n "${args['--producer']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--producer" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--pipeline SINK_FILE" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--pipeline']="$2"
          shift
          shift
        else
          printf "%s\n" "--pipeline requires an argument: --pipeline SINK_FILE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--file']+x} ]]; then
    printf "missing required flag: --file, -f FILE\n" >&2
    exit 1
  fi
  if [[ -z ${args['--description']+x} ]]; then
    printf "missing required flag: --description, -d DESCRIPTION\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--producer']:-} ]] || args['--producer']="none"
  [[ -n ${args['--nb-producers']:-} ]] || args['--nb-producers']=""

  # :command.whitelist_filter
  if [[ ! ${args['--producer']} =~ ^(none|avro|avro-with-key|protobuf|protobuf-with-key|json-schema|json-schema-with-key)$ ]]; then
    printf "%s\n" "--producer must be one of: none, avro, avro-with-key, protobuf, protobuf-with-key, json-schema, json-schema-with-key" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_get_properties_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_properties_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="get-properties"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_get_all_schemas_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_all_schemas_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="get-all-schemas"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_enable_remote_debugging_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_enable_remote_debugging_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="enable-remote-debugging"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_get_jmx_metrics_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_jmx_metrics_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="get-jmx-metrics"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --component | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--component']="$2"
          shift
          shift
        else
          printf "%s\n" "--component requires an argument: --component, -c COMPONENT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --domain | -d)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--domain']="$2"
          shift
          shift
        else
          printf "%s\n" "--domain requires an argument: --domain, -d DOMAIN" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--component']:-} ]] || args['--component']="connect"

  # :command.whitelist_filter
  if [[ ! ${args['--component']} =~ ^(zookeeper|broker|connect|schema-registry)$ ]]; then
    printf "%s\n" "--component must be one of: zookeeper, broker, connect, schema-registry" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_container_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    recreate)
      action="recreate"
      shift
      playground_container_recreate_parse_requirements "$@"
      shift $#
      ;;

    get-ip-addresses)
      action="get-ip-addresses"
      shift
      playground_container_get_ip_addresses_parse_requirements "$@"
      shift $#
      ;;

    kill-all)
      action="kill-all"
      shift
      playground_container_kill_all_parse_requirements "$@"
      shift $#
      ;;

    logs)
      action="logs"
      shift
      playground_container_logs_parse_requirements "$@"
      shift $#
      ;;

    ssh)
      action="ssh"
      shift
      playground_container_ssh_parse_requirements "$@"
      shift $#
      ;;

    exec)
      action="exec"
      shift
      playground_container_exec_parse_requirements "$@"
      shift $#
      ;;

    restart)
      action="restart"
      shift
      playground_container_restart_parse_requirements "$@"
      shift $#
      ;;

    pause)
      action="pause"
      shift
      playground_container_pause_parse_requirements "$@"
      shift $#
      ;;

    resume)
      action="resume"
      shift
      playground_container_resume_parse_requirements "$@"
      shift $#
      ;;

    kill)
      action="kill"
      shift
      playground_container_kill_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_container_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_container_recreate_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_recreate_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="container recreate"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_container_get_ip_addresses_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_get_ip_addresses_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="container get-ip-addresses"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_container_kill_all_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_kill_all_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="container kill-all"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_container_logs_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_logs_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="container logs"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --open | -o)
        # :flag.conflicts
        if [[ -n "${args['--wait-for-log']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--wait-for-log" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_editor_exists "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--open, -o EDITOR" "$(validate_editor_exists "$2")" >&2
            exit 1
          fi

          args['--open']="$2"
          shift
          shift
        else
          printf "%s\n" "--open requires an argument: --open, -o EDITOR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --wait-for-log | -w)
        # :flag.conflicts
        if [[ -n "${args['--open']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--open" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--wait-for-log, -w LOG" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--wait-for-log']="$2"
          shift
          shift
        else
          printf "%s\n" "--wait-for-log requires an argument: --wait-for-log, -w LOG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --max-wait | -m)
        # :flag.conflicts
        if [[ -n "${args['--open']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--open" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_integer "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--max-wait, -m MAX_WAIT" "$(validate_integer "$2")" >&2
            exit 1
          fi

          args['--max-wait']="$2"
          shift
          shift
        else
          printf "%s\n" "--max-wait requires an argument: --max-wait, -m MAX_WAIT" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"
  [[ -n ${args['--max-wait']:-} ]] || args['--max-wait']="600"

}

# :command.parse_requirements
playground_container_ssh_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_ssh_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="container ssh"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --shell | -s)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--shell']="$2"
          shift
          shift
        else
          printf "%s\n" "--shell requires an argument: --shell, -s SHELL" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"
  [[ -n ${args['--shell']:-} ]] || args['--shell']="bash"

  # :command.whitelist_filter
  if [[ ! ${args['--shell']} =~ ^(bash|sh|ksh|zsh)$ ]]; then
    printf "%s\n" "--shell must be one of: bash, sh, ksh, zsh" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_container_exec_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_exec_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="container exec"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --command | -d)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--command, -d COMMAND" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--command']="$2"
          shift
          shift
        else
          printf "%s\n" "--command requires an argument: --command, -d COMMAND" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --root)

        # :flag.case_no_arg
        args['--root']=1
        shift
        ;;

      # :flag.case
      --shell)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--shell']="$2"
          shift
          shift
        else
          printf "%s\n" "--shell requires an argument: --shell SHELL" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--command']+x} ]]; then
    printf "missing required flag: --command, -d COMMAND\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"
  [[ -n ${args['--shell']:-} ]] || args['--shell']="bash"

  # :command.whitelist_filter
  if [[ ! ${args['--shell']} =~ ^(bash|sh|ksh|zsh)$ ]]; then
    printf "%s\n" "--shell must be one of: bash, sh, ksh, zsh" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_container_restart_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_restart_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="container restart"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_container_pause_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_pause_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="container pause"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_container_resume_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_resume_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="container resume"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_container_kill_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_kill_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="container kill"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_topic_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    get-number-records)
      action="get-number-records"
      shift
      playground_topic_get_number_records_parse_requirements "$@"
      shift $#
      ;;

    display-connect-offsets)
      action="display-connect-offsets"
      shift
      playground_topic_display_connect_offsets_parse_requirements "$@"
      shift $#
      ;;

    display-consumer-offsets)
      action="display-consumer-offsets"
      shift
      playground_topic_display_consumer_offsets_parse_requirements "$@"
      shift $#
      ;;

    describe)
      action="describe"
      shift
      playground_topic_describe_parse_requirements "$@"
      shift $#
      ;;

    consume)
      action="consume"
      shift
      playground_topic_consume_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_topic_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_topic_get_number_records_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_get_number_records_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="topic get-number-records"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--topic']+x} ]]; then
    printf "missing required flag: --topic, -t TOPIC\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_topic_display_connect_offsets_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_display_connect_offsets_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="topic display-connect-offsets"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_topic_display_consumer_offsets_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_display_consumer_offsets_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="topic display-consumer-offsets"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_topic_describe_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_describe_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="topic describe"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--topic']+x} ]]; then
    printf "missing required flag: --topic, -t TOPIC\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_topic_consume_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_consume_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="topic consume"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    status)
      action="status"
      shift
      playground_connector_status_parse_requirements "$@"
      shift $#
      ;;

    plugins)
      action="plugins"
      shift
      playground_connector_plugins_parse_requirements "$@"
      shift $#
      ;;

    pause)
      action="pause"
      shift
      playground_connector_pause_parse_requirements "$@"
      shift $#
      ;;

    restart)
      action="restart"
      shift
      playground_connector_restart_parse_requirements "$@"
      shift $#
      ;;

    resume)
      action="resume"
      shift
      playground_connector_resume_parse_requirements "$@"
      shift $#
      ;;

    delete)
      action="delete"
      shift
      playground_connector_delete_parse_requirements "$@"
      shift $#
      ;;

    show-lag)
      action="show-lag"
      shift
      playground_connector_show_lag_parse_requirements "$@"
      shift $#
      ;;

    log-level)
      action="log-level"
      shift
      playground_connector_log_level_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_connector_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_status_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_status_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="connector status"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --json)

        # :flag.case_no_arg
        args['--json']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_plugins_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_plugins_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="connector plugins"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_pause_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_pause_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="connector pause"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--connector']+x} ]]; then
    printf "missing required flag: --connector, -c CONNECTOR\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_restart_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_restart_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="connector restart"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--connector']+x} ]]; then
    printf "missing required flag: --connector, -c CONNECTOR\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_resume_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_resume_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="connector resume"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--connector']+x} ]]; then
    printf "missing required flag: --connector, -c CONNECTOR\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_delete_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_delete_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="connector delete"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--connector']+x} ]]; then
    printf "missing required flag: --connector, -c CONNECTOR\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_show_lag_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_show_lag_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="connector show-lag"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--connector']+x} ]]; then
    printf "missing required flag: --connector, -c CONNECTOR\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_log_level_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_log_level_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    get)
      action="get"
      shift
      playground_connector_log_level_get_parse_requirements "$@"
      shift $#
      ;;

    set)
      action="set"
      shift
      playground_connector_log_level_set_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_connector_log_level_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_log_level_get_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_log_level_get_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="connector log-level get"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --package | -p)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--package, -p PACKAGE" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--package']="$2"
          shift
          shift
        else
          printf "%s\n" "--package requires an argument: --package, -p PACKAGE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_log_level_set_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_log_level_set_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter

  # :command.command_filter
  action="connector log-level set"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --package | -p)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--package, -p PACKAGE" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--package']="$2"
          shift
          shift
        else
          printf "%s\n" "--package requires an argument: --package, -p PACKAGE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --level | -l)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--level']="$2"
          shift
          shift
        else
          printf "%s\n" "--level requires an argument: --level, -l LEVEL" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--package']+x} ]]; then
    printf "missing required flag: --package, -p PACKAGE\n" >&2
    exit 1
  fi
  if [[ -z ${args['--level']+x} ]]; then
    printf "missing required flag: --level, -l LEVEL\n" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ! ${args['--level']} =~ ^(INFO|WARN|DEBUG|TRACE)$ ]]; then
    printf "%s\n" "--level must be one of: INFO, WARN, DEBUG, TRACE" >&2
    exit 1
  fi

}

# :command.initialize
initialize() {
  version="1.0.3"
  long_usage=''
  set -e

  # src/initialize.sh

}

# :command.run
run() {
  declare -A args=()
  declare -A deps=()
  declare -a other_args=()
  declare -a input=()
  normalize_input "$@"
  parse_requirements "${input[@]}"

  case "$action" in
    "get-connector-list")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_get_connector_list_usage
      else
        playground_get_connector_list_command
      fi
      ;;

    "get-topic-list")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_get_topic_list_usage
      else
        playground_get_topic_list_command
      fi
      ;;

    "get-examples-list-with-fzf")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_get_examples_list_with_fzf_usage
      else
        playground_get_examples_list_with_fzf_command
      fi
      ;;

    "run")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_run_usage
      else
        playground_run_command
      fi
      ;;

    "re-run")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_re_run_usage
      else
        playground_re_run_command
      fi
      ;;

    "bootstrap-reproduction-model")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_bootstrap_reproduction_model_usage
      else
        playground_bootstrap_reproduction_model_command
      fi
      ;;

    "get-properties")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_get_properties_usage
      else
        playground_get_properties_command
      fi
      ;;

    "get-all-schemas")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_get_all_schemas_usage
      else
        playground_get_all_schemas_command
      fi
      ;;

    "enable-remote-debugging")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_enable_remote_debugging_usage
      else
        playground_enable_remote_debugging_command
      fi
      ;;

    "get-jmx-metrics")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_get_jmx_metrics_usage
      else
        playground_get_jmx_metrics_command
      fi
      ;;

    "container")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_container_usage
      else
        playground_container_command
      fi
      ;;

    "container recreate")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_container_recreate_usage
      else
        playground_container_recreate_command
      fi
      ;;

    "container get-ip-addresses")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_container_get_ip_addresses_usage
      else
        playground_container_get_ip_addresses_command
      fi
      ;;

    "container kill-all")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_container_kill_all_usage
      else
        playground_container_kill_all_command
      fi
      ;;

    "container logs")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_container_logs_usage
      else
        playground_container_logs_command
      fi
      ;;

    "container ssh")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_container_ssh_usage
      else
        playground_container_ssh_command
      fi
      ;;

    "container exec")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_container_exec_usage
      else
        playground_container_exec_command
      fi
      ;;

    "container restart")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_container_restart_usage
      else
        playground_container_restart_command
      fi
      ;;

    "container pause")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_container_pause_usage
      else
        playground_container_pause_command
      fi
      ;;

    "container resume")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_container_resume_usage
      else
        playground_container_resume_command
      fi
      ;;

    "container kill")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_container_kill_usage
      else
        playground_container_kill_command
      fi
      ;;

    "topic")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_topic_usage
      else
        playground_topic_command
      fi
      ;;

    "topic get-number-records")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_topic_get_number_records_usage
      else
        playground_topic_get_number_records_command
      fi
      ;;

    "topic display-connect-offsets")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_topic_display_connect_offsets_usage
      else
        playground_topic_display_connect_offsets_command
      fi
      ;;

    "topic display-consumer-offsets")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_topic_display_consumer_offsets_usage
      else
        playground_topic_display_consumer_offsets_command
      fi
      ;;

    "topic describe")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_topic_describe_usage
      else
        playground_topic_describe_command
      fi
      ;;

    "topic consume")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_topic_consume_usage
      else
        playground_topic_consume_command
      fi
      ;;

    "connector")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_connector_usage
      else
        playground_connector_command
      fi
      ;;

    "connector status")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_connector_status_usage
      else
        playground_connector_status_command
      fi
      ;;

    "connector plugins")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_connector_plugins_usage
      else
        playground_connector_plugins_command
      fi
      ;;

    "connector pause")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_connector_pause_usage
      else
        playground_connector_pause_command
      fi
      ;;

    "connector restart")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_connector_restart_usage
      else
        playground_connector_restart_command
      fi
      ;;

    "connector resume")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_connector_resume_usage
      else
        playground_connector_resume_command
      fi
      ;;

    "connector delete")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_connector_delete_usage
      else
        playground_connector_delete_command
      fi
      ;;

    "connector show-lag")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_connector_show_lag_usage
      else
        playground_connector_show_lag_command
      fi
      ;;

    "connector log-level")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_connector_log_level_usage
      else
        playground_connector_log_level_command
      fi
      ;;

    "connector log-level get")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_connector_log_level_get_usage
      else
        playground_connector_log_level_get_command
      fi
      ;;

    "connector log-level set")
      if [[ ${args['--help']:-} ]]; then
        long_usage=yes
        playground_connector_log_level_set_usage
      else
        playground_connector_log_level_set_command
      fi
      ;;

  esac
}

initialize
run "$@"
