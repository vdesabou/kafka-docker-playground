#!/usr/bin/env bash
# This script was generated by bashly 1.1.1 (https://bashly.dannyb.co)
# Modifying it manually is not recommended

# :wrapper.bash3_bouncer
if [[ "${BASH_VERSINFO:-0}" -lt 4 ]]; then
  printf "bash version 4 or higher is required\n" >&2
  exit 1
fi

# :command.master_script

# :command.version_command
version_command() {
  echo "$version"
}

# :command.usage
playground_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground\n"
    echo

    printf "  ğŸ§  CLI for Kafka Docker Playground ğŸ³\n  \n  ğŸ‘‰ Check documentation https://kafka-docker-playground.io/#/cli\n"
    echo

  else
    printf "playground - ğŸ§  CLI for Kafka Docker Playground ğŸ³\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground COMMAND\n"
  printf "  playground [COMMAND] --help | -h\n"
  printf "  playground --version | -v\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   Show help about a command\n" "$(green "help")                                   "
  printf "  %s   ğŸ—ºï¸ Show a status\n" "$(green "status")                                 "
  echo
  printf "%s\n" "$(bold "Run commands:")"
  printf "  %s   ğŸ•¹ï¸ Run any example, except for Confluent Cloud (in this case use run-ccloud command)\n" "$(green "run")                                    "
  printf "  %s   âš¡ Simply re-run last example you ran with <playground run> or <playground run-ccloud>\n" "$(green "re-run")                                 "
  printf "  %s   â›… Run any Confluent Cloud (ccloud) example\n" "$(green "run-ccloud")                             "
  printf "  %s   âœ¨ Update current confluent platform or connector(s) with new version(s)\n" "$(green "update-version")                         "
  printf "  %s   ğŸ‘ When --file is not provided, simply open last example you ran with <playground run> or <playground run-ccloud>\n" "$(green "open")                                   "
  printf "  %s   ğŸ›‘ Stop currently running example\n" "$(green "stop")                                   "
  printf "  %s   ğŸ§‘â€ğŸ“ Open Confluent documentation of currently running example\n" "$(green "open-docs")                              "
  echo
  printf "%s\n" "$(bold "Repro commands:")"
  printf "  %s   ğŸ‘·â€â™‚ï¸ Reproduction model commands\n" "$(green "repro")                                  "
  [[ -n $long_usage ]] && printf "  %s   ğŸ“¤ Export as tgz file uncommitted reproduction models from the folder of current reproduction model\n" "$(green "repro export")                           "
  [[ -n $long_usage ]] && printf "  %s   ğŸ“¥ Import tgz file which was created with export command\n" "$(green "repro import")                           "
  [[ -n $long_usage ]] && printf "  %s   ğŸ›   Bootstrap reproduction model\n" "$(green "repro bootstrap")                        "
  echo
  printf "%s\n" "$(bold "Kafka commands:")"
  printf "  %s   ğŸ‹ Get docker-compose\n" "$(green "get-docker-compose")                     "
  printf "  %s   ğŸ“ Get properties file from a container\n" "$(green "get-properties")                         "
  printf "  %s   ğŸ”¢ Get JMX metrics from a component\n" "$(green "get-jmx-metrics")                        "
  echo
  printf "%s\n" "$(bold "Schema commands:")"
  printf "  %s   ğŸ”° Schema commands\n" "$(green "schema")                                 "
  [[ -n $long_usage ]] && printf "  %s   ğŸ”° Get all schemas versions for specified subject (if --subject is not specified, all subjects will be used)\n" "$(green "schema get")                             "
  [[ -n $long_usage ]] && printf "  %s   âºï¸ Register a schema in specified subject\n" "$(green "schema register")                        "
  [[ -n $long_usage ]] && printf "  %s   ğŸ›¡ï¸ Get subject-level compatibility\n" "$(green "schema get-compatibility")               "
  [[ -n $long_usage ]] && printf "  %s   ğŸ›¡ï¸ Set subject-level compatibility\n" "$(green "schema set-compatibility")               "
  [[ -n $long_usage ]] && printf "  %s   ğŸ” Get subject-level mode\n" "$(green "schema get-mode")                        "
  [[ -n $long_usage ]] && printf "  %s   ğŸ” Set subject-level mode\n" "$(green "schema set-mode")                        "
  [[ -n $long_usage ]] && printf "  %s   ğŸ§Ÿ Delete schema\n" "$(green "schema delete")                          "
  echo
  printf "%s\n" "$(bold "Debug commands:")"
  printf "  %s   ğŸ Debug commands\n" "$(green "debug")                                  "
  [[ -n $long_usage ]] && printf "  %s   ğŸª„ Install a slightly modified version of \"Shell Script Command Completion\" Visual Studio Code extension (https://marketplace.visualstudio.com/items?itemName=tetradresearch.vscode-h2o)\n" "$(green "debug install-vscode-extension")         "
  [[ -n $long_usage ]] && printf "  %s   âœ¨ Enable java remote debugging for container\n" "$(green "debug enable-remote-debugging")          "
  [[ -n $long_usage ]] && printf "  %s   ğŸ” Testing TLS/SSL encryption using https://testssl.sh/\n" "$(green "debug testssl")                          "
  [[ -n $long_usage ]] && printf "  %s   â›‘ï¸ Generate a diagnostic bundle with Diagnostics Bundle Tool\n" "$(green "debug generate-diagnostics")             "
  [[ -n $long_usage ]] && printf "  %s   ğŸ¯ Take a java thread dump\n" "$(green "debug thread-dump")                      "
  [[ -n $long_usage ]] && printf "  %s   ğŸ‘» Take a heap dump\n" "$(green "debug heap-dump")                        "
  [[ -n $long_usage ]] && printf "  %s   ğŸ•µï¸â€â™‚ï¸ Take a tcp dump (sniffing network)\n" "$(green "debug tcp-dump")                         "
  [[ -n $long_usage ]] && printf "  %s   ğŸš« Blocking traffic using iptables\n" "$(green "debug block-traffic")                    "
  [[ -n $long_usage ]] && printf "  %s   ğŸ›©ï¸ Record flight recorder\n" "$(green "debug flight-recorder")                  "
  [[ -n $long_usage ]] && printf "  %s   ğŸ§¬ Set log level for any package\n" "$(green "debug log-level")                        "
  echo
  printf "%s\n" "$(bold "Container commands:")"
  printf "  %s   ğŸ³ Container commands\n" "$(green "container")                              "
  [[ -n $long_usage ]] && printf "  %s   ğŸ’« Recreate container(s)\n" "$(green "container recreate")                     "
  [[ -n $long_usage ]] && printf "  %s   ğŸ–¥ï¸  Get ip address of running containers\n" "$(green "container get-ip-addresses")             "
  [[ -n $long_usage ]] && printf "  %s   ğŸ’€ Kill all containers\n" "$(green "container kill-all")                     "
  [[ -n $long_usage ]] && printf "  %s   ğŸ•µï¸  Tail and follow container logs\n" "$(green "container logs")                         "
  [[ -n $long_usage ]] && printf "  %s   ğŸ›¬ SSH into container\n" "$(green "container ssh")                          "
  [[ -n $long_usage ]] && printf "  %s   ğŸª„  Execute command in a container\n" "$(green "container exec")                         "
  [[ -n $long_usage ]] && printf "  %s   ğŸ” Restart a container\n" "$(green "container restart")                      "
  [[ -n $long_usage ]] && printf "  %s   â¸ï¸  Pause a container\n" "$(green "container pause")                        "
  [[ -n $long_usage ]] && printf "  %s   â¯ï¸  Resume a container\n" "$(green "container resume")                       "
  [[ -n $long_usage ]] && printf "  %s   ğŸ”« Kill a container\n" "$(green "container kill")                         "
  echo
  printf "%s\n" "$(bold "Topic commands:")"
  printf "  %s   ğŸ—³ Topic commands\n" "$(green "topic")                                  "
  [[ -n $long_usage ]] && printf "  %s   ğŸ’¯ Get number of records in a topic\n" "$(green "topic get-number-records")               "
  [[ -n $long_usage ]] && printf "  %s   ğŸ“­ Display content of __consumer_offsets topic\n" "$(green "topic display-consumer-offsets")         "
  [[ -n $long_usage ]] && printf "  %s   ğŸ”˜ List topics\n" "$(green "topic list")                             "
  [[ -n $long_usage ]] && printf "  %s   ğŸ”¬ Describe topic\n" "$(green "topic describe")                         "
  [[ -n $long_usage ]] && printf "  %s   ğŸ›¡ï¸ Change topic's schema compatibility\n" "$(green "topic set-schema-compatibility")         "
  [[ -n $long_usage ]] && printf "  %s   ğŸ“¥ Consume topic from beginning\n" "$(green "topic consume")                          "
  [[ -n $long_usage ]] && printf "  %s   ğŸ“¤ Produce to a topic\n" "$(green "topic produce")                          "
  [[ -n $long_usage ]] && printf "  %s   ğŸ†• Create topic\n" "$(green "topic create")                           "
  [[ -n $long_usage ]] && printf "  %s   âŒ Delete topic\n" "$(green "topic delete")                           "
  [[ -n $long_usage ]] && printf "  %s   ğŸª› Alter topic config\n" "$(green "topic alter")                            "
  echo
  printf "%s\n" "$(bold "Connector commands:")"
  printf "  %s   ğŸ”—â˜ï¸ Fully Managed Connector commands\n" "$(green "ccloud-connector")                       "
  [[ -n $long_usage ]] && printf "  %s   ğŸ§© Show status of all connectors\n" "$(green "ccloud-connector status")                "
  [[ -n $long_usage ]] && printf "  %s   ğŸ¨ Show all plugins installed\n" "$(green "ccloud-connector plugins")               "
  [[ -n $long_usage ]] && printf "  %s   â¸ï¸  Pause connector\n" "$(green "ccloud-connector pause")                 "
  [[ -n $long_usage ]] && printf "  %s   â¯ï¸  Resume connector\n" "$(green "ccloud-connector resume")                "
  [[ -n $long_usage ]] && printf "  %s   ğŸ—‘ï¸  Delete connector\n" "$(green "ccloud-connector delete")                "
  [[ -n $long_usage ]] && printf "  %s   ğŸ¢ Show lag of sink connector\n" "$(green "ccloud-connector show-lag")              "
  [[ -n $long_usage ]] && printf "  %s   ğŸ§° Show current connector config\n" "$(green "ccloud-connector show-config")           "
  [[ -n $long_usage ]] && printf "  %s   ğŸ”© Show all possible configuration parameters of connector\n" "$(green "ccloud-connector show-config-parameters")"
  [[ -n $long_usage ]] && printf "  %s   ğŸ§‘â€ğŸ¨  Create or update connector\n" "$(green "ccloud-connector create-or-update")      "
  printf "  %s   ğŸ”— Connector commands\n" "$(green "connector")                              "
  [[ -n $long_usage ]] && printf "  %s   ğŸ§© Show status of all connectors\n" "$(green "connector status")                       "
  [[ -n $long_usage ]] && printf "  %s   ğŸ¨ Show all plugins installed\n" "$(green "connector plugins")                      "
  [[ -n $long_usage ]] && printf "  %s   â¸ï¸  Pause connector\n" "$(green "connector pause")                        "
  [[ -n $long_usage ]] && printf "  %s   ğŸ§ Get current and latest version available on Confluent Hub for connector(s) used in example\n" "$(green "connector versions")                     "
  [[ -n $long_usage ]] && printf "  %s   â™»ï¸  Restart connector\n" "$(green "connector restart")                      "
  [[ -n $long_usage ]] && printf "  %s   â¯ï¸  Resume connector\n" "$(green "connector resume")                       "
  [[ -n $long_usage ]] && printf "  %s   ğŸ—‘ï¸  Delete connector\n" "$(green "connector delete")                       "
  [[ -n $long_usage ]] && printf "  %s   ğŸ¢ Show lag of sink connector\n" "$(green "connector show-lag")                     "
  [[ -n $long_usage ]] && printf "  %s   ğŸ§° Show current connector config\n" "$(green "connector show-config")                  "
  [[ -n $long_usage ]] && printf "  %s   ğŸ”© Show all possible configuration parameters of connector\n" "$(green "connector show-config-parameters")       "
  [[ -n $long_usage ]] && printf "  %s   ğŸ§¬ Set connect log level\n" "$(green "connector log-level")                    "
  [[ -n $long_usage ]] && printf "  %s   ğŸ§‘â€ğŸ¨  Create or update connector\n" "$(green "connector create-or-update")             "
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo
    printf "  %s\n" "$(magenta "--version, -v")"
    printf "    Show version number\n"
    echo

  fi
}

# :command.usage
playground_help_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground help - Show help about a command\n"
    echo

  else
    printf "playground help - Show help about a command\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground help [COMMAND]\n"
  printf "  playground help --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "COMMAND")"
    printf "    ğŸ†˜ Help command\n"
    echo

  fi
}

# :command.usage
playground_status_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground status - ğŸ—ºï¸ Show a status\n"
    echo

  else
    printf "playground status - ğŸ—ºï¸ Show a status\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground status\n"
  printf "  playground status --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_connector_list_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-connector-list - Return some completion for connector list\n"
    echo

  else
    printf "playground get-connector-list - Return some completion for connector list\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-connector-list\n"
  printf "  playground get-connector-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_ccloud_connector_list_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-ccloud-connector-list - Return some completion for ccloud connector list\n"
    echo

  else
    printf "playground get-ccloud-connector-list - Return some completion for ccloud connector list\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-ccloud-connector-list\n"
  printf "  playground get-ccloud-connector-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_kafka_region_list_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-kafka-region-list - Return some completion for confluent cloud kafka cluster region list\n"
    echo

  else
    printf "playground get-kafka-region-list - Return some completion for confluent cloud kafka cluster region list\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-kafka-region-list\n"
  printf "  playground get-kafka-region-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_topic_list_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-topic-list - Return some completion for topic list\n"
    echo

  else
    printf "playground get-topic-list - Return some completion for topic list\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-topic-list [OPTIONS]\n"
  printf "  playground get-topic-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--skip-connect-internal-topics")"
    printf "\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_subject_list_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-subject-list - Return some completion for subject list\n"
    echo

  else
    printf "playground get-subject-list - Return some completion for subject list\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-subject-list [OPTIONS]\n"
  printf "  playground get-subject-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--deleted")"
    printf "    ğŸ§Ÿ Include soft deleted schemas\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_examples_list_with_fzf_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-examples-list-with-fzf - Return some completion for examples list\n"
    echo

  else
    printf "playground get-examples-list-with-fzf - Return some completion for examples list\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-examples-list-with-fzf [CUR] [OPTIONS]\n"
  printf "  playground get-examples-list-with-fzf --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--without-repro")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--sink-only")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--ccloud-only")"
    printf "\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_zip_or_jar_with_fzf_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-zip-or-jar-with-fzf - Return some completion for zip or jar list\n"
    echo

  else
    printf "playground get-zip-or-jar-with-fzf - Return some completion for zip or jar list\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-zip-or-jar-with-fzf [CUR] [OPTIONS]\n"
  printf "  playground get-zip-or-jar-with-fzf --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--type TYPE")"
    printf "\n"
    printf "    Allowed: zip, jar\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_any_file_with_fzf_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-any-file-with-fzf - Return some completion for any files\n"
    echo

  else
    printf "playground get-any-file-with-fzf - Return some completion for any files\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-any-file-with-fzf [CUR]\n"
  printf "  playground get-any-file-with-fzf --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_playground_repro_export_with_fzf_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-playground-repro-export-with-fzf - Return some completion for export tgz files\n"
    echo

  else
    printf "playground get-playground-repro-export-with-fzf - Return some completion for export tgz files\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-playground-repro-export-with-fzf [CUR]\n"
  printf "  playground get-playground-repro-export-with-fzf --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_predefined_schemas_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-predefined-schemas - Return some completion for predefined schemas\n"
    echo

  else
    printf "playground get-predefined-schemas - Return some completion for predefined schemas\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-predefined-schemas [CUR]\n"
  printf "  playground get-predefined-schemas --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_bashly_reload_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground bashly-reload\n"
    echo

  else
    printf "playground bashly-reload\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground bashly-reload\n"
  printf "  playground bashly-reload --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_run_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground run - ğŸ•¹ï¸ Run any example, except for Confluent Cloud (in this case use run-ccloud command)\n"
    echo

  else
    printf "playground run - ğŸ•¹ï¸ Run any example, except for Confluent Cloud (in this case use run-ccloud command)\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground run [OPTIONS] [ARGUMENTS...]\n"
  printf "  playground run --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--file, -f FILE (required)")"
    printf "    ğŸ”– Example file to run\n    \n    â• It must be absolute full path\n    \n    ğŸ“ Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--open, -o")"
    printf "    ğŸ“– Opening example file with text editor set with config.ini (default is\n    code)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--tag TAG")"
    printf "    ğŸ¯ Confluent Platform (CP) version to use\n    \n    Must be greater or equal to 5.0.0\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-tag CONNECTOR_TAG")"
    printf "    ğŸ”— Connector version to use\n    \n    By default, for each connector, the latest available version on Confluent\n    Hub is used\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-zip CONNECTOR_ZIP")"
    printf "    ğŸ¤ Connector zip to use\n    \n    â• It must be absolute full path\n    \n    ğŸ“ Tip: use <tab> completion to trigger fzf completion \n            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to\n    configure where to search the files (current folder is always used)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-jar CONNECTOR_JAR")"
    printf "    â™¨ï¸ Connector jar to use\n    \n    â• It must be absolute full path\n    \n    ğŸ“ Tip: use <tab> completion to trigger fzf completion \n            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to\n    configure where to search the files (current folder is always used)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-ksqldb")"
    printf "    ğŸš€ Enable ksqlDB\n    \n    By default, ksqldb-server and ksqldb-cli containers are not started for\n    every test\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-control-center")"
    printf "    ğŸ’  Enable Control Center\n    \n    By default, control-center container is not started for every test\n    \n    Control Center is reachable at http://127.0.0.1:9021\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-conduktor")"
    printf "    ğŸº Enable Conduktor Platform\n    \n    By default, Conduktor Platform container is not started for every test\n    \n    Conduktor is reachable at http://127.0.0.1:8080/console (admin/admin)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-multiple-brokers")"
    printf "    3ï¸âƒ£ Enable multiple brokers\n    \n    By default, there is only one broker node enabled\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-multiple-connect-workers")"
    printf "    ğŸ¥‰ Enable multiple connect node\n    \n    By default, there is only one connect node enabled\n    \n    It only works when plaintext environment is used\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-jmx-grafana")"
    printf "    Enable Grafana, Prometheus and Pyroscope\n    \n    ğŸ“Š Grafana is reachable at http://127.0.0.1:3000\n    \n    ğŸ›¡ï¸ Prometheus is reachable at http://127.0.0.1:9090\n    \n    ğŸ“› Pyroscope is reachable at http://127.0.0.1:4040\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-kcat")"
    printf "    ğŸˆâ€â¬› Enable kcat\n    \n    You can use it with:\n    \n    $ docker exec kcat kcat -b broker:9092 -L\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-sr-maven-plugin-app")"
    printf "    ğŸ”° Enable Schema Registry Maven plugin App\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-sql-datagen")"
    printf "    ğŸŒªï¸ Enable SQL Datagen injection\n    \n    This only works for Oracle, MySql, Postgres and Microsoft Sql Server source\n    connector examples with JDBC and Debezium\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    echo "  ARGUMENTS..."
    printf "    Arguments to use by example script\n    \n    Most of examples support to get required options either by using arguments\n    or environment variables.\n    \n    Example with Zendesk:\n    \n    playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME>\n    <ZENDESK_PASSWORD>\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground run -f zendesk-source<tab> --tag 7.2.1 --enable-control-center\n  <ZENDESK_URL> <ZENDESK_USERNAME> <ZENDESK_PASSWORD>\n"
    printf "  playground run -f jdbc<tab> --connector-tag 10.6.0 --enable-jmx-grafana --open\n"
    echo

  fi
}

# :command.usage
playground_re_run_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground re-run - âš¡ Simply re-run last example you ran with <playground run> or <playground run-ccloud>\n"
    echo

  else
    printf "playground re-run - âš¡ Simply re-run last example you ran with <playground run> or <playground run-ccloud>\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground re-run [OPTIONS] [ARGUMENTS...]\n"
  printf "  playground re-run --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--clear")"
    printf "    ğŸ§¼ Clear any previous flags\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--tag TAG")"
    printf "    ğŸ¯ Confluent Platform (CP) version to use\n    \n    Must be greater or equal to 5.0.0\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-tag CONNECTOR_TAG")"
    printf "    ğŸ”— Connector version to use\n    \n    By default, for each connector, the latest available version on Confluent\n    Hub is used\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-zip CONNECTOR_ZIP")"
    printf "    ğŸ¤ Connector zip to use\n    \n    â• It must be absolute full path\n    \n    ğŸ“ Tip: use <tab> completion to trigger fzf completion \n            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to\n    configure where to search the files (current folder is always used)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-jar CONNECTOR_JAR")"
    printf "    â™¨ï¸ Connector jar to use\n    \n    â• It must be absolute full path\n    \n    ğŸ“ Tip: use <tab> completion to trigger fzf completion \n            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to\n    configure where to search the files (current folder is always used)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-ksqldb")"
    printf "    ğŸš€ Enable ksqlDB\n    \n    By default, ksqldb-server and ksqldb-cli containers are not started for\n    every test\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-control-center")"
    printf "    ğŸ’  Enable Control Center\n    \n    By default, control-center container is not started for every test\n    \n    Control Center is reachable at http://127.0.0.1:9021\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-conduktor")"
    printf "    ğŸº Enable Conduktor Platform\n    \n    By default, Conduktor Platform container is not started for every test\n    \n    Conduktor is reachable at http://127.0.0.1:8080/console (admin/admin)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-multiple-brokers")"
    printf "    3ï¸âƒ£ Enable multiple brokers\n    \n    By default, there is only one broker node enabled\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-multiple-connect-workers")"
    printf "    ğŸ¥‰ Enable multiple connect node\n    \n    By default, there is only one connect node enabled\n    \n    It only works when plaintext environment is used\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-jmx-grafana")"
    printf "    Enable Grafana, Prometheus and Pyroscope\n    \n    ğŸ“Š Grafana is reachable at http://127.0.0.1:3000\n    \n    ğŸ›¡ï¸ Prometheus is reachable at http://127.0.0.1:9090\n    \n    ğŸ“› Pyroscope is reachable at http://127.0.0.1:4040\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-kcat")"
    printf "    ğŸˆâ€â¬› Enable kcat\n    \n    You can use it with:\n    \n    $ docker exec kcat kcat -b broker:9092 -L\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-sr-maven-plugin-app")"
    printf "    ğŸ”° Enable Schema Registry Maven plugin App\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-sql-datagen")"
    printf "    ğŸŒªï¸ Enable SQL Datagen injection\n    \n    This only works for Oracle, MySql, Postgres and Microsoft Sql Server source\n    connector examples with JDBC and Debezium\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    echo "  ARGUMENTS..."
    printf "    Arguments to use by example script\n    \n    Most of examples support to get required options either by using arguments\n    or environment variables.\n    \n    Example with Zendesk:\n    \n    playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME>\n    <ZENDESK_PASSWORD>\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground re-run\n"
    printf "  playground re-run --tag=6.2.1\n"
    echo

  fi
}

# :command.usage
playground_run_ccloud_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground run-ccloud\n"
    echo

    printf "  â›… Run any Confluent Cloud (ccloud) example\n  \n  All you have to do is to be already logged in with confluent CLI.\n  \n  By default, a new Confluent Cloud environment with a Cluster will be created.\n  \n  You can configure the new cluster by setting:\n  \n  --cluster-type (or CLUSTER_TYPE environment variable): The type of cluster\n  (possible values: \`basic\`, \`standard\` and \`dedicated\`, default \`basic\`)\n  --cluster-cloud (or CLUSTER_CLOUD environment variable): The Cloud provider\n  (possible values: \`aws\`, \`gcp\` and \`azure\`, default \`aws\`)\n  --cluster-region (or CLUSTER_REGION environment variable): The Cloud region\n  (use \`confluent kafka region list\` to get the list, default \`eu-west-2\`)\n  --cluster-environment (or ENVIRONMENT environment variable) (optional): The\n  environment id where want your new cluster (example: \`env-xxxxx\`)\n  \n  In case you want to use your own existing cluster, you need to setup, in\n  addition to previous ones:\n  \n  --cluster-name (or CLUSTER_NAME environment variable): The cluster name\n  --cluster-creds (or CLUSTER_CREDS environment variable): The Kafka api key and\n  secret to use, it should be separated with semi-colon (example:\n  \`<API_KEY>:<API_KEY_SECRET>\`)\n  --cluster-schema-registry-creds (or SCHEMA_REGISTRY_CREDS environment\n  variable) (optional, if not set, new one will be created): The Schema Registry\n  api key and secret to use, it should be separated with semi-colon (example:\n  \`<SR_API_KEY>:<SR_API_KEY_SECRET>\`)\n"
    echo

  else
    printf "playground run-ccloud - â›… Run any Confluent Cloud (ccloud) example\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground run-ccloud [OPTIONS] [ARGUMENTS...]\n"
  printf "  playground run-ccloud --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--file, -f FILE (required)")"
    printf "    ğŸ”– Example file to run\n    \n    â• It must be absolute full path\n    \n    ğŸ“ Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--open, -o")"
    printf "    ğŸ“– Opening example file with text editor set with config.ini (default is\n    code)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--tag TAG")"
    printf "    ğŸ¯ Confluent Platform (CP) version to use\n    \n    Must be greater or equal to 5.0.0\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-tag CONNECTOR_TAG")"
    printf "    ğŸ”— Connector version to use\n    \n    By default, for each connector, the latest available version on Confluent\n    Hub is used\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-zip CONNECTOR_ZIP")"
    printf "    ğŸ¤ Connector zip to use\n    \n    â• It must be absolute full path\n    \n    ğŸ“ Tip: use <tab> completion to trigger fzf completion \n            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to\n    configure where to search the files (current folder is always used)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-jar CONNECTOR_JAR")"
    printf "    â™¨ï¸ Connector jar to use\n    \n    â• It must be absolute full path\n    \n    ğŸ“ Tip: use <tab> completion to trigger fzf completion \n            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to\n    configure where to search the files (current folder is always used)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-control-center")"
    printf "    ğŸ’  Enable Control Center\n    \n    By default, control-center container is not started for every test\n    \n    Control Center is reachable at http://127.0.0.1:9021\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-conduktor")"
    printf "    ğŸº Enable Conduktor Platform\n    \n    By default, Conduktor Platform container is not started for every test\n    \n    Conduktor is reachable at http://127.0.0.1:8080/console (admin/admin)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-kcat")"
    printf "    ğŸˆâ€â¬› Enable kcat\n    \n    You can use it with:\n    \n    $ docker exec kcat kcat -b broker:9092 -L\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-cloud CLUSTER-CLOUD")"
    printf "    ğŸŒ¤ The cloud provider: aws, gcp or azure. Default is aws\n    \n    ğŸ“ Tip: you can also use CLUSTER_CLOUD environment variable\n"
    printf "    Allowed: aws, gcp, azure\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-type CLUSTER-TYPE")"
    printf "    ğŸ”‹ The cluster type: basic, standard or dedicated. Default is basic\n    \n    ğŸ“ Tip: you can also use CLUSTER_TYPE environment variable\n"
    printf "    Allowed: basic, standard, dedicated\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-region CLUSTER-REGION")"
    printf "    ğŸ—º The Cloud region. \n    \n    ğŸ“ Tip: you can also use CLUSTER_REGION environment variable\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-environment CLUSTER-ENVIRONMENT")"
    printf "    ğŸŒ The environment id where want your new cluster (example: env-xxxxx)\n    \n    â„¹ï¸ Optional, if not set, new environment will be created\n    \n    ğŸ“ Tip: you can also use ENVIRONMENT environment variable\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-name CLUSTER-NAME")"
    printf "    ğŸ° The cluster name. \n    \n    â£ï¸ Only required if you want to use your own existing cluster\n    \n    ğŸ“ Tip: you can also use CLUSTER_NAME environment variable\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-creds CLUSTER-CREDS")"
    printf "    ğŸ”’ The Kafka api key and secret to use, it should be separated with\n    semi-colon (example: <API_KEY>:<API_KEY_SECRET>)\n    \n    â£ï¸ Only required if you want to use your own existing cluster\n    \n    ğŸ“ Tip: you can also use CLUSTER_CREDS environment variable\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-schema-registry-creds CLUSTER-SCHEMA-REGISTRY-CREDS")"
    printf "    ğŸ”’ The Schema Registry api key and secret to use, it should be separated with\n    semi-colon (example: <SR_API_KEY>:<SR_API_KEY_SECRET>)\n    \n    â„¹ï¸ Optional, if not set, new credentials will be created\n    \n    â£ï¸ Only required if you want to use your own existing cluster\n    \n    ğŸ“ Tip: you can also use SCHEMA_REGISTRY_CREDS environment variable\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    echo "  ARGUMENTS..."
    printf "    Arguments to use by example script\n    \n    Most of examples support to get required options either by using arguments\n    or environment variables.\n    \n    Example with Zendesk:\n    \n    playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME>\n    <ZENDESK_PASSWORD>\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground run-ccloud mqtt<tab> --cluster-cloud aws --cluster-region eu-west-3\n  --enable-control-center --connector-tag 1.2.3\n"
    echo

  fi
}

# :command.usage
playground_update_version_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground update-version - âœ¨ Update current confluent platform or connector(s) with new version(s)\n"
    echo

  else
    printf "playground update-version - âœ¨ Update current confluent platform or connector(s) with new version(s)\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground update-version [OPTIONS]\n"
  printf "  playground update-version --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--tag TAG")"
    printf "    ğŸ¯ Confluent Platform (CP) version to use\n    \n    Must be greater or equal to 5.0.0\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-tag CONNECTOR_TAG")"
    printf "    ğŸ”— Connector version to use\n    \n    By default, for each connector, the latest available version on Confluent\n    Hub is used\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-zip CONNECTOR_ZIP")"
    printf "    ğŸ¤ Connector zip to use\n    \n    â• It must be absolute full path\n    \n    ğŸ“ Tip: use <tab> completion to trigger fzf completion \n            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to\n    configure where to search the files (current folder is always used)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-jar CONNECTOR_JAR")"
    printf "    â™¨ï¸ Connector jar to use\n    \n    â• It must be absolute full path\n    \n    ğŸ“ Tip: use <tab> completion to trigger fzf completion \n            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to\n    configure where to search the files (current folder is always used)\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_open_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground open\n"
    echo

    printf "  ğŸ‘ When --file is not provided, simply open last example you ran with\n  <playground run> or <playground run-ccloud>\n  \n  Otherwise, open any file from the playground using --file.\n"
    echo

  else
    printf "playground open - ğŸ‘ When --file is not provided, simply open last example you ran with <playground run> or <playground run-ccloud>\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground open [OPTIONS]\n"
  printf "  playground open --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--file, -f FILE")"
    printf "    ğŸ” Search any file and open it.\n    \n    â• It must be absolute full path\n    \n    ğŸ“ Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_stop_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground stop - ğŸ›‘ Stop currently running example\n"
    echo

  else
    printf "playground stop - ğŸ›‘ Stop currently running example\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground stop\n"
  printf "  playground stop --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_open_docs_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground open-docs - ğŸ§‘â€ğŸ“ Open Confluent documentation of currently running example\n"
    echo

  else
    printf "playground open-docs - ğŸ§‘â€ğŸ“ Open Confluent documentation of currently running example\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground open-docs [OPTIONS]\n"
  printf "  playground open-docs --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--only-show-url")"
    printf "    ğŸŒ Only show url\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_repro_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground repro - ğŸ‘·â€â™‚ï¸ Reproduction model commands\n"
    echo

  else
    printf "playground repro - ğŸ‘·â€â™‚ï¸ Reproduction model commands\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground repro COMMAND\n"
  printf "  playground repro [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   ğŸ“¤ Export as tgz file uncommitted reproduction models from the folder of current reproduction model\n" "$(green "export")   "
  printf "  %s   ğŸ“¥ Import tgz file which was created with export command\n" "$(green "import")   "
  printf "  %s   ğŸ›   Bootstrap reproduction model\n" "$(green "bootstrap")"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_environment_variables
    printf "%s\n" "$(bold "Environment Variables:")"

    # :environment_variable.usage
    printf "  %s\n" "$(cyan "OUTPUT_FOLDER")"
    printf "    ğŸ“ Output folder where to generate bootstrapped files\n"
    printf "    Default: reproduction-models\n"
    echo

  fi
}

# :command.usage
playground_repro_export_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground repro export - ğŸ“¤ Export as tgz file uncommitted reproduction models from the folder of current reproduction model\n"
    echo

  else
    printf "playground repro export - ğŸ“¤ Export as tgz file uncommitted reproduction models from the folder of current reproduction model\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground repro export [OPTIONS]\n"
  printf "  playground repro export --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--all")"
    printf "    Export all uncommitted reproduction models\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_repro_import_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground repro import - ğŸ“¥ Import tgz file which was created with export command\n"
    echo

  else
    printf "playground repro import - ğŸ“¥ Import tgz file which was created with export command\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground repro import [OPTIONS]\n"
  printf "  playground repro import --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--file, -f FILE")"
    printf "    ğŸ¤ playground_repro_export.tgz file\n    \n    â• It must be absolute full path\n    \n    ğŸ“ Tip: use <tab> completion to trigger fzf completion \n            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to\n    configure where to search the files (current folder is always used)\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_repro_bootstrap_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground repro bootstrap\n"
    echo

    printf "  ğŸ›   Bootstrap reproduction model\n  \n  ğŸ‘‰ Check documentation\n  https://kafka-docker-playground.io/#/reusables?id=%f0%9f%9b%a0-bootstrap-reproduction-model\n"
    echo

  else
    printf "playground repro bootstrap - ğŸ›   Bootstrap reproduction model\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground repro bootstrap [OPTIONS] [ARGUMENTS...]\n"
  printf "  playground repro bootstrap --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--tag TAG")"
    printf "    ğŸ¯ Confluent Platform (CP) version to use\n    \n    Must be greater or equal to 5.0.0\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-tag CONNECTOR_TAG")"
    printf "    ğŸ”— Connector version to use\n    \n    By default, for each connector, the latest available version on Confluent\n    Hub is used\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-zip CONNECTOR_ZIP")"
    printf "    ğŸ¤ Connector zip to use\n    \n    â• It must be absolute full path\n    \n    ğŸ“ Tip: use <tab> completion to trigger fzf completion \n            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to\n    configure where to search the files (current folder is always used)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-jar CONNECTOR_JAR")"
    printf "    â™¨ï¸ Connector jar to use\n    \n    â• It must be absolute full path\n    \n    ğŸ“ Tip: use <tab> completion to trigger fzf completion \n            use folder_zip_or_jar (default: ~/Downloads) in config.ini file to\n    configure where to search the files (current folder is always used)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-ksqldb")"
    printf "    ğŸš€ Enable ksqlDB\n    \n    By default, ksqldb-server and ksqldb-cli containers are not started for\n    every test\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-control-center")"
    printf "    ğŸ’  Enable Control Center\n    \n    By default, control-center container is not started for every test\n    \n    Control Center is reachable at http://127.0.0.1:9021\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-conduktor")"
    printf "    ğŸº Enable Conduktor Platform\n    \n    By default, Conduktor Platform container is not started for every test\n    \n    Conduktor is reachable at http://127.0.0.1:8080/console (admin/admin)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-multiple-brokers")"
    printf "    3ï¸âƒ£ Enable multiple brokers\n    \n    By default, there is only one broker node enabled\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-multiple-connect-workers")"
    printf "    ğŸ¥‰ Enable multiple connect node\n    \n    By default, there is only one connect node enabled\n    \n    It only works when plaintext environment is used\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-jmx-grafana")"
    printf "    Enable Grafana, Prometheus and Pyroscope\n    \n    ğŸ“Š Grafana is reachable at http://127.0.0.1:3000\n    \n    ğŸ›¡ï¸ Prometheus is reachable at http://127.0.0.1:9090\n    \n    ğŸ“› Pyroscope is reachable at http://127.0.0.1:4040\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-kcat")"
    printf "    ğŸˆâ€â¬› Enable kcat\n    \n    You can use it with:\n    \n    $ docker exec kcat kcat -b broker:9092 -L\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-sr-maven-plugin-app")"
    printf "    ğŸ”° Enable Schema Registry Maven plugin App\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-sql-datagen")"
    printf "    ğŸŒªï¸ Enable SQL Datagen injection\n    \n    This only works for Oracle, MySql, Postgres and Microsoft Sql Server source\n    connector examples with JDBC and Debezium\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-type CLUSTER-TYPE")"
    printf "    ğŸ”‹ The cluster type: basic, standard or dedicated. Default is basic\n    \n    ğŸ“ Tip: you can also use CLUSTER_TYPE environment variable\n"
    printf "    Allowed: basic, standard, dedicated\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-region CLUSTER-REGION")"
    printf "    ğŸ—º The Cloud region. \n    \n    ğŸ“ Tip: you can also use CLUSTER_REGION environment variable\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-environment CLUSTER-ENVIRONMENT")"
    printf "    ğŸŒ The environment id where want your new cluster (example: env-xxxxx)\n    \n    â„¹ï¸ Optional, if not set, new environment will be created\n    \n    ğŸ“ Tip: you can also use ENVIRONMENT environment variable\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-name CLUSTER-NAME")"
    printf "    ğŸ° The cluster name. \n    \n    â£ï¸ Only required if you want to use your own existing cluster\n    \n    ğŸ“ Tip: you can also use CLUSTER_NAME environment variable\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-creds CLUSTER-CREDS")"
    printf "    ğŸ”’ The Kafka api key and secret to use, it should be separated with\n    semi-colon (example: <API_KEY>:<API_KEY_SECRET>)\n    \n    â£ï¸ Only required if you want to use your own existing cluster\n    \n    ğŸ“ Tip: you can also use CLUSTER_CREDS environment variable\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-schema-registry-creds CLUSTER-SCHEMA-REGISTRY-CREDS")"
    printf "    ğŸ”’ The Schema Registry api key and secret to use, it should be separated with\n    semi-colon (example: <SR_API_KEY>:<SR_API_KEY_SECRET>)\n    \n    â„¹ï¸ Optional, if not set, new credentials will be created\n    \n    â£ï¸ Only required if you want to use your own existing cluster\n    \n    ğŸ“ Tip: you can also use SCHEMA_REGISTRY_CREDS environment variable\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--file, -f FILE (required)")"
    printf "    ğŸ”– Example file to use as basis\n    \n    â• It must be absolute full path\n    \n    ğŸ“ Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--description, -d DESCRIPTION (required)")"
    printf "    ğŸ’­ Description for the reproduction model\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--producer, -p PRODUCER-TYPE")"
    printf "    â™¨ï¸ Java producer type to use\n    \n    One of avro, avro-with-key, protobuf, protobuf-with-key, json-schema,\n    json-schema-with-key\n    \n    ğŸ“ Tip: Most of times, it's much simpler to use 'playground topic produce'.\n    Use java producer only if you have very specific requirements such as\n    specifying record timestamp, use key with schema or to do perf testing\n    \n    ğŸ“ Tip: 'with-key' will also produce key with selected converter, otherwise\n    LongConverter is used\n"
    printf "    Allowed: none, avro, avro-with-key, protobuf, protobuf-with-key, json-schema, json-schema-with-key\n"
    printf "    Default: none\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--nb-producers, -n NB-PRODUCERS")"
    printf "    2ï¸âƒ£ Number of java producers to generate\n"
    printf "    Default: \n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--producer-schema-key")"
    printf "    ğŸ”° Schema to use for the key\n    \n    âœ¨ Copy and paste the schema you want to use for the key, save and close the\n    file to continue\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--producer-schema-value")"
    printf "    ğŸ”° Schema to use for the value\n    \n    âœ¨ Copy and paste the schema you want to use for the key, save and close the\n    file to continue\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--custom-smt")"
    printf "    âš™ï¸ Add a custom SMT (which is a no-op)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--pipeline SINK_FILE")"
    printf "    ğŸ”– Sink example file to use for creating a pipeline\n    \n    â• It must be absolute full path. \n    \n    ğŸ“ Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    echo "  ARGUMENTS..."
    printf "    Arguments to use by example script\n    \n    Most of examples support to get required options either by using arguments\n    or environment variables.\n    \n    Example with Zendesk:\n    \n    playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME>\n    <ZENDESK_PASSWORD>\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground repro bootstrap -f hdfs2<tab> -d \"simple test\"\n"
    printf "  playground repro bootstrap -f /full/path/hdfs2-sink.sh -d \"testing with avro\n  producer\" --producer avro --producer-schema-value myschema<tab>\n"
    printf "  playground repro bootstrap -f hdfs2<tab> -d \"testing with 2 protobuf\n  producers\" --producer protobuf --nb-producers 2\n"
    printf "  playground repro bootstrap -f hdfs2<tab> -d \"testing custom smt\" --custom-smt\n"
    printf "  playground repro bootstrap -f debeziumpostgres<tab> -d \"create pipeline\"\n  --pipeline jdbcsink<tab>\n"
    echo

  fi
}

# :command.usage
playground_get_docker_compose_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-docker-compose - ğŸ‹ Get docker-compose\n"
    echo

  else
    printf "playground get-docker-compose - ğŸ‹ Get docker-compose\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-docker-compose\n"
  printf "  playground get-docker-compose --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_properties_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-properties\n"
    echo

    printf "  ğŸ“ Get properties file from a container\n  \n  ğŸ‘‰ Check documentation\n  https://kafka-docker-playground.io/#/how-to-use?id=%f0%9f%93%9d-see-properties-file\n"
    echo

  else
    printf "playground get-properties - ğŸ“ Get properties file from a container\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-properties [OPTIONS]\n"
  printf "  playground get-properties --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    ğŸ³ Container name\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground get-properties\n"
    printf "  playground get-properties --container broker\n"
    printf "  playground get-properties -c broker\n"
    echo

  fi
}

# :command.usage
playground_schema_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground schema - ğŸ”° Schema commands\n"
    echo

  else
    printf "playground schema - ğŸ”° Schema commands\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema COMMAND\n"
  printf "  playground schema [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "Schema commands:")"
  printf "  %s   ğŸ”° Get all schemas versions for specified subject (if --subject is not specified, all subjects will be used)\n" "$(green "get")              "
  printf "  %s   âºï¸ Register a schema in specified subject\n" "$(green "register")         "
  printf "  %s   ğŸ›¡ï¸ Get subject-level compatibility\n" "$(green "get-compatibility")"
  printf "  %s   ğŸ›¡ï¸ Set subject-level compatibility\n" "$(green "set-compatibility")"
  printf "  %s   ğŸ” Get subject-level mode\n" "$(green "get-mode")         "
  printf "  %s   ğŸ” Set subject-level mode\n" "$(green "set-mode")         "
  printf "  %s   ğŸ§Ÿ Delete schema\n" "$(green "delete")           "
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_schema_get_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground schema get - ğŸ”° Get all schemas versions for specified subject (if --subject is not specified, all subjects will be used)\n"
    echo

  else
    printf "playground schema get - ğŸ”° Get all schemas versions for specified subject (if --subject is not specified, all subjects will be used)\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema get [OPTIONS]\n"
  printf "  playground schema get --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--subject SUBJECT")"
    printf "    ğŸ“› Subject name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--deleted")"
    printf "    ğŸ§Ÿ Include soft deleted subjects\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground schema get\n"
    printf "  playground schema get --subject <SUBJECT>\n"
    printf "  playground schema get --deleted\n"
    echo

  fi
}

# :command.usage
playground_schema_register_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground schema register - âºï¸ Register a schema in specified subject\n"
    echo

  else
    printf "playground schema register - âºï¸ Register a schema in specified subject\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema register [OPTIONS]\n"
  printf "  playground schema register --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--subject SUBJECT (required)")"
    printf "    ğŸ“› Subject name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    ğŸ Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--input INPUT")"
    printf "    ğŸ”¥ You can either:\n    \n    * Set your own schema (avro, json-schema, protobuf) with stdin (see example\n    section).\n    \n    * Use completion to select predefined schemas (or use your own schema file)\n    ğŸ“ Tip: use <tab> completion to trigger fzf completion\n"
    printf "    Default: -\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground schema register --subject test-protobuf << 'EOF'\n  syntax = \"proto3\";\n  \n  package com.github.vdesabou;\n  \n  message Customer {\n      int64 count = 1;\n      string first_name = 2;\n      string last_name = 3;\n      string address = 4;\n  }\n  EOF\n  \n  playground schema register --subject test-avro << 'EOF'\n  {\n      \"type\": \"record\",\n      \"namespace\": \"com.github.vdesabou\",\n      \"name\": \"Customer\",\n      \"fields\": [\n          {\n              \"name\": \"count\",\n              \"type\": \"long\",\n              \"doc\": \"count\"\n          },\n          {\n              \"name\": \"first_name\",\n              \"type\": \"string\",\n              \"doc\": \"First Name of Customer\"\n          },\n          {\n              \"name\": \"last_name\",\n              \"type\": \"string\",\n              \"doc\": \"Last Name of Customer\"\n          },\n          {\n              \"name\": \"address\",\n              \"type\": \"string\",\n              \"doc\": \"Address of Customer\"\n          }\n      ]\n  }\n  EOF\n"
    echo

  fi
}

# :command.usage
playground_schema_get_compatibility_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground schema get-compatibility - ğŸ›¡ï¸ Get subject-level compatibility\n"
    echo

  else
    printf "playground schema get-compatibility - ğŸ›¡ï¸ Get subject-level compatibility\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema get-compatibility [OPTIONS]\n"
  printf "  playground schema get-compatibility --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--subject SUBJECT (required)")"
    printf "    ğŸ“› Subject name\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_schema_set_compatibility_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground schema set-compatibility - ğŸ›¡ï¸ Set subject-level compatibility\n"
    echo

  else
    printf "playground schema set-compatibility - ğŸ›¡ï¸ Set subject-level compatibility\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema set-compatibility [OPTIONS]\n"
  printf "  playground schema set-compatibility --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--subject SUBJECT (required)")"
    printf "    ğŸ“› Subject name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--compatibility COMPATIBILITY (required)")"
    printf "    Schema Registry compatibility rule\n"
    printf "    Allowed: BACKWARD, BACKWARD_TRANSITIVE, FORWARD, FORWARD_TRANSITIVE, FULL, FULL_TRANSITIVE, NONE\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_schema_get_mode_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground schema get-mode - ğŸ” Get subject-level mode\n"
    echo

  else
    printf "playground schema get-mode - ğŸ” Get subject-level mode\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema get-mode [OPTIONS]\n"
  printf "  playground schema get-mode --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--subject SUBJECT (required)")"
    printf "    ğŸ“› Subject name\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_schema_set_mode_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground schema set-mode\n"
    echo

    printf "  ğŸ” Set subject-level mode\n  \n  To enable mode changes on a Schema Registry cluster, you must also set\n  mode.mutability=true in the Schema Registry properties file before starting\n  Schema Registry\n"
    echo

  else
    printf "playground schema set-mode - ğŸ” Set subject-level mode\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema set-mode [OPTIONS]\n"
  printf "  playground schema set-mode --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--subject SUBJECT (required)")"
    printf "    ğŸ“› Subject name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--mode MODE (required)")"
    printf "    Schema Registry mode\n"
    printf "    Allowed: IMPORT, READONLY, READWRITE\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_schema_delete_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground schema delete - ğŸ§Ÿ Delete schema\n"
    echo

  else
    printf "playground schema delete - ğŸ§Ÿ Delete schema\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema delete [OPTIONS]\n"
  printf "  playground schema delete --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--subject SUBJECT")"
    printf "    ğŸ“› Subject name to delete:\n      \n      if --version is provided, only that version will be deleted. Otherwise the\n    complete subject will be deleted\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--version VERSION")"
    printf "    ğŸ”¢ Schema version of the provided subject to delete\n    \n    Can only be used when --subject is provided\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--permanent")"
    printf "    ğŸ’€ Hard delete (default is soft delete)\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_debug_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug - ğŸ Debug commands\n"
    echo

  else
    printf "playground debug - ğŸ Debug commands\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug COMMAND\n"
  printf "  playground debug [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   ğŸª„ Install a slightly modified version of \"Shell Script Command Completion\" Visual Studio Code extension (https://marketplace.visualstudio.com/items?itemName=tetradresearch.vscode-h2o)\n" "$(green "install-vscode-extension")"
  printf "  %s   âœ¨ Enable java remote debugging for container\n" "$(green "enable-remote-debugging") "
  printf "  %s   ğŸ” Testing TLS/SSL encryption using https://testssl.sh/\n" "$(green "testssl")                 "
  printf "  %s   â›‘ï¸ Generate a diagnostic bundle with Diagnostics Bundle Tool\n" "$(green "generate-diagnostics")    "
  printf "  %s   ğŸ¯ Take a java thread dump\n" "$(green "thread-dump")             "
  printf "  %s   ğŸ‘» Take a heap dump\n" "$(green "heap-dump")               "
  printf "  %s   ğŸ•µï¸â€â™‚ï¸ Take a tcp dump (sniffing network)\n" "$(green "tcp-dump")                "
  printf "  %s   ğŸš« Blocking traffic using iptables\n" "$(green "block-traffic")           "
  printf "  %s   ğŸ›©ï¸ Record flight recorder\n" "$(green "flight-recorder")         "
  printf "  %s   ğŸ§¬ Set log level for any package\n" "$(green "log-level")               "
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_debug_install_vscode_extension_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug install-vscode-extension\n"
    echo

    printf "  ğŸª„ Install a slightly modified version of \"Shell Script Command Completion\"\n  Visual Studio Code extension\n  (https://marketplace.visualstudio.com/items?itemName=tetradresearch.vscode-h2o)\n  \n  After installation, install \"playground\" command:\n  \n  * Go on a .sh file\n  \n  * Type Ctrl+Shift+P (or âŒ˜+â‡§+P on macOS) and choose \"Shell Completion: Load\n  Command Spec (experimental)\"\" and then type \"playground\"\n  \n  ğŸ‘‰ Check documentation\n  https://kafka-docker-playground.io/#/cli?id=%f0%9f%aa%84-setup-shell-script-command-completion-visual-studio-code-extension\n"
    echo

  else
    printf "playground debug install-vscode-extension - ğŸª„ Install a slightly modified version of \"Shell Script Command Completion\" Visual Studio Code extension (https://marketplace.visualstudio.com/items?itemName=tetradresearch.vscode-h2o)\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug install-vscode-extension\n"
  printf "  playground debug install-vscode-extension --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground install-vscode-extension\n"
    echo

  fi
}

# :command.usage
playground_debug_enable_remote_debugging_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug enable-remote-debugging\n"
    echo

    printf "  âœ¨ Enable java remote debugging for container\n  \n  ğŸ‘‰ Check documentation\n  https://kafka-docker-playground.io/#/reusables?id=%e2%9c%a8-remote-debugging\n"
    echo

  else
    printf "playground debug enable-remote-debugging - âœ¨ Enable java remote debugging for container\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug enable-remote-debugging [OPTIONS]\n"
  printf "  playground debug enable-remote-debugging --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    ğŸ³ Container name\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug enable-remote-debugging\n"
    printf "  playground debug enable-remote-debugging --container broker\n"
    printf "  playground debug enable-remote-debugging -c broker\n"
    echo

  fi
}

# :command.usage
playground_debug_testssl_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug testssl\n"
    echo

    printf "  ğŸ” Testing TLS/SSL encryption using https://testssl.sh/\n  \n  testssl <URI>, where <URI> is:\n  \n  host|host:port|URL|URL:port   port 443 is default, URL can only contain HTTPS\n  protocol\n"
    echo

  else
    printf "playground debug testssl - ğŸ” Testing TLS/SSL encryption using https://testssl.sh/\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug testssl [ARGUMENTS]\n"
  printf "  playground debug testssl --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "ARGUMENTS")"
    printf "    arguments to pass to testssl, see https://testssl.sh for all options\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug testssl https://google.com\n"
    printf "  playground debug testssl pkc-xxxx.us-west-2.aws.confluent.cloud:9092\n"
    echo

  fi
}

# :command.usage
playground_debug_generate_diagnostics_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug generate-diagnostics\n"
    echo

    printf "  â›‘ï¸ Generate a diagnostic bundle with Diagnostics Bundle Tool\n  \n  âš ï¸ only connect and broker containers are supported for now\n  \n  see\n  https://docs.confluent.io/platform/current/tools/diagnostics-tool.html#collect-diagnostics\n"
    echo

  else
    printf "playground debug generate-diagnostics - â›‘ï¸ Generate a diagnostic bundle with Diagnostics Bundle Tool\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug generate-diagnostics [OPTIONS]\n"
  printf "  playground debug generate-diagnostics --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    ğŸ³ Container name\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug generate-diagnostics\n"
    printf "  playground debug generate-diagnostics --container broker\n"
    echo

  fi
}

# :command.usage
playground_debug_thread_dump_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug thread-dump\n"
    echo

    printf "  ğŸ¯ Take a java thread dump\n  \n  ğŸ”– It will save output to a file and open with text editor set with config.ini\n  (default is code)\n"
    echo

  else
    printf "playground debug thread-dump - ğŸ¯ Take a java thread dump\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug thread-dump [OPTIONS]\n"
  printf "  playground debug thread-dump --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    ğŸ³ Container name\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug thread-dump\n"
    printf "  playground debug thread-dump --container broker\n"
    echo

  fi
}

# :command.usage
playground_debug_heap_dump_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug heap-dump\n"
    echo

    printf "  ğŸ‘» Take a heap dump\n  \n  ğŸ”– It will save output to a .hprof file. VisualVM (https://visualvm.github.io/)\n  or MAT (https://www.eclipse.org/mat/) can be used to read the file.\n"
    echo

  else
    printf "playground debug heap-dump - ğŸ‘» Take a heap dump\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug heap-dump [OPTIONS]\n"
  printf "  playground debug heap-dump --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    ğŸ³ Container name\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug heap-dump\n"
    printf "  playground debug heap-dump --container broker\n"
    echo

  fi
}

# :command.usage
playground_debug_tcp_dump_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug tcp-dump - ğŸ•µï¸â€â™‚ï¸ Take a tcp dump (sniffing network)\n"
    echo

  else
    printf "playground debug tcp-dump - ğŸ•µï¸â€â™‚ï¸ Take a tcp dump (sniffing network)\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug tcp-dump [OPTIONS]\n"
  printf "  playground debug tcp-dump --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    ğŸ³ Container name\n"
    printf "    Default: connect\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--port PORT")"
    printf "    Port on which tcp dump should be done, if not set sniffing is done on every\n    port\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--duration DURATION")"
    printf "    Duration of the dump (default is 30 seconds).\n"
    printf "    Default: 30\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug tcp-dump --container control-center --port 9021 --duration 60\n"
    echo

  fi
}

# :command.usage
playground_debug_block_traffic_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug block-traffic - ğŸš« Blocking traffic using iptables\n"
    echo

  else
    printf "playground debug block-traffic - ğŸš« Blocking traffic using iptables\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug block-traffic [OPTIONS]\n"
  printf "  playground debug block-traffic --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    ğŸ³ Container name\n"
    printf "    Default: connect\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--destination DESTINATION (required)")"
    printf "    Destination: it could be an ip address, a container name or a hostname\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--port PORT")"
    printf "    Port on which tcp traffic should be blocked\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--action ACTION (required)")"
    printf "    ğŸŸ¢ start or stop\n"
    printf "    Allowed: start, stop\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug block-traffic --destination google.com --action start\n"
    printf "  playground debug block-traffic --container broker --destination zookeeper\n  --action start\n"
    echo

  fi
}

# :command.usage
playground_debug_flight_recorder_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug flight-recorder\n"
    echo

    printf "  ğŸ›©ï¸ Record flight recorder\n  \n  Read more about it at https://www.baeldung.com/java-flight-recorder-monitoring\n  \n  Open the jfr file with JDK Mission Control JMC(https://jdk.java.net/jmc/)\n"
    echo

  else
    printf "playground debug flight-recorder - ğŸ›©ï¸ Record flight recorder\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug flight-recorder [OPTIONS]\n"
  printf "  playground debug flight-recorder --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    ğŸ³ Container name\n"
    printf "    Default: connect\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--action ACTION (required)")"
    printf "    ğŸŸ¢ start or stop\n"
    printf "    Allowed: start, stop\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug flight-recorder --action start\n"
    printf "  playground debug flight-recorder --action stop\n"
    echo

  fi
}

# :command.usage
playground_debug_log_level_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug log-level - ğŸ§¬ Set log level for any package\n"
    echo

  else
    printf "playground debug log-level - ğŸ§¬ Set log level for any package\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug log-level COMMAND\n"
  printf "  playground debug log-level [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   Get log levels\n" "$(green "get")"
  printf "  %s   Set log level for specific logger\n" "$(green "set")"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug log-level get\n"
    printf "  playground debug log-level get -p io.confluent.connect.oracle.cdc\n"
    printf "  playground debug log-level get --package io.confluent.connect.oracle.cdc\n"
    printf "  playground debug log-level set -p\n  io.confluent.connect.oracle.cdc.logging.LogUtils -l TRACE\n"
    echo

  fi
}

# :command.usage
playground_debug_log_level_get_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug log-level get - Get log levels\n"
    echo

  else
    printf "playground debug log-level get - Get log levels\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug log-level get [OPTIONS]\n"
  printf "  playground debug log-level get --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--package, -p PACKAGE")"
    printf "    Package name\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_debug_log_level_set_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug log-level set - Set log level for specific logger\n"
    echo

  else
    printf "playground debug log-level set - Set log level for specific logger\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug log-level set [OPTIONS]\n"
  printf "  playground debug log-level set --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--package, -p PACKAGE (required)")"
    printf "    ğŸ“¦ Package name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--level, -l LEVEL (required)")"
    printf "    â•Log level\n"
    printf "    Allowed: INFO, WARN, DEBUG, TRACE\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_jmx_metrics_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-jmx-metrics\n"
    echo

    printf "  ğŸ”¢ Get JMX metrics from a component\n  \n  ğŸ‘‰ Check documentation\n  https://kafka-docker-playground.io/#/how-to-use?id=%f0%9f%94%a2-jmx-metrics\n"
    echo

  else
    printf "playground get-jmx-metrics - ğŸ”¢ Get JMX metrics from a component\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-jmx-metrics [OPTIONS]\n"
  printf "  playground get-jmx-metrics --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--component, -c COMPONENT")"
    printf "    Component name\n"
    printf "    Allowed: zookeeper, broker, connect, schema-registry\n"
    printf "    Default: connect\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--open, -o")"
    printf "    ğŸ”– Save output to a file and open with text editor set with config.ini\n    (default is code)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--domain, -d DOMAIN")"
    printf "    Domain name\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground get-jmx-metrics --component connect\n"
    printf "  playground get-jmx-metrics --component connect --domain \"kafka.connect\n  kafka.consumer kafka.producer\"\n"
    printf "  playground get-jmx-metrics -c broker\n"
    echo

  fi
}

# :command.usage
playground_container_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container - ğŸ³ Container commands\n"
    echo

  else
    printf "playground container - ğŸ³ Container commands\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container COMMAND\n"
  printf "  playground container [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "Container commands:")"
  printf "  %s   ğŸ’« Recreate container(s)\n" "$(green "recreate")        "
  printf "  %s   ğŸ–¥ï¸  Get ip address of running containers\n" "$(green "get-ip-addresses")"
  printf "  %s   ğŸ’€ Kill all containers\n" "$(green "kill-all")        "
  printf "  %s   ğŸ•µï¸  Tail and follow container logs\n" "$(green "logs")            "
  printf "  %s   ğŸ›¬ SSH into container\n" "$(green "ssh")             "
  printf "  %s   ğŸª„  Execute command in a container\n" "$(green "exec")            "
  printf "  %s   ğŸ” Restart a container\n" "$(green "restart")         "
  printf "  %s   â¸ï¸  Pause a container\n" "$(green "pause")           "
  printf "  %s   â¯ï¸  Resume a container\n" "$(green "resume")          "
  printf "  %s   ğŸ”« Kill a container\n" "$(green "kill")            "
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_recreate_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container recreate\n"
    echo

    printf "  ğŸ’« Recreate container(s)\n  \n  ğŸ‘‰ Check documentation\n  https://kafka-docker-playground.io/#/how-to-use?id=%e2%99%bb%ef%b8%8f-re-create-containers\n"
    echo

  else
    printf "playground container recreate - ğŸ’« Recreate container(s)\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container recreate [OPTIONS]\n"
  printf "  playground container recreate --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--ignore-current-versions")"
    printf "    Ignore current confluent platform version\n    \n    By default, the current version is used\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_get_ip_addresses_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container get-ip-addresses - ğŸ–¥ï¸  Get ip address of running containers\n"
    echo

  else
    printf "playground container get-ip-addresses - ğŸ–¥ï¸  Get ip address of running containers\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container get-ip-addresses\n"
  printf "  playground container get-ip-addresses --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground get-ip-address-container\n"
    echo

  fi
}

# :command.usage
playground_container_kill_all_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container kill-all - ğŸ’€ Kill all containers\n"
    echo

  else
    printf "playground container kill-all - ğŸ’€ Kill all containers\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container kill-all\n"
  printf "  playground container kill-all --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_logs_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container logs - ğŸ•µï¸  Tail and follow container logs\n"
    echo

  else
    printf "playground container logs - ğŸ•µï¸  Tail and follow container logs\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container logs [OPTIONS]\n"
  printf "  playground container logs --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    ğŸ³ Container name\n"
    printf "    Default: connect\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--open, -o")"
    printf "    ğŸ”– Save output to a file and open with text editor set with config.ini\n    (default is code)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--wait-for-log, -w LOG")"
    printf "    ğŸ˜´ Wait until log appears\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--max-wait, -m MAX_WAIT")"
    printf "    â³ Max time in seconds to wait when using --wait-for-log (default 600s)\n"
    printf "    Default: 600\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground container logs --container connect\n"
    printf "  playground container logs -c connect --open\n"
    printf "  playground container logs -c connect --wait-for-log \"StackOverflowError\"\n"
    echo

  fi
}

# :command.usage
playground_container_ssh_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container ssh - ğŸ›¬ SSH into container\n"
    echo

  else
    printf "playground container ssh - ğŸ›¬ SSH into container\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container ssh [OPTIONS]\n"
  printf "  playground container ssh --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    ğŸ³ Container name\n"
    printf "    Default: connect\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--shell, -s SHELL")"
    printf "    ğŸ’¾ Shell to use (default is bash)\n"
    printf "    Allowed: bash, sh, ksh, zsh\n"
    printf "    Default: bash\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground ssh -c connect\n"
    printf "  playground ssh -c connect -s sh\n"
    printf "  playground ssh --container connect --shell sh\n"
    echo

  fi
}

# :command.usage
playground_container_exec_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container exec - ğŸª„  Execute command in a container\n"
    echo

  else
    printf "playground container exec - ğŸª„  Execute command in a container\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container exec [OPTIONS]\n"
  printf "  playground container exec --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    ğŸ³ Container name\n"
    printf "    Default: connect\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--command COMMAND (required)")"
    printf "    ğŸ“² Command to execute\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--root")"
    printf "    ğŸ‘‘ Run command as root\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--shell SHELL")"
    printf "    ğŸ’¾ Shell to use (default is bash)\n"
    printf "    Allowed: bash, sh, ksh, zsh\n"
    printf "    Default: bash\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground exec -c connect -d \"date\"\n"
    printf "  playground exec -c connect -d \"whoami\" --root\n"
    printf "  playground exec --container connect --command \"whoami\" --shell sh\n"
    echo

  fi
}

# :command.usage
playground_container_restart_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container restart - ğŸ” Restart a container\n"
    echo

  else
    printf "playground container restart - ğŸ” Restart a container\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container restart [OPTIONS]\n"
  printf "  playground container restart --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    ğŸ³ Container name\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_pause_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container pause - â¸ï¸  Pause a container\n"
    echo

  else
    printf "playground container pause - â¸ï¸  Pause a container\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container pause [OPTIONS]\n"
  printf "  playground container pause --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    ğŸ³ Container name\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_resume_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container resume - â¯ï¸  Resume a container\n"
    echo

  else
    printf "playground container resume - â¯ï¸  Resume a container\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container resume [OPTIONS]\n"
  printf "  playground container resume --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    ğŸ³ Container name\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_kill_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container kill - ğŸ”« Kill a container\n"
    echo

  else
    printf "playground container kill - ğŸ”« Kill a container\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container kill [OPTIONS]\n"
  printf "  playground container kill --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER")"
    printf "    ğŸ³ Container name\n"
    printf "    Default: connect\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic - ğŸ—³ Topic commands\n"
    echo

  else
    printf "playground topic - ğŸ—³ Topic commands\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic COMMAND\n"
  printf "  playground topic [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "Topic commands:")"
  printf "  %s   ğŸ’¯ Get number of records in a topic\n" "$(green "get-number-records")      "
  printf "  %s   ğŸ“­ Display content of __consumer_offsets topic\n" "$(green "display-consumer-offsets")"
  printf "  %s   ğŸ”˜ List topics\n" "$(green "list")                    "
  printf "  %s   ğŸ”¬ Describe topic\n" "$(green "describe")                "
  printf "  %s   ğŸ›¡ï¸ Change topic's schema compatibility\n" "$(green "set-schema-compatibility")"
  printf "  %s   ğŸ“¥ Consume topic from beginning\n" "$(green "consume")                 "
  printf "  %s   ğŸ“¤ Produce to a topic\n" "$(green "produce")                 "
  printf "  %s   ğŸ†• Create topic\n" "$(green "create")                  "
  printf "  %s   âŒ Delete topic\n" "$(green "delete")                  "
  printf "  %s   ğŸª› Alter topic config\n" "$(green "alter")                   "
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_get_number_records_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic get-number-records - ğŸ’¯ Get number of records in a topic\n"
    echo

  else
    printf "playground topic get-number-records - ğŸ’¯ Get number of records in a topic\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic get-number-records [OPTIONS]\n"
  printf "  playground topic get-number-records --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC")"
    printf "    ğŸ—³ Topic name\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground get-number-records --topic a-topic\n"
    printf "  playground get-number-records -t a-topic\n"
    echo

  fi
}

# :command.usage
playground_topic_display_consumer_offsets_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic display-consumer-offsets - ğŸ“­ Display content of __consumer_offsets topic\n"
    echo

  else
    printf "playground topic display-consumer-offsets - ğŸ“­ Display content of __consumer_offsets topic\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic display-consumer-offsets\n"
  printf "  playground topic display-consumer-offsets --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_list_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic list - ğŸ”˜ List topics\n"
    echo

  else
    printf "playground topic list - ğŸ”˜ List topics\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic list\n"
  printf "  playground topic list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_describe_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic describe - ğŸ”¬ Describe topic\n"
    echo

  else
    printf "playground topic describe - ğŸ”¬ Describe topic\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic describe [OPTIONS]\n"
  printf "  playground topic describe --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC")"
    printf "    ğŸ—³ Topic name\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_set_schema_compatibility_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic set-schema-compatibility - ğŸ›¡ï¸ Change topic's schema compatibility\n"
    echo

  else
    printf "playground topic set-schema-compatibility - ğŸ›¡ï¸ Change topic's schema compatibility\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic set-schema-compatibility [OPTIONS]\n"
  printf "  playground topic set-schema-compatibility --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC")"
    printf "    ğŸ—³ Topic name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--compatibility COMPATIBILITY (required)")"
    printf "    Schema Registry compatibility rule\n"
    printf "    Allowed: BACKWARD, BACKWARD_TRANSITIVE, FORWARD, FORWARD_TRANSITIVE, FULL, FULL_TRANSITIVE, NONE\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_consume_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic consume - ğŸ“¥ Consume topic from beginning\n"
    echo

  else
    printf "playground topic consume - ğŸ“¥ Consume topic from beginning\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic consume [OPTIONS]\n"
  printf "  playground topic consume --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    ğŸ Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC")"
    printf "    ğŸ—³ Topic name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--max-messages MAX-MESSAGES")"
    printf "    Max number of messages to display (default is 10)\n"
    printf "    Default: 10\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--min-expected-messages MIN-EXPECTED-MESSAGES")"
    printf "    Minimum expected number of messages to be present in topic, returns an error\n    if this is not the case\n    \n    Note: --topic should be specified in this case.\n"
    printf "    Default: \n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--grep GREP")"
    printf "    Verify that topic content contains record which contains specified string\n"
    printf "    Default: \n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--timeout TIMEOUT")"
    printf "    Max number of seconds to wait when --min-expected-messages is used.\n    \n    Default is 60 seconds\n"
    printf "    Default: 60\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--tail")"
    printf "    Tail on logs.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--plot-latencies-timestamp-field TIMESTAMP")"
    printf "    ğŸ—³ Timestamp field name that represents when record was created in source\n    system\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--subject SUBJECT")"
    printf "    ğŸ“› Subject for value in schema-registry to use (useful when data was produced\n    with --value-subject-name-strategy other than TopicNameStrategy)\n    \n    Note: --topic should be specified in this case.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--max-characters MAX-CHARACTERS")"
    printf "    Max characters per message to display (default is 2500)\n"
    printf "    Default: 2500\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_produce_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic produce - ğŸ“¤ Produce to a topic\n"
    echo

  else
    printf "playground topic produce - ğŸ“¤ Produce to a topic\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic produce [OPTIONS]\n"
  printf "  playground topic produce --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--input INPUT")"
    printf "    ğŸ”¥ You can either:\n    \n    * Set your own schema (avro, json-schema, protobuf) with stdin (see example\n    section).\n    \n    * You can also generate json data using json or sql format using syntax from\n    https://github.com/MaterializeInc/datagen\n    \n    * Use completion to select predefined schemas (or use your own schema file)\n    ğŸ“ Tip: use <tab> completion to trigger fzf completion\n    \n    * Directly set payload (\"%g\" can be used to generate a counter)\n"
    printf "    Default: -\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    ğŸ Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC (required)")"
    printf "    ğŸ—³ Topic name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--nb-messages NB-MESSAGES")"
    printf "    ğŸ’¯ Number of messages to produce (default is 1)\n"
    printf "    Default: 1\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--nb-partitions NB-PARTITIONS")"
    printf "    ğŸ”¢ Number of partitions for the topic. (default is 1)\n    \n    âŒ Important: If topic is existing, it will be re-created before producing to\n    topic.\n"
    printf "    Default: \n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--compatibility COMPATIBILITY")"
    printf "    Schema Registry compatibility rule\n"
    printf "    Allowed: BACKWARD, BACKWARD_TRANSITIVE, FORWARD, FORWARD_TRANSITIVE, FULL, FULL_TRANSITIVE, NONE\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--value-subject-name-strategy VALUE-SUBJECT-NAME-STRATEGY")"
    printf "    Value Subject Name Strategy\n"
    printf "    Allowed: TopicNameStrategy, RecordNameStrategy, TopicRecordNameStrategy\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--key KEY")"
    printf "    ğŸ—ï¸ Key to use. If not set, no key is used.\n    \n    If the key contain a number, it will be used as starting point and\n    incremented for each record.\n    \n    Example: key1 will start with key1, then key2, etc..\n    Example: mykey-10-suffix will start with mykey-10-suffix then\n    mykey-11-suffix, etc..\n    \n    \"%g\" can also be used to generate a counter\n    \n    Example: key%g will start with key1, then key2, etc..\n    \n    Otherwise, the key will be same for all records.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--headers HEADERS")"
    printf "    ğŸš Headers to use for all records. If not set, no header is used.\n    \n    Example: --headers \"header1:value1,header2:value2\"\n    \n    Note: CP 7.2+ is required.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--forced-value FORCED-VALUE")"
    printf "    â˜¢ï¸ Value to use for all records. \n    \n    ğŸ“ Tip: use --generate-only first with avro, json-schema or protobuf to get\n    skeleton of messages and then use --forced-value to send the message you\n    need.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--generate-only")"
    printf "    ğŸšª Only generate messages without sending to kafka topic.\n    \n    Used with --forced-value, this is a powerful way to send specific messages.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--tombstone")"
    printf "    âš°ï¸ Generate tombstone (record with null value). \n    \n    --key must be set when this flag is used.\n    \n    Note: CP 7.2+ is required.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--validate")"
    printf "    â˜‘ï¸ Validate schema according to connect sink converter used\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--validate-config VALIDATE-CONFIG (repeatable)")"
    printf "    ğŸ”© Converter configuration parameters to use \n    \n    See docs:\n    https://docs.confluent.io/platform/current/schema-registry/connect.html#using-kconnect-long-with-sr\n    \n    ğŸ“ Tip: you can pass multiple parameters by specifying --validate-config\n    multiple times\n"
    printf "    Allowed: scrub.invalid.names=true, enhanced.avro.schema.support=true, connect.meta.data=false, object.additional.properties=false, use.optional.for.nonrequired=true, ignore.default.for.nullables=true, generalized.sum.type.support=true, enhanced.protobuf.schema.support=true, generate.index.for.unions=false, int.for.enums=true, optional.for.nullables=true, generate.struct.for.nulls=true, wrapper.for.nullables=true, wrapper.for.raw.primitives=false\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--producer-property PRODUCER-PROPERTY (repeatable)")"
    printf "    ğŸ”© Producer configuration parameters to use \n    \n    See docs:\n    https://docs.confluent.io/platform/current/installation/configuration/producer-configs.html#cp-config-producer\n    \n    ğŸ“ Tip: you can pass multiple parameters by specifying --producer-property\n    multiple times\n    \n    Example: --producer-property \"max.request.size=990485760\"\n    --producer-property \"client.id=myid\"\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--record-size RECORD-SIZE")"
    printf "    ğŸ‹ï¸ Record size in bytes, eg. 1048576 for 1MB\n    \n    ğŸ“¢ If size is > 1Mb, --producer-property max.request.size and topic\n    max.message.bytes will be automatically set to support the record size.\n"
    printf "    Default: 0\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground topic produce --tombstone --topic a-topic --key mykey\n  \n  playground topic produce -t topic-json --nb-messages 10 << 'EOF'\n  {\n      \"_meta\": {\n          \"topic\": \"\",\n          \"key\": \"\",\n          \"relationships\": []\n      },\n      \"nested\": {\n          \"phone\": \"faker.phone.imei()\",\n          \"website\": \"faker.internet.domainName()\"\n      },\n      \"id\": \"iteration.index\",\n      \"name\": \"faker.internet.userName()\",\n      \"email\": \"faker.internet.exampleEmail()\",\n      \"phone\": \"faker.phone.imei()\",\n      \"website\": \"faker.internet.domainName()\",\n      \"city\": \"faker.address.city()\",\n      \"company\": \"faker.company.name()\"\n  }\n  EOF\n  \n  playground topic produce -t topic-avro --nb-messages 10 << 'EOF'\n  {\n      \"type\": \"record\",\n      \"namespace\": \"com.github.vdesabou\",\n      \"name\": \"Customer\",\n      \"fields\": [\n          {\n              \"name\": \"count\",\n              \"type\": \"long\",\n              \"doc\": \"count\"\n          },\n          {\n              \"name\": \"first_name\",\n              \"type\": \"string\",\n              \"doc\": \"First Name of Customer\"\n          },\n          {\n              \"name\": \"last_name\",\n              \"type\": \"string\",\n              \"doc\": \"Last Name of Customer\"\n          },\n          {\n              \"name\": \"address\",\n              \"type\": \"string\",\n              \"doc\": \"Address of Customer\"\n          }\n      ]\n  }\n  EOF\n  \n  playground topic produce -t topic-json-schema --nb-messages 3 << 'EOF'\n  {\n    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    \"additionalProperties\": false,\n    \"$id\": \"http://lh.test/Customer.schema.json\",\n    \"title\": \"Customer\",\n    \"description\": \"Customer description\",\n    \"type\": \"object\",\n    \"properties\": {\n      \"name\": {\n        \"description\": \"Customer name\",\n        \"type\": \"string\",\n        \"maxLength\": 25\n      },\n      \"surname\": {\n        \"description\": \"Customer surname\",\n        \"type\": \"string\",\n        \"minLength\": 2\n      },\n      \"email\": {\n        \"description\": \"Email\",\n        \"type\": \"string\",\n        \"pattern\": \"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$\"\n      }\n    },\n    \"required\": [\n      \"name\",\n      \"surname\"\n    ]\n  }\n  EOF\n  \n  \n  playground topic produce -t topic-proto --nb-messages 1 << 'EOF'\n  syntax = \"proto3\";\n  \n  package com.github.vdesabou;\n  \n  message Customer {\n      int64 count = 1;\n      string first_name = 2;\n      string last_name = 3;\n      string address = 4;\n  }\n  EOF\n  \n  playground topic produce -t topic-jsql --nb-messages 10 << 'EOF'\n  CREATE TABLE \"notused\".\"notused\" (\n    \"id\" int PRIMARY KEY,\n    \"name\" varchar COMMENT 'faker.internet.userName()',\n    \"merchant_id\" int NOT NULL COMMENT 'faker.datatype.number()',\n    \"price\" int COMMENT 'faker.datatype.number()',\n    \"status\" int COMMENT 'faker.datatype.boolean()',\n    \"created_at\" datetime DEFAULT (now())\n  );\n  EOF\n  \n  playground topic produce -t topic-json --nb-messages 1 --producer-property\n  \"max.request.size=990485760\" < bigjson.json\n"
    echo

  fi
}

# :command.usage
playground_topic_create_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic create - ğŸ†• Create topic\n"
    echo

  else
    printf "playground topic create - ğŸ†• Create topic\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic create [OPTIONS] [ARGUMENTS...]\n"
  printf "  playground topic create --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC (required)")"
    printf "    ğŸ—³ Topic name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--nb-partitions NB-PARTITIONS")"
    printf "    Number of partitions for the topic. (default is 1)\n"
    printf "    Default: \n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    echo "  ARGUMENTS..."
    printf "    Any arguments to be used with kafka-topics --create\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground topic create --topic atopic\n  playground topic create --topic atopic --nb-partitions 8 --config\n  retention.ms=30000\n"
    echo

  fi
}

# :command.usage
playground_topic_delete_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic delete - âŒ Delete topic\n"
    echo

  else
    printf "playground topic delete - âŒ Delete topic\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic delete [OPTIONS]\n"
  printf "  playground topic delete --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC (required)")"
    printf "    ğŸ—³ Topic name\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_alter_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic alter - ğŸª› Alter topic config\n"
    echo

  else
    printf "playground topic alter - ğŸª› Alter topic config\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic alter [OPTIONS] [ARGUMENTS...]\n"
  printf "  playground topic alter --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC (required)")"
    printf "    ğŸ—³ Topic name\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    echo "  ARGUMENTS..."
    printf "    Any arguments to be used with kafka-configs --alter. If the topic does not\n    exist, it is created first.\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground topic alter --topic atopic --add-config max.message.bytes=5242940\n"
    echo

  fi
}

# :command.usage
playground_ccloud_connector_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground ccloud-connector - ğŸ”—â˜ï¸ Fully Managed Connector commands\n"
    echo

  else
    printf "playground ccloud-connector - ğŸ”—â˜ï¸ Fully Managed Connector commands\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ccloud-connector COMMAND\n"
  printf "  playground ccloud-connector [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   ğŸ§© Show status of all connectors\n" "$(green "status")                "
  printf "  %s   ğŸ¨ Show all plugins installed\n" "$(green "plugins")               "
  printf "  %s   â¸ï¸  Pause connector\n" "$(green "pause")                 "
  printf "  %s   â¯ï¸  Resume connector\n" "$(green "resume")                "
  printf "  %s   ğŸ—‘ï¸  Delete connector\n" "$(green "delete")                "
  printf "  %s   ğŸ¢ Show lag of sink connector\n" "$(green "show-lag")              "
  printf "  %s   ğŸ§° Show current connector config\n" "$(green "show-config")           "
  printf "  %s   ğŸ”© Show all possible configuration parameters of connector\n" "$(green "show-config-parameters")"
  printf "  %s   ğŸ§‘â€ğŸ¨  Create or update connector\n" "$(green "create-or-update")      "
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_environment_variables
    printf "%s\n" "$(bold "Environment Variables:")"

    # :environment_variable.usage
    printf "  %s\n" "$(cyan "CLOUD_API_KEY (required)")"
    printf "    Cloud API key, see\n    https://docs.confluent.io/cloud/current/access-management/authenticate/api-keys/api-keys.html#cloud-cloud-api-keys\n"
    echo

    # :environment_variable.usage
    printf "  %s\n" "$(cyan "CLOUD_API_SECRET (required)")"
    printf "    Cloud API secret, see\n    https://docs.confluent.io/cloud/current/access-management/authenticate/api-keys/api-keys.html#cloud-cloud-api-keys\n"
    echo

  fi
}

# :command.usage
playground_ccloud_connector_status_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground ccloud-connector status - ğŸ§© Show status of all connectors\n"
    echo

  else
    printf "playground ccloud-connector status - ğŸ§© Show status of all connectors\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ccloud-connector status [OPTIONS]\n"
  printf "  playground ccloud-connector status --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    ğŸ”— Connector name\n    \n    ğŸ“ Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_ccloud_connector_plugins_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground ccloud-connector plugins - ğŸ¨ Show all plugins installed\n"
    echo

  else
    printf "playground ccloud-connector plugins - ğŸ¨ Show all plugins installed\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ccloud-connector plugins\n"
  printf "  playground ccloud-connector plugins --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_ccloud_connector_pause_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground ccloud-connector pause - â¸ï¸  Pause connector\n"
    echo

  else
    printf "playground ccloud-connector pause - â¸ï¸  Pause connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ccloud-connector pause [OPTIONS]\n"
  printf "  playground ccloud-connector pause --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    ğŸ”— Connector name\n    \n    ğŸ“ Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_ccloud_connector_resume_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground ccloud-connector resume - â¯ï¸  Resume connector\n"
    echo

  else
    printf "playground ccloud-connector resume - â¯ï¸  Resume connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ccloud-connector resume [OPTIONS]\n"
  printf "  playground ccloud-connector resume --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    ğŸ”— Connector name\n    \n    ğŸ“ Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_ccloud_connector_delete_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground ccloud-connector delete - ğŸ—‘ï¸  Delete connector\n"
    echo

  else
    printf "playground ccloud-connector delete - ğŸ—‘ï¸  Delete connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ccloud-connector delete [OPTIONS]\n"
  printf "  playground ccloud-connector delete --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    ğŸ”— Connector name\n    \n    ğŸ“ Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_ccloud_connector_show_lag_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground ccloud-connector show-lag - ğŸ¢ Show lag of sink connector\n"
    echo

  else
    printf "playground ccloud-connector show-lag - ğŸ¢ Show lag of sink connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ccloud-connector show-lag [OPTIONS]\n"
  printf "  playground ccloud-connector show-lag --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    ğŸ”— Connector name\n    \n    ğŸ“ Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--wait-for-zero-lag")"
    printf "    ğŸ˜´ Wait until lag becomes 0\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_ccloud_connector_show_config_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground ccloud-connector show-config - ğŸ§° Show current connector config\n"
    echo

  else
    printf "playground ccloud-connector show-config - ğŸ§° Show current connector config\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ccloud-connector show-config [OPTIONS]\n"
  printf "  playground ccloud-connector show-config --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    ğŸ”— Connector name\n    \n    ğŸ“ Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_ccloud_connector_show_config_parameters_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground ccloud-connector show-config-parameters - ğŸ”© Show all possible configuration parameters of connector\n"
    echo

  else
    printf "playground ccloud-connector show-config-parameters - ğŸ”© Show all possible configuration parameters of connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ccloud-connector show-config-parameters [OPTIONS]\n"
  printf "  playground ccloud-connector show-config-parameters --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    ğŸ”— Connector name\n    \n    ğŸ“ Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--open, -o")"
    printf "    ğŸ”– Save output to a file and open with text editor set with config.ini\n    (default is code)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--force-refresh")"
    printf "    â˜¢ï¸ Force refresh.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--only-show-file-path")"
    printf "    ğŸ“‚ Only show the path of the file containing the configuration parameters\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_ccloud_connector_create_or_update_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground ccloud-connector create-or-update - ğŸ§‘â€ğŸ¨  Create or update connector\n"
    echo

  else
    printf "playground ccloud-connector create-or-update - ğŸ§‘â€ğŸ¨  Create or update connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ccloud-connector create-or-update [JSON] [OPTIONS]\n"
  printf "  playground ccloud-connector create-or-update --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR (required)")"
    printf "    ğŸ”— Connector name\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "JSON")"
    printf "    json (reads from stdin if empty)\n"
    printf "    Default: -\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground ccloud-connector create-or-update --connector HttpSink << EOF\n  {\n      \"connector.class\": \"HttpSink\",\n      \"name\": \"HttpSink\",\n      \"kafka.auth.mode\": \"KAFKA_API_KEY\",\n      \"kafka.api.key\": \"$CLOUD_KEY\",\n      \"kafka.api.secret\": \"$CLOUD_SECRET\",\n      \"topics\": \"http-topic\",\n      \"input.data.format\": \"AVRO\",\n      \"http.api.url\": \"http://httpstat.us/200/\",\n      \"behavior.on.error\": \"fail\",\n      \"tasks.max\" : \"1\"\n  }\n  EOF\n"
    echo

  fi
}

# :command.usage
playground_connector_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector - ğŸ”— Connector commands\n"
    echo

  else
    printf "playground connector - ğŸ”— Connector commands\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector COMMAND\n"
  printf "  playground connector [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   ğŸ§© Show status of all connectors\n" "$(green "status")                "
  printf "  %s   ğŸ¨ Show all plugins installed\n" "$(green "plugins")               "
  printf "  %s   â¸ï¸  Pause connector\n" "$(green "pause")                 "
  printf "  %s   ğŸ§ Get current and latest version available on Confluent Hub for connector(s) used in example\n" "$(green "versions")              "
  printf "  %s   â™»ï¸  Restart connector\n" "$(green "restart")               "
  printf "  %s   â¯ï¸  Resume connector\n" "$(green "resume")                "
  printf "  %s   ğŸ—‘ï¸  Delete connector\n" "$(green "delete")                "
  printf "  %s   ğŸ¢ Show lag of sink connector\n" "$(green "show-lag")              "
  printf "  %s   ğŸ§° Show current connector config\n" "$(green "show-config")           "
  printf "  %s   ğŸ”© Show all possible configuration parameters of connector\n" "$(green "show-config-parameters")"
  printf "  %s   ğŸ§¬ Set connect log level\n" "$(green "log-level")             "
  printf "  %s   ğŸ§‘â€ğŸ¨  Create or update connector\n" "$(green "create-or-update")      "
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground connector status\n"
    printf "  playground connector status --json\n"
    printf "  playground connector resume --connector <connector-name>\n"
    printf "  playground connector pause -c <connector-name>\n"
    printf "  playground connector delete -c <connector-name>\n"
    echo

  fi
}

# :command.usage
playground_connector_status_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector status - ğŸ§© Show status of all connectors\n"
    echo

  else
    printf "playground connector status - ğŸ§© Show status of all connectors\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector status [OPTIONS]\n"
  printf "  playground connector status --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    ğŸ”— Connector name\n    \n    ğŸ“ Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_plugins_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector plugins - ğŸ¨ Show all plugins installed\n"
    echo

  else
    printf "playground connector plugins - ğŸ¨ Show all plugins installed\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector plugins\n"
  printf "  playground connector plugins --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_pause_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector pause - â¸ï¸  Pause connector\n"
    echo

  else
    printf "playground connector pause - â¸ï¸  Pause connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector pause [OPTIONS]\n"
  printf "  playground connector pause --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    ğŸ”— Connector name\n    \n    ğŸ“ Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_versions_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector versions - ğŸ§ Get current and latest version available on Confluent Hub for connector(s) used in example\n"
    echo

  else
    printf "playground connector versions - ğŸ§ Get current and latest version available on Confluent Hub for connector(s) used in example\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector versions\n"
  printf "  playground connector versions --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_restart_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector restart - â™»ï¸  Restart connector\n"
    echo

  else
    printf "playground connector restart - â™»ï¸  Restart connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector restart [OPTIONS]\n"
  printf "  playground connector restart --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    ğŸ”— Connector name\n    \n    ğŸ“ Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_resume_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector resume - â¯ï¸  Resume connector\n"
    echo

  else
    printf "playground connector resume - â¯ï¸  Resume connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector resume [OPTIONS]\n"
  printf "  playground connector resume --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    ğŸ”— Connector name\n    \n    ğŸ“ Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_delete_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector delete - ğŸ—‘ï¸  Delete connector\n"
    echo

  else
    printf "playground connector delete - ğŸ—‘ï¸  Delete connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector delete [OPTIONS]\n"
  printf "  playground connector delete --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    ğŸ”— Connector name\n    \n    ğŸ“ Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_show_lag_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector show-lag - ğŸ¢ Show lag of sink connector\n"
    echo

  else
    printf "playground connector show-lag - ğŸ¢ Show lag of sink connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector show-lag [OPTIONS]\n"
  printf "  playground connector show-lag --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    ğŸ”— Connector name\n    \n    ğŸ“ Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--wait-for-zero-lag")"
    printf "    ğŸ˜´ Wait until lag becomes 0\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_show_config_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector show-config - ğŸ§° Show current connector config\n"
    echo

  else
    printf "playground connector show-config - ğŸ§° Show current connector config\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector show-config [OPTIONS]\n"
  printf "  playground connector show-config --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    ğŸ”— Connector name\n    \n    ğŸ“ Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_show_config_parameters_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector show-config-parameters - ğŸ”© Show all possible configuration parameters of connector\n"
    echo

  else
    printf "playground connector show-config-parameters - ğŸ”© Show all possible configuration parameters of connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector show-config-parameters [OPTIONS]\n"
  printf "  playground connector show-config-parameters --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    ğŸ”— Connector name\n    \n    ğŸ“ Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--open, -o")"
    printf "    ğŸ”– Save output to a file and open with text editor set with config.ini\n    (default is code)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--force-refresh")"
    printf "    â˜¢ï¸ Force refresh.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--only-show-file-path")"
    printf "    ğŸ“‚ Only show the path of the file containing the configuration parameters\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_log_level_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector log-level\n"
    echo

    printf "  ğŸ§¬ Set connect log level\n  \n  ğŸ“ Tip: it will also set\n  io.confluent.kafka.schemaregistry.client.rest.RestService (to see schema\n  registry rest requests) and\n  org.apache.kafka.connect.runtime.TransformationChain (to see records before\n  and after SMTs)\n"
    echo

  else
    printf "playground connector log-level - ğŸ§¬ Set connect log level\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector log-level [OPTIONS]\n"
  printf "  playground connector log-level --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    ğŸ”— Connector name\n    \n    ğŸ“ Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--level, -l LEVEL (required)")"
    printf "    â•Log level\n"
    printf "    Allowed: INFO, WARN, DEBUG, TRACE\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_create_or_update_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector create-or-update - ğŸ§‘â€ğŸ¨  Create or update connector\n"
    echo

  else
    printf "playground connector create-or-update - ğŸ§‘â€ğŸ¨  Create or update connector\n"
    echo

  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector create-or-update [JSON] [OPTIONS]\n"
  printf "  playground connector create-or-update --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n $long_usage ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR (required)")"
    printf "    ğŸ”— Connector name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--level, -l LEVEL")"
    printf "    â•Log level\n"
    printf "    Allowed: INFO, WARN, DEBUG, TRACE\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--package, -p PACKAGE")"
    printf "    Package name\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "JSON")"
    printf "    json (reads from stdin if empty)\n"
    printf "    Default: -\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground connector create-or-update -c filestream-sink << EOF\n  {\n      \"tasks.max\": \"1\",\n      \"connector.class\":\n  \"org.apache.kafka.connect.file.FileStreamSinkConnector\",\n      \"topics\": \"filestream\",\n      \"file\": \"/tmp/output.json\",\n      \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\",\n      \"value.converter\": \"org.apache.kafka.connect.json.JsonConverter\",\n      \"value.converter.schemas.enable\": \"false\"\n  }\n  EOF\n"
    echo

  fi
}

# :command.normalize_input
normalize_input() {
  local arg flags

  while [[ $# -gt 0 ]]; do
    arg="$1"
    if [[ $arg =~ ^(--[a-zA-Z0-9_\-]+)=(.+)$ ]]; then
      input+=("${BASH_REMATCH[1]}")
      input+=("${BASH_REMATCH[2]}")
    elif [[ $arg =~ ^(-[a-zA-Z0-9])=(.+)$ ]]; then
      input+=("${BASH_REMATCH[1]}")
      input+=("${BASH_REMATCH[2]}")
    elif [[ $arg =~ ^-([a-zA-Z0-9][a-zA-Z0-9]+)$ ]]; then
      flags="${BASH_REMATCH[1]}"
      for ((i = 0; i < ${#flags}; i++)); do
        input+=("-${flags:i:1}")
      done
    else
      input+=("$arg")
    fi

    shift
  done
}
# :command.inspect_args
inspect_args() {
  if ((${#args[@]})); then
    readarray -t sorted_keys < <(printf '%s\n' "${!args[@]}" | sort)
    echo args:
    for k in "${sorted_keys[@]}"; do echo "- \${args[$k]} = ${args[$k]}"; done
  else
    echo args: none
  fi

  if ((${#other_args[@]})); then
    echo
    echo other_args:
    echo "- \${other_args[*]} = ${other_args[*]}"
    for i in "${!other_args[@]}"; do
      echo "- \${other_args[$i]} = ${other_args[$i]}"
    done
  fi

  if ((${#deps[@]})); then
    readarray -t sorted_keys < <(printf '%s\n' "${!deps[@]}" | sort)
    echo
    echo deps:
    for k in "${sorted_keys[@]}"; do echo "- \${deps[$k]} = ${deps[$k]}"; done
  fi

}

# :command.user_lib
# src/lib/cli_function.sh
function get_environment_used() {
  if [ ! -f /tmp/playground-command ]
  then
    echo "error"
    return
  fi

  patterns=("environment/2way-ssl" "environment/sasl-ssl" "environment/rbac-sasl-plain" "environment/kerberos" "environment/ssl_kerberos" "environment/ldap-authorizer-sasl-plain" "environment/sasl-plain" "environment/ldap-sasl-plain" "environment/sasl-scram" "environment/mdc-plaintext" "environment/mdc-sasl-plain" "environment/mdc-kerberos" "environment/ldap-authorizer-sasl-plain" "ccloud/environment")

  for pattern in "${patterns[@]}"; do
    if grep -q "$pattern" /tmp/playground-command; then
      echo "${pattern#*/}"
      return
    fi
  done

  echo "plaintext"
}

function get_connect_url_and_security() {
  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi
  connect_url="http://localhost:8083"
  security=""
  if [[ "$environment" == "sasl-ssl" ]] || [[ "$environment" == "2way-ssl" ]]
  then
      connect_url="https://localhost:8083"
      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

      security="--cert $DIR_CLI/../../environment/$environment/security/connect.certificate.pem --key $DIR_CLI/../../environment/$environment/security/connect.key --tlsv1.2 --cacert $DIR_CLI/../../environment/$environment/security/snakeoil-ca-1.crt"
  elif [[ "$environment" == "rbac-sasl-plain" ]]
  then
      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

      security="-u connectorSubmitter:connectorSubmitter"
  fi

  echo "$connect_url@$security"
}

function get_ccloud_connect() {
  if [ ! -f /tmp/delta_configs/ak-tools-ccloud.delta ]
  then
      logerror "ERROR: /tmp/delta_configs/ak-tools-ccloud.delta has not been generated"
      exit 1
  fi
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  root_folder=$(echo ${dir1%/*})
  IGNORE_CHECK_FOR_DOCKER_COMPOSE=true
  source $root_folder/scripts/utils.sh

  environment=$(grep "ENVIRONMENT ID" /tmp/delta_configs/ak-tools-ccloud.delta | cut -d " " -f 4)
  cluster=$(grep "KAFKA CLUSTER ID" /tmp/delta_configs/ak-tools-ccloud.delta | cut -d " " -f 5)

  if [[ "$OSTYPE" == "darwin"* ]]
  then
      authorization=$(echo -n "$CLOUD_API_KEY:$CLOUD_API_SECRET" | base64)
  else
      authorization=$(echo -n "$CLOUD_API_KEY:$CLOUD_API_SECRET" | base64 -w 0)
  fi

  echo "$environment@$cluster@$authorization"
}

function get_sr_url_and_security() {
  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  sr_url="http://localhost:8081"
  security_sr=""

  if [[ "$environment" == "sasl-ssl" ]] || [[ "$environment" == "2way-ssl" ]]
  then
      sr_url="https://localhost:8081"
      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

      security="--cert $DIR_CLI/../../environment/$environment/security/schema-registry.certificate.pem --key $DIR_CLI/../../environment/$environment/security/schema-registry.key --tlsv1.2 --cacert $DIR_CLI/../../environment/$environment/security/snakeoil-ca-1.crt"
  elif [[ "$environment" == "rbac-sasl-plain" ]]
  then
      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

      security="-u superUser:superUser"
  elif [[ "$environment" == "environment" ]]
  then
    if [ -f /tmp/delta_configs/env.delta ]
    then
        source /tmp/delta_configs/env.delta
    else
        logerror "ERROR: /tmp/delta_configs/env.delta has not been generated"
        exit 1
    fi
    sr_url=$SCHEMA_REGISTRY_URL
    security="-u $SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO"
  fi

  echo "$sr_url@$security"
}

function get_security_broker() {
  config_file_name="$1"
  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  container="broker"
  security=""
  if [[ "$environment" == "kerberos" ]] || [[ "$environment" == "ssl_kerberos" ]]
  then
      container="client"
      security="$config_file_name /etc/kafka/consumer.properties"

      docker exec -i client kinit -k -t /var/lib/secret/kafka-connect.key connect
  elif [ "$environment" == "ldap-authorizer-sasl-plain" ]
  then
      security="$config_file_name /service/kafka/users/kafka.properties"
  elif [ "$environment" == "ldap-sasl-plain" ] || [ "$environment" == "sasl-plain" ] || [ "$environment" == "sasl-scram" ]
  then
      security="$config_file_name /tmp/client.properties"
  elif [ "$environment" != "plaintext" ]
  then
      security="$config_file_name /etc/kafka/secrets/client_without_interceptors.config"
  fi
  echo "$container@$security"
}

function get_fzf_version() {
    version=$(fzf --version | grep -oE "[0-9]+\.[0-9]+\.[0-9]+" | cut -d " " -f 1)
    echo "$version"
}

function get_examples_list_with_fzf() {
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  dir2=$(echo ${dir1%/*})

  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=ğŸ‘‰"
    fzf_option_rounded="--border=rounded"
  else
    fzf_options=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  terminal_columns=$(tput cols)
  if [[ $terminal_columns -gt 180 ]]
  then
    if [[ $(type -f bat 2>&1) =~ "not found" ]]
    then
        res=$(find $dir2 -name \*.sh ! -name 'stop.sh' ! -path '*/scripts/*' ! -path '*/ccloud/*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-*/*' ! -path '*/security/*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="ğŸº" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-3,-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'cat {}');echo "$cur@$res"
    else
      res=$(find $dir2 -name \*.sh ! -name 'stop.sh' ! -path '*/scripts/*' ! -path '*/ccloud/*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-*/*' ! -path '*/security/*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="ğŸº" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-3,-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'bat --style=plain --color=always --line-range :500 {}');echo "$cur@$res"
    fi
  else
    res=$(find $dir2 -name \*.sh ! -name 'stop.sh' ! -path '*/scripts/*' ! -path '*/ccloud/*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-*/*' ! -path '*/security/*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="ğŸº" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-3,-2,-1" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
  fi
}

function get_examples_list_with_fzf_ccloud_only() {
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  dir2=$(echo ${dir1%/*})

  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=ğŸ‘‰"
    fzf_option_rounded="--border=rounded"
  else
    fzf_options=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  terminal_columns=$(tput cols)
  if [[ $terminal_columns -gt 180 ]]
  then
    if [[ $(type -f bat 2>&1) =~ "not found" ]]
    then
      res=$(find $dir2 -name \*.sh ! -name 'stop.sh' -path '*/ccloud*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-*/*' ! -path '*/security/*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="ğŸº" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-3,-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'cat {}');echo "$cur@$res"
    else
      res=$(find $dir2 -name \*.sh ! -name 'stop.sh' -path '*/ccloud*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-*/*' ! -path '*/security/*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="ğŸº" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-3,-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'bat --style=plain --color=always --line-range :500 {}');echo "$cur@$res"
    fi
  else
    res=$(find $dir2 -name \*.sh ! -name 'stop.sh' -path '*/ccloud*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-*/*' ! -path '*/security/*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="ğŸº" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-3,-2,-1" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
  fi
}

function get_examples_list_with_fzf_without_repro() {
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  dir2=$(echo ${dir1%/*})

  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=ğŸ‘‰"
    fzf_option_rounded="--border=rounded"
  else
    fzf_options=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  terminal_columns=$(tput cols)
  if [[ $terminal_columns -gt 180 ]]
  then
    if [[ $(type -f bat 2>&1) =~ "not found" ]]
    then
      res=$(find $dir2 -name \*.sh ! -name 'stop.sh' ! -path '*/scripts/*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-*/*' ! -path '*/security/*' ! -path '*/reproduction-models/*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="ğŸº" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-3,-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'cat {}');echo "$cur@$res"
    else
      res=$(find $dir2 -name \*.sh ! -name 'stop.sh' ! -path '*/scripts/*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-*/*' ! -path '*/security/*' ! -path '*/reproduction-models/*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="ğŸº" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-3,-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'bat --style=plain --color=always --line-range :500 {}');echo "$cur@$res"
    fi
  else
    res=$(find $dir2 -name \*.sh ! -name 'stop.sh' ! -path '*/scripts/*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-*/*' ! -path '*/security/*' ! -path '*/reproduction-models/*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="ğŸº" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-3,-2,-1" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
  fi
}

function get_examples_list_with_fzf_without_repro_sink_only() {
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  dir2=$(echo ${dir1%/*})

  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=ğŸ‘‰"
    fzf_option_rounded="--border=rounded"
  else
    fzf_options=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  terminal_columns=$(tput cols)
  if [[ $terminal_columns -gt 180 ]]
  then
    if [[ $(type -f bat 2>&1) =~ "not found" ]]
    then
      res=$(find $dir2 -name \*.sh ! -name 'stop.sh' -path '*/connect-*-sink/*' ! -path '*/scripts/*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-*/*' ! -path '*/security/*' ! -path '*/reproduction-models/*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="ğŸº" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-3,-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'cat {}');echo "$cur@$res"
    else
      res=$(find $dir2 -name \*.sh ! -name 'stop.sh' -path '*/connect-*-sink/*' ! -path '*/scripts/*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-*/*' ! -path '*/security/*' ! -path '*/reproduction-models/*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="ğŸº" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-3,-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'bat --style=plain --color=always --line-range :500 {}');echo "$cur@$res"
    fi
  else
    res=$(find $dir2 -name \*.sh ! -name 'stop.sh' -path '*/connect-*-sink/*' ! -path '*/scripts/*' ! -path '*/sample-sql-scripts/*' ! -path '*/ora-*/*' ! -path '*/security/*' ! -path '*/reproduction-models/*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="ğŸº" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-3,-2,-1" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
  fi
}

function get_zip_or_jar_with_fzf() {
  cur="$1"
  type="$2"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=ğŸ‘‰"
    fzf_option_rounded="--border=rounded"
  else
    fzf_options=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  if config_has_key "folder_zip_or_jar"
  then
    folder_zip_or_jar=$(config_get "folder_zip_or_jar")
  else
    logerror "Could not find config value <folder_zip_or_jar> !"
    exit 1
  fi

  folder_zip_or_jar=${folder_zip_or_jar//\~/$HOME}
  folder_zip_or_jar=${folder_zip_or_jar//,/ }

  res=$(find $folder_zip_or_jar $PWD -name \*.$type ! -path '*/\.*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="ğŸº" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
}

function get_playground_repro_export_with_fzf() {
  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=ğŸ‘‰"
    fzf_option_rounded="--border=rounded"
  else
    fzf_options=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  if config_has_key "folder_zip_or_jar"
  then
    folder_zip_or_jar=$(config_get "folder_zip_or_jar")
  else
    logerror "Could not find config value <folder_zip_or_jar> !"
    exit 1
  fi

  folder_zip_or_jar=${folder_zip_or_jar//\~/$HOME}
  folder_zip_or_jar=${folder_zip_or_jar//,/ }

  res=$(find $folder_zip_or_jar $PWD -name playground_repro_export.tgz ! -path '*/\.*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="ğŸº" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
}

function get_any_files_with_fzf() {
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  dir2=$(echo ${dir1%/*})

  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=ğŸ‘‰"
    fzf_option_rounded="--border=rounded"
  else
    fzf_options=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  res=$(find $dir2 -type f ! -path '*/\.*' | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="ğŸº" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
}

function get_predefined_schemas_with_fzf() {
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  dir2=$(echo ${dir1%/*})
  predefined_folder=$dir2/scripts/cli/src/predefined-schemas

  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=70%,wrap"
    fzf_option_pointer="--pointer=ğŸ‘‰"
    fzf_option_rounded="--border=rounded"
  else
    fzf_options=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  terminal_columns=$(tput cols)
  if [[ $terminal_columns -gt 180 ]]
  then
    if [[ $(type -f bat 2>&1) =~ "not found" ]]
    then
      res=$(find $predefined_folder $PWD -maxdepth 2 \( -name "*.json" -o -name "*.avsc" -o -name "*.proto" -o -name "*.proto5" -o -name "*.sql" \) | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="ğŸº" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'cat {}');echo "$cur@$res"
    else
      res=$(find $predefined_folder $PWD -maxdepth 2 \( -name "*.json" -o -name "*.avsc" -o -name "*.proto" -o -name "*.proto5" -o -name "*.sql" \) | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="ğŸº" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'bat --style=plain --color=always --line-range :500 {}');echo "$cur@$res"
    fi
  else
    res=$(find $predefined_folder $PWD -maxdepth 2 \( -name "*.json" -o -name "*.avsc" -o -name "*.proto" -o -name "*.proto5" -o -name "*.sql" \) | fzf --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --prompt="ğŸº" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-2,-1" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
  fi
}

function filter_not_mdc_environment() {
  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  if [[ "$environment" == "mdc"* ]]
  then
    echo "$environment is not supported with this command !"
  fi
}

function filter_ccloud_environment() {
  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  if [[ "$environment" != "environment" ]]
  then
    echo "environment should be ccloud with this command (it is $environment)!"
  fi
}

function filter_schema_registry_running() {
  ret=$(get_sr_url_and_security)

  sr_url=$(echo "$ret" | cut -d "@" -f 1)
  sr_security=$(echo "$ret" | cut -d "@" -f 2)

  ret=$(curl $sr_security -s "${sr_url}/config")
  if [ $? != 0 ]
  then
    echo "schema registry rest api should be running to run this command"
  fi
}

function filter_connect_running() {
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  ret=$(curl $security -s "${connect_url}")
  if [ $? != 0 ]
  then
    echo "connect rest api should be running to run this command"
  fi
}

function filter_docker_running() {
  docker info >/dev/null 2>&1 || echo "Docker must be running"
}

# src/lib/colors.sh
print_in_color() {
  local color="$1"
  shift
  if [[ -z ${NO_COLOR+x} ]]; then
    printf "$color%b\e[0m\n" "$*"
  else
    printf "%b\n" "$*"
  fi
}

red() { print_in_color "\e[31m" "$*"; }
green() { print_in_color "\e[32m" "$*"; }
yellow() { print_in_color "\e[33m" "$*"; }
blue() { print_in_color "\e[34m" "$*"; }
magenta() { print_in_color "\e[35m" "$*"; }
cyan() { print_in_color "\e[36m" "$*"; }
bold() { print_in_color "\e[1m" "$*"; }
underlined() { print_in_color "\e[4m" "$*"; }
red_bold() { print_in_color "\e[1;31m" "$*"; }
green_bold() { print_in_color "\e[1;32m" "$*"; }
yellow_bold() { print_in_color "\e[1;33m" "$*"; }
blue_bold() { print_in_color "\e[1;34m" "$*"; }
magenta_bold() { print_in_color "\e[1;35m" "$*"; }
cyan_bold() { print_in_color "\e[1;36m" "$*"; }
red_underlined() { print_in_color "\e[4;31m" "$*"; }
green_underlined() { print_in_color "\e[4;32m" "$*"; }
yellow_underlined() { print_in_color "\e[4;33m" "$*"; }
blue_underlined() { print_in_color "\e[4;34m" "$*"; }
magenta_underlined() { print_in_color "\e[4;35m" "$*"; }
cyan_underlined() { print_in_color "\e[4;36m" "$*"; }

# src/lib/config.sh
config_init() {
  CONFIG_FILE=${CONFIG_FILE:=config.ini}
  [[ -f "$CONFIG_FILE" ]] || touch "$CONFIG_FILE"
}

config_get() {
  local key=$1
  local regex="^$key *= *(.+)$"
  local value=""

  config_init

  while IFS= read -r line || [ -n "$line" ]; do
    if [[ $line =~ $regex ]]; then
      value="${BASH_REMATCH[1]}"
      break
    fi
  done <"$CONFIG_FILE"

  echo "$value"
}

config_set() {
  local key=$1
  shift
  local value="$*"

  config_init

  local regex="^($key) *= *.+$"
  local output=""
  local found_key=""
  local newline

  while IFS= read -r line || [ -n "$line" ]; do
    newline=$line
    if [[ $line =~ $regex ]]; then
      found_key="${BASH_REMATCH[1]}"
      newline="$key = $value"
      output="$output$newline\n"
    elif [[ $line ]]; then
      output="$output$line\n"
    fi
  done <"$CONFIG_FILE"

  if [[ -z $found_key ]]; then
    output="$output$key = $value\n"
  fi

  printf "%b\n" "$output" >"$CONFIG_FILE"
}

config_del() {
  local key=$1

  local regex="^($key) *="
  local output=""

  config_init

  while IFS= read -r line || [ -n "$line" ]; do
    if [[ $line ]] && [[ ! $line =~ $regex ]]; then
      output="$output$line\n"
    fi
  done <"$CONFIG_FILE"

  printf "%b\n" "$output" >"$CONFIG_FILE"
}

config_show() {
  config_init
  cat "$CONFIG_FILE"
}

config_keys() {
  local regex="^([a-zA-Z0-9_\-\/\.]+) *="

  config_init

  local keys=()
  local key

  while IFS= read -r line || [ -n "$line" ]; do
    if [[ $line =~ $regex ]]; then
      key="${BASH_REMATCH[1]}"
      keys+=("$key")
    fi
  done <"$CONFIG_FILE"
  echo "${keys[@]}"
}

config_has_key() {
  [[ $(config_get "$1") ]]
}

# src/lib/heredocs.sh
function get_properties_command_heredoc () {
docker exec -i "$1" sh << EOF
ps -ef | grep properties | grep java | grep -v grep | awk '{ print \$NF }' > /tmp/propertie_file
propertie_file=\$(cat /tmp/propertie_file)
if [ ! -f \$propertie_file ]
then
  logerror 'ERROR: Could not determine properties file!'
  exit 1
fi
cat \$propertie_file | grep -v None | grep . | sort
EOF
}

function get_producer_heredoc () {
        cat << EOF >> $tmp_dir/producer

  $producer_hostname:
    build:
      context: ../../$output_folder/$final_dir/$producer_hostname/
    hostname: producer
    container_name: $producer_hostname
    environment:
      KAFKA_BOOTSTRAP_SERVERS: broker:9092
      TOPIC: "$topic_name"
      REPLICATION_FACTOR: 1
      NUMBER_OF_PARTITIONS: 1
      NB_MESSAGES: 10 # -1 for MAX_VALUE
      MESSAGE_BACKOFF: 100 # Frequency of message injection
      KAFKA_ACKS: "all" # default: "1"
      KAFKA_REQUEST_TIMEOUT_MS: 20000
      KAFKA_RETRY_BACKOFF_MS: 500
      KAFKA_CLIENT_ID: "my-java-$producer_hostname"
      KAFKA_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      JAVA_OPTS: \${GRAFANA_AGENT_PRODUCER}
    volumes:
      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/
      - ../../$output_folder/$final_dir/$producer_hostname/target/producer-1.0.0-jar-with-dependencies.jar:/producer-1.0.0-jar-with-dependencies.jar

EOF
}

function get_producer_ccloud_heredoc () {
        cat << EOF >> $tmp_dir/producer

  $producer_hostname:
    build:
      context: ../../$output_folder/$final_dir/$producer_hostname/
    hostname: producer
    container_name: $producer_hostname
    environment:
      KAFKA_BOOTSTRAP_SERVERS: \$BOOTSTRAP_SERVERS
      KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: "https"
      KAFKA_SASL_MECHANISM: "PLAIN"
      KAFKA_SASL_JAAS_CONFIG: \$SASL_JAAS_CONFIG
      KAFKA_SECURITY_PROTOCOL: "SASL_SSL"
      TOPIC: "$topic_name"
      REPLICATION_FACTOR: 3
      NUMBER_OF_PARTITIONS: 1
      NB_MESSAGES: 10 # -1 for MAX_VALUE
      MESSAGE_BACKOFF: 100 # Frequency of message injection
      KAFKA_ACKS: "all" # default: "1"
      KAFKA_REQUEST_TIMEOUT_MS: 20000
      KAFKA_RETRY_BACKOFF_MS: 500
      KAFKA_CLIENT_ID: "my-java-$producer_hostname"
      KAFKA_SCHEMA_REGISTRY_URL: \$SCHEMA_REGISTRY_URL
      KAFKA_BASIC_AUTH_CREDENTIALS_SOURCE: \$BASIC_AUTH_CREDENTIALS_SOURCE
      KAFKA_SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO: \$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO
      JAVA_OPTS: \${GRAFANA_AGENT_PRODUCER}
      EXTRA_ARGS:

    volumes:
      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/
      - ../../$output_folder/$final_dir/$producer_hostname/target/producer-1.0.0-jar-with-dependencies.jar:/producer-1.0.0-jar-with-dependencies.jar

EOF
}

function get_producer_build_heredoc () {
    cat << EOF > $tmp_dir/build_producer
for component in $list
do
    set +e
    log "ğŸ— Building jar for \${component}"
    docker run -i --rm -e KAFKA_CLIENT_TAG=\$KAFKA_CLIENT_TAG -e TAG=\$TAG_BASE -v "\${DIR}/\${component}":/usr/src/mymaven -v "\$HOME/.m2":/root/.m2 -v "\$PWD/../../scripts/settings.xml:/tmp/settings.xml" -v "\${DIR}/\${component}/target:/usr/src/mymaven/target" -w /usr/src/mymaven maven:3.6.1-jdk-11 mvn -s /tmp/settings.xml -Dkafka.tag=\$TAG -Dkafka.client.tag=\$KAFKA_CLIENT_TAG package > /tmp/result.log 2>&1
    if [ \$? != 0 ]
    then
        logerror "ERROR: failed to build java component $component"
        tail -500 /tmp/result.log
        exit 1
    fi
    set -e
done

EOF
}

function get_producer_fixthis_heredoc () {
    cat << EOF >> $tmp_dir/java_producer
# ğŸš¨ğŸš¨ğŸš¨ FIXTHIS: move it to the correct place ğŸš¨ğŸš¨ğŸš¨
EOF
}

function get_producer_run_heredoc () {
    cat << EOF >> $tmp_dir/java_producer
log "âœ¨ Run the $schema_format java producer v$i which produces to topic $topic_name"
docker exec $producer_hostname bash -c "java \${JAVA_OPTS} -jar producer-1.0.0-jar-with-dependencies.jar"
EOF
}

function get_producer_run_heredoc () {
    cat << EOF >> $tmp_dir/java_producer
log "âœ¨ Run the $schema_format java producer v$i which produces to topic $topic_name"
docker exec $producer_hostname bash -c "java \${JAVA_OPTS} -jar producer-1.0.0-jar-with-dependencies.jar"
EOF
}

function get_remote_debugging_command_heredoc () {
tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)
trap 'rm -rf $tmp_dir' EXIT
cat << EOF > $tmp_dir/docker-compose-remote-debugging.yml
version: '3.5'
services:
  $1:
    environment:
      # https://kafka-docker-playground.io/#/reusables?id=âœ¨-remote-debugging
      KAFKA_DEBUG: 'true'
      # With JDK9+, need to specify address=*:5005, see https://www.baeldung.com/java-application-remote-debugging#from-java9
      JAVA_DEBUG_OPTS: '-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=0.0.0.0:5005'
EOF

sed -e "s|up -d|-f $tmp_dir/docker-compose-remote-debugging.yml up -d|g" \
    /tmp/playground-command > /tmp/playground-command-debugging
}

function get_custom_smt_build_heredoc () {
    cat << EOF > $tmp_dir/build_custom_smt
for component in $custom_smt_name
do
    set +e
    log "ğŸ— Building jar for \${component}"
    docker run -i --rm -e KAFKA_CLIENT_TAG=\$KAFKA_CLIENT_TAG -e TAG=\$TAG_BASE -v "\${DIR}/\${component}":/usr/src/mymaven -v "\$HOME/.m2":/root/.m2 -v "\$PWD/../../scripts/settings.xml:/tmp/settings.xml" -v "\${DIR}/\${component}/target:/usr/src/mymaven/target" -w /usr/src/mymaven maven:3.6.1-jdk-11 mvn -s /tmp/settings.xml -Dkafka.tag=\$TAG -Dkafka.client.tag=\$KAFKA_CLIENT_TAG package > /tmp/result.log 2>&1
    if [ \$? != 0 ]
    then
        logerror "ERROR: failed to build java component $component"
        tail -500 /tmp/result.log
        exit 1
    fi
    set -e
done

EOF
}

# src/lib/send_completions.sh
send_completions() {
  echo $'# playground completion                                    -*- shell-script -*-'
  echo $''
  echo $'# This bash completions script was generated by'
  echo $'# completely (https://github.com/dannyben/completely)'
  echo $'# Modifying it manually is not recommended'
  echo $''
  echo $'_playground_completions_filter() {'
  echo $'  local words="$1"'
  echo $'  local cur=${COMP_WORDS[COMP_CWORD]}'
  echo $'  local result=()'
  echo $''
  echo $'  if [[ "${cur:0:1}" == "-" ]]; then'
  echo $'    echo "$words"'
  echo $'  '
  echo $'  else'
  echo $'    for word in $words; do'
  echo $'      [[ "${word:0:1}" != "-" ]] && result+=("$word")'
  echo $'    done'
  echo $''
  echo $'    echo "${result[*]}"'
  echo $''
  echo $'  fi'
  echo $'}'
  echo $''
  echo $'_playground_completions() {'
  echo $'  local cur=${COMP_WORDS[COMP_CWORD]}'
  echo $'  local compwords=("${COMP_WORDS[@]:1:$COMP_CWORD-1}")'
  echo $'  local compline="${compwords[*]}"'
  echo $''
  echo $'  case "$compline" in'
  echo $'    \'recreate-container\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'get-properties\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h broker.* connect.* schema-registry.* zookeeper.*")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'completions\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'properties\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h broker.* connect.* schema-registry.* zookeeper.*")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'bootstrap\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -A file -W "$(_playground_completions_filter "--help -h avro avro-with-key json-schema json-schema-with-key none protobuf protobuf-with-key")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'recreate\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'boot\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -A file -W "$(_playground_completions_filter "--help -h avro avro-with-key json-schema json-schema-with-key none protobuf protobuf-with-key")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'get\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h broker.* connect.* schema-registry.* zookeeper.*")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'b\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -A file -W "$(_playground_completions_filter "--help -h avro avro-with-key json-schema json-schema-with-key none protobuf protobuf-with-key")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'g\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h broker.* connect.* schema-registry.* zookeeper.*")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'r\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    *)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help --version -h -v b boot bootstrap completions g get get-properties properties r recreate recreate-container")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'  esac'
  echo $'} &&'
  echo $'complete -F _playground_completions playground'
  echo $''
  echo $'# ex: filetype=sh'
}

# src/lib/utils_function.sh
function log() {
  YELLOW='\033[0;33m'
  NC='\033[0m' # No Color
  echo -e "$YELLOW`date +"%H:%M:%S"` â„¹ï¸ $@$NC"
}

function logerror() {
  RED='\033[0;31m'
  NC='\033[0m' # No Color
  echo -e "$RED`date +"%H:%M:%S"` ğŸ”¥ $@$NC"
}

function logwarn() {
  PURPLE='\033[0;35m'
  NC='\033[0m' # No Color
  echo -e "$PURPLE`date +"%H:%M:%S"` â— $@$NC"
}

function urlencode() {
  # https://gist.github.com/cdown/1163649
  # urlencode <string>

  old_lc_collate=$LC_COLLATE
  LC_COLLATE=C

  local length="${#1}"
  for (( i = 0; i < length; i++ )); do
      local c="${1:$i:1}"
      case $c in
          [a-zA-Z0-9.~_-]) printf '%s' "$c" ;;
          *) printf '%%%02X' "'$c" ;;
      esac
  done

  LC_COLLATE=$old_lc_collate
}

function jq() {
    if [[ $(type -f jq 2>&1) =~ "not found" ]]
    then
      docker run --rm -i imega/jq "$@"
    else
      $(which jq) "$@"
    fi
}

function yq() {
    if [[ $(type -f yq 2>&1) =~ "not found" ]]
    then
      docker run -u0 -v /tmp:/tmp --rm -i mikefarah/yq "$@"
    else
      $(which yq) "$@"
    fi
}

# https://stackoverflow.com/a/24067243
function version_gt() {
  test "$(printf '%s\n' "$@" | sort -V | head -n 1)" != "$1";
}

function set_kafka_client_tag()
{
    if [[ $TAG_BASE = 7.5.* ]]
    then
      export KAFKA_CLIENT_TAG="3.5.0"
    fi

    if [[ $TAG_BASE = 7.4.* ]]
    then
      export KAFKA_CLIENT_TAG="3.4.0"
    fi

    if [[ $TAG_BASE = 7.3.* ]]
    then
      export KAFKA_CLIENT_TAG="3.3.0"
    fi

    if [[ $TAG_BASE = 7.2.* ]]
    then
      export KAFKA_CLIENT_TAG="3.2.0"
    fi

    if [[ $TAG_BASE = 7.1.* ]]
    then
      export KAFKA_CLIENT_TAG="3.1.0"
    fi

    if [[ $TAG_BASE = 7.0.* ]]
    then
      export KAFKA_CLIENT_TAG="3.0.0"
    fi

    if [[ $TAG_BASE = 6.2.* ]]
    then
      export KAFKA_CLIENT_TAG="2.8.0"
    fi

    if [[ $TAG_BASE = 6.1.* ]]
    then
      export KAFKA_CLIENT_TAG="2.7.0"
    fi

    if [[ $TAG_BASE = 6.0.* ]]
    then
      export KAFKA_CLIENT_TAG="2.6.0"
    fi

    if [[ $TAG_BASE = 5.5.* ]]
    then
      export KAFKA_CLIENT_TAG="2.5.0"
    fi

    if [[ $TAG_BASE = 5.4.* ]]
    then
      export KAFKA_CLIENT_TAG="2.4.0"
    fi

    if [[ $TAG_BASE = 5.3.* ]]
    then
      export KAFKA_CLIENT_TAG="2.3.0"
    fi

    if [[ $TAG_BASE = 5.2.* ]]
    then
      export KAFKA_CLIENT_TAG="2.2.0"
    fi

    if [[ $TAG_BASE = 5.1.* ]]
    then
      export KAFKA_CLIENT_TAG="2.1.0"
    fi

    if [[ $TAG_BASE = 5.0.* ]]
    then
      export KAFKA_CLIENT_TAG="2.0.0"
    fi
}

function displaytime {
  local T=$1
  local D=$((T/60/60/24))
  local H=$((T/60/60%24))
  local M=$((T/60%60))
  local S=$((T%60))
  (( $D > 0 )) && printf '%d days ' $D
  (( $H > 0 )) && printf '%d hours ' $H
  (( $M > 0 )) && printf '%d minutes ' $M
  (( $D > 0 || $H > 0 || $M > 0 )) && printf 'and '
  printf '%d seconds\n' $S
}

function choosejar()
{
  log "â˜• Select the jar to replace:"
  select jar
  do
    # Check the selected menu jar number
    if [ 1 -le "$REPLY" ] && [ "$REPLY" -le $# ];
    then
      break;
    else
      logwarn "Wrong selection: select any number from 1-$#"
    fi
  done
}

function verify_installed()
{
  local cmd="$1"
  if [[ $(type $cmd 2>&1) =~ "not found" ]]; then
    echo -e "\nERROR: This script requires '$cmd'. Please install '$cmd' and run again.\n"
    exit 1
  fi
}

function maybe_create_image()
{
  if [ ! -z "$DOCKER_COMPOSE_FILE_UPDATE_VERSION" ]
  then
    return
  fi
  set +e
  log "ğŸ§° Checking if Docker image ${CP_CONNECT_IMAGE}:${CONNECT_TAG} contains additional tools"
  log "ğŸ§° it can take a while if image is downloaded for the first time"
  docker run --rm ${CP_CONNECT_IMAGE}:${CONNECT_TAG} type unzip > /dev/null 2>&1
  if [ $? != 0 ]
  then
    if [[ "$TAG" == *ubi8 ]] || version_gt $TAG_BASE "5.9.0"
    then
      export CONNECT_USER="appuser"
      if [ `uname -m` = "arm64" ]
      then
        CONNECT_3RDPARTY_INSTALL="if [ ! -f /tmp/done ]; then yum -y install --disablerepo='Confluent*' bind-utils openssl unzip findutils net-tools nc jq which iptables libmnl krb5-workstation krb5-libs vim && yum clean all && rm -rf /var/cache/yum && rpm -i --nosignature https://rpmfind.net/linux/centos/8-stream/AppStream/aarch64/os/Packages/tcpdump-4.9.3-2.el8.aarch64.rpm && touch /tmp/done; fi"
      else
        CONNECT_3RDPARTY_INSTALL="if [ ! -f /tmp/done ]; then curl http://mirror.centos.org/centos/8-stream/AppStream/x86_64/os/Packages/tcpdump-4.9.3-1.el8.x86_64.rpm -o tcpdump-4.9.3-1.el8.x86_64.rpm && rpm -Uvh tcpdump-4.9.3-1.el8.x86_64.rpm && yum -y install --disablerepo='Confluent*' bind-utils openssl unzip findutils net-tools nc jq which iptables libmnl krb5-workstation krb5-libs vim && yum clean all && rm -rf /var/cache/yum && touch /tmp/done; fi"
      fi
    else
      export CONNECT_USER="root"
      CONNECT_3RDPARTY_INSTALL="if [ ! -f /tmp/done ]; then apt-get update && echo bind-utils openssl unzip findutils net-tools nc jq which iptables tree | xargs -n 1 apt-get install --force-yes -y && rm -rf /var/lib/apt/lists/* && touch /tmp/done; fi"
    fi

    tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)
    trap 'rm -rf $tmp_dir' EXIT
cat << EOF > $tmp_dir/Dockerfile
FROM ${CP_CONNECT_IMAGE}:${CONNECT_TAG}
USER root
RUN ${CONNECT_3RDPARTY_INSTALL}
USER ${CONNECT_USER}
EOF
    log "ğŸ‘·ğŸ“¦ Re-building Docker image ${CP_CONNECT_IMAGE}:${CONNECT_TAG} to include additional tools"
    docker build -t ${CP_CONNECT_IMAGE}:${CONNECT_TAG} $tmp_dir
    rm -rf $tmp_dir
  fi
  set -e
}

function verify_docker_and_memory()
{
  set +e
  docker info > /dev/null 2>&1
  if [[ $? -ne 0 ]]
  then
    logerror "Cannot connect to the Docker daemon. Is the docker daemon running?"
    exit 1
  fi
  set -e
  # Check only with Mac OS
  # if [[ "$OSTYPE" == "darwin"* ]]
  # then
  #   # Verify Docker memory is increased to at least 8GB
  #   DOCKER_MEMORY=$(docker system info | grep Memory | grep -o "[0-9\.]\+")
  #   if (( $(echo "$DOCKER_MEMORY 7.0" | awk '{print ($1 < $2)}') )); then
  #       logerror "WARNING: Did you remember to increase the memory available to Docker to at least 8GB (default is 2GB)? Demo may otherwise not work properly"
  #       exit 1
  #   fi
  # fi
  return 0
}

function verify_confluent_login()
{
  local cmd="$1"
  set +e
  output=$($cmd 2>&1)
  set -e
  if [ "${output}" = "Error: You must login to run that command." ] || [ "${output}" = "Error: Your session has expired. Please login again." ]; then
    logerror "This script requires confluent CLI to be logged in. Please execute 'confluent login' and run again."
    exit 1
  fi
}

function verify_confluent_details()
{
    if [ "$(confluent prompt -f "%E")" = "(none)" ]
    then
        logerror "confluent command is badly configured: environment is not set"
        logerror "Example: confluent kafka environment list"
        logerror "then: confluent kafka environment use <environment id>"
        exit 1
    fi

    if [ "$(confluent prompt -f "%K")" = "(none)" ]
    then
        logerror "confluent command is badly configured: cluster is not set"
        logerror "Example: confluent kafka cluster list"
        logerror "then: confluent kafka cluster use <cluster id>"
        exit 1
    fi

    if [ "$(confluent prompt -f "%a")" = "(none)" ]
    then
        logerror "confluent command is badly configured: api key is not set"
        logerror "Example: confluent api-key store <api key> <password>"
        logerror "then: confluent api-key use <api key>"
        exit 1
    fi

    CCLOUD_PROMPT_FMT='You will be using Confluent Cloud cluster with user={{fgcolor "green" "%u"}}, environment={{fgcolor "red" "%E"}}, cluster={{fgcolor "cyan" "%K"}}, api key={{fgcolor "yellow" "%a"}}'
    confluent prompt -f "$CCLOUD_PROMPT_FMT"
}

function check_if_continue()
{
    if [ ! -z "$GITHUB_RUN_NUMBER" ]
    then
        # running with github actions, continue
        return
    fi
    read -p "Continue (y/n)?" choice
    case "$choice" in
    y|Y ) ;;
    n|N ) exit 1;;
    * ) logerror "invalid response!";exit 1;;
    esac
}

function create_topic()
{
  local topic="$1"
  # log "Check if topic $topic exists"
  confluent kafka topic create "$topic" --partitions 1 --dry-run > /dev/null 2>/dev/null
  if [[ $? == 0 ]]; then
    log "Create topic $topic"
    log "confluent kafka topic create $topic --partitions 1"
    confluent kafka topic create "$topic" --partitions 1 || true
  else
    log "Topic $topic already exists"
  fi
}

function delete_topic()
{
  local topic="$1"
  # log "Check if topic $topic exists"
  confluent kafka topic create "$topic" --partitions 1 --dry-run > /dev/null 2>/dev/null
  if [[ $? != 0 ]]; then
    log "Delete topic $topic"
    log "confluent kafka topic delete $topic --force"
    confluent kafka topic delete "$topic" --force || true
  else
    log "Topic $topic does not exist"
  fi
}

function version_gt() {
  test "$(printf '%s\n' "$@" | sort -V | head -n 1)" != "$1";
}

function get_docker_compose_version() {
  docker compose version | grep "^Docker Compose version" | cut -d' ' -f3 | cut -d',' -f1
}

function check_docker_compose_version() {
  REQUIRED_DOCKER_COMPOSE_VER=${1:-"1.28.0"}
  DOCKER_COMPOSE_VER=$(get_docker_compose_version)

  if version_gt $REQUIRED_DOCKER_COMPOSE_VER $DOCKER_COMPOSE_VER; then
    logerror "docker compose version ${REQUIRED_DOCKER_COMPOSE_VER} or greater is required. Current reported version: ${DOCKER_COMPOSE_VER}"
    exit 1
  fi
}

function get_bash_version() {
  bash_major_version=$(bash --version | head -n1 | awk '{print $4}')
  major_version="${bash_major_version%%.*}"
  echo "$major_version"
}

function check_bash_version() {
  REQUIRED_BASH_VER=${1:-"4"}
  BASH_VER=$(get_bash_version)

  if version_gt $REQUIRED_BASH_VER $BASH_VER; then
    logerror "bash version ${REQUIRED_BASH_VER} or greater is required. Current reported version: ${BASH_VER}"
    exit 1
  fi
}

function get_confluent_version() {
  confluent version | grep "^Version:" | cut -d':' -f2 | cut -d'v' -f2
}

function get_ansible_version() {
  ansible --version | grep "core" | cut -d'[' -f2 | cut -d']' -f1 | cut -d' ' -f 2
}

function check_confluent_version() {
  REQUIRED_CONFLUENT_VER=${1:-"3.0.0"}
  CONFLUENT_VER=$(get_confluent_version)

  if version_gt $REQUIRED_CONFLUENT_VER $CONFLUENT_VER; then
    log "confluent version ${REQUIRED_CONFLUENT_VER} or greater is required.  Current reported version: ${CONFLUENT_VER}"
    echo 'To update run: confluent update'
    exit 1
  fi
}

function container_to_ip() {
    name=$1
    echo $(docker exec $name hostname -I)
}

function block_host() {
    name=$1
    shift 1

    # https://serverfault.com/a/906499
    docker exec --privileged -t $name bash -c "tc qdisc add dev eth0 root handle 1: prio" 2>&1

    for ip in $@; do
        docker exec --privileged -t $name bash -c "tc filter add dev eth0 protocol ip parent 1: prio 1 u32 match ip dst $ip flowid 1:1" 2>&1
    done

    docker exec --privileged -t $name bash -c "tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip dst 0.0.0.0/0 flowid 1:2" 2>&1
    docker exec --privileged -t $name bash -c "tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip protocol 1 0xff flowid 1:2" 2>&1
    docker exec --privileged -t $name bash -c "tc qdisc add dev eth0 parent 1:1 handle 10: netem loss 100%" 2>&1
    docker exec --privileged -t $name bash -c "tc qdisc add dev eth0 parent 1:2 handle 20: sfq" 2>&1
}

function remove_partition() {
    for name in $@; do
        docker exec --privileged -t $name bash -c "tc qdisc del dev eth0 root"
    done
}

function aws() {

    if [ -z "$AWS_ACCESS_KEY_ID" ] && [ -z "$AWS_SECRET_ACCESS_KEY" ] && [ ! -f $HOME/.aws/config ] && [ ! -f $HOME/.aws/credentials ]
    then
      logerror 'ERROR: Neither AWS_ACCESS_KEY_ID/AWS_SECRET_ACCESS_KEY or $HOME/.aws/credentials are set. AWS credentials must be set !'
      if [ -z "$AWS_ACCESS_KEY_ID" ]
      then
        log 'AWS_ACCESS_KEY_ID environment variable is not set.'
      fi
      if [ -z "$AWS_SECRET_ACCESS_KEY" ]
      then
        log 'AWS_SECRET_ACCESS_KEY environment variable is not set.'
      fi
      if [ ! -f $HOME/.aws/credentials ]
      then
        log '$HOME/.aws/credentials does not exist.'
      fi
      return 1
    fi

    if [ ! -f $HOME/.aws/config ]
    then
          tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
cat << EOF > $tmp_dir/config
[default]
region = $AWS_REGION
EOF
    fi

    if [ ! -f $HOME/.aws/credentials ]
    then
      #log "Using aws cli with environment variables AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY"
      docker run --rm -iv $tmp_dir/config:/root/.aws/config -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY -v $(pwd):/aws -v /tmp:/tmp amazon/aws-cli "$@"
      rm -rf $tmp_dir
    else
      #log "Using aws cli with credentials file"
      docker run --rm -iv $HOME/.aws:/root/.aws -v $(pwd):/aws -v /tmp:/tmp amazon/aws-cli "$@"
    fi
}

function timeout() {
  if [[ $(type -f timeout 2>&1) =~ "not found" ]]; then
    # ignore
    shift
    eval "$@"
  else
    $(which timeout) "$@"
  fi
}

function az() {
    docker run -v /tmp:/tmp -v $HOME/.azure:/home/az/.azure -e HOME=/home/az --rm -i mcr.microsoft.com/azure-cli az "$@"
}

function display_docker_container_error_log() {
  set +e
  logerror "####################################################"
  logerror "ğŸ³ docker ps"
  docker ps
  logerror "####################################################"
  for container in $(docker ps  --format="{{.Names}}")
  do
      logerror "####################################################"
      logerror "$container logs"
      if [[ "$container" == "connect" ]] || [[ "$container" == "sap" ]]
      then
          # always show all logs for connect
          docker container logs --tail=100 $container 2>&1 | grep -v "was supplied but isn't a known config"
      else
          docker container logs $container 2>&1 | egrep "ERROR|FATAL"

      fi
      logwarn "####################################################"
  done
}

function retry() {
  local n=1
  local max_retriable=4
  local max_default_retry=2
  while true; do
    "$@"
    ret=$?
    if [ $ret -eq 0 ]
    then
      return 0
    elif [ $ret -eq 111 ] # skipped
    then
      return 111
    elif [ $ret -eq 107 ] # known issue https://github.com/vdesabou/kafka-docker-playground/issues/907
    then
      return 107
    else
      test_file=$(echo "$@" | awk '{ print $4}')
      script=$(basename $test_file)
      # check for retriable scripts in scripts/tests-retriable.txt
      grep "$script" ${DIR}/tests-retriable.txt > /dev/null
      if [ $? = 0 ]
      then
        if [[ $n -lt $max_retriable ]]; then
          ((n++))
          logwarn "####################################################"
          logwarn "ğŸ§Ÿâ€â™‚ï¸ The test $script (retriable) has failed. Retrying (attempt $n/$max_retriable)"
          logwarn "####################################################"
          display_docker_container_error_log
        else
          logerror "ğŸ’€ The test $script (retriable) has failed after $n attempts."
          return 1
        fi
      else
        if [[ $n -lt $max_default_retry ]]; then
          ((n++))
          logwarn "####################################################"
          logwarn "ğŸ° The test $script (default_retry) has failed. Retrying (attempt $n/$max_default_retry)"
          logwarn "####################################################"
          display_docker_container_error_log
        else
          logerror "ğŸ’€ The test $script (default_retry) has failed after $n attempts."
          return 1
        fi
      fi
    fi
  done
}

retrycmd() {
    local -r -i max_attempts="$1"; shift
    local -r -i sleep_interval="$1"; shift
    local -r cmd="$@"
    local -i attempt_num=1

    until $cmd
    do
        if (( attempt_num == max_attempts ))
        then
            display_docker_container_error_log
            logerror "Failed after $attempt_num attempts. Please troubleshoot and run again."
            return 1
        else
            printf "."
            ((attempt_num++))
            sleep $sleep_interval
        fi
    done
    printf "\n"
}

# for RBAC, taken from cp-demo
function host_check_kafka_cluster_registered() {
  KAFKA_CLUSTER_ID=$(docker container exec zookeeper zookeeper-shell zookeeper:2181 get /cluster/id 2> /dev/null | grep \"version\" | jq -r .id)
  if [ -z "$KAFKA_CLUSTER_ID" ]; then
    return 1
  fi
  echo $KAFKA_CLUSTER_ID
  return 0
}

# for RBAC, taken from cp-demo
function host_check_mds_up() {
  docker container logs broker > /tmp/out.txt 2>&1
  FOUND=$(cat /tmp/out.txt | grep "Started NetworkTrafficServerConnector")
  if [ -z "$FOUND" ]; then
    return 1
  fi
  return 0
}

# for RBAC, taken from cp-demo
function mds_login() {
  MDS_URL=$1
  SUPER_USER=$2
  SUPER_USER_PASSWORD=$3

  # Log into MDS
  if [[ $(type expect 2>&1) =~ "not found" ]]; then
    echo "'expect' is not found. Install 'expect' and try again"
    exit 1
  fi
  echo -e "\n# Login"
  OUTPUT=$(
  expect <<END
    log_user 1
    spawn confluent login --url $MDS_URL
    expect "Username: "
    send "${SUPER_USER}\r";
    expect "Password: "
    send "${SUPER_USER_PASSWORD}\r";
    expect "Logged in as "
    set result $expect_out(buffer)
END
  )
  echo "$OUTPUT"
  if [[ ! "$OUTPUT" =~ "Logged in as" ]]; then
    echo "Failed to log into MDS.  Please check all parameters and run again"
    exit 1
  fi
}

# https://raw.githubusercontent.com/zlabjp/kubernetes-scripts/master/wait-until-pods-ready

function __is_pod_ready() {
  [[ "$(kubectl get po "$1" -n $namespace -o 'jsonpath={.status.conditions[?(@.type=="Ready")].status}')" == 'True' ]]
}

function __pods_ready() {
  local pod

  [[ "$#" == 0 ]] && return 0

  for pod in $pods; do
    __is_pod_ready "$pod" || return 1
  done

  return 0
}

function wait-until-pods-ready() {
  local period interval i pods

  if [[ $# != 3 ]]; then
    echo "Usage: wait-until-pods-ready PERIOD INTERVAL NAMESPACE" >&2
    echo "" >&2
    echo "This script waits for all pods to be ready in the current namespace." >&2

    return 1
  fi

  period="$1"
  interval="$2"
  namespace="$3"

  sleep 10

  for ((i=0; i<$period; i+=$interval)); do
    pods="$(kubectl get po -n $namespace -o 'jsonpath={.items[*].metadata.name}')"
    if __pods_ready $pods; then
      return 0
    fi

    echo "Waiting for pods to be ready..."
    sleep "$interval"
  done

  echo "Waited for $period seconds, but all pods are not ready yet."
  return 1
}

function wait_for_datagen_connector_to_inject_data () {
  sleep 3
  connector_name="$1"
  datagen_tasks="$2"
  prefix_cmd="$3"
  set +e
  # wait for all tasks to be FAILED with org.apache.kafka.connect.errors.ConnectException: Stopping connector: generated the configured xxx number of messages
  MAX_WAIT=3600
  CUR_WAIT=0
  log "âŒ› Waiting up to $MAX_WAIT seconds for connector $connector_name to finish injecting requested load"
  $prefix_cmd curl -s -X GET http://localhost:8083/connectors/datagen-${connector_name}/status | jq .tasks[].trace | grep "generated the configured" | wc -l > /tmp/out.txt 2>&1
  while [[ ! $(cat /tmp/out.txt) =~ "${datagen_tasks}" ]]; do
    sleep 5
    $prefix_cmd curl -s -X GET http://localhost:8083/connectors/datagen-${connector_name}/status | jq .tasks[].trace | grep "generated the configured" | wc -l > /tmp/out.txt 2>&1
    CUR_WAIT=$(( CUR_WAIT+10 ))
    if [[ "$CUR_WAIT" -gt "$MAX_WAIT" ]]; then
      echo -e "\nERROR: Please troubleshoot'.\n"
      $prefix_cmd curl -s -X GET http://localhost:8083/connectors/datagen-${connector_name}/status | jq
      exit 1
    fi
  done
  log "Connector $connector_name has finish injecting requested load"
  set -e
}

# https://gist.github.com/Fuxy22/da4b7ca3bcb0bfea2c582964eafeb4ed
# remove specified host from /etc/hosts
function removehost() {
    if [ ! -z "$1" ]
    then
        HOSTNAME=$1

        if [ -n "$(grep $HOSTNAME /etc/hosts)" ]
        then
            echo "$HOSTNAME Found in your /etc/hosts, Removing now...";
            sudo sed -i".bak" "/$HOSTNAME/d" /etc/hosts
        else
            echo "$HOSTNAME was not found in your /etc/hosts";
        fi
    else
        echo "Error: missing required parameters."
        echo "Usage: "
        echo "  removehost domain"
    fi
}

# https://gist.github.com/Fuxy22/da4b7ca3bcb0bfea2c582964eafeb4ed
#add new ip host pair to /etc/hosts
function addhost() {
    if [ $# -eq 2 ]
    then
        IP=$1
        HOSTNAME=$2

        if [ -n "$(grep $HOSTNAME /etc/hosts)" ]
            then
                echo "$HOSTNAME already exists:";
                echo $(grep $HOSTNAME /etc/hosts);
            else
                echo "Adding $HOSTNAME to your /etc/hosts";
                printf "%s\t%s\n" "$IP" "$HOSTNAME" | sudo tee -a /etc/hosts > /dev/null;

                if [ -n "$(grep $HOSTNAME /etc/hosts)" ]
                    then
                        echo "$HOSTNAME was added succesfully:";
                        echo $(grep $HOSTNAME /etc/hosts);
                    else
                        echo "Failed to Add $HOSTNAME, Try again!";
                fi
        fi
    else
        echo "Error: missing required parameters."
        echo "Usage: "
        echo "  addhost ip domain"
    fi
}

function stop_all() {
  current_dir="$1"
  cd ${current_dir}
  if ls docker-compose.* 1> /dev/null 2>&1;
  then
    for docker_compose_file in $(ls docker-compose.*)
    do
        environment=$(echo $docker_compose_file | cut -d "." -f 2)
        ${DIR}/../../environment/${environment}/stop.sh "${PWD}/${docker_compose_file}"
    done
  else
    ${DIR}/../../environment/plaintext/stop.sh
  fi
  cd -
}

function display_jmx_info() {
  if [ -z "$ENABLE_JMX_GRAFANA" ]
  then
    log "ğŸ“Š JMX metrics are available locally on those ports:"
  else
    log "ğŸ›¡ï¸ Prometheus is reachable at http://127.0.0.1:9090"
    log "ğŸ“› Pyroscope is reachable at http://127.0.0.1:4040"
    log "ğŸ“Š Grafana is reachable at http://127.0.0.1:3000 or JMX metrics are available locally on those ports:"
  fi

  log "    - zookeeper       : 9999"
  log "    - broker          : 10000"
  log "    - schema-registry : 10001"
  log "    - connect         : 10002"

  if [ ! -z "$ENABLE_KSQLDB" ]
  then
    log "    - ksqldb-server   : 10003"
  fi
}
function get_jmx_metrics() {
  JMXTERM_VERSION="1.0.2"
  JMXTERM_UBER_JAR="/tmp/jmxterm-$JMXTERM_VERSION-uber.jar"
  if [ ! -f $JMXTERM_UBER_JAR ]
  then
    curl -L https://github.com/jiaqi/jmxterm/releases/download/v$JMXTERM_VERSION/jmxterm-$JMXTERM_VERSION-uber.jar -o $JMXTERM_UBER_JAR -s
  fi

  rm -f /tmp/commands
  rm -f /tmp/jmx_metrics.log

  component="$1"
  domains="$2"
  open="$3"
  if [ "$domains" = "" ]
  then
    # non existing domain: all domains will be in output !
    logwarn "You did not specify a list of domains, all domains will be exported!"
    domains="ALL"
  fi

  case "$component" in
  zookeeper )
    port=9999
  ;;
  broker )
    port=10000
  ;;
  schema-registry )
    port=10001
  ;;
  connect )
    port=10002
  ;;
  n|N ) ;;
  * ) logerror "invalid component $component! it should be one of zookeeper, broker, schema-registry or connect";exit 1;;
  esac

  docker cp $JMXTERM_UBER_JAR $component:$JMXTERM_UBER_JAR
  if [ "$domains" = "ALL" ]
  then

log "This is the list of domains for component $component"
docker exec -i $component java -jar $JMXTERM_UBER_JAR  -l localhost:$port -n -v silent << EOF
domains
exit
EOF
  fi

for domain in `echo $domains`
do
docker exec -i $component java -jar $JMXTERM_UBER_JAR  -l localhost:$port -n -v silent > /tmp/beans.log << EOF
domain $domain
beans
exit
EOF
  while read line; do echo "get *"  -b $line; done < /tmp/beans.log >> /tmp/commands

  if [[ -n "$open" ]]
  then
    echo "####### domain $domain ########" >> /tmp/jmx_metrics.log
    docker exec -i $component java -jar $JMXTERM_UBER_JAR  -l localhost:$port -n < /tmp/commands >> /tmp/jmx_metrics.log 2>&1
  else
    echo "####### domain $domain ########"
    docker exec -i $component java -jar $JMXTERM_UBER_JAR  -l localhost:$port -n < /tmp/commands 2>&1
  fi
done

  if [[ -n "$open" ]]
  then
    if config_has_key "editor"
    then
      editor=$(config_get "editor")
      log "ğŸ“– Opening /tmp/jmx_metrics.log using configured editor $editor"
      $editor /tmp/jmx_metrics.log
    else
      if [[ $(type code 2>&1) =~ "not found" ]]
      then
        logerror "Could not determine an editor to use as default code is not found - you can change editor by updating config.ini"
        exit 1
      else
        log "ğŸ“– Opening /tmp/jmx_metrics.log with code (default) - you can change editor by updating config.ini"
        code /tmp/jmx_metrics.log
      fi
    fi
  fi
}

# https://www.linuxjournal.com/content/validating-ip-address-bash-script
function valid_ip()
{
    local  ip=$1
    local  stat=1

    if [[ $ip =~ ^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$ ]]; then
        OIFS=$IFS
        IFS='.'
        ip=($ip)
        IFS=$OIFS
        [[ ${ip[0]} -le 255 && ${ip[1]} -le 255 \
            && ${ip[2]} -le 255 && ${ip[3]} -le 255 ]]
        stat=$?
    fi
    return $stat
}

function container_to_name() {
    container=$1
    echo "${PWD##*/}_${container}_1"
}

function container_to_ip() {
    if [ $# -lt 1 ]; then
        echo "Usage: container_to_ip container"
    fi
    echo $(docker inspect $1 -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}')
}

function clear_traffic_control() {
    if [ $# -lt 1 ]; then
        echo "Usage: clear_traffic_control src_container"
    fi

    src_container=$1

    echo "Removing all traffic control settings on $src_container"

    # Delete the entry from the tc table so the changes made to tc do not persist
    docker exec --privileged -u0 -t $src_container tc qdisc del dev eth0 root
}

function get_latency() {
    if [ $# -lt 2 ]; then
        echo "Usage: get_latency src_container dst_container"
    fi
    src_container=$1
    dst_container=$2
    docker exec --privileged -u0 -t $src_container ping $dst_container -c 4 -W 80 | tail -1 | awk -F '/' '{print $5}'
}

# https://serverfault.com/a/906499
function add_latency() {
    if [ $# -lt 3 ]; then
        echo "Usage: add_latency src_container dst_container (or ip address) latency"
        echo "Example: add_latency container-1 container-2 100ms"
    fi

    src_container=$1
    if valid_ip $2
    then

      dst_ip=$2
    else

      dst_ip=$(container_to_ip $2)
    fi
    latency=$3

    set +e
    clear_traffic_control $src_container
    set -e

    echo "Adding $latency latency from $src_container to $2"

    # Add a classful priority queue which lets us differentiate messages.
    # This queue is named 1:.
    # Three children classes, 1:1, 1:2 and 1:3, are automatically created.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 root handle 1: prio

    # Add a filter to the parent queue 1: (also called 1:0). The filter has priority 1 (if we had more filters this would make a difference).
    # For all messages with the ip of dst_ip as their destination, it routes them to class 1:1, which
    # subsequently sends them to its only child, queue 10: (All messages need to  "end up" in a queue).
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol ip parent 1: prio 1 u32 match ip dst $dst_ip flowid 1:1

    # Route the rest of the of the packets without any control.
    # Add a filter to the parent queue 1:. The filter has priority 2.
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip dst 0.0.0.0/0 flowid 1:2
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip protocol 1 0xff flowid 1:2

    # Add a child queue named 10: under class 1:1. All outgoing packets that will be routed to 10: will have delay applied them.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:1 handle 10: netem delay $latency

    # Add a child queue named 20: under class 1:2
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:2 handle 20: sfq
}

function add_packet_corruption() {
    if [ $# -lt 3 ]; then
        echo "Usage: add_packet_corruption src_container dst_container (or ip address) corrupt"
        echo "Exemple: add_packet_corruption container-1 container-2 1%"
    fi

    src_container=$1
    if valid_ip $2
    then

      dst_ip=$2
    else

      dst_ip=$(container_to_ip $2)
    fi
    corruption=$3

    set +e
    clear_traffic_control $src_container
    set -e

    echo "Adding $corruption corruption from $src_container to $2"

    # Add a classful priority queue which lets us differentiate messages.
    # This queue is named 1:.
    # Three children classes, 1:1, 1:2 and 1:3, are automatically created.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 root handle 1: prio

    # Add a filter to the parent queue 1: (also called 1:0). The filter has priority 1 (if we had more filters this would make a difference).
    # For all messages with the ip of dst_ip as their destination, it routes them to class 1:1, which
    # subsequently sends them to its only child, queue 10: (All messages need to  "end up" in a queue).
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol ip parent 1: prio 1 u32 match ip dst $dst_ip flowid 1:1

    # Route the rest of the of the packets without any control.
    # Add a filter to the parent queue 1:. The filter has priority 2.
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip dst 0.0.0.0/0 flowid 1:2

    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip protocol 1 0xff flowid 1:2

    # Add a child queue named 10: under class 1:1. All outgoing packets that will be routed to 10: will have corrupt applied them.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:1 handle 10: netem corrupt $corruption

    # Add a child queue named 20: under class 1:2
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:2 handle 20: sfq

}

function add_packet_loss() {
    if [ $# -lt 3 ]; then
        echo "Usage: add_packet_loss src_container dst_container (or ip address) corrupt"
        echo "Exemple: add_packet_loss container-1 container-2 1%"
    fi

    src_container=$1
    if valid_ip $2
    then

      dst_ip=$2
    else

      dst_ip=$(container_to_ip $2)
    fi
    loss=$3

    set +e
    clear_traffic_control $src_container
    set -e

    echo "Adding $loss loss from $src_container to $2"

    # Add a classful priority queue which lets us differentiate messages.
    # This queue is named 1:.
    # Three children classes, 1:1, 1:2 and 1:3, are automatically created.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 root handle 1: prio

    # Add a filter to the parent queue 1: (also called 1:0). The filter has priority 1 (if we had more filters this would make a difference).
    # For all messages with the ip of dst_ip as their destination, it routes them to class 1:1, which
    # subsequently sends them to its only child, queue 10: (All messages need to  "end up" in a queue).
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol ip parent 1: prio 1 u32 match ip dst $dst_ip flowid 1:1

    # Route the rest of the of the packets without any control.
    # Add a filter to the parent queue 1:. The filter has priority 2.
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip dst 0.0.0.0/0 flowid 1:2

    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip protocol 1 0xff flowid 1:2

    # Add a child queue named 10: under class 1:1. All outgoing packets that will be routed to 10: will have loss applied them.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:1 handle 10: netem loss $loss

    # Add a child queue named 20: under class 1:2
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:2 handle 20: sfq

}

function get_3rdparty_file () {
  file="$1"

  if [ -f $file ]
  then
    log "$file already present, skipping"
    return
  fi

  folder="3rdparty"
  if [[ "$file" == *repro* ]]
  then
    folder="repro-files"
  fi
  set +e
  aws s3 ls s3://kafka-docker-playground/$folder/$file > /dev/null 2>&1
  if [ $? -eq 0 ]
  then
      log "Downloading <s3://kafka-docker-playground/$folder/$file> from S3 bucket"
      aws s3 cp --only-show-errors "s3://kafka-docker-playground/$folder/$file" .
      if [ $? -eq 0 ]; then
        log "ğŸ“„ <s3://kafka-docker-playground/$folder/$file> was downloaded from S3 bucket"
      fi
      if [[ "$OSTYPE" == "darwin"* ]]
      then
          # workaround for issue on linux, see https://github.com/vdesabou/kafka-docker-playground/issues/851#issuecomment-821151962
          chmod a+rw $file
      else
          # on CI, docker is run as runneradmin user, need to use sudo
          sudo chmod a+rw $file
      fi
  fi
  set -e
}

function remove_cdb_oracle_image() {
  ZIP_FILE="$1"
  SETUP_FOLDER="$2"

  if [ "$ZIP_FILE" == "linuxx64_12201_database.zip" ]
  then
      ORACLE_VERSION="12.2.0.1-ee"
  elif [ "$ZIP_FILE" == "LINUX.X64_180000_db_home.zip" ]
  then
      ORACLE_VERSION="18.3.0-ee"
  elif [ "$ZIP_FILE" == "LINUX.X64_213000_db_home.zip" ]
  then
      ORACLE_VERSION="21.3.0-ee"
  else
      ORACLE_VERSION="19.3.0-ee"
  fi

  SETUP_FILE=${SETUP_FOLDER}/01_user-setup.sh
  SETUP_FILE_CKSUM=$(cksum $SETUP_FILE | awk '{ print $1 }')
  if [ `uname -m` = "arm64" ]
  then
      export ORACLE_IMAGE="db-prebuilt-arm64-$SETUP_FILE_CKSUM:$ORACLE_VERSION"
  else
      export ORACLE_IMAGE="db-prebuilt-$SETUP_FILE_CKSUM:$ORACLE_VERSION"
  fi

  if ! test -z "$(docker images -q $ORACLE_IMAGE)"
  then
    log "ğŸ§¹ Removing Oracle image $ORACLE_IMAGE"
    docker image rm $ORACLE_IMAGE
  fi
}

function create_or_get_oracle_image() {
  ZIP_FILE="$1"
  SETUP_FOLDER="$2"

  if [ "$ZIP_FILE" == "linuxx64_12201_database.zip" ]
  then
      ORACLE_VERSION="12.2.0.1-ee"
  elif [ "$ZIP_FILE" == "LINUX.X64_180000_db_home.zip" ]
  then
      ORACLE_VERSION="18.3.0-ee"
  elif [ "$ZIP_FILE" == "LINUX.X64_213000_db_home.zip" ]
  then
      ORACLE_VERSION="21.3.0-ee"
  else
      if [ `uname -m` = "arm64" ]
      then
          ZIP_FILE="LINUX.ARM64_1919000_db_home.zip"
      else
          ZIP_FILE="LINUX.X64_193000_db_home.zip"
      fi
      ORACLE_VERSION="19.3.0-ee"
  fi
  # used for docker-images repo
  DOCKERFILE_VERSION=$(echo "$ORACLE_VERSION" | cut -d "-" -f 1)

  # https://github.com/oracle/docker-images/tree/main/OracleDatabase/SingleInstance/samples/prebuiltdb
  SETUP_FILE=${SETUP_FOLDER}/01_user-setup.sh
  SETUP_FILE_CKSUM=$(cksum $SETUP_FILE | awk '{ print $1 }')

  if [ `uname -m` = "arm64" ]
  then
      export ORACLE_IMAGE="db-prebuilt-arm64-$SETUP_FILE_CKSUM:$ORACLE_VERSION"
  else
      export ORACLE_IMAGE="db-prebuilt-$SETUP_FILE_CKSUM:$ORACLE_VERSION"
  fi
  TEMP_CONTAINER="oracle-build-$ORACLE_VERSION-$(basename $SETUP_FOLDER)"

  if test -z "$(docker images -q $ORACLE_IMAGE)"
  then
    set +e
    aws s3 ls s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar > /dev/null 2>&1
    if [ $? -eq 0 ]
    then
        log "Downloading <s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar> from S3 bucket"
        aws s3 cp --only-show-errors "s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar" .
        if [ $? -eq 0 ]
        then
          log "ğŸ“„ <s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar> was downloaded from S3 bucket"
          docker load -i $ORACLE_IMAGE.tar
          if [ $? -eq 0 ]
          then
            log "ğŸ“„ image $ORACLE_IMAGE has been installed locally"
          fi

          if [[ "$OSTYPE" == "darwin"* ]]
          then
            log "ğŸ§¹ Removing $ORACLE_IMAGE.tar"
            rm -f $ORACLE_IMAGE.tar
          else
            log "ğŸ§¹ Removing $ORACLE_IMAGE.tar with sudo"
            sudo rm -f $ORACLE_IMAGE.tar
          fi
        fi
    else
        logwarn "If you're a Confluent employee, please check this link https://confluent.slack.com/archives/C0116NM415F/p1636391410032900 and also here https://confluent.slack.com/archives/C0116NM415F/p1636389483030900."
    fi
    set -e
  fi

  if ! test -z "$(docker images -q $ORACLE_IMAGE)"
  then
    log "âœ¨ Using Oracle prebuilt image $ORACLE_IMAGE (oracle version ğŸ”¢ $ORACLE_VERSION and ğŸ“‚ setup folder $SETUP_FOLDER)"
    return
  fi

  BASE_ORACLE_IMAGE="oracle/database:$ORACLE_VERSION"

  if test -z "$(docker images -q $BASE_ORACLE_IMAGE)"
  then
    set +e
    aws s3 ls s3://kafka-docker-playground/3rdparty/oracle_database_$ORACLE_VERSION.tar > /dev/null 2>&1
    if [ $? -eq 0 ]
    then
        log "Downloading <s3://kafka-docker-playground/3rdparty/oracle_database_$ORACLE_VERSION.tar> from S3 bucket"
        aws s3 cp --only-show-errors "s3://kafka-docker-playground/3rdparty/oracle_database_$ORACLE_VERSION.tar" .
        if [ $? -eq 0 ]
        then
          log "ğŸ“„ <s3://kafka-docker-playground/3rdparty/oracle_database_$ORACLE_VERSION.tar> was downloaded from S3 bucket"
          docker load -i oracle_database_$ORACLE_VERSION.tar
          if [ $? -eq 0 ]
          then
            log "ğŸ“„ image $BASE_ORACLE_IMAGE has been installed locally"
          fi

          if [[ "$OSTYPE" == "darwin"* ]]
          then
            log "ğŸ§¹ Removing $ORACLE_IMAGE.tar"
            rm -f oracle_database_$ORACLE_VERSION.tar
          else
            log "ğŸ§¹ Removing $ORACLE_IMAGE.tar with sudo"
            sudo rm -f oracle_database_$ORACLE_VERSION.tar
          fi
        fi
    fi
    set -e
  fi

  if test -z "$(docker images -q $BASE_ORACLE_IMAGE)"
  then
      if [ ! -f ${ZIP_FILE} ]
      then
          set +e
          aws s3 ls s3://kafka-docker-playground/3rdparty/${ZIP_FILE} > /dev/null 2>&1
          if [ $? -eq 0 ]
          then
              log "Downloading <s3://kafka-docker-playground/3rdparty/${ZIP_FILE}> from S3 bucket"
              aws s3 cp --only-show-errors "s3://kafka-docker-playground/3rdparty/${ZIP_FILE}" .
              if [ $? -eq 0 ]; then
                    log "ğŸ“„ <s3://kafka-docker-playground/3rdparty/${ZIP_FILE}> was downloaded from S3 bucket"
              fi
          fi
          set -e
      fi
      if [ ! -f ${ZIP_FILE} ]
      then
          logerror "ERROR: ${ZIP_FILE} is missing. It must be downloaded manually in order to acknowledge user agreement"
          exit 1
      fi
      log "ğŸ‘· Building $BASE_ORACLE_IMAGE docker image..it can take a while...(more than 15 minutes!)"
      OLDDIR=$PWD
      rm -rf docker-images
      git clone https://github.com/oracle/docker-images.git

      mv ${ZIP_FILE} docker-images/OracleDatabase/SingleInstance/dockerfiles/$DOCKERFILE_VERSION/${ZIP_FILE}
      cd docker-images/OracleDatabase/SingleInstance/dockerfiles
      ./buildContainerImage.sh -v $DOCKERFILE_VERSION -e
      rm -rf docker-images
      cd ${OLDDIR}
  fi

  if test -z "$(docker images -q $ORACLE_IMAGE)"
  then
      log "ğŸ­ Prebuilt $ORACLE_IMAGE docker image does not exist, building it now..it can take a while..."
      log "ğŸš¦ Startup a container ${TEMP_CONTAINER} with setup folder $SETUP_FOLDER and create the database"
      cd $SETUP_FOLDER
      docker run -d -e ORACLE_PWD=Admin123 -v $PWD:/opt/oracle/scripts/setup --name ${TEMP_CONTAINER} ${BASE_ORACLE_IMAGE}
      cd -

      MAX_WAIT=2500
      CUR_WAIT=0
      log "âŒ› Waiting up to $MAX_WAIT seconds for ${TEMP_CONTAINER} to start"
      docker container logs ${TEMP_CONTAINER} > /tmp/out.txt 2>&1
      while [[ ! $(cat /tmp/out.txt) =~ "DATABASE IS READY TO USE" ]]; do
      sleep 10
      docker container logs ${TEMP_CONTAINER} > /tmp/out.txt 2>&1
      CUR_WAIT=$(( CUR_WAIT+10 ))
      if [[ "$CUR_WAIT" -gt "$MAX_WAIT" ]]; then
            logerror "ERROR: The logs in ${TEMP_CONTAINER} container do not show 'DATABASE IS READY TO USE' after $MAX_WAIT seconds. Please troubleshoot with 'docker container ps' and 'docker container logs'.\n"
            exit 1
      fi
      done
      log "${TEMP_CONTAINER} has started! Check logs in /tmp/${TEMP_CONTAINER}.log"
      docker container logs ${TEMP_CONTAINER} > /tmp/${TEMP_CONTAINER}.log 2>&1
      log "ğŸ›‘ Stop the running container"
      docker stop -t 600 ${TEMP_CONTAINER}
      log "ğŸ›  Create the image with the prebuilt database"
      docker commit -m "Image with prebuilt database" ${TEMP_CONTAINER} ${ORACLE_IMAGE}
      log "ğŸ§¹ Clean up ${TEMP_CONTAINER}"
      docker rm ${TEMP_CONTAINER}

      if [ ! -z "$GITHUB_RUN_NUMBER" ]
      then
          set +e
          aws s3 ls s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar > /dev/null 2>&1
          if [ $? -ne 0 ]
          then
              log "ğŸ“„ Uploading </tmp/$ORACLE_IMAGE.tar> to S3 bucket"
              docker save -o /tmp/$ORACLE_IMAGE.tar $ORACLE_IMAGE
              aws s3 cp --only-show-errors "/tmp/$ORACLE_IMAGE.tar" "s3://kafka-docker-playground/3rdparty/"
              if [ $? -eq 0 ]; then
                    log "ğŸ“„ </tmp/$ORACLE_IMAGE.tar> was uploaded to S3 bucket"
              fi
          fi
          set -e
      fi
  fi

  log "âœ¨ Using Oracle prebuilt image $ORACLE_IMAGE (oracle version ğŸ”¢ $ORACLE_VERSION and ğŸ“‚ setup folder $SETUP_FOLDER)"
}

function print_code_pass() {
  local MESSAGE=""
	local CODE=""
  OPTIND=1
  while getopts ":c:m:" opt; do
    case ${opt} in
			c ) CODE=${OPTARG};;
      m ) MESSAGE=${OPTARG};;
		esac
	done
  shift $((OPTIND-1))
	printf "${PRETTY_PASS}${PRETTY_CODE}%s\e[0m\n" "${CODE}"
	[[ -z "$MESSAGE" ]] || printf "\t$MESSAGE\n"

}
function print_code_error() {
  local MESSAGE=""
	local CODE=""
  OPTIND=1
  while getopts ":c:m:" opt; do
    case ${opt} in
			c ) CODE=${OPTARG};;
      m ) MESSAGE=${OPTARG};;
		esac
	done
  shift $((OPTIND-1))
	printf "${PRETTY_ERROR}${PRETTY_CODE}%s\e[0m\n" "${CODE}"
	[[ -z "$MESSAGE" ]] || printf "\t$MESSAGE\n"

}

function exit_with_error()
{
  local USAGE="\nUsage: exit_with_error -c code -n name -m message -l line_number\n"
  local NAME=""
  local MESSAGE=""
  local CODE=$UNSPECIFIED_ERROR
  local LINE=
  OPTIND=1
  while getopts ":n:m:c:l:" opt; do
    case ${opt} in
      n ) NAME=${OPTARG};;
      m ) MESSAGE=${OPTARG};;
      c ) CODE=${OPTARG};;
      l ) LINE=${OPTARG};;
      ? ) printf $USAGE;return 1;;
    esac
  done
  shift $((OPTIND-1))
  print_error "error ${CODE} occurred in ${NAME} at line $LINE"
	printf "\t${MESSAGE}\n"
  exit $CODE
}

function maybe_delete_ccloud_environment () {
  DELTA_CONFIGS_ENV=/tmp/delta_configs/env.delta

  if [ -f $DELTA_CONFIGS_ENV ]
  then
    source $DELTA_CONFIGS_ENV
  else
    logerror "ERROR: $DELTA_CONFIGS_ENV has not been generated"
    exit 1
  fi

  if [ -z "$CLUSTER_NAME" ]
  then
    #

    # CLUSTER_NAME is not set
    #
    log "ğŸ§¹âŒ Confluent Cloud cluster will be deleted..."
    verify_installed "confluent"
    check_confluent_version 2.0.0 || exit 1
    verify_confluent_login  "confluent kafka cluster list"

    export QUIET=true

    if [ ! -z "$ENVIRONMENT" ]
    then
      log "ğŸŒ ENVIRONMENT $ENVIRONMENT is set, it will not be deleted"
      export PRESERVE_ENVIRONMENT=true
    else
      export PRESERVE_ENVIRONMENT=false
    fi
    SERVICE_ACCOUNT_ID=$(ccloud:get_service_account_from_current_cluster_name)
    set +e
    ccloud::destroy_ccloud_stack $SERVICE_ACCOUNT_ID
    set -e
  fi
}

function bootstrap_ccloud_environment () {
  DELTA_CONFIGS_ENV=/tmp/delta_configs/env.delta

  if [ -z "$GITHUB_RUN_NUMBER" ] && [ -z "$CLOUDFORMATION" ]
  then
    # not running with CI
    verify_installed "confluent"
    check_confluent_version 3.0.0 || exit 1
    verify_confluent_login  "confluent kafka cluster list"
  else
      log "Installing confluent CLI"
      curl -L --http1.1 https://cnfl.io/cli | sudo sh -s -- -b /usr/local/bin
      export PATH=$PATH:/usr/local/bin
      log "##################################################"
      log "Log in to Confluent Cloud"
      log "##################################################"
      confluent login --save
  fi

  if [ -z "$CLUSTER_NAME" ]
  then
    #

    # CLUSTER_NAME is not set
    #
    log "ğŸ› ğŸ‘·â€â™€ï¸ CLUSTER_NAME is not set, a new Confluent Cloud cluster will be created..."
    log "ğŸ“ If you wanted to use an existing cluster, set CLUSTER_NAME, ENVIRONMENT, CLUSTER_CLOUD, CLUSTER_REGION and CLUSTER_CREDS (also optionnaly SCHEMA_REGISTRY_CREDS)"

    if [ -z "$CLUSTER_CLOUD" ] || [ -z "$CLUSTER_REGION" ]
    then
      logwarn "CLUSTER_CLOUD and/or CLUSTER_REGION are not set, the cluster will be created ğŸŒ¤ AWS provider and ğŸ—º eu-west-2 region"
      export CLUSTER_CLOUD=aws

      export CLUSTER_REGION=eu-west-2
    fi

    if [ ! -z $ENVIRONMENT ]
    then
      log "ğŸŒ ENVIRONMENT is set with $ENVIRONMENT and will be used"
    fi
    log "ğŸ”‹  CLUSTER_TYPE is set with $CLUSTER_TYPE"
    log "ğŸŒ¤  CLUSTER_CLOUD is set with $CLUSTER_CLOUD"
    log "ğŸ—º  CLUSTER_REGION is set with $CLUSTER_REGION"

    export EXAMPLE=$(basename $PWD)
    export WARMUP_TIME=15
    export QUIET=true

    check_if_continue
  else
    #

    # CLUSTER_NAME is set
    #
    log "ğŸŒ± CLUSTER_NAME is set, your existing Confluent Cloud cluster will be used..."
    if [ -z $ENVIRONMENT ] || [ -z $CLUSTER_CLOUD ] || [ -z $CLUSTER_CLOUD ] || [ -z $CLUSTER_REGION ] || [ -z $CLUSTER_CREDS ]
    then
      logerror "One mandatory environment variable to use your cluster is missing:"
      logerror "ENVIRONMENT=$ENVIRONMENT"
      logerror "CLUSTER_NAME=$CLUSTER_NAME"
      logerror "CLUSTER_CLOUD=$CLUSTER_CLOUD"
      logerror "CLUSTER_REGION=$CLUSTER_REGION"
      logerror "CLUSTER_CREDS=$CLUSTER_CREDS"
      exit 1
    fi

    log "ğŸŒ ENVIRONMENT is set with $ENVIRONMENT"
    log "ğŸ° CLUSTER_NAME is set with $CLUSTER_NAME"
    log "ğŸŒ¤  CLUSTER_CLOUD is set with $CLUSTER_CLOUD"
    log "ğŸ—º  CLUSTER_REGION is set with $CLUSTER_REGION"

    export WARMUP_TIME=0
  fi

  ccloud::create_ccloud_stack false  \
    && print_code_pass -c "ccloud::create_ccloud_stack false"

  CCLOUD_CONFIG_FILE=/tmp/tmp.config
  export CCLOUD_CONFIG_FILE=$CCLOUD_CONFIG_FILE
  ccloud::validate_ccloud_config $CCLOUD_CONFIG_FILE || exit 1

  ccloud::generate_configs $CCLOUD_CONFIG_FILE \
    && print_code_pass -c "ccloud::generate_configs $CCLOUD_CONFIG_FILE"

  if [ -f $DELTA_CONFIGS_ENV ]
  then
    source $DELTA_CONFIGS_ENV
  else
    logerror "ERROR: $DELTA_CONFIGS_ENV has not been generated"
    exit 1
  fi

  # trick
  echo "ccloud/environment" > /tmp/playground-command
}

function create_ccloud_connector() {
  file=$1

  log "ğŸ› ï¸ Creating connector from $file"
  confluent connect cluster create --config-file $file
  if [[ $? != 0 ]]
  then
    logerror "Exit status was not 0 while creating connector from $file.  Please troubleshoot and try again"
  fi

  return 0
}

function validate_ccloud_connector_up() {
  confluent connect cluster list -o json | jq -e 'map(select(.name == "'"$1"'" and .status == "RUNNING")) | .[]' > /dev/null 2>&1
}

function get_ccloud_connector_lcc() {
  confluent connect cluster list -o json | jq -r -e 'map(select(.name == "'"$1"'")) | .[].id'
}

function ccloud::retry() {
    local -r -i max_wait="$1"; shift
    local -r cmd="$@"

    local -i sleep_interval=5
    local -i curr_wait=0

    until $cmd
    do
        if (( curr_wait >= max_wait ))
        then
            echo "ERROR: Failed after $curr_wait seconds. Please troubleshoot and run again."
            return 1
        else
            printf "."
            curr_wait=$((curr_wait+sleep_interval))
            sleep $sleep_interval
        fi
    done
    printf "\n"
}

function wait_for_ccloud_connector_up() {
  connectorName=$1
  maxWait=$2

  connectorId=$(get_ccloud_connector_lcc $connectorName)
  log "Waiting up to $maxWait seconds for connector $connectorName ($connectorId) to be RUNNING"
  ccloud::retry $maxWait validate_ccloud_connector_up $connectorName || exit 1
  log "Connector $connectorName ($connectorId) is RUNNING"

  return 0
}

function delete_ccloud_connector() {
  connectorName=$1
  connectorId=$(get_ccloud_connector_lcc $connectorName)

  log "Deleting connector $connectorName ($connectorId)"
  confluent connect cluster delete $connectorId --force
  return 0
}

function wait_for_log () {
     message="$1"
     container=${2:-connect}
     max_wait=${3:-600}
     cur_wait=0
     log "âŒ› Waiting up to $max_wait seconds for message $message to be present in $container container logs..."
     docker container logs connect > /tmp/out.txt 2>&1
     while ! grep "$message" /tmp/out.txt > /dev/null;
     do
          sleep 10
          docker container logs connect > /tmp/out.txt 2>&1
          cur_wait=$(( cur_wait+10 ))
          if [[ "$cur_wait" -gt "$max_wait" ]]; then
               logerror "The logs in $container container do not show '$message' after $max_wait seconds. Please troubleshoot with 'docker container ps' and 'docker container logs'."
               return 1
          fi
     done
     grep "$message" /tmp/out.txt
     log "The log is there !"
}


CLI_MIN_VERSION=${CLI_MIN_VERSION:-2.5.0}

# --------------------------------------------------------------
# Library
# --------------------------------------------------------------

function ccloud::validate_expect_installed() {
  if [[ $(type expect 2>&1) =~ "not found" ]]; then
    echo "'expect' is not found. Install 'expect' and try again"
    exit 1
  fi

  return 0
}
function ccloud::validate_cli_installed() {
  if [[ $(type confluent 2>&1) =~ "not found" ]]; then
    echo "'confluent' is not found. Install the Confluent CLI (https://docs.confluent.io/confluent-cli/current/install.html) and try again."
    exit 1
  fi
}

function ccloud::validate_cli_v2() {
  ccloud::validate_cli_installed || exit 1

  if [[ -z $(confluent version 2>&1 | grep "Go") ]]; then
    echo "This example requires the new Confluent CLI. Please update your version and try again."
    exit 1
  fi

  return 0
}

function ccloud::validate_logged_in_cli() {
  ccloud::validate_cli_v2 || exit 1

  if [[ "$(confluent kafka cluster list 2>&1)" =~ "confluent login" ]]; then
    echo
    echo "ERROR: Not logged into Confluent Cloud."
    echo "Log in with the command 'confluent login --save' before running the example. The '--save' argument saves your Confluent Cloud user login credentials or refresh token (in the case of SSO) to the local netrc file."
    exit 1
  fi

  return 0
}

function ccloud::get_version_cli() {
  confluent version | grep "^Version:" | cut -d':' -f2 | cut -d'v' -f2
}

function ccloud::validate_version_cli() {
  ccloud::validate_cli_installed || exit 1

  CLI_VERSION=$(ccloud::get_version_cli)

  if ccloud::version_gt $CLI_MIN_VERSION $CLI_VERSION; then
    echo "confluent version ${CLI_MIN_VERSION} or greater is required. Current version: ${CLI_VERSION}"
    echo "To update, follow: https://docs.confluent.io/confluent-cli/current/migrate.html"
    exit 1
  fi
}

function ccloud::validate_psql_installed() {
  if [[ $(type psql 2>&1) =~ "not found" ]]; then
    echo "psql is not found. Install psql and try again"
    exit 1
  fi

  return 0
}

function ccloud::validate_aws_cli_installed() {
  if [[ $(type aws 2>&1) =~ "not found" ]]; then
    echo "AWS CLI is not found. Install AWS CLI and try again"
    exit 1
  fi

  return 0
}

function ccloud::get_version_aws_cli() {
  version_major=$(aws --version 2>&1 | awk -F/ '{print $2;}' | head -c 1)
  if [[ "$version_major" -eq 2 ]]; then
    echo "2"
  else
    echo "1"
  fi
  return 0
}

function ccloud::validate_gsutil_installed() {
  if [[ $(type gsutil 2>&1) =~ "not found" ]]; then
    echo "Google Cloud gsutil is not found. Install Google Cloud gsutil and try again"
    exit 1
  fi

  return 0
}

function ccloud::validate_az_installed() {
  if [[ $(type az 2>&1) =~ "not found" ]]; then
    echo "Azure CLI is not found. Install Azure CLI and try again"
    exit 1
  fi

  return 0
}

function ccloud::validate_cloud_source() {
  config=$1

  source $config

  if [[ "$DATA_SOURCE" == "kinesis" ]]; then
    ccloud::validate_aws_cli_installed || exit 1
    if [[ -z "$KINESIS_REGION" || -z "$AWS_PROFILE" ]]; then
      echo "ERROR: DATA_SOURCE=kinesis, but KINESIS_REGION or AWS_PROFILE is not set.  Please set these parameters in config/demo.cfg and try again."
      exit 1
    fi
    aws kinesis list-streams --profile $AWS_PROFILE --region $KINESIS_REGION > /dev/null \
      || { echo "Could not run 'aws kinesis list-streams'.  Check credentials and run again." ; exit 1; }
  elif [[ "$DATA_SOURCE" == "rds" ]]; then
    ccloud::validate_aws_cli_installed || exit 1
    if [[ -z "$RDS_REGION" || -z "$AWS_PROFILE" ]]; then
      echo "ERROR: DATA_SOURCE=rds, but RDS_REGION or AWS_PROFILE is not set.  Please set these parameters in config/demo.cfg and try again."
      exit 1
    fi
    aws rds describe-db-instances --profile $AWS_PROFILE --region $RDS_REGION > /dev/null \
      || { echo "Could not run 'aws rds describe-db-instances'.  Check credentials and run again." ; exit 1; }
  else
    echo "Cloud source $cloudsource is not valid.  Must be one of [kinesis|rds]."
    exit 1
  fi

  return 0
}

function ccloud::validate_cloud_storage() {
  config=$1

  source $config
  storage=$DESTINATION_STORAGE

  if [[ "$storage" == "s3" ]]; then
    ccloud::validate_aws_cli_installed || exit 1
    ccloud::validate_credentials_s3 $S3_PROFILE $S3_BUCKET || exit 1
    aws s3api list-buckets --profile $S3_PROFILE --region $STORAGE_REGION > /dev/null \
      || { echo "Could not run 'aws s3api list-buckets'.  Check credentials and run again." ; exit 1; }
  elif [[ "$storage" == "gcs" ]]; then
    ccloud::validate_gsutil_installed || exit 1
    ccloud::validate_credentials_gcp $GCS_CREDENTIALS_FILE $GCS_BUCKET || exit 1
  elif [[ "$storage" == "az" ]]; then
    ccloud::validate_az_installed || exit 1
    ccloud::validate_credentials_az $AZBLOB_STORAGE_ACCOUNT $AZBLOB_CONTAINER || exit 1
  else
    echo "Storage destination $storage is not valid.  Must be one of [s3|gcs|az]."
    exit 1
  fi

  return 0
}

function ccloud::validate_credentials_gcp() {
  GCS_CREDENTIALS_FILE=$1
  GCS_BUCKET=$2

  if [[ -z "$GCS_CREDENTIALS_FILE" || -z "$GCS_BUCKET" ]]; then
    echo "ERROR: DESTINATION_STORAGE=gcs, but GCS_CREDENTIALS_FILE or GCS_BUCKET is not set.  Please set these parameters in config/demo.cfg and try again."
    exit 1
  fi

  gcloud auth activate-service-account --key-file $GCS_CREDENTIALS_FILE || {
    echo "ERROR: Cannot activate service account with key file $GCS_CREDENTIALS_FILE. Verify your credentials and try again."
    exit 1
  }

  # Create JSON-formatted string of the GCS credentials
  export GCS_CREDENTIALS=$(python ./stringify-gcp-credentials.py $GCS_CREDENTIALS_FILE)
  # Remove leading and trailing double quotes, otherwise connector creation from CLI fails
  GCS_CREDENTIALS=$(echo "${GCS_CREDENTIALS:1:${#GCS_CREDENTIALS}-2}")

  return 0
}

function ccloud::validate_credentials_az() {
  AZBLOB_STORAGE_ACCOUNT=$1
  AZBLOB_CONTAINER=$2

  if [[ -z "$AZBLOB_STORAGE_ACCOUNT" || -z "$AZBLOB_CONTAINER" ]]; then
    echo "ERROR: DESTINATION_STORAGE=az, but AZBLOB_STORAGE_ACCOUNT or AZBLOB_CONTAINER is not set.  Please set these parameters in config/demo.cfg and try again."
    exit 1
  fi

  if [[ "$AZBLOB_STORAGE_ACCOUNT" == "default" ]]; then
    echo "ERROR: Azure Blob storage account name cannot be 'default'. Verify the value of the storage account name (did you create one?) in config/demo.cfg, as specified by the parameter AZBLOB_STORAGE_ACCOUNT, and try again."
    exit 1
  fi

  exists=$(az storage account check-name --name $AZBLOB_STORAGE_ACCOUNT | jq -r .reason)
  if [[ "$exists" != "AlreadyExists" ]]; then
    echo "ERROR: Azure Blob storage account name $AZBLOB_STORAGE_ACCOUNT does not exist. Check the value of AZBLOB_STORAGE_ACCOUNT in config/demo.cfg and try again."
    exit 1
  fi
  export AZBLOB_ACCOUNT_KEY=$(az storage account keys list --account-name $AZBLOB_STORAGE_ACCOUNT | jq -r '.[0].value')
  if [[ "$AZBLOB_ACCOUNT_KEY" == "" ]]; then
    echo "ERROR: Cannot get the key for Azure Blob storage account name $AZBLOB_STORAGE_ACCOUNT. Check the value of AZBLOB_STORAGE_ACCOUNT in config/demo.cfg, and your key, and try again."
    exit 1
  fi

  return 0
}

function ccloud::validate_credentials_s3() {
  S3_PROFILE=$1
  S3_BUCKET=$2

  if [[ -z "$S3_PROFILE" || -z "$S3_BUCKET" ]]; then
    echo "ERROR: DESTINATION_STORAGE=s3, but S3_PROFILE or S3_BUCKET is not set.  Please set these parameters in config/demo.cfg and try again."
    exit 1
  fi

  aws configure get aws_access_key_id --profile $S3_PROFILE 1>/dev/null || {
    echo "ERROR: Cannot determine aws_access_key_id from S3_PROFILE=$S3_PROFILE.  Verify your credentials and try again."
    exit 1
  }
  aws configure get aws_secret_access_key --profile $S3_PROFILE 1>/dev/null || {
    echo "ERROR: Cannot determine aws_secret_access_key from S3_PROFILE=$S3_PROFILE.  Verify your credentials and try again."
    exit 1
  }
  return 0
}

function ccloud::validate_schema_registry_up() {
  auth=$1
  sr_endpoint=$2

  curl --silent -u $auth $sr_endpoint > /dev/null || {
    echo "ERROR: Could not validate credentials to Confluent Cloud Schema Registry. Please troubleshoot"
    exit 1
  }

  echo "Validated credentials to Confluent Cloud Schema Registry at $sr_endpoint"
  return 0
}

function ccloud::get_environment_id_from_service_id() {
  SERVICE_ACCOUNT_ID=$1

  ENVIRONMENT_NAME_PREFIX=${ENVIRONMENT_NAME_PREFIX:-"pg-$SERVICE_ACCOUNT_ID"}
  local environment_id=$(confluent environment list -o json | jq -r 'map(select(.name | startswith("'"$ENVIRONMENT_NAME_PREFIX"'"))) | .[].id')

  echo $environment_id

  return 0
}

function ccloud::create_and_use_environment() {
  ENVIRONMENT_NAME=$1

  OUTPUT=$(confluent environment create $ENVIRONMENT_NAME -o json)
  (($? != 0)) && { echo "ERROR: Failed to create environment $ENVIRONMENT_NAME. Please troubleshoot and run again"; exit 1; }
  ENVIRONMENT=$(echo "$OUTPUT" | jq -r ".id")
  confluent environment use $ENVIRONMENT &>/dev/null

  echo $ENVIRONMENT

  return 0
}

function ccloud::find_cluster() {
  CLUSTER_NAME=$1
  CLUSTER_CLOUD=$2
  CLUSTER_REGION=$3

  local FOUND_CLUSTER=$(confluent kafka cluster list -o json | jq -c -r '.[] | select((.name == "'"$CLUSTER_NAME"'") and (.provider == "'"$CLUSTER_CLOUD"'") and (.region == "'"$CLUSTER_REGION"'"))')
  [[ ! -z "$FOUND_CLUSTER" ]] && {
      echo "$FOUND_CLUSTER" | jq -r .id
      return 0

    } || {
      return 1
    }
}

function ccloud::create_and_use_cluster() {
  CLUSTER_NAME=$1
  CLUSTER_CLOUD=$2
  CLUSTER_REGION=$3
  CLUSTER_TYPE=$4

  OUTPUT=$(confluent kafka cluster create "$CLUSTER_NAME" --cloud $CLUSTER_CLOUD --region $CLUSTER_REGION --type $CLUSTER_TYPE --output json 2>&1)
  (($? != 0)) && { echo "$OUTPUT"; exit 1; }
  CLUSTER=$(echo "$OUTPUT" | jq -r .id)
  confluent kafka cluster use $CLUSTER 2>/dev/null
  echo $CLUSTER

  return 0
}

function ccloud::maybe_create_and_use_cluster() {
  CLUSTER_NAME=$1
  CLUSTER_CLOUD=$2
  CLUSTER_REGION=$3
  CLUSTER_TYPE=$4
  CLUSTER_ID=$(ccloud::find_cluster $CLUSTER_NAME $CLUSTER_CLOUD $CLUSTER_REGION)
  if [ $? -eq 0 ]
  then
    confluent kafka cluster use $CLUSTER_ID
    echo $CLUSTER_ID
  else

    # VINC: added
    if [[ ! -z "$CLUSTER_CREDS" ]]
    then
      echo "ERROR: Could not find your $CLUSTER_CLOUD cluster $CLUSTER_NAME in region $CLUSTER_REGION"
      echo "Make sure CLUSTER_CLOUD and CLUSTER_REGION are set with values that correspond to your cluster!"
      exit 1
    else
      OUTPUT=$(ccloud::create_and_use_cluster "$CLUSTER_NAME" "$CLUSTER_CLOUD" "$CLUSTER_REGION" "$CLUSTER_TYPE")
      (($? != 0)) && { echo "$OUTPUT"; exit 1; }
      echo "$OUTPUT"
    fi
  fi

  return 0
}

function ccloud::create_service_account() {
  SERVICE_NAME=$1

  CCLOUD_EMAIL=$(confluent prompt -f '%u')
  OUTPUT=$(confluent iam service-account create $SERVICE_NAME --description "SA for $EXAMPLE run by $CCLOUD_EMAIL"  -o json)
  SERVICE_ACCOUNT_ID=$(echo "$OUTPUT" | jq -r ".id")

  echo $SERVICE_ACCOUNT_ID

  return 0
}

function ccloud:get_service_account_from_current_cluster_name() {
  SERVICE_ACCOUNT_ID=$(confluent kafka cluster describe -o json | jq -r '.name' | awk -F'-' '{print $3 "-" $4;}')

  echo $SERVICE_ACCOUNT_ID

  return 0
}

function ccloud::enable_schema_registry() {
  SCHEMA_REGISTRY_CLOUD=$1
  SCHEMA_REGISTRY_GEO=$2

  OUTPUT=$(confluent schema-registry cluster enable --cloud $SCHEMA_REGISTRY_CLOUD --geo $SCHEMA_REGISTRY_GEO -o json)
  SCHEMA_REGISTRY=$(echo "$OUTPUT" | jq -r ".id")

  echo $SCHEMA_REGISTRY

  return 0
}

function ccloud::find_credentials_resource() {
  SERVICE_ACCOUNT_ID=$1
  RESOURCE=$2
  local FOUND_CRED=$(confluent api-key list -o json | jq -c -r 'map(select((.resource_id == "'"$RESOURCE"'") and (.owner_resource_id == "'"$SERVICE_ACCOUNT_ID"'")))')
  local FOUND_COUNT=$(echo "$FOUND_CRED" | jq 'length')
  [[ $FOUND_COUNT -ne 0 ]] && {
      echo "$FOUND_CRED" | jq -r '.[0].api_key'
      return 0

    } || {
      return 1
    }
}
function ccloud::create_credentials_resource() {
  SERVICE_ACCOUNT_ID=$1
  RESOURCE=$2

  OUTPUT=$(confluent api-key create --service-account $SERVICE_ACCOUNT_ID --resource $RESOURCE -o json)
  API_KEY_SA=$(echo "$OUTPUT" | jq -r ".api_key")
  API_SECRET_SA=$(echo "$OUTPUT" | jq -r ".api_secret")
  echo "${API_KEY_SA}:${API_SECRET_SA}"

  # vinc
  sleep 30
  return 0
}
# The return from this function will be a colon ':' delimited
#   list, if the api-key is created the second element of the
#   list will be the secret.  If the api-key is being reused
#   the second element of the list will be empty
function ccloud::maybe_create_credentials_resource() {
  SERVICE_ACCOUNT_ID=$1
  RESOURCE=$2

  local KEY=$(ccloud::find_credentials_resource $SERVICE_ACCOUNT_ID $RESOURCE)
  [[ -z $KEY ]] && {
    ccloud::create_credentials_resource $SERVICE_ACCOUNT_ID $RESOURCE
  } || {
    echo "$KEY:"; # the secret cannot be retrieved from a found key, caller needs to handle this
    return 0
  }
}

function ccloud::find_ksqldb_app() {
  KSQLDB_NAME=$1
  CLUSTER=$2

  local FOUND_APP=$(confluent ksql cluster list -o json | jq -c -r 'map(select((.name == "'"$KSQLDB_NAME"'") and (.kafka == "'"$CLUSTER"'")))')
  local FOUND_COUNT=$(echo "$FOUND_APP" | jq 'length')
  [[ $FOUND_COUNT -ne 0 ]] && {
      echo "$FOUND_APP" | jq -r '.[].id'
      return 0

    } || {
      return 1
    }
}

function ccloud::create_ksqldb_app() {
  KSQLDB_NAME=$1
  CLUSTER=$2
  # colon deliminated credentials (APIKEY:APISECRET)
  local ksqlDB_kafka_creds=$3
  local kafka_api_key=$(echo $ksqlDB_kafka_creds | cut -d':' -f1)
  local kafka_api_secret=$(echo $ksqlDB_kafka_creds | cut -d':' -f2)

  KSQLDB=$(confluent ksql cluster create --cluster $CLUSTER --api-key "$kafka_api_key" --api-secret "$kafka_api_secret" --csu 1 -o json "$KSQLDB_NAME" | jq -r ".id")
  echo $KSQLDB

  return 0
}
function ccloud::maybe_create_ksqldb_app() {
  KSQLDB_NAME=$1
  CLUSTER=$2
  # colon deliminated credentials (APIKEY:APISECRET)
  local ksqlDB_kafka_creds=$3

  APP_ID=$(ccloud::find_ksqldb_app $KSQLDB_NAME $CLUSTER)
  if [ $? -eq 0 ]
  then
    echo $APP_ID
  else
    ccloud::create_ksqldb_app "$KSQLDB_NAME" "$CLUSTER" "$ksqlDB_kafka_creds"
  fi

  return 0
}

function ccloud::create_acls_all_resources_full_access() {
  SERVICE_ACCOUNT_ID=$1
  # Setting default QUIET=false to surface potential errors
  QUIET="${QUIET:-false}"
  [[ $QUIET == "true" ]] &&
    local REDIRECT_TO="/dev/null" ||
    local REDIRECT_TO="/dev/tty"

  confluent kafka acl create --allow --service-account $SERVICE_ACCOUNT_ID --operations CREATE,DELETE,WRITE,READ,DESCRIBE,DESCRIBE_CONFIGS --topic '*' &>"$REDIRECT_TO"

  confluent kafka acl create --allow --service-account $SERVICE_ACCOUNT_ID --operations READ,WRITE,CREATE,DESCRIBE --consumer-group '*' &>"$REDIRECT_TO"

  confluent kafka acl create --allow --service-account $SERVICE_ACCOUNT_ID --operations DESCRIBE,WRITE --transactional-id '*' &>"$REDIRECT_TO"

  confluent kafka acl create --allow --service-account $SERVICE_ACCOUNT_ID --operations IDEMPOTENT-WRITE,DESCRIBE --cluster-scope &>"$REDIRECT_TO"

  return 0
}

function ccloud::delete_acls_ccloud_stack() {
  SERVICE_ACCOUNT_ID=$1
  # Setting default QUIET=false to surface potential errors
  QUIET="${QUIET:-false}"
  [[ $QUIET == "true" ]] &&
    local REDIRECT_TO="/dev/null" ||
    local REDIRECT_TO="/dev/tty"

  echo "Deleting ACLs for service account ID $SERVICE_ACCOUNT_ID"

  confluent kafka acl delete --allow --service-account $SERVICE_ACCOUNT_ID --operations CREATE,DELETE,WRITE,READ,DESCRIBE,DESCRIBE_CONFIGS --topic '*' &>"$REDIRECT_TO"

  confluent kafka acl delete --allow --service-account $SERVICE_ACCOUNT_ID --operations READ,WRITE,CREATE,DESCRIBE --consumer-group '*' &>"$REDIRECT_TO"

  confluent kafka acl delete --allow --service-account $SERVICE_ACCOUNT_ID --operations DESCRIBE,WRITE --transactional-id '*' &>"$REDIRECT_TO"

  confluent kafka acl delete --allow --service-account $SERVICE_ACCOUNT_ID --operations IDEMPOTENT-WRITE,DESCRIBE --cluster-scope &>"$REDIRECT_TO"

  return 0
}

function ccloud::validate_ccloud_config() {
  [ -z "$1" ] && {
    echo "ccloud::validate_ccloud_config expects one parameter (configuration file with Confluent Cloud connection information)"
    exit 1
  }

  local cfg_file="$1"
  local bootstrap=$(grep "bootstrap\.servers" "$cfg_file" | cut -d'=' -f2-)
  [ -z "$bootstrap" ] && {
    echo "ERROR: Cannot read the 'bootstrap.servers' key-value pair from $cfg_file."
    exit 1;
  }
  return 0;
}

function ccloud::validate_ksqldb_up() {
  [ -z "$1" ] && {
    echo "ccloud::validate_ksqldb_up expects one parameter (ksqldb endpoint)"
    exit 1
  }

  [ $# -gt 1 ] && echo "WARN: ccloud::validate_ksqldb_up function expects one parameter"

  local ksqldb_endpoint=$1

  ccloud::validate_logged_in_cli || exit 1

  local ksqldb_meta=$(confluent ksql cluster list -o json | jq -r 'map(select(.endpoint == "'"$ksqldb_endpoint"'")) | .[]')

  local ksqldb_appid=$(echo "$ksqldb_meta" | jq -r '.id')
  if [[ "$ksqldb_appid" == "" ]]; then
    echo "ERROR: Confluent Cloud ksqlDB endpoint $ksqldb_endpoint is not found. Provision a ksqlDB cluster via the Confluent Cloud UI and add the configuration parameter ksql.endpoint and ksql.basic.auth.user.info into your Confluent Cloud configuration file at $ccloud_config_file and try again."
    exit 1
  fi

  local ksqldb_status=$(echo "$ksqldb_meta" | jq -r '.status')
  if [[ $ksqldb_status != "UP" ]]; then
    echo "ERROR: Confluent Cloud ksqlDB endpoint $ksqldb_endpoint with id $ksqlDBAppId is not in UP state. Troubleshoot and try again."
    exit 1
  fi

  return 0
}

function ccloud::validate_azure_account() {
  AZBLOB_STORAGE_ACCOUNT=$1

  if [[ "$AZBLOB_STORAGE_ACCOUNT" == "default" ]]; then
    echo "ERROR: Azure Blob storage account name cannot be 'default'. Verify the value of the storage account name (did you create one?) in config/demo.cfg, as specified by the parameter AZBLOB_STORAGE_ACCOUNT, and try again."
    exit 1
  fi

  exists=$(az storage account check-name --name $AZBLOB_STORAGE_ACCOUNT | jq -r .reason)
  if [[ "$exists" != "AlreadyExists" ]]; then
    echo "ERROR: Azure Blob storage account name $AZBLOB_STORAGE_ACCOUNT does not exist. Check the value of STORAGE_PROFILE in config/demo.cfg and try again."
    exit 1
  fi
  export AZBLOB_ACCOUNT_KEY=$(az storage account keys list --account-name $AZBLOB_STORAGE_ACCOUNT | jq -r '.[0].value')
  if [[ "$AZBLOB_ACCOUNT_KEY" == "" ]]; then
    echo "ERROR: Cannot get the key for Azure Blob storage account name $AZBLOB_STORAGE_ACCOUNT. Check the value of STORAGE_PROFILE in config/demo.cfg, and your key, and try again."
    exit 1
  fi

  return 0
}

function ccloud::validate_credentials_ksqldb() {
  ksqldb_endpoint=$1
  ccloud_config_file=$2
  credentials=$3

  response=$(curl ${ksqldb_endpoint}/info \
             -H "Content-Type: application/vnd.ksql.v1+json; charset=utf-8" \
             --silent \
             -u $credentials)
  if [[ "$response" =~ "Unauthorized" ]]; then
    echo "ERROR: Authorization failed to the ksqlDB cluster. Check your ksqlDB credentials set in the configuration parameter ksql.basic.auth.user.info in your Confluent Cloud configuration file at $ccloud_config_file and try again."
    exit 1
  fi

  echo "Validated credentials to Confluent Cloud ksqlDB at $ksqldb_endpoint"
  return 0
}

function ccloud::create_connector() {
  file=$1

  echo -e "\nCreating connector from $file\n"

  # About the Confluent CLI command 'confluent connect cluster create':
  # - Typical usage of this CLI would be 'confluent connect cluster create --config-file <filename>'
  # - However, in this example, the connector's configuration file contains parameters that need to be first substituted
  #   so the CLI command includes eval and heredoc.
  # - The '-vvv' is added for verbose output
  confluent connect cluster create -vvv --config <(eval "cat <<EOF
$(<$file)
EOF
")
  if [[ $? != 0 ]]; then
    echo "ERROR: Exit status was not 0 while creating connector from $file.  Please troubleshoot and try again"
    exit 1
  fi

  return 0
}

function ccloud::validate_connector_up() {
  confluent connect cluster list -o json | jq -e 'map(select(.name == "'"$1"'" and .status == "RUNNING")) | .[]' > /dev/null 2>&1
}

function ccloud::wait_for_connector_up() {
  connectorName=$1
  maxWait=$2

  echo "Waiting up to $maxWait seconds for connector $filename ($connectorName) to be RUNNING"
  ccloud::retry $maxWait ccloud::validate_connector_up $connectorName || exit 1
  echo "Connector $filename ($connectorName) is RUNNING"

  return 0
}

function ccloud::validate_ccloud_ksqldb_endpoint_ready() {
  KSQLDB_ENDPOINT=$1

  STATUS=$(confluent ksql cluster list -o json | jq -r 'map(select(.endpoint == "'"$KSQLDB_ENDPOINT"'")) | .[].status' | grep UP)
  if [[ "$STATUS" == "" ]]; then
    return 1
  fi

  return 0
}

function ccloud::validate_ccloud_cluster_ready() {
  confluent kafka topic list &>/dev/null
  return $?
}

function ccloud::validate_topic_exists() {
  topic=$1

  confluent kafka topic describe $topic &>/dev/null
  return $?
}

function ccloud::validate_subject_exists() {
  subject=$1
  sr_url=$2
  sr_credentials=$3

  curl --silent -u $sr_credentials $sr_url/subjects/$subject/versions/latest | jq -r ".subject" | grep $subject > /dev/null
  return $?
}

function ccloud::login_cli(){
  URL=$1
  EMAIL=$2
  PASSWORD=$3

  ccloud::validate_expect_installed

  echo -e "\n# Login"
  OUTPUT=$(
  expect <<END
    log_user 1
    spawn confluent login --url $URL --prompt -vvvv
    expect "Email: "
    send "$EMAIL\r";
    expect "Password: "
    send "$PASSWORD\r";
    expect "Logged in as "
    set result $expect_out(buffer)
END
  )
  echo "$OUTPUT"
  if [[ ! "$OUTPUT" =~ "Logged in as" ]]; then
    echo "Failed to log into your cluster. Please check all parameters and run again."
  fi

  return 0
}

function ccloud::get_service_account() {

  [ -z "$1" ] && {
    echo "ccloud::get_service_account expects one parameter (API Key)"
    exit 1
  }

  [ $# -gt 1 ] && echo "WARN: ccloud::get_service_account function expects one parameter, received two"

  local key="$1"

  serviceAccount=$(confluent api-key list -o json | jq -r -c 'map(select((.api_key == "'"$key"'"))) | .[].owner_resource_id')
  if [[ "$serviceAccount" == "" ]]; then
    echo "ERROR: Could not associate key $key to a service account. Verify your credentials, ensure the API key has a set resource type, and try again."
    exit 1
  fi
  if ! [[ "$serviceAccount" =~ ^sa-[a-z0-9]+$ ]]; then
    echo "ERROR: $serviceAccount value is not a valid value for a service account. Verify your credentials, ensure the API key has a set resource type, and try again."
    exit 1
  fi

  echo "$serviceAccount"

  return 0
}

function ccloud::create_acls_connector() {
  serviceAccount=$1

  confluent kafka acl create --allow --service-account $serviceAccount --operations DESCRIBE --cluster-scope
  confluent kafka acl create --allow --service-account $serviceAccount --operations CREATE,WRITE --prefix --topic dlq-lcc
  confluent kafka acl create --allow --service-account $serviceAccount --operations READ --prefix --consumer-group connect-lcc

  return 0
}

function ccloud::create_acls_control_center() {
  serviceAccount=$1

  echo "Confluent Control Center: creating _confluent-command and ACLs for service account $serviceAccount"
  confluent kafka topic create _confluent-command --partitions 1

  confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ,CREATE --topic _confluent --prefix

  confluent kafka acl create --allow --service-account $serviceAccount --operations READ,WRITE,CREATE --consumer-group _confluent --prefix

  return 0
}

function ccloud::create_acls_replicator() {
  serviceAccount=$1
  topic=$2

  confluent kafka acl create --allow --service-account $serviceAccount --operations CREATE,WRITE,READ,DESCRIBE,DESCRIBE_CONFIGS,ALTER-CONFIGS,DESCRIBE --topic $topic

  return 0
}

function ccloud::create_acls_connect_topics() {
  serviceAccount=$1

  echo "Connect: creating topics and ACLs for service account $serviceAccount"

  TOPIC=connect-demo-configs
  confluent kafka topic create $TOPIC --partitions 1 --config "cleanup.policy=compact"
  confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ --topic $TOPIC --prefix

  TOPIC=connect-demo-offsets
  confluent kafka topic create $TOPIC --partitions 6 --config "cleanup.policy=compact"
  confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ --topic $TOPIC --prefix

  TOPIC=connect-demo-statuses

  confluent kafka topic create $TOPIC --partitions 3 --config "cleanup.policy=compact"
  confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ  --topic $TOPIC --prefix

  for TOPIC in _confluent-monitoring _confluent-command ; do
    confluent kafka topic create $TOPIC --partitions 1 &>/dev/null
    confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ  --topic $TOPIC --prefix
  done

  confluent kafka acl create --allow --service-account $serviceAccount --operations READ --consumer-group connect-cloud

  echo "Connectors: creating topics and ACLs for service account $serviceAccount"
  confluent kafka acl create --allow --service-account $serviceAccount --operations READ --consumer-group connect-replicator
  confluent kafka acl create --allow --service-account $serviceAccount --operations DESCRIBE --cluster-scope

  return 0
}

function ccloud::validate_ccloud_stack_up() {
  CLOUD_KEY=$1
  CCLOUD_CONFIG_FILE=$2
  enable_ksqldb=$3

  if [ -z "$enable_ksqldb" ]; then
    enable_ksqldb=true
  fi

  ccloud::validate_environment_set || exit 1
  ccloud::set_kafka_cluster_use_from_api_key "$CLOUD_KEY" || exit 1
  ccloud::validate_schema_registry_up "$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" "$SCHEMA_REGISTRY_URL" || exit 1
  if $enable_ksqldb ; then
    ccloud::validate_ksqldb_up "$KSQLDB_ENDPOINT" || exit 1
    ccloud::validate_credentials_ksqldb "$KSQLDB_ENDPOINT" "$CCLOUD_CONFIG_FILE" "$KSQLDB_BASIC_AUTH_USER_INFO" || exit 1
  fi
}

function ccloud::validate_environment_set() {
  confluent environment list | grep '*' &>/dev/null || {
    echo "ERROR: could not determine if environment is set. Run 'confluent environment list' and set 'confluent environment use' and try again"
    exit 1
  }

  return 0
}

function ccloud::set_kafka_cluster_use_from_api_key() {
  [ -z "$1" ] && {
    echo "ccloud::set_kafka_cluster_use_from_api_key expects one parameter (API Key)"
    exit 1
  }

  [ $# -gt 1 ] && echo "WARN: ccloud::set_kafka_cluster_use_from_api_key function expects one parameter, received two"

  local key="$1"

  local kafkaCluster=$(confluent api-key list -o json | jq -r -c 'map(select((.api_key == "'"$key"'" and .resource_type == "kafka"))) | .[].resource_id')
  if [[ "$kafkaCluster" == "" ]]; then
    echo "ERROR: Could not associate key $key to a Confluent Cloud Kafka cluster. Verify your credentials, ensure the API key has a set resource type, and try again."
    exit 1
  fi

  confluent kafka cluster use $kafkaCluster
  local endpoint=$(confluent kafka cluster describe $kafkaCluster -o json | jq -r ".endpoint" | cut -c 12-)
  echo -e "\nAssociated key $key to Confluent Cloud Kafka cluster $kafkaCluster at $endpoint"

  return 0
}

# Deprecated 10/28/2020, use ccloud::set_kafka_cluster_use_from_api_key
function ccloud::set_kafka_cluster_use() {
  echo "WARN: set_kafka_cluster_use is deprecated, use ccloud::set_kafka_cluster_use_from_api_key"
  ccloud::set_kafka_cluster_use_from_api_key "$@"
}

#
# ccloud-stack documentation:
# https://docs.confluent.io/platform/current/tutorials/examples/ccloud/docs/ccloud-stack.html
#
function ccloud::create_ccloud_stack() {
  #ccloud::validate_version_cli $CLI_MIN_VERSION || exit 1
  QUIET="${QUIET:-false}"
  REPLICATION_FACTOR=${REPLICATION_FACTOR:-3}
  enable_ksqldb=${1:-false}
  EXAMPLE=${EXAMPLE:-ccloud-stack-function}
  CHECK_CREDIT_CARD="${CHECK_CREDIT_CARD:-false}"

  # Check if credit card is on file, which is required for cluster creation
  if $CHECK_CREDIT_CARD && [[ $(confluent admin payment describe) =~ "not found" ]]; then
    echo "ERROR: No credit card on file. Add a payment method and try again."
    echo "If you are using a cloud provider's Marketplace, see documentation for a workaround: https://docs.confluent.io/platform/current/tutorials/examples/ccloud/docs/ccloud-stack.html#running-with-marketplace"
    exit 1
  fi

  # VINC: added
  if [[ -z "$CLUSTER_CREDS" ]]
  then
    if [[ -z "$SERVICE_ACCOUNT_ID" ]]; then
      # Service Account is not received so it will be created
      local RANDOM_NUM=$((1 + RANDOM % 1000000))
      SERVICE_NAME=${SERVICE_NAME:-"pg-app-$RANDOM_NUM"}
      SERVICE_ACCOUNT_ID=$(ccloud::create_service_account $SERVICE_NAME)
    fi

    if [[ "$SERVICE_NAME" == "" ]]; then
      echo "ERROR: SERVICE_NAME is not defined. If you are providing the SERVICE_ACCOUNT_ID to this function please also provide the SERVICE_NAME"
      exit 1
    fi

    echo "Creating Confluent Cloud stack for service account $SERVICE_NAME, ID: $SERVICE_ACCOUNT_ID."
  fi

  if [[ -z "$ENVIRONMENT" ]];

  then
    # Environment is not received so it will be created
    ENVIRONMENT_NAME=${ENVIRONMENT_NAME:-"pg-$SERVICE_ACCOUNT_ID-$EXAMPLE"}
    ENVIRONMENT=$(ccloud::create_and_use_environment $ENVIRONMENT_NAME)
    (($? != 0)) && { echo "$ENVIRONMENT"; exit 1; }
  else
    confluent environment use $ENVIRONMENT || exit 1
  fi

  CLUSTER_NAME=${CLUSTER_NAME:-"pg-cluster-$SERVICE_ACCOUNT_ID"}
  CLUSTER_CLOUD="${CLUSTER_CLOUD:-aws}"
  CLUSTER_REGION="${CLUSTER_REGION:-us-west-2}"
  CLUSTER_TYPE="${CLUSTER_TYPE:-basic}"
  CLUSTER=$(ccloud::maybe_create_and_use_cluster "$CLUSTER_NAME" $CLUSTER_CLOUD $CLUSTER_REGION $CLUSTER_TYPE)
  (($? != 0)) && { echo "$CLUSTER"; exit 1; }
  if [[ "$CLUSTER" == "" ]] ; then
    echo "Kafka cluster id is empty"
    echo "ERROR: Could not create cluster. Please troubleshoot."
    exit 1
  fi

  endpoint=$(confluent kafka cluster describe $CLUSTER -o json | jq -r ".endpoint")
  if [[ $endpoint == "SASL_SSL://"* ]]
  then
    BOOTSTRAP_SERVERS=$(echo "$endpoint" | cut -c 12-)
  else
    BOOTSTRAP_SERVERS="$endpoint"
  fi

  NEED_ACLS=0
  # VINC: added
  if [[ -z "$CLUSTER_CREDS" ]]
  then
    CLUSTER_CREDS=$(ccloud::maybe_create_credentials_resource $SERVICE_ACCOUNT_ID $CLUSTER)
    NEED_ACLS=1
  fi

  MAX_WAIT=720
  echo ""
  echo "Waiting up to $MAX_WAIT seconds for Confluent Cloud cluster to be ready"
  ccloud::retry $MAX_WAIT ccloud::validate_ccloud_cluster_ready || exit 1

  # VINC: added
  if [[ $NEED_ACLS -eq 1 ]]
  then
    # Estimating another 80s wait still sometimes required
    WARMUP_TIME=${WARMUP_TIME:-80}
    echo "Sleeping an additional ${WARMUP_TIME} seconds to ensure propagation of all metadata"
    sleep $WARMUP_TIME

    ccloud::create_acls_all_resources_full_access $SERVICE_ACCOUNT_ID
  fi

  SCHEMA_REGISTRY_GEO="${SCHEMA_REGISTRY_GEO:-us}"
  SCHEMA_REGISTRY=$(ccloud::enable_schema_registry $CLUSTER_CLOUD $SCHEMA_REGISTRY_GEO)

  # VINC: added
  if [[ -z "$SCHEMA_REGISTRY_CREDS" ]]
  then
    if [[ -z "$SERVICE_ACCOUNT_ID" ]]; then
      # Service Account is not received so it will be created
      local RANDOM_NUM=$((1 + RANDOM % 1000000))
      SERVICE_NAME=${SERVICE_NAME:-"pg-app-$RANDOM_NUM"}
      SERVICE_ACCOUNT_ID=$(ccloud::create_service_account $SERVICE_NAME)
    fi
    SCHEMA_REGISTRY_CREDS=$(ccloud::maybe_create_credentials_resource $SERVICE_ACCOUNT_ID $SCHEMA_REGISTRY)
  fi

  SCHEMA_REGISTRY_ENDPOINT=$(confluent schema-registry cluster describe -o json | jq -r ".endpoint_url")

  if [[ $NEED_ACLS -eq 1 ]]
  then
    # VINC
    set +e
    if [ "$SERVICE_ACCOUNT_ID" != "" ]
    then
      log "Adding ResourceOwner RBAC role for all subjects"
      confluent iam rbac role-binding create --principal User:$SERVICE_ACCOUNT_ID --role ResourceOwner --environment $ENVIRONMENT --schema-registry-cluster $SCHEMA_REGISTRY --resource Subject:*
    fi
    set -e
  fi

  if $enable_ksqldb ; then
    KSQLDB_NAME=${KSQLDB_NAME:-"demo-ksqldb-$SERVICE_ACCOUNT_ID"}
    KSQLDB=$(ccloud::maybe_create_ksqldb_app "$KSQLDB_NAME" $CLUSTER "$CLUSTER_CREDS")
    KSQLDB_ENDPOINT=$(confluent ksql cluster describe $KSQLDB -o json | jq -r ".endpoint")
    KSQLDB_CREDS=$(ccloud::maybe_create_credentials_resource $SERVICE_ACCOUNT_ID $KSQLDB)
    confluent ksql cluster configure-acls $KSQLDB
  fi

  KAFKA_API_KEY=`echo $CLUSTER_CREDS | awk -F: '{print $1}'`
  KAFKA_API_SECRET=`echo $CLUSTER_CREDS | awk -F: '{print $2}'`
  # FIX THIS: added by me
  confluent api-key store "$KAFKA_API_KEY" "$KAFKA_API_SECRET" --resource ${CLUSTER} --force
  confluent api-key use $KAFKA_API_KEY --resource ${CLUSTER}

  if [[ -z "$SKIP_CONFIG_FILE_WRITE" ]]; then
    if [[ -z "$CCLOUD_CONFIG_FILE" ]]; then
      CCLOUD_CONFIG_FILE="/tmp/tmp.config"
    fi

    cat <<EOF > $CCLOUD_CONFIG_FILE
# --------------------------------------
# Confluent Cloud connection information
# --------------------------------------
# ENVIRONMENT ID: ${ENVIRONMENT}
# SERVICE ACCOUNT ID: ${SERVICE_ACCOUNT_ID}
# KAFKA CLUSTER ID: ${CLUSTER}
# SCHEMA REGISTRY CLUSTER ID: ${SCHEMA_REGISTRY}
EOF
    if $enable_ksqldb ; then
      cat <<EOF >> $CCLOUD_CONFIG_FILE
# KSQLDB APP ID: ${KSQLDB}
EOF
    fi
    cat <<EOF >> $CCLOUD_CONFIG_FILE
# --------------------------------------
sasl.mechanism=PLAIN
security.protocol=SASL_SSL
bootstrap.servers=${BOOTSTRAP_SERVERS}
sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='${KAFKA_API_KEY}' password='${KAFKA_API_SECRET}';
basic.auth.credentials.source=USER_INFO
schema.registry.url=${SCHEMA_REGISTRY_ENDPOINT}
basic.auth.user.info=`echo $SCHEMA_REGISTRY_CREDS | awk -F: '{print $1}'`:`echo $SCHEMA_REGISTRY_CREDS | awk -F: '{print $2}'`
replication.factor=${REPLICATION_FACTOR}
EOF
    if $enable_ksqldb ; then
      cat <<EOF >> $CCLOUD_CONFIG_FILE
ksql.endpoint=${KSQLDB_ENDPOINT}
ksql.basic.auth.user.info=`echo $KSQLDB_CREDS | awk -F: '{print $1}'`:`echo $KSQLDB_CREDS | awk -F: '{print $2}'`
EOF
    fi

    echo
    echo "Client configuration file saved to: $CCLOUD_CONFIG_FILE"
  fi

  return 0
}

function ccloud::destroy_ccloud_stack() {
  if [ $# -eq 0 ];then
    echo "ccloud::destroy_ccloud_stack requires a single parameter, the service account id."
    exit 1
  fi

  SERVICE_ACCOUNT_ID=$1
  ENVIRONMENT=${ENVIRONMENT:-$(ccloud::get_environment_id_from_service_id $SERVICE_ACCOUNT_ID)}

  confluent environment use $ENVIRONMENT || exit 1

  PRESERVE_ENVIRONMENT="${PRESERVE_ENVIRONMENT:-false}"

  ENVIRONMENT_NAME_PREFIX=${ENVIRONMENT_NAME_PREFIX:-"pg-$SERVICE_ACCOUNT_ID"}
  CLUSTER_NAME=${CLUSTER_NAME:-"pg-cluster-$SERVICE_ACCOUNT_ID"}
  CCLOUD_CONFIG_FILE=${CCLOUD_CONFIG_FILE:-"/tmp/tmp.config"}
  KSQLDB_NAME=${KSQLDB_NAME:-"demo-ksqldb-$SERVICE_ACCOUNT_ID"}

  # Setting default QUIET=false to surface potential errors
  QUIET="${QUIET:-false}"
  [[ $QUIET == "true" ]] &&

    local REDIRECT_TO="/dev/null" ||
    local REDIRECT_TO="/dev/tty"

  echo "Destroying Confluent Cloud stack associated to service account id $SERVICE_ACCOUNT_ID"

  # Delete associated ACLs
  ccloud::delete_acls_ccloud_stack $SERVICE_ACCOUNT_ID

  ksqldb_id_found=$(confluent ksql cluster list -o json | jq -r 'map(select(.name == "'"$KSQLDB_NAME"'")) | .[].id')
  if [[ $ksqldb_id_found != "" ]]; then
    echo "Deleting KSQLDB: $KSQLDB_NAME : $ksqldb_id_found"
    confluent ksql cluster delete $ksqldb_id_found &> "$REDIRECT_TO"
  fi

  # Delete connectors associated to this Kafka cluster, otherwise cluster deletion fails
  local cluster_id=$(confluent kafka cluster list -o json | jq -r 'map(select(.name == "'"$CLUSTER_NAME"'")) | .[].id')
  confluent connect cluster list --cluster $cluster_id -o json | jq -r '.[].id' | xargs -I{} confluent connect cluster delete {} --force

  echo "Deleting CLUSTER: $CLUSTER_NAME : $cluster_id"
  confluent kafka cluster delete $cluster_id &> "$REDIRECT_TO"

  # Delete API keys associated to the service account
  confluent api-key list --service-account $SERVICE_ACCOUNT_ID -o json | jq -r '.[].api_key' | xargs -I{} confluent api-key delete {} --force

  # Delete service account
  confluent iam service-account delete $SERVICE_ACCOUNT_ID --force &>"$REDIRECT_TO"

  if [[ $PRESERVE_ENVIRONMENT == "false" ]]; then
    local environment_id=$(confluent environment list -o json | jq -r 'map(select(.name | startswith("'"$ENVIRONMENT_NAME_PREFIX"'"))) | .[].id')
    if [[ "$environment_id" == "" ]]; then
      echo "WARNING: Could not find environment with name that starts with $ENVIRONMENT_NAME_PREFIX (did you create this ccloud-stack reusing an existing environment?)"
    else
      echo "Deleting ENVIRONMENT: prefix $ENVIRONMENT_NAME_PREFIX : $environment_id"
      confluent environment delete $environment_id &> "$REDIRECT_TO"
    fi
  fi

  rm -f $CCLOUD_CONFIG_FILE

  return 0
}

# Overview:
#
# This code reads a local Confluent Cloud configuration file
# and writes delta configuration files into ./delta_configs for
# Confluent Platform components and clients connecting to Confluent Cloud.
#
# Confluent Platform Components:
# - Confluent Schema Registry
# - KSQL Data Generator
# - ksqlDB server
# - Confluent Replicator (executable)
# - Confluent Control Center
# - Confluent Metrics Reporter
# - Confluent REST Proxy
# - Kafka Connect
# - Kafka connector
# - Kafka command line tools
#
# Kafka Clients:
# - Java (Producer/Consumer)
# - Java (Streams)
# - librdkafka config
# - Python
# - .NET
# - Go
# - Node.js (https://github.com/Blizzard/node-rdkafka)
# - C++
#
# Documentation for using this script:
#
#   https://docs.confluent.io/current/cloud/connect/auto-generate-configs.html
#
# Arguments:
#
#   CCLOUD_CONFIG_FILE, defaults to ~/.ccloud/config
#
# Example CCLOUD_CONFIG_FILE at ~/.ccloud/config
#
#   $ cat $HOME/.ccloud/config
#
#   bootstrap.servers=<BROKER ENDPOINT>
#   security.protocol=SASL_SSL
#   sasl.mechanism=PLAIN
#   sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='<API KEY>' password='<API SECRET>';
#
# If you are using Confluent Cloud Schema Registry, add the following configuration parameters
#
#   basic.auth.credentials.source=USER_INFO
#   basic.auth.user.info=<SR API KEY>:<SR API SECRET>
#   schema.registry.url=https://<SR ENDPOINT>
#
# If you are using Confluent Cloud ksqlDB, add the following configuration parameters
#
#   ksql.endpoint=<ksqlDB ENDPOINT>
#   ksql.basic.auth.user.info=<ksqlDB API KEY>:<ksqlDB API SECRET>
#
function ccloud::generate_configs() {
  CCLOUD_CONFIG_FILE=$1
  if [[ -z "$CCLOUD_CONFIG_FILE" ]]; then
    CCLOUD_CONFIG_FILE=~/.ccloud/config
  fi
  if [[ ! -f "$CCLOUD_CONFIG_FILE" ]]; then
    echo "File $CCLOUD_CONFIG_FILE is not found.  Please create this properties file to connect to your Confluent Cloud cluster and then try again"
    echo "See https://docs.confluent.io/current/cloud/connect/auto-generate-configs.html for more information"
    return 1
  fi

  echo -e "\nGenerating component configurations from $CCLOUD_CONFIG_FILE"
  echo -e "\n(If you want to run any of these components to talk to Confluent Cloud, these are the configurations to add to the properties file for each component)"

  # Set permissions
  PERM=600
  if ls --version 2>/dev/null | grep -q 'coreutils' ; then
    # GNU binutils
    PERM=$(stat -c "%a" $CCLOUD_CONFIG_FILE)
  else
    # BSD
    PERM=$(stat -f "%OLp" $CCLOUD_CONFIG_FILE)
  fi

  # Make destination
  DEST="/tmp/delta_configs"
  mkdir -p $DEST

  # Glean parameters from the Confluent Cloud configuration file

  # Kafka cluster
  BOOTSTRAP_SERVERS=$( grep "^bootstrap.server" $CCLOUD_CONFIG_FILE | awk -F'=' '{print $2;}' )
  BOOTSTRAP_SERVERS=${BOOTSTRAP_SERVERS/\\/}
  SASL_JAAS_CONFIG=$( grep "^sasl.jaas.config" $CCLOUD_CONFIG_FILE | cut -d'=' -f2- )
  SASL_JAAS_CONFIG_PROPERTY_FORMAT=${SASL_JAAS_CONFIG/username\\=/username=}
  SASL_JAAS_CONFIG_PROPERTY_FORMAT=${SASL_JAAS_CONFIG_PROPERTY_FORMAT/password\\=/password=}
  CLOUD_KEY=$( echo $SASL_JAAS_CONFIG | awk '{print $3}' | awk -F"'" '$0=$2' )
  CLOUD_SECRET=$( echo $SASL_JAAS_CONFIG | awk '{print $4}' | awk -F"'" '$0=$2' )

  # Schema Registry
  BASIC_AUTH_CREDENTIALS_SOURCE=$( grep "^basic.auth.credentials.source" $CCLOUD_CONFIG_FILE | awk -F'=' '{print $2;}' )
  SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO=$( grep "^basic.auth.user.info" $CCLOUD_CONFIG_FILE | awk -F'=' '{print $2;}' )
  SCHEMA_REGISTRY_URL=$( grep "^schema.registry.url" $CCLOUD_CONFIG_FILE | awk -F'=' '{print $2;}' )

  # ksqlDB
  KSQLDB_ENDPOINT=$( grep "^ksql.endpoint" $CCLOUD_CONFIG_FILE | awk -F'=' '{print $2;}' )
  KSQLDB_BASIC_AUTH_USER_INFO=$( grep "^ksql.basic.auth.user.info" $CCLOUD_CONFIG_FILE | awk -F'=' '{print $2;}' )

  # Build configuration file with Confluent Cloud connection parameters and
  # Confluent Monitoring Interceptors for Streams Monitoring in Confluent Control Center
  INTERCEPTORS_CONFIG_FILE=$DEST/interceptors-ccloud.config
  rm -f $INTERCEPTORS_CONFIG_FILE
  echo "# Configuration derived from $CCLOUD_CONFIG_FILE" > $INTERCEPTORS_CONFIG_FILE
  while read -r line
  do
    # Skip lines that are commented out
    if [[ ! -z $line && ${line:0:1} == '#' ]]; then
      continue
    fi
    # Skip lines that contain just whitespace
    if [[ -z "${line// }" ]]; then
      continue
    fi
    if [[ ${line:0:9} == 'bootstrap' ]]; then
      line=${line/\\/}
    fi
    echo $line >> $INTERCEPTORS_CONFIG_FILE
  done < "$CCLOUD_CONFIG_FILE"
  echo -e "\n# Confluent Monitoring Interceptor specific configuration" >> $INTERCEPTORS_CONFIG_FILE
  while read -r line
  do
    # Skip lines that are commented out
    if [[ ! -z $line && ${line:0:1} == '#' ]]; then
      continue
    fi
    # Skip lines that contain just whitespace
    if [[ -z "${line// }" ]]; then
      continue
    fi
    if [[ ${line:0:9} == 'bootstrap' ]]; then
      line=${line/\\/}
    fi
    if [[ ${line:0:4} == 'sasl' ||
          ${line:0:3} == 'ssl' ||
          ${line:0:8} == 'security' ||
          ${line:0:9} == 'bootstrap' ]]; then
      echo "confluent.monitoring.interceptor.$line" >> $INTERCEPTORS_CONFIG_FILE
    fi
  done < "$CCLOUD_CONFIG_FILE"
  chmod $PERM $INTERCEPTORS_CONFIG_FILE

  echo -e "\nConfluent Platform Components:"

  # Confluent Schema Registry instance (local) for Confluent Cloud
  SR_CONFIG_DELTA=$DEST/schema-registry-ccloud.delta
  echo "$SR_CONFIG_DELTA"
  rm -f $SR_CONFIG_DELTA
  while read -r line
  do
    if [[ ! -z $line && ${line:0:1} != '#' ]]; then
      if [[ ${line:0:29} != 'basic.auth.credentials.source' && ${line:0:15} != 'schema.registry' ]]; then
        echo "kafkastore.$line" >> $SR_CONFIG_DELTA
      fi
    fi
  done < "$CCLOUD_CONFIG_FILE"
  chmod $PERM $SR_CONFIG_DELTA

  # Confluent Replicator (executable) for Confluent Cloud
  REPLICATOR_PRODUCER_DELTA=$DEST/replicator-to-ccloud-producer.delta
  echo "$REPLICATOR_PRODUCER_DELTA"
  rm -f $REPLICATOR_PRODUCER_DELTA
  cp $INTERCEPTORS_CONFIG_FILE $REPLICATOR_PRODUCER_DELTA
  echo -e "\n# Confluent Replicator (executable) specific configuration" >> $REPLICATOR_PRODUCER_DELTA
  echo "interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor" >> $REPLICATOR_PRODUCER_DELTA
  REPLICATOR_SASL_JAAS_CONFIG=$SASL_JAAS_CONFIG
  REPLICATOR_SASL_JAAS_CONFIG=${REPLICATOR_SASL_JAAS_CONFIG//\\=/=}
  REPLICATOR_SASL_JAAS_CONFIG=${REPLICATOR_SASL_JAAS_CONFIG//\"/\\\"}
  chmod $PERM $REPLICATOR_PRODUCER_DELTA

  # ksqlDB Server runs locally and connects to Confluent Cloud
  KSQLDB_SERVER_DELTA=$DEST/ksqldb-server-ccloud.delta
  echo "$KSQLDB_SERVER_DELTA"
  rm -f $KSQLDB_SERVER_DELTA
  cp $INTERCEPTORS_CONFIG_FILE $KSQLDB_SERVER_DELTA
  echo -e "\n# ksqlDB Server specific configuration" >> $KSQLDB_SERVER_DELTA
  echo "producer.interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor" >> $KSQLDB_SERVER_DELTA
  echo "consumer.interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor" >> $KSQLDB_SERVER_DELTA
  echo "ksql.streams.producer.retries=2147483647" >> $KSQLDB_SERVER_DELTA
  echo "ksql.streams.producer.confluent.batch.expiry.ms=9223372036854775807" >> $KSQLDB_SERVER_DELTA
  echo "ksql.streams.producer.request.timeout.ms=300000" >> $KSQLDB_SERVER_DELTA
  echo "ksql.streams.producer.max.block.ms=9223372036854775807" >> $KSQLDB_SERVER_DELTA
  echo "ksql.streams.replication.factor=3" >> $KSQLDB_SERVER_DELTA
  echo "ksql.internal.topic.replicas=3" >> $KSQLDB_SERVER_DELTA
  echo "ksql.sink.replicas=3" >> $KSQLDB_SERVER_DELTA
  echo -e "\n# Confluent Schema Registry configuration for ksqlDB Server" >> $KSQLDB_SERVER_DELTA
  while read -r line
  do
    if [[ ${line:0:29} == 'basic.auth.credentials.source' ]]; then
      echo "ksql.schema.registry.$line" >> $KSQLDB_SERVER_DELTA
    elif [[ ${line:0:15} == 'schema.registry' ]]; then
      echo "ksql.$line" >> $KSQLDB_SERVER_DELTA
    fi
  done < $CCLOUD_CONFIG_FILE
  chmod $PERM $KSQLDB_SERVER_DELTA

  # KSQL DataGen for Confluent Cloud
  KSQL_DATAGEN_DELTA=$DEST/ksql-datagen.delta
  echo "$KSQL_DATAGEN_DELTA"
  rm -f $KSQL_DATAGEN_DELTA
  cp $INTERCEPTORS_CONFIG_FILE $KSQL_DATAGEN_DELTA
  echo -e "\n# KSQL DataGen specific configuration" >> $KSQL_DATAGEN_DELTA
  echo "interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor" >> $KSQL_DATAGEN_DELTA
  echo -e "\n# Confluent Schema Registry configuration for KSQL DataGen" >> $KSQL_DATAGEN_DELTA
  while read -r line
  do
    if [[ ${line:0:29} == 'basic.auth.credentials.source' ]]; then
      echo "ksql.schema.registry.$line" >> $KSQL_DATAGEN_DELTA
    elif [[ ${line:0:15} == 'schema.registry' ]]; then
      echo "ksql.$line" >> $KSQL_DATAGEN_DELTA
    fi
  done < $CCLOUD_CONFIG_FILE
  chmod $PERM $KSQL_DATAGEN_DELTA

  # Confluent Control Center runs locally, monitors Confluent Cloud, and uses Confluent Cloud cluster as the backstore
  C3_DELTA=$DEST/control-center-ccloud.delta
  echo "$C3_DELTA"
  rm -f $C3_DELTA
  echo -e "\n# Confluent Control Center specific configuration" >> $C3_DELTA
  while read -r line
    do
    if [[ ! -z $line && ${line:0:1} != '#' ]]; then
      if [[ ${line:0:9} == 'bootstrap' ]]; then
        line=${line/\\/}
        echo "$line" >> $C3_DELTA
      fi
      if [[ ${line:0:4} == 'sasl' || ${line:0:3} == 'ssl' || ${line:0:8} == 'security' ]]; then
        echo "confluent.controlcenter.streams.$line" >> $C3_DELTA
      fi
    fi
  done < "$CCLOUD_CONFIG_FILE"
  # max.message.bytes is enforced to 8MB in Confluent Cloud
  echo "confluent.metrics.topic.max.message.bytes=8388608" >> $C3_DELTA
  echo -e "\n# Confluent Schema Registry configuration for Confluent Control Center" >> $C3_DELTA
  while read -r line
  do
    if [[ ${line:0:29} == 'basic.auth.credentials.source' ]]; then
      echo "confluent.controlcenter.schema.registry.$line" >> $C3_DELTA
    elif [[ ${line:0:15} == 'schema.registry' ]]; then
      echo "confluent.controlcenter.$line" >> $C3_DELTA
    fi
  done < $CCLOUD_CONFIG_FILE
  chmod $PERM $C3_DELTA

  # Confluent Metrics Reporter to Confluent Cloud
  METRICS_REPORTER_DELTA=$DEST/metrics-reporter.delta
  echo "$METRICS_REPORTER_DELTA"
  rm -f $METRICS_REPORTER_DELTA
  echo "metric.reporters=io.confluent.metrics.reporter.ConfluentMetricsReporter" >> $METRICS_REPORTER_DELTA
  echo "confluent.metrics.reporter.topic.replicas=3" >> $METRICS_REPORTER_DELTA
  while read -r line
    do
    if [[ ! -z $line && ${line:0:1} != '#' ]]; then
      if [[ ${line:0:9} == 'bootstrap' || ${line:0:4} == 'sasl' || ${line:0:3} == 'ssl' || ${line:0:8} == 'security' ]]; then
        echo "confluent.metrics.reporter.$line" >> $METRICS_REPORTER_DELTA
      fi
    fi
  done < "$CCLOUD_CONFIG_FILE"
  chmod $PERM $METRICS_REPORTER_DELTA

  # Confluent REST Proxy to Confluent Cloud
  REST_PROXY_DELTA=$DEST/rest-proxy.delta
  echo "$REST_PROXY_DELTA"
  rm -f $REST_PROXY_DELTA
  while read -r line
    do
    if [[ ! -z $line && ${line:0:1} != '#' ]]; then
      if [[ ${line:0:9} == 'bootstrap' || ${line:0:4} == 'sasl' || ${line:0:3} == 'ssl' || ${line:0:8} == 'security' ]]; then
        echo "$line" >> $REST_PROXY_DELTA
        echo "client.$line" >> $REST_PROXY_DELTA
      fi
    fi
  done < "$CCLOUD_CONFIG_FILE"
  echo -e "\n# Confluent Schema Registry configuration for REST Proxy" >> $REST_PROXY_DELTA
  while read -r line
  do
    if [[ ${line:0:29} == 'basic.auth.credentials.source' || ${line:0:36} == 'schema.registry.basic.auth.user.info' ]]; then
      echo "client.$line" >> $REST_PROXY_DELTA
    elif [[ ${line:0:19} == 'schema.registry.url' ]]; then
      echo "$line" >> $REST_PROXY_DELTA
    fi
  done < $CCLOUD_CONFIG_FILE
  chmod $PERM $REST_PROXY_DELTA

  # Kafka Connect runs locally and connects to Confluent Cloud
  CONNECT_DELTA=$DEST/connect-ccloud.delta
  echo "$CONNECT_DELTA"
  rm -f $CONNECT_DELTA
  cat <<EOF > $CONNECT_DELTA
# Configuration for embedded admin client
replication.factor=3
config.storage.replication.factor=3
offset.storage.replication.factor=3
status.storage.replication.factor=3

EOF
  while read -r line
    do
    if [[ ! -z $line && ${line:0:1} != '#' ]]; then
      if [[ ${line:0:9} == 'bootstrap' ]]; then
        line=${line/\\/}
        echo "$line" >> $CONNECT_DELTA
      fi
      if [[ ${line:0:4} == 'sasl' || ${line:0:3} == 'ssl' || ${line:0:8} == 'security' ]]; then
        echo "$line" >> $CONNECT_DELTA
      fi
    fi
  done < "$CCLOUD_CONFIG_FILE"

  for prefix in "producer" "consumer" "producer.confluent.monitoring.interceptor" "consumer.confluent.monitoring.interceptor" ; do

  echo -e "\n# Configuration for embedded $prefix" >> $CONNECT_DELTA
  while read -r line
    do
    if [[ ! -z $line && ${line:0:1} != '#' ]]; then
      if [[ ${line:0:9} == 'bootstrap' ]]; then
        line=${line/\\/}
      fi
      if [[ ${line:0:4} == 'sasl' || ${line:0:3} == 'ssl' || ${line:0:8} == 'security' ]]; then
        echo "${prefix}.$line" >> $CONNECT_DELTA
      fi
    fi
  done < "$CCLOUD_CONFIG_FILE"

  done

  cat <<EOF >> $CONNECT_DELTA

# Confluent Schema Registry for Kafka Connect
value.converter=io.confluent.connect.avro.AvroConverter
value.converter.basic.auth.credentials.source=$BASIC_AUTH_CREDENTIALS_SOURCE
value.converter.schema.registry.basic.auth.user.info=$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO
value.converter.schema.registry.url=$SCHEMA_REGISTRY_URL
EOF
  chmod $PERM $CONNECT_DELTA

  # Kafka connector
  CONNECTOR_DELTA=$DEST/connector-ccloud.delta
  echo "$CONNECTOR_DELTA"
  rm -f $CONNECTOR_DELTA
  cat <<EOF >> $CONNECTOR_DELTA
// Confluent Schema Registry for Kafka connectors
value.converter=io.confluent.connect.avro.AvroConverter
value.converter.basic.auth.credentials.source=$BASIC_AUTH_CREDENTIALS_SOURCE
value.converter.schema.registry.basic.auth.user.info=$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO
value.converter.schema.registry.url=$SCHEMA_REGISTRY_URL
EOF
  chmod $PERM $CONNECTOR_DELTA

  # AK command line tools
  AK_TOOLS_DELTA=$DEST/ak-tools-ccloud.delta
  echo "$AK_TOOLS_DELTA"
  rm -f $AK_TOOLS_DELTA
  cp $CCLOUD_CONFIG_FILE $AK_TOOLS_DELTA
  chmod $PERM $AK_TOOLS_DELTA

  echo -e "\nKafka Clients:"

  # Java (Producer/Consumer)
  JAVA_PC_CONFIG=$DEST/java_producer_consumer.delta
  echo "$JAVA_PC_CONFIG"
  rm -f $JAVA_PC_CONFIG

  cat <<EOF >> $JAVA_PC_CONFIG
import java.util.Properties;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ConsumerConfig;
import org.apache.kafka.common.config.SaslConfigs;

Properties props = new Properties();

// Basic Confluent Cloud Connectivity
props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "$BOOTSTRAP_SERVERS");
props.put(ProducerConfig.REPLICATION_FACTOR_CONFIG, 3);
props.put(ProducerConfig.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
props.put(SaslConfigs.SASL_MECHANISM, "PLAIN");
props.put(SaslConfigs.SASL_JAAS_CONFIG, "$SASL_JAAS_CONFIG");

// Confluent Schema Registry for Java
props.put("basic.auth.credentials.source", "$BASIC_AUTH_CREDENTIALS_SOURCE");
props.put("schema.registry.basic.auth.user.info", "$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO");
props.put("schema.registry.url", "$SCHEMA_REGISTRY_URL");

// Optimize Performance for Confluent Cloud
props.put(ProducerConfig.RETRIES_CONFIG, 2147483647);
props.put("producer.confluent.batch.expiry.ms", 9223372036854775807);
props.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, 300000);
props.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 9223372036854775807);

// Required for Streams Monitoring in Confluent Control Center
props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor");
props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, confluent.monitoring.interceptor.bootstrap.servers, "$BOOTSTRAP_SERVERS");
props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + ProducerConfig.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_MECHANISM, "PLAIN");
props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_JAAS_CONFIG, "$SASL_JAAS_CONFIG");
props.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG, "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor");
props.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, confluent.monitoring.interceptor.bootstrap.servers, "$BOOTSTRAP_SERVERS");
props.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + ProducerConfig.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
props.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_MECHANISM, "PLAIN");
props.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_JAAS_CONFIG, "$SASL_JAAS_CONFIG");

// .... additional configuration settings
EOF
  chmod $PERM $JAVA_PC_CONFIG

  # Java (Streams)
  JAVA_STREAMS_CONFIG=$DEST/java_streams.delta
  echo "$JAVA_STREAMS_CONFIG"
  rm -f $JAVA_STREAMS_CONFIG

  cat <<EOF >> $JAVA_STREAMS_CONFIG
import java.util.Properties;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ConsumerConfig;
import org.apache.kafka.common.config.SaslConfigs;
import org.apache.kafka.streams.StreamsConfig;

Properties props = new Properties();

// Basic Confluent Cloud Connectivity
props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "$BOOTSTRAP_SERVERS");
props.put(StreamsConfig.REPLICATION_FACTOR_CONFIG, 3);
props.put(StreamsConfig.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
props.put(SaslConfigs.SASL_MECHANISM, "PLAIN");
props.put(SaslConfigs.SASL_JAAS_CONFIG, "$SASL_JAAS_CONFIG");

// Confluent Schema Registry for Java
props.put("basic.auth.credentials.source", "$BASIC_AUTH_CREDENTIALS_SOURCE");
props.put("schema.registry.basic.auth.user.info", "$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO");
props.put("schema.registry.url", "$SCHEMA_REGISTRY_URL");

// Optimize Performance for Confluent Cloud
props.put(StreamsConfig.producerPrefix(ProducerConfig.RETRIES_CONFIG), 2147483647);
props.put("producer.confluent.batch.expiry.ms", 9223372036854775807);
props.put(StreamsConfig.producerPrefix(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG), 300000);
props.put(StreamsConfig.producerPrefix(ProducerConfig.MAX_BLOCK_MS_CONFIG), 9223372036854775807);

// Required for Streams Monitoring in Confluent Control Center
props.put(StreamsConfig.PRODUCER_PREFIX + ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor");
props.put(StreamsConfig.PRODUCER_PREFIX + ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, confluent.monitoring.interceptor.bootstrap.servers, "$BOOTSTRAP_SERVERS");
props.put(StreamsConfig.PRODUCER_PREFIX + ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + StreamsConfig.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
props.put(StreamsConfig.PRODUCER_PREFIX + ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_MECHANISM, "PLAIN");
props.put(StreamsConfig.PRODUCER_PREFIX + ProducerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_JAAS_CONFIG, "$SASL_JAAS_CONFIG");
props.put(StreamsConfig.CONSUMER_PREFIX + ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG, "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor");
props.put(StreamsConfig.CONSUMER_PREFIX + ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, confluent.monitoring.interceptor.bootstrap.servers, "$BOOTSTRAP_SERVERS");
props.put(StreamsConfig.CONSUMER_PREFIX + ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + StreamsConfig.SECURITY_PROTOCOL_CONFIG, "SASL_SSL");
props.put(StreamsConfig.CONSUMER_PREFIX + ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_MECHANISM, "PLAIN");
props.put(StreamsConfig.CONSUMER_PREFIX + ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG + SaslConfigs.SASL_JAAS_CONFIG, "$SASL_JAAS_CONFIG");

// .... additional configuration settings
EOF
  chmod $PERM $JAVA_STREAMS_CONFIG

  # librdkafka
  LIBRDKAFKA_CONFIG=$DEST/librdkafka.delta
  echo "$LIBRDKAFKA_CONFIG"
  rm -f $LIBRDKAFKA_CONFIG

  cat <<EOF >> $LIBRDKAFKA_CONFIG
bootstrap.servers="$BOOTSTRAP_SERVERS"
security.protocol=SASL_SSL
sasl.mechanisms=PLAIN
sasl.username="$CLOUD_KEY"
sasl.password="$CLOUD_SECRET"
schema.registry.url="$SCHEMA_REGISTRY_URL"
basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO"
EOF
  chmod $PERM $LIBRDKAFKA_CONFIG

  # Python
  PYTHON_CONFIG=$DEST/python.delta
  echo "$PYTHON_CONFIG"
  rm -f $PYTHON_CONFIG

  cat <<EOF >> $PYTHON_CONFIG
from confluent_kafka import Producer, Consumer, KafkaError

producer = Producer({
           'bootstrap.servers': '$BOOTSTRAP_SERVERS',
           'broker.version.fallback': '0.10.0.0',
           'api.version.fallback.ms': 0,
           'sasl.mechanisms': 'PLAIN',
           'security.protocol': 'SASL_SSL',
           'sasl.username': '$CLOUD_KEY',
           'sasl.password': '$CLOUD_SECRET',
           // 'ssl.ca.location': '/usr/local/etc/openssl/cert.pem', // varies by distro
           'plugin.library.paths': 'monitoring-interceptor',
           // .... additional configuration settings
})

consumer = Consumer({
           'bootstrap.servers': '$BOOTSTRAP_SERVERS',
           'broker.version.fallback': '0.10.0.0',
           'api.version.fallback.ms': 0,
           'sasl.mechanisms': 'PLAIN',
           'security.protocol': 'SASL_SSL',
           'sasl.username': '$CLOUD_KEY',
           'sasl.password': '$CLOUD_SECRET',
           // 'ssl.ca.location': '/usr/local/etc/openssl/cert.pem', // varies by distro
           'plugin.library.paths': 'monitoring-interceptor',
           // .... additional configuration settings
})
EOF
  chmod $PERM $PYTHON_CONFIG

  # .NET

  DOTNET_CONFIG=$DEST/dotnet.delta
  echo "$DOTNET_CONFIG"
  rm -f $DOTNET_CONFIG

  cat <<EOF >> $DOTNET_CONFIG
using Confluent.Kafka;

var producerConfig = new Dictionary<string, object>
{
    { "bootstrap.servers", "$BOOTSTRAP_SERVERS" },
    { "broker.version.fallback", "0.10.0.0" },
    { "api.version.fallback.ms", 0 },
    { "sasl.mechanisms", "PLAIN" },
    { "security.protocol", "SASL_SSL" },
    { "sasl.username", "$CLOUD_KEY" },
    { "sasl.password", "$CLOUD_SECRET" },
    // { "ssl.ca.location", "/usr/local/etc/openssl/cert.pem" }, // varies by distro
    { â€œplugin.library.pathsâ€, â€œmonitoring-interceptorâ€},
    // .... additional configuration settings
};

var consumerConfig = new Dictionary<string, object>
{
    { "bootstrap.servers", "$BOOTSTRAP_SERVERS" },
    { "broker.version.fallback", "0.10.0.0" },
    { "api.version.fallback.ms", 0 },
    { "sasl.mechanisms", "PLAIN" },
    { "security.protocol", "SASL_SSL" },
    { "sasl.username", "$CLOUD_KEY" },
    { "sasl.password", "$CLOUD_SECRET" },
    // { "ssl.ca.location", "/usr/local/etc/openssl/cert.pem" }, // varies by distro
    { â€œplugin.library.pathsâ€, â€œmonitoring-interceptorâ€},
    // .... additional configuration settings
};
EOF
  chmod $PERM $DOTNET_CONFIG

  # Go
  GO_CONFIG=$DEST/go.delta
  echo "$GO_CONFIG"
  rm -f $GO_CONFIG

  cat <<EOF >> $GO_CONFIG
import (
  "github.com/confluentinc/confluent-kafka-go/kafka"

producer, err := kafka.NewProducer(&kafka.ConfigMap{
           "bootstrap.servers": "$BOOTSTRAP_SERVERS",
          "broker.version.fallback": "0.10.0.0",
          "api.version.fallback.ms": 0,
          "sasl.mechanisms": "PLAIN",
          "security.protocol": "SASL_SSL",
          "sasl.username": "$CLOUD_KEY",
          "sasl.password": "$CLOUD_SECRET",
                 // "ssl.ca.location": "/usr/local/etc/openssl/cert.pem", // varies by distro
                 "plugin.library.paths": "monitoring-interceptor",
                 // .... additional configuration settings
                 })

consumer, err := kafka.NewConsumer(&kafka.ConfigMap{
     "bootstrap.servers": "$BOOTSTRAP_SERVERS",
       "broker.version.fallback": "0.10.0.0",
       "api.version.fallback.ms": 0,
       "sasl.mechanisms": "PLAIN",
       "security.protocol": "SASL_SSL",
       "sasl.username": "$CLOUD_KEY",
       "sasl.password": "$CLOUD_SECRET",
                 // "ssl.ca.location": "/usr/local/etc/openssl/cert.pem", // varies by distro
       "session.timeout.ms": 6000,
                 "plugin.library.paths": "monitoring-interceptor",
                 // .... additional configuration settings
                 })
EOF
  chmod $PERM $GO_CONFIG

  # Node.js
  NODE_CONFIG=$DEST/node.delta
  echo "$NODE_CONFIG"
  rm -f $NODE_CONFIG

  cat <<EOF >> $NODE_CONFIG
var Kafka = require('node-rdkafka');

var producer = new Kafka.Producer({
    'metadata.broker.list': '$BOOTSTRAP_SERVERS',
    'sasl.mechanisms': 'PLAIN',
    'security.protocol': 'SASL_SSL',
    'sasl.username': '$CLOUD_KEY',
    'sasl.password': '$CLOUD_SECRET',
     // 'ssl.ca.location': '/usr/local/etc/openssl/cert.pem', // varies by distro
    'plugin.library.paths': 'monitoring-interceptor',
    // .... additional configuration settings
  });

var consumer = Kafka.KafkaConsumer.createReadStream({
    'metadata.broker.list': '$BOOTSTRAP_SERVERS',
    'sasl.mechanisms': 'PLAIN',
    'security.protocol': 'SASL_SSL',
    'sasl.username': '$CLOUD_KEY',
    'sasl.password': '$CLOUD_SECRET',
     // 'ssl.ca.location': '/usr/local/etc/openssl/cert.pem', // varies by distro
    'plugin.library.paths': 'monitoring-interceptor',
    // .... additional configuration settings
  }, {}, {
    topics: '<topic name>',
    waitInterval: 0,
    objectMode: false
});
EOF
  chmod $PERM $NODE_CONFIG

  # C++
  CPP_CONFIG=$DEST/cpp.delta
  echo "$CPP_CONFIG"
  rm -f $CPP_CONFIG

  cat <<EOF >> $CPP_CONFIG
#include <librdkafka/rdkafkacpp.h>

RdKafka::Conf *producerConfig = RdKafka::Conf::create(RdKafka::Conf::CONF_GLOBAL);
if (producerConfig->set("metadata.broker.list", "$BOOTSTRAP_SERVERS", errstr) != RdKafka::Conf::CONF_OK ||
    producerConfig->set("sasl.mechanisms", "PLAIN", errstr) != RdKafka::Conf::CONF_OK ||
    producerConfig->set("security.protocol", "SASL_SSL", errstr) != RdKafka::Conf::CONF_OK ||
    producerConfig->set("sasl.username", "$CLOUD_KEY", errstr) != RdKafka::Conf::CONF_OK ||
    producerConfig->set("sasl.password", "$CLOUD_SECRET", errstr) != RdKafka::Conf::CONF_OK ||
    // producerConfig->set("ssl.ca.location", "/usr/local/etc/openssl/cert.pem", errstr) != RdKafka::Conf::CONF_OK || // varies by distro
    producerConfig->set("plugin.library.paths", "monitoring-interceptor", errstr) != RdKafka::Conf::CONF_OK ||
    // .... additional configuration settings
   ) {
        std::cerr << "Configuration failed: " << errstr << std::endl;
        exit(1);
}
RdKafka::Producer *producer = RdKafka::Producer::create(producerConfig, errstr);

RdKafka::Conf *consumerConfig = RdKafka::Conf::create(RdKafka::Conf::CONF_GLOBAL);
if (consumerConfig->set("metadata.broker.list", "$BOOTSTRAP_SERVERS", errstr) != RdKafka::Conf::CONF_OK ||
    consumerConfig->set("sasl.mechanisms", "PLAIN", errstr) != RdKafka::Conf::CONF_OK ||
    consumerConfig->set("security.protocol", "SASL_SSL", errstr) != RdKafka::Conf::CONF_OK ||
    consumerConfig->set("sasl.username", "$CLOUD_KEY", errstr) != RdKafka::Conf::CONF_OK ||
    consumerConfig->set("sasl.password", "$CLOUD_SECRET", errstr) != RdKafka::Conf::CONF_OK ||
    // consumerConfig->set("ssl.ca.location", "/usr/local/etc/openssl/cert.pem", errstr) != RdKafka::Conf::CONF_OK || // varies by distro
    consumerConfig->set("plugin.library.paths", "monitoring-interceptor", errstr) != RdKafka::Conf::CONF_OK ||
    // .... additional configuration settings
   ) {
        std::cerr << "Configuration failed: " << errstr << std::endl;
        exit(1);
}
RdKafka::Consumer *consumer = RdKafka::Consumer::create(consumerConfig, errstr);
EOF
  chmod $PERM $CPP_CONFIG

  # ENV
  ENV_CONFIG=$DEST/env.delta
  echo "$ENV_CONFIG"
  rm -f $ENV_CONFIG

  cat <<EOF >> $ENV_CONFIG
export BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS"
export SASL_JAAS_CONFIG="$SASL_JAAS_CONFIG"
export SASL_JAAS_CONFIG_PROPERTY_FORMAT="$SASL_JAAS_CONFIG_PROPERTY_FORMAT"
export REPLICATOR_SASL_JAAS_CONFIG="$REPLICATOR_SASL_JAAS_CONFIG"
export BASIC_AUTH_CREDENTIALS_SOURCE="$BASIC_AUTH_CREDENTIALS_SOURCE"
export SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO"
export SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL"
export CLOUD_KEY="$CLOUD_KEY"
export CLOUD_SECRET="$CLOUD_SECRET"
export KSQLDB_ENDPOINT="$KSQLDB_ENDPOINT"
export KSQLDB_BASIC_AUTH_USER_INFO="$KSQLDB_BASIC_AUTH_USER_INFO"
EOF
  chmod $PERM $ENV_CONFIG

  return 0
}

# These are some duplicate functions from

#  helper.sh to decouple the script files.  In

#  the future we can work to remove this

#  duplication if necessary
function ccloud::retry() {
    local -r -i max_wait="$1"; shift
    local -r cmd="$@"

    local -i sleep_interval=5
    local -i curr_wait=0

    until $cmd
    do
        if (( curr_wait >= max_wait ))
        then
            echo "ERROR: Failed after $curr_wait seconds. Please troubleshoot and run again."
            return 1
        else
            printf "."
            curr_wait=$((curr_wait+sleep_interval))
            sleep $sleep_interval
        fi
    done
    printf "\n"
}
function ccloud::version_gt() {

  test "$(printf '%s\n' "$@" | sort -V | head -n 1)" != "$1";
}


function check_arm64_support() {

  DIR="$1"
  DOCKER_COMPOSE_FILE="$2"
  set +e
  if [ `uname -m` = "arm64" ]
  then
    test=$(echo "$DOCKER_COMPOSE_FILE" | awk -F"/" '{ print $(NF-2)"/"$(NF-1) }')
    base_test=$(echo $test | cut -d "/" -f 2)
    grep "${base_test}" ${DIR}/../../scripts/arm64-support-none.txt > /dev/null
    if [ $? = 0 ]
    then
        logerror "ğŸ–¥ï¸ This example is not working with ARM64 !"
        log "Do you want to start test anyway ?"
        check_if_continue
        return
    fi

    grep "${base_test}" ${DIR}/../../scripts/arm64-support-with-emulation.txt > /dev/null
    if [ $? = 0 ]
    then
        logwarn "ğŸ–¥ï¸ This example is working with ARM64 but requires emulation"
        return
    fi

    log "ğŸ–¥ï¸ This example should work natively with ARM64"
  fi
  set -e
}

function playground() {
  if [[ $(type -f playground 2>&1) =~ "not found" ]]
  then
    ../../scripts/cli/playground "$@"
  else
    $(which playground) "$@"
  fi
}

function force_enable () {
  flag=$1
  env_variable=$2

  logwarn "ğŸ’ª Forcing $flag ($env_variable env variable)"
  line_final_source=$(grep -n 'source ${DIR}/../../scripts/utils.sh$' $repro_test_file | cut -d ":" -f 1 | tail -n1)
  tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)
  trap 'rm -rf $tmp_dir' EXIT
  echo "# remove or comment those lines if you don't need it anymore" > $tmp_dir/tmp_force_enable
  echo "logwarn \"ğŸ’ª Forcing $flag ($env_variable env variable) as it was set when reproduction model was created\"" >> $tmp_dir/tmp_force_enable
  echo "export $env_variable=true" >> $tmp_dir/tmp_force_enable
  cp $repro_test_file $tmp_dir/tmp_file

  { head -n $(($line_final_source+1)) $tmp_dir/tmp_file; cat $tmp_dir/tmp_force_enable; tail -n  +$(($line_final_source+1)) $tmp_dir/tmp_file; } > $repro_test_file
}

# src/lib/validations/validate_dir_exists.sh
validate_dir_exists() {
  [[ -d "$1" ]] || echo "must be an existing directory"
}

# src/lib/validations/validate_editor_exists.sh
validate_editor_exists() {
  local cmd="$1"
  if [[ $(type $cmd 2>&1) =~ "not found" ]]
  then
    echo "this script requires $cmd. Please install $cmd and run again."
  fi
}

# src/lib/validations/validate_file_exists.sh
validate_file_exists() {
  [[ -f "$1" ]] || echo "must be an existing file"
}

# src/lib/validations/validate_file_exists_with_trick.sh
validate_file_exists_with_trick() {
  file="$1"

  real_file=$file
  if [[ $file == *"@"* ]]
  then
    real_file=$(echo "$file" | cut -d "@" -f 2)
  fi

  [[ -f "$real_file" ]] || echo "$real_file must be an existing file"
}

# src/lib/validations/validate_integer.sh
validate_integer() {
  [[ "$1" =~ ^[0-9]+$ ]] || echo "must be an integer"
}

# src/lib/validations/validate_minimal_cp_version.sh
validate_minimal_cp_version() {
  version="$1"
  if ! version_gt $version "4.9.99"
  then
      echo "CP version (--tag) must be > 5.0.0"
  fi
}

# src/lib/validations/validate_not_empty.sh
validate_not_empty() {
  [[ -z "$1" ]] && echo "must not be empty"
}

# :command.command_functions
# :command.function
playground_help_command() {
  # src/help_command.sh
  command="${args[command]}"
  long_usage=yes

  if [[ -z "$command" ]]; then
    # No command argument, show the global help
    help_function=playground_usage
  else
    # Show the help for the requested command
    help_function="playground_${command}_usage"
  fi

  # Call the help function if it exists
  if [[ $(type -t "$help_function") ]]; then
    "$help_function"
  else
    echo "No help available for this command"
    exit 1
  fi

}

# :command.function
playground_status_command() {
  # src/status_command.sh
  if [ ! -f /tmp/playground-run ]
  then
    logerror "File containing re-run command /tmp/playground-run does not exist!"
    logerror "Make sure to use <playground run> command !"
    exit 1
  fi

  test_file=$(cat /tmp/playground-run | awk '{ print $4}')

  if [ ! -f $test_file ]
  then

  logerror "File $test_file retrieved from /tmp/playground-run does not exist!"
  logerror "Make sure to use <playground run> command !"
  exit 1
  fi

  last_two_folders=$(basename $(dirname $(dirname $test_file)))/$(basename $(dirname $test_file))
  filename=$(basename $test_file)
  last_folder=$(basename $(dirname $test_file))

  log "ğŸš€ Running example "
  echo $last_two_folders/$filename

  playground open-docs --only-show-url

  if [[ $filename == "fully-managed"* ]]
  then
      playground ccloud-connector status | grep -v "applying command to all connectors"
      playground ccloud-connector show-config | grep -v "applying command to all connectors"
      playground ccloud-connector show-config-parameters --only-show-file-path | grep -v "applying command to all connectors"
  fi

  if [[ $last_folder == "connect"* ]]
  then
      playground connector status | grep -v "applying command to all connectors"
      playground connector show-config | grep -v "applying command to all connectors"
      playground connector show-config-parameters --only-show-file-path | grep -v "applying command to all connectors"
  fi

  playground topic list
}

# :command.function
playground_get_connector_list_command() {
  # src/get_connector_list_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  curl $security -s "$connect_url/connectors" | jq -r '.[]' | tr '\n' ' ' | sed -e 's/[[:space:]]*$//'
}

# :command.function
playground_get_ccloud_connector_list_command() {
  # src/get_ccloud_connector_list_command.sh
  ret=$(get_ccloud_connect)

  environment=$(echo "$ret" | cut -d "@" -f 1)
  cluster=$(echo "$ret" | cut -d "@" -f 2)
  authorization=$(echo "$ret" | cut -d "@" -f 3)

  curl_output=$(curl -s --request GET "https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors" \
  --header "authorization: Basic $authorization")
  ret=$?
  if [ $ret -eq 0 ]
  then
      error_code=$(echo "$curl_output" | jq -r .error_code)
      if [ "$error_code" != "null" ]
      then
          message=$(echo "$curl_output" | jq -r .message)
          logerror "Command failed with error code $error_code"
          logerror "$message"
          exit 1
      else
          echo "$curl_output" | jq -r '.[]' | tr '\n' ' ' | sed -e 's/[[:space:]]*$//'
      fi
  else
      logerror "âŒ curl request failed with error code $ret!"
      exit 1
  fi
}

# :command.function
playground_get_kafka_region_list_command() {
  # src/get_kafka_region_list_command.sh
  confluent kafka region list
}

# :command.function
playground_get_topic_list_command() {
  # src/get_topic_list_command.sh
  skip_connect_internal_topics="${args[--skip-connect-internal-topics]}"

  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  if [[ "$environment" == "environment" ]]
  then
    confluent kafka topic list | grep -v "^\s*_" | grep -v "Name" | grep -v "\-\-\-"
  else
    # trick to be faster
    docker exec broker ls /var/lib/kafka/data > /dev/null 2>&1
    if [ $? -eq 0 ]
    then
      if [[ -n "$skip_connect_internal_topics" ]]
      then
        docker exec broker ls /var/lib/kafka/data | grep -v "checkpoint" | grep -v "meta.properties" | grep -v "connect-" | grep -v "^_" | grep -v "delete" | sed 's/[^-]*$//' | sed 's/.$//' | sort | uniq
      else
        docker exec broker ls /var/lib/kafka/data | grep -v "checkpoint" | grep -v "meta.properties" | grep -v "^_" | grep -v "delete" | sed 's/[^-]*$//' | sed 's/.$//' | sort | uniq
      fi
    fi
  fi
}

# :command.function
playground_get_subject_list_command() {
  # src/get_subject_list_command.sh
  ret=$(get_sr_url_and_security)
  deleted="${args[--deleted]}"

  sr_url=$(echo "$ret" | cut -d "@" -f 1)
  sr_security=$(echo "$ret" | cut -d "@" -f 2)

  if [[ -n "$deleted" ]]
  then
      curl $sr_security -s "${sr_url}/subjects?deleted=true" | jq -r '.[]'
  else
      curl $sr_security -s "${sr_url}/subjects" | jq -r '.[]'
  fi
}

# :command.function
playground_get_examples_list_with_fzf_command() {
  # src/get_examples_list_with_fzf_command.sh
  without_repro="${args[--without-repro]}"
  sink_only="${args[--sink-only]}"
  ccloud_only="${args[--ccloud-only]}"
  cur="${args[cur]}"

  if [[ -n "$without_repro" ]] && [[ -n "$sink_only" ]]
  then
      get_examples_list_with_fzf_without_repro_sink_only "$cur"
      return
  fi

  if [[ -n "$without_repro" ]]
  then
      get_examples_list_with_fzf_without_repro "$cur"
      return
  fi

  if [[ -n "$ccloud_only" ]]
  then
      get_examples_list_with_fzf_ccloud_only "$cur"
      return
  fi

  get_examples_list_with_fzf "$cur"
}

# :command.function
playground_get_zip_or_jar_with_fzf_command() {
  # src/get_zip_or_jar_with_fzf_command.sh
  cur="${args[cur]}"
  type="${args[--type]}"

  get_zip_or_jar_with_fzf "$cur" "$type"
}

# :command.function
playground_get_any_file_with_fzf_command() {
  # src/get_any_file_with_fzf_command.sh
  cur="${args[cur]}"

  get_any_files_with_fzf "$cur"
}

# :command.function
playground_get_playground_repro_export_with_fzf_command() {
  # src/get_playground_repro_export_with_fzf_command.sh
  cur="${args[cur]}"

  get_playground_repro_export_with_fzf "$cur"
}

# :command.function
playground_get_predefined_schemas_command() {
  # src/get_predefined_schemas_command.sh
  cur="${args[cur]}"

  get_predefined_schemas_with_fzf "$cur"
}

# :command.function
playground_bashly_reload_command() {
  # src/bashly_reload_command.sh
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  root_folder=$(echo ${dir1%/*})

  cd $root_folder/scripts/cli
  bashly generate
  rm -f $root_folder/scripts/cli/completions.bash
  bashly add completions_script
  cd - > /dev/null
}

# :command.function
playground_run_command() {
  # src/run_command.sh
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

  root_folder=${DIR_CLI}/../..

  test_file="${args[--file]}"
  open="${args[--open]}"
  tag="${args[--tag]}"
  connector_tag="${args[--connector-tag]}"
  connector_zip="${args[--connector-zip]}"
  connector_jar="${args[--connector-jar]}"
  enable_ksqldb="${args[--enable-ksqldb]}"
  enable_c3="${args[--enable-control-center]}"
  enable_conduktor="${args[--enable-conduktor]}"
  enable_multiple_brokers="${args[--enable-multiple-brokers]}"
  enable_multiple_connect_workers="${args[--enable-multiple-connect-workers]}"
  enable_jmx_grafana="${args[--enable-jmx-grafana]}"
  enable_kcat="${args[--enable-kcat]}"
  enable_sr_maven_plugin_app="${args[--enable-sr-maven-plugin-app]}"
  enable_sql_datagen="${args[--enable-sql-datagen]}"

  if [ "$test_file" = "" ]
  then
    logerror "ERROR: test_file is not provided as argument!"
    exit 1
  fi

  if [[ $test_file == *"@"* ]]
  then
    test_file=$(echo "$test_file" | cut -d "@" -f 2)
  fi

  if [ ! -f "$test_file" ]
  then
    logerror "ERROR: test_file $test_file does not exist!"
    exit 1
  fi

  if [[ "$test_file" != *".sh" ]]
  then
    logerror "ERROR: test_file $test_file is not a .sh file!"
    exit 1
  fi

  test_file_directory="$(dirname "${test_file}")"
  filename=$(basename -- "$test_file")
  extension="${filename##*.}"

  base1="${test_file_directory##*/}" # connect-cdc-oracle12-source
  dir1="${test_file_directory%/*}" #connect
  dir2="${dir1##*/}/$base1" # connect/connect-cdc-oracle12-source
  final_dir=$(echo $dir2 | tr '/' '-') # connect-connect-cdc-oracle12-source

  flag_list=""
  if [[ -n "$tag" ]]
  then
    flag_list="--tag=$tag"
    export TAG=$tag
  fi

  if [[ -n "$connector_tag" ]]
  then
    flag_list="$flag_list --connector-tag=$connector_tag"
    export CONNECTOR_TAG=$connector_tag
  fi

  if [[ -n "$connector_zip" ]]
  then
    if [[ $connector_zip == *"@"* ]]
    then
      connector_zip=$(echo "$connector_zip" | cut -d "@" -f 2)
    fi
    flag_list="$flag_list --connector-zip=$connector_zip"
    export CONNECTOR_ZIP=$connector_zip
  fi

  if [[ -n "$connector_jar" ]]
  then
    if [[ $connector_jar == *"@"* ]]
    then
      connector_jar=$(echo "$connector_jar" | cut -d "@" -f 2)
    fi
    flag_list="$flag_list --connector-jar=$connector_jar"
    export CONNECTOR_JAR=$connector_jar
  fi

  if [[ -n "$enable_ksqldb" ]]
  then
    flag_list="$flag_list --enable-ksqldb"
    export ENABLE_KSQLDB=true
  fi

  if [[ -n "$enable_c3" ]]
  then
    flag_list="$flag_list --enable-control-center"
    export ENABLE_CONTROL_CENTER=true
  fi

  if [[ -n "$enable_conduktor" ]]
  then
    flag_list="$flag_list --enable-conduktor"
    export ENABLE_CONDUKTOR=true
  fi

  if [[ -n "$enable_multiple_brokers" ]]
  then
    flag_list="$flag_list --enable-multiple-broker"
    export ENABLE_KAFKA_NODES=true
  fi

  if [[ -n "$enable_multiple_connect_workers" ]]
  then
    flag_list="$flag_list --enable-multiple-connect-workers"
    export ENABLE_CONNECT_NODES=true

    # determining the docker-compose file from from test_file
    docker_compose_file=$(grep "environment" "$test_file" | grep DIR | grep start.sh | cut -d "/" -f 7 | cut -d '"' -f 1 | tail -n1 | xargs)
    docker_compose_file="${test_file_directory}/${docker_compose_file}"
    cp $docker_compose_file /tmp/playground-backup-docker-compose.yml
    yq -i '.services.connect2 = .services.connect' /tmp/playground-backup-docker-compose.yml
    yq -i '.services.connect3 = .services.connect' /tmp/playground-backup-docker-compose.yml
    cp /tmp/playground-backup-docker-compose.yml $docker_compose_file
  fi

  if [[ -n "$enable_jmx_grafana" ]]
  then
    flag_list="$flag_list --enable-jmx-grafana"
    export ENABLE_JMX_GRAFANA=true
  fi

  if [[ -n "$enable_kcat" ]]
  then
    flag_list="$flag_list --enable-kcat"
    export ENABLE_KCAT=true
  fi

  if [[ -n "$enable_sr_maven_plugin_app" ]]
  then
    flag_list="$flag_list --enable-sr-maven-plugin-app"
    export ENABLE_SR_MAVEN_PLUGIN_NODE=true
  fi

  if [[ -n "$enable_sql_datagen" ]]
  then
    flag_list="$flag_list --enable-sql-datagen"
    export SQL_DATAGEN=true
  fi

  if [[ -n "$open" ]]
  then
    if config_has_key "editor"
    then
      editor=$(config_get "editor")
      log "ğŸ“– Opening ${test_file} using configured editor $editor"
      $editor ${test_file}
      check_if_continue
    else
      if [[ $(type code 2>&1) =~ "not found" ]]
      then
        logerror "Could not determine an editor to use as default code is not found - you can change editor by updating config.ini"
        exit 1
      else
        log "ğŸ“– Opening ${test_file} with code (default) - you can change editor by updating config.ini"
        code ${test_file}
        check_if_continue
      fi
    fi
  fi

  if [ "$flag_list" != "" ]
  then
    log "ğŸš€ Running example with flags"
    log "â›³ Flags used are $flag_list"
  else
    log "ğŸš€ Running example without any flags"
  fi
  set +e
  playground container kill-all
  set -e
  echo "playground run -f $test_file $flag_list ${other_args[*]}" > /tmp/playground-run
  log "####################################################"
  log "ğŸš€ Executing $filename in dir $test_file_directory"
  log "####################################################"
  SECONDS=0
  cd $test_file_directory
  if [[ -n "$enable_multiple_connect_workers" ]]
  then
    trap "cp /tmp/playground-backup-docker-compose.yml $docker_compose_file;rm /tmp/playground-run-command-used;echo '';sleep 3;set +e;playground connector status;playground connector versions;playground open-docs --only-show-url" EXIT
  else
    trap 'rm /tmp/playground-run-command-used;echo "";sleep 3;set +e;playground connector status;playground connector versions;playground open-docs --only-show-url' EXIT
  fi
  touch /tmp/playground-run-command-used
  bash $filename ${other_args[*]}
  ret=$?
  ELAPSED="took: $((($SECONDS / 60) % 60))min $(($SECONDS % 60))sec"
  let ELAPSED_TOTAL+=$SECONDS
  set +e
  # just run it in background in case it is called later, the

  # file will be present and it will be much faster to display config
  playground connector show-config-parameters > /dev/null 2>&1 &
  set -e
  if [ $ret -eq 0 ]
  then
      log "####################################################"
      log "âœ… RESULT: SUCCESS for $filename ($ELAPSED - $CUMULATED)"
      log "####################################################"
  else
      logerror "####################################################"
      logerror "ğŸ”¥ RESULT: FAILURE for $filename ($ELAPSED - $CUMULATED)"
      logerror "####################################################"

      display_docker_container_error_log
  fi
}

# :command.function
playground_re_run_command() {
  # src/re_run_command.sh
  if [ ! -f /tmp/playground-run ]
  then
    logerror "File containing re-run command /tmp/playground-run does not exist!"
    logerror "Make sure to use <playground run> command !"
    exit 1
  fi

  tag="${args[--tag]}"
  connector_tag="${args[--connector-tag]}"
  connector_zip="${args[--connector-zip]}"
  connector_jar="${args[--connector-jar]}"
  enable_ksqldb="${args[--enable-ksqldb]}"
  enable_c3="${args[--enable-control-center]}"
  enable_conduktor="${args[--enable-conduktor]}"
  enable_multiple_brokers="${args[--enable-multiple-brokers]}"
  enable_multiple_connect_workers="${args[--enable-multiple-connect-workers]}"
  enable_jmx_grafana="${args[--enable-jmx-grafana]}"
  enable_kcat="${args[--enable-kcat]}"
  enable_sr_maven_plugin_app="${args[--enable-sr-maven-plugin-app]}"
  enable_sql_datagen="${args[--enable-sql-datagen]}"
  clear="${args[--clear]}"

  flag_list=""
  if [[ -n "$tag" ]]
  then
    flag_list="--tag=$tag"
  fi

  if [[ -n "$connector_tag" ]]
  then
    flag_list="$flag_list --connector-tag=$connector_tag"
  fi

  if [[ -n "$connector_zip" ]]
  then
    if [[ $connector_zip == *"@"* ]]
    then
      connector_zip=$(echo "$connector_zip" | cut -d "@" -f 2)
    fi
    flag_list="$flag_list --connector-zip=$connector_zip"
  fi

  if [[ -n "$connector_jar" ]]
  then
    if [[ $connector_jar == *"@"* ]]
    then
      connector_jar=$(echo "$connector_jar" | cut -d "@" -f 2)
    fi
    flag_list="$flag_list --connector-jar=$connector_jar"
  fi

  if [[ -n "$enable_ksqldb" ]]
  then
    flag_list="$flag_list --enable-ksqldb"
  fi

  if [[ -n "$enable_c3" ]]
  then
    flag_list="$flag_list --enable-control-center"
  fi

  if [[ -n "$enable_conduktor" ]]
  then
    flag_list="$flag_list --enable-conduktor"
  fi

  if [[ -n "$enable_multiple_brokers" ]]
  then
    flag_list="$flag_list --enable-multiple-broker"
  fi

  if [[ -n "$enable_multiple_connect_workers" ]]
  then
    flag_list="$flag_list --enable-multiple-connect-workers"
  fi

  if [[ -n "$enable_jmx_grafana" ]]
  then
    flag_list="$flag_list --enable-jmx-grafana"
  fi

  if [[ -n "$enable_kcat" ]]
  then
    flag_list="$flag_list --enable-kcat"
  fi

  if [[ -n "$enable_sr_maven_plugin_app" ]]
  then
    flag_list="$flag_list --enable-sr-maven-plugin-app"
  fi

  if [[ -n "$enable_sql_datagen" ]]
  then
    flag_list="$flag_list --enable-sql-datagen"
  fi

  if [ "$flag_list" != "" ]
  then
    test_file=$(cat /tmp/playground-run | awk '{ print $4}')

    if [ ! -f $test_file ]
    then

      logerror "File $test_file retrieved from /tmp/playground-run does not exist!"
      logerror "Make sure to use <playground run> command !"
      exit 1
    fi

    log "ğŸš€ Running example again with new flags"
    log "â›³ Flags used are $flag_list"
    playground run -f $test_file $flag_list ${other_args[*]}
  else
    if [[ -n "$clear" ]]
    then
      test_file=$(cat /tmp/playground-run | awk '{ print $4}')

      if [ ! -f $test_file ]
      then

        logerror "File $test_file retrieved from /tmp/playground-run does not exist!"
        logerror "Make sure to use <playground run> command !"
        exit 1
      fi

      log "ğŸ§¼ Running example again with no flags"
      playground run -f $test_file ${other_args[*]}
    else
      log "ğŸš€ Running example again with same flags as before"
      cat /tmp/playground-run
      bash /tmp/playground-run
    fi
  fi
}

# :command.function
playground_run_ccloud_command() {
  # src/run_ccloud_command.sh
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

  root_folder=${DIR_CLI}/../..

  test_file="${args[--file]}"
  open="${args[--open]}"
  tag="${args[--tag]}"
  connector_tag="${args[--connector-tag]}"
  connector_zip="${args[--connector-zip]}"
  connector_jar="${args[--connector-jar]}"
  enable_c3="${args[--enable-control-center]}"
  enable_conduktor="${args[--enable-conduktor]}"
  enable_kcat="${args[--enable-kcat]}"

  cluster_type="${args[--cluster-type]}"
  cluster_cloud="${args[--cluster-cloud]}"
  cluster_region="${args[--cluster-region]}"
  cluster_environment="${args[--cluster-environment]}"
  cluster_name="${args[--cluster-name]}"
  cluster_creds="${args[--cluster-creds]}"
  cluster_schema_registry_creds="${args[--cluster-schema-registry-creds]}"

  if [ "$test_file" = "" ]
  then
    logerror "ERROR: test_file is not provided as argument!"
    exit 1
  fi

  if [[ $test_file == *"@"* ]]
  then
    test_file=$(echo "$test_file" | cut -d "@" -f 2)
  fi

  if [ ! -f "$test_file" ]
  then
    logerror "ERROR: test_file $test_file does not exist!"
    exit 1
  fi

  if [[ "$test_file" != *".sh" ]]
  then
    logerror "ERROR: test_file $test_file is not a .sh file!"
    exit 1
  fi

  test_file_directory="$(dirname "${test_file}")"
  filename=$(basename -- "$test_file")

  base1="${test_file_directory##*/}" # connect-cdc-oracle12-source
  dir1="${test_file_directory%/*}" #connect
  dir2="${dir1##*/}/$base1" # connect/connect-cdc-oracle12-source

  flag_list=""
  if [[ -n "$tag" ]]
  then
    flag_list="--tag=$tag"
    export TAG=$tag
  fi

  if [[ -n "$connector_tag" ]]
  then
    flag_list="$flag_list --connector-tag=$connector_tag"
    export CONNECTOR_TAG=$connector_tag
  fi

  if [[ -n "$connector_zip" ]]
  then
    if [[ $connector_zip == *"@"* ]]
    then
      connector_zip=$(echo "$connector_zip" | cut -d "@" -f 2)
    fi
    flag_list="$flag_list --connector-zip=$connector_zip"
    export CONNECTOR_ZIP=$connector_zip
  fi

  if [[ -n "$connector_jar" ]]
  then
    if [[ $connector_jar == *"@"* ]]
    then
      connector_jar=$(echo "$connector_jar" | cut -d "@" -f 2)
    fi
    flag_list="$flag_list --connector-jar=$connector_jar"
    export CONNECTOR_JAR=$connector_jar
  fi

  if [[ -n "$enable_c3" ]]
  then
    flag_list="$flag_list --enable-control-center"
    export ENABLE_CONTROL_CENTER=true
  fi

  if [[ -n "$enable_conduktor" ]]
  then
    flag_list="$flag_list --enable-conduktor"
    export ENABLE_CONDUKTOR=true
  fi

  if [[ -n "$enable_kcat" ]]
  then
    flag_list="$flag_list --enable-kcat"
    export ENABLE_KCAT=true
  fi

  if [[ -n "$cluster_type" ]]
  then
    flag_list="$flag_list --cluster-type $cluster_type"
    export CLUSTER_TYPE=$cluster_type
  else
    if [ -z "$CLUSTER_TYPE" ]
    then
      export CLUSTER_TYPE="basic"
    fi
  fi

  if [[ -n "$cluster_cloud" ]]
  then
    flag_list="$flag_list --cluster-cloud $cluster_cloud"
    export CLUSTER_CLOUD=$cluster_cloud
  else
    if [ -z "$CLUSTER_CLOUD" ]
    then
      export CLUSTER_CLOUD="aws"
    fi
  fi

  if [[ -n "$cluster_region" ]]
  then
    flag_list="$flag_list --cluster-region $cluster_region"
    export CLUSTER_REGION=$cluster_region
  else
    if [ -z "$CLUSTER_REGION" ]
    then
      export CLUSTER_REGION="eu-west-2"
    fi
  fi

  if [[ -n "$cluster_environment" ]]
  then
    flag_list="$flag_list --cluster-environment $cluster_environment"
    export ENVIRONMENT=$cluster_environment
  fi

  if [[ -n "$cluster_name" ]]
  then
    flag_list="$flag_list --cluster-name $cluster_name"
    export CLUSTER_NAME=$cluster_name
  fi

  if [[ -n "$cluster_creds" ]]
  then
    flag_list="$flag_list --cluster-creds $cluster_creds"
    export CLUSTER_CREDS=$cluster_creds
  fi

  if [[ -n "$cluster_schema_registry_creds" ]]
  then
    flag_list="$flag_list --cluster-schema-registry-creds $cluster_schema_registry_creds"
    export SCHEMA_REGISTRY_CREDS=$cluster_schema_registry_creds
  fi

  if [[ -n "$open" ]]
  then
    if config_has_key "editor"
    then
      editor=$(config_get "editor")
      log "ğŸ“– Opening ${test_file} using configured editor $editor"
      $editor ${test_file}
      check_if_continue
    else
      if [[ $(type code 2>&1) =~ "not found" ]]
      then
        logerror "Could not determine an editor to use as default code is not found - you can change editor by updating config.ini"
        exit 1
      else
        log "ğŸ“– Opening ${test_file} with code (default) - you can change editor by updating config.ini"
        code ${test_file}
        check_if_continue
      fi
    fi
  fi

  if [ "$flag_list" != "" ]
  then
    log "ğŸš€â›… Running ccloud example with flags"
    log "â›³ Flags used are $flag_list"
  else
    log "ğŸš€â›… Running ccloud example without any flags"
  fi
  set +e
  playground container kill-all
  set -e
  echo "playground run -f $test_file $flag_list ${other_args[*]}" > /tmp/playground-run
  log "####################################################"
  log "ğŸš€ Executing $filename in dir $test_file_directory"
  log "####################################################"
  SECONDS=0
  cd $test_file_directory
  trap 'rm /tmp/playground-run-command-used;echo "";sleep 3;set +e;playground connector status;playground ccloud-connector status;playground connector versions' EXIT
  touch /tmp/playground-run-command-used
  bash $filename ${other_args[*]}
  ret=$?
  ELAPSED="took: $((($SECONDS / 60) % 60))min $(($SECONDS % 60))sec"
  let ELAPSED_TOTAL+=$SECONDS
  set +e
  # just run it in background in case it is called later, the

  # file will be present and it will be much faster to display config
  playground ccloud-connector show-config-parameters > /dev/null 2>&1 &
  set -e
  if [ $ret -eq 0 ]
  then
      log "####################################################"
      log "âœ… RESULT: SUCCESS for $filename ($ELAPSED - $CUMULATED)"
      log "####################################################"
  else
      logerror "####################################################"
      logerror "ğŸ”¥ RESULT: FAILURE for $filename ($ELAPSED - $CUMULATED)"
      logerror "####################################################"

      display_docker_container_error_log
  fi
}

# :command.function
playground_update_version_command() {
  # src/update_version_command.sh
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

  root_folder=${DIR_CLI}/../..

  tag="${args[--tag]}"
  connector_tag="${args[--connector-tag]}"
  connector_zip="${args[--connector-zip]}"
  connector_jar="${args[--connector-jar]}"

  tag_changed=0
  flag_list=""
  if [[ -n "$tag" ]]
  then
    current_tag=$(docker inspect -f '{{.Config.Image}}' broker 2> /dev/null | cut -d ":" -f 2)

    if [ "$current_tag" == "" ]
    then
      logerror "âŒ Could not retrieve current cp version (--tag or TAG) being used"
      exit 1
    fi

    if [ "$current_tag" == "$tag" ]
    then
      logwarn "--tag=$tag is same as current tag, ignoring..."
    else
      tag_changed=1
      flag_list="--tag=$tag"
    fi

    export TAG=$tag
  fi

  if [[ -n "$connector_tag" ]]
  then
    flag_list="$flag_list --connector-tag=$connector_tag"
    export CONNECTOR_TAG=$connector_tag
  fi

  if [[ -n "$connector_zip" ]]
  then
    if [[ $connector_zip == *"@"* ]]
    then
      connector_zip=$(echo "$connector_zip" | cut -d "@" -f 2)
    fi
    flag_list="$flag_list --connector-zip=$connector_zip"
    export CONNECTOR_ZIP=$connector_zip
  fi

  if [[ -n "$connector_jar" ]]
  then
    if [[ $connector_jar == *"@"* ]]
    then
      connector_jar=$(echo "$connector_jar" | cut -d "@" -f 2)
    fi
    flag_list="$flag_list --connector-jar=$connector_jar"
    export CONNECTOR_JAR=$connector_jar
  fi

  if [ ! -f /tmp/playground-run ]
  then
    logerror "File containing run command /tmp/playground-run does not exist!"
    logerror "Make sure to use <playground run> command !"
    exit 1
  fi

  test_file=$(cat /tmp/playground-run | awk '{ print $4}')

  if [ ! -f $test_file ]
  then

    logerror "File $test_file retrieved from /tmp/playground-run does not exist!"
    logerror "Make sure to use <playground run> command !"
    exit 1
  fi

  # determining the docker-compose file from from test_file
  docker_compose_file=$(grep "environment" "$test_file" | grep DIR | grep start.sh | cut -d "/" -f 7 | cut -d '"' -f 1 | tail -n1 | xargs)
  test_file_directory="$(dirname "${test_file}")"
  docker_compose_file="${test_file_directory}/${docker_compose_file}"

  if [ "${docker_compose_file}" != "" ] && [ ! -f "${docker_compose_file}" ]
  then
      logwarn "Skipping as docker-compose override file could not be detemined"
      exit 0
  fi

  test_file_directory="$(dirname "${test_file}")"
  cd ${test_file_directory}

  export DOCKER_COMPOSE_FILE_UPDATE_VERSION="$docker_compose_file"

  if [ "$flag_list" != "" ]
  then
    log "âœ¨ Loading new version(s) based on flags â›³ $flag_list"
  else
    log "âœ¨ Loading new version(s) without any flags â›³"
  fi

  if [ $tag_changed -eq 1 ]
  then
      log "ğŸ’£ Detected confluent version change, restarting containers"
      playground container recreate --ignore-current-versions
  else
      # in case there is a change in docker-compose...
      playground container recreate
  fi

  if [[ -n "$connector_tag" ]] || [[ -n "$connector_zip" ]] || [[ -n "$connector_jar" ]]
  then
      if [ $tag_changed -eq 0 ]
      then
          log "ğŸ§© a connector flag is set: restarting connect container to make sure new version(s) are used"
          playground container restart --container connect
      fi
      sleep 5

      $root_folder/scripts/wait-for-connect-and-controlcenter.sh

      sleep 10

      playground connector versions
  else
      sleep 4

      $root_folder/scripts/wait-for-connect-and-controlcenter.sh
  fi
}

# :command.function
playground_open_command() {
  # src/open_command.sh
  test_file="${args[--file]}"

  if [[ -n "$test_file" ]]
  then
    if [[ $test_file == *"@"* ]]
    then
      test_file=$(echo "$test_file" | cut -d "@" -f 2)
    fi
  else
    if [ ! -f /tmp/playground-run ]
    then
      logerror "File containing run command /tmp/playground-run does not exist!"
      logerror "Make sure to use <playground run> command !"
      exit 1
    fi

    test_file=$(cat /tmp/playground-run | awk '{ print $4}')

    if [ ! -f $test_file ]
    then

      logerror "File $test_file retrieved from /tmp/playground-run does not exist!"
      logerror "Make sure to use <playground run> command !"
      exit 1
    fi
  fi

  if config_has_key "editor"
  then
    editor=$(config_get "editor")
    log "ğŸ“– Opening ${test_file} using configured editor $editor"
    $editor ${test_file}
  else
    if [[ $(type code 2>&1) =~ "not found" ]]
    then
      logerror "Could not determine an editor to use as default code is not found - you can change editor by updating config.ini"
      exit 1
    else
      log "ğŸ“– Opening ${test_file} with code (default) - you can change editor by updating config.ini"
      code ${test_file}
    fi
  fi
}

# :command.function
playground_stop_command() {
  # src/stop_command.sh
  if [ ! -f /tmp/playground-run ]
  then
    logerror "File containing run command /tmp/playground-run does not exist!"
    logerror "Make sure to use <playground run> command !"
    exit 1
  fi

  test_file=$(cat /tmp/playground-run | awk '{ print $4}')

  if [ ! -f $test_file ]
  then

    logerror "File $test_file retrieved from /tmp/playground-run does not exist!"
    logerror "Make sure to use <playground run> command !"
    exit 1
  fi
  filename=$(basename -- "$test_file")
  test_file_directory="$(dirname "${test_file}")"
  cd ${test_file_directory}

  if [ ! -f $test_file_directory/stop.sh ]
  then

    logerror "File stop.sh in directory $test_file_directory does not exist"
    exit 1
  fi

  log "ğŸ›‘ Stopping example $filename in dir $test_file_directory"
  bash stop.sh
}

# :command.function
playground_open_docs_command() {
  # src/open_docs_command.sh
  only_show_url="${args[--only-show-url]}"
  if [ ! -f /tmp/playground-run ]
  then
      logerror "File containing re-run command /tmp/playground-run does not exist!"
      logerror "Make sure to use <playground run> command !"
      exit 1
  fi

  test_file=$(cat /tmp/playground-run | awk '{ print $4}')

  if [ ! -f $test_file ]
  then

      logerror "File $test_file retrieved from /tmp/playground-run does not exist!"
      logerror "Make sure to use <playground run> command !"
      exit 1
  fi

  readme_file="$(dirname $test_file)/README.md"
  if [ ! -f $readme_file ]
  then

      logerror "README file $readme_file does not exist"
      exit 1
  fi

  string=$(grep "Quickly test " $readme_file)
  url=$(echo "$string" | grep -oE 'https?://[^ ]+')
  url=${url//)/}

  if [[ $url =~ "http" ]]
  then
      short_url=$(echo $url | cut -d '#' -f 1)
      if [[ -n "$only_show_url" ]]
      then
          log "ğŸŒ documentation is available at:"
          echo "$short_url"
      else
          log "ğŸŒ opening documentation $short_url"
          open "$short_url"
      fi
  else
      logerror "Could not find documentation link in README file $readme_file"
      exit 1
  fi
}

# :command.function
playground_repro_export_command() {
  # src/repro_export_command.sh
  all="${args[--all]}"

  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  root_folder=$(echo ${dir1%/*})

  if [ ! -z "$OUTPUT_FOLDER" ]
  then
    output_folder="$OUTPUT_FOLDER"
  else
    output_folder="reproduction-models"
  fi

  if [ "$output_folder" != "reproduction-models" ]
  then
      logerror "âŒ OUTPUT_FOLDER $output_folder is not set with reproduction-models, this is the only supported value !"
      exit 1
  fi

  repro_dir=$root_folder/$output_folder
  cd $repro_dir

  output_filename="playground_repro_export.tgz"
  final_archive=$repro_dir/$output_filename
  if [ -f $final_archive ]
  then
      rm -rf $final_archive
  fi
  set +e
  if [[ -n "$all" ]]
  then
      if [ -d .git ]
      then
          new_files=$(git status --porcelain 2>/dev/null  | grep "^?? " | cut -d " " -f2-)
          if [[ -n "$new_files" ]]
          then
              log "ğŸ’« detected new files:"
              echo "$new_files"
              tar cvfz "$output_filename" $new_files > /dev/null 2>&1
              if [ -f $final_archive ]
              then
                  log "ğŸ“¤ Exported archive is available: $final_archive"
              else
                  logerror "âŒ export failed as archive could not be created !"
                  exit 1
              fi
          else
              logerror "âŒ No new files found !"
              exit 1
          fi
      else
          logwarn "output folder is not managed by git, creating a full tgz of $output_folder"
          tar cvfz "$output_filename" * > /dev/null 2>&1
          if [ -f $final_archive ]
          then
              log "ğŸ“¤ Exported archive is available: $final_archive"
          else
              logerror "âŒ export failed as archive could not be created !"
              exit 1
          fi
      fi
  else
      # copy only current example
      if [ ! -f /tmp/playground-run ]
      then
          logerror "File containing re-run command /tmp/playground-run does not exist!"
          logerror "Make sure to use <playground run> command !"
          exit 1
      fi

      test_file=$(cat /tmp/playground-run | awk '{ print $4}')

      if [ ! -f $test_file ]
      then
          logerror "File $test_file retrieved from /tmp/playground-run does not exist!"
          logerror "Make sure to use <playground run> command !"
          exit 1
      fi

      test_file_directory="$(dirname "${test_file}")"
      base1="${test_file_directory##*/}" # connect-connect-aws-s3-sink
      dir1="${test_file_directory%/*}" # reproduction-models
      dir2="${dir1##*/}/$base1" # reproduction-models/connect-connect-aws-s3-sink

      if [[ "$dir2" != ${output_folder}* ]]
      then
          logerror "example <$dir2> is not from OUTPUT_FOLDER ${output_folder} folder, only examples in there can be exported"
          exit 1
      fi

      if [ -d .git ]
      then
          cd $test_file_directory

          new_files=$(git status --porcelain . 2>/dev/null  | grep "^?? " | cut -d " " -f2-)
          if [[ -n "$new_files" ]]
          then
              log "ğŸ’« detected new files:"
              echo "$new_files"
              cd - >/dev/null
              tar cvfz "$output_filename" $new_files > /dev/null 2>&1
              if [ -f $final_archive ]
              then
                  log "ğŸ“¤ Exported archive is available: $final_archive"
              else
                  logerror "âŒ export failed as archive could not be created !"
                  exit 1
              fi
          else
              logerror "âŒ No new files found !"
              exit 1
          fi
      else
          logwarn "output folder is not managed by git, creating a full tgz of $test_file_directory"
          tar cvfz "$output_filename" $test_file_directory > /dev/null 2>&1
          if [ -f $final_archive ]
          then
              log "ğŸ“¤ Exported archive is available: $final_archive"
          else
              logerror "âŒ export failed as archive could not be created !"
              exit 1
          fi
      fi
  fi

}

# :command.function
playground_repro_import_command() {
  # src/repro_import_command.sh
  file="${args[--file]}"

  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  root_folder=$(echo ${dir1%/*})

  if [ ! -z "$OUTPUT_FOLDER" ]
  then
    output_folder="$OUTPUT_FOLDER"
  else
    output_folder="reproduction-models"
  fi

  if [ "$output_folder" != "reproduction-models" ]
  then
      logerror "âŒ OUTPUT_FOLDER $output_folder is not set with reproduction-models, this is the only supported value !"
      exit 1
  fi

  if [[ $file == *"@"* ]]
  then
    file=$(echo "$file" | cut -d "@" -f 2)
  fi

  filename=$(basename $file)

  if [ "playground_repro_export.tgz" != ${filename} ]
  then
      logerror "file $file is not named playground_repro_export.tgz"
      exit 1
  fi

  repro_dir=$root_folder/$output_folder
  cd $repro_dir

  log "ğŸ“¥ Installing $file"
  tar xvfz $file
}

# :command.function
playground_repro_bootstrap_command() {
  # src/repro_bootstrap_command.sh
  IGNORE_CHECK_FOR_DOCKER_COMPOSE=true

  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  root_folder=$(echo ${dir1%/*})

  test_file="${args[--file]}"
  description="${args[--description]}"
  producer="${args[--producer]}"
  nb_producers="${args[--nb-producers]}"
  add_custom_smt="${args[--custom-smt]}"
  sink_file="${args[--pipeline]}"
  schema_file_key="${args[--producer-schema-key]}"
  schema_file_value="${args[--producer-schema-value]}"

  tag="${args[--tag]}"
  connector_tag="${args[--connector-tag]}"
  connector_zip="${args[--connector-zip]}"
  connector_jar="${args[--connector-jar]}"
  enable_ksqldb="${args[--enable-ksqldb]}"
  enable_c3="${args[--enable-control-center]}"
  enable_conduktor="${args[--enable-conduktor]}"
  enable_multiple_brokers="${args[--enable-multiple-brokers]}"
  enable_multiple_connect_workers="${args[--enable-multiple-connect-workers]}"
  enable_jmx_grafana="${args[--enable-jmx-grafana]}"
  enable_kcat="${args[--enable-kcat]}"
  enable_sr_maven_plugin_app="${args[--enable-sr-maven-plugin-app]}"
  enable_sql_datagen="${args[--enable-sql-datagen]}"

  if [[ $test_file == *"@"* ]]
  then
    test_file=$(echo "$test_file" | cut -d "@" -f 2)
  fi

  if [[ "$test_file" != *".sh" ]]
  then
    logerror "test_file $test_file is not a .sh file!"
    exit 1
  fi

  if [[ "$(dirname $test_file)" != /* ]]
  then
    logerror "do not use relative path for test file!"
    exit 1
  fi

  if [ "$description" = "" ]
  then
    logerror "description is not provided as argument!"
    exit 1
  fi

  if [ "$nb_producers" == "" ]
  then
    nb_producers=1
  fi

  if [[ -n "$schema_file_key" ]]
  then
    if [ "$producer" == "none" ]
    then
      logerror "--producer-schema-key is set but not --producer"
      exit 1
    fi

    if [[ "$producer" != *"with-key" ]]
    then
      logerror "--producer-schema-key is set but --producer is not set with <with-key>"
      exit 1
    fi
  fi

  if [[ -n "$schema_file_value" ]]
  then
    if [ "$producer" == "none" ]
    then
      logerror "--producer-schema-value is set but not --producer"
      exit 1
    fi
  fi

  test_file_directory="$(dirname "${test_file}")"
  cd ${test_file_directory}

  topic_name="customer-$producer"
  topic_name=$(echo $topic_name | tr '-' '_')
  filename=$(basename -- "$test_file")
  extension="${filename##*.}"
  filename="${filename%.*}"

  base1="${test_file_directory##*/}" # connect-cdc-oracle12-source
  dir1="${test_file_directory%/*}" #connect
  dir2="${dir1##*/}/$base1" # connect/connect-cdc-oracle12-source
  final_dir=$(echo $dir2 | tr '/' '-') # connect-connect-cdc-oracle12-source

  if [[ -n "$sink_file" ]]
  then
    if [[ "$base1" != *source ]]
    then
      logerror "example <$base1> must be source connector example when building a pipeline !"
      exit 1
    fi

    if [[ "$dir2" != connect* ]]
    then
      logerror "example <$dir2> is not from connect folder, only connect in connect folder are supported"
      exit 1
    fi
  fi

  if [ "$producer" != "none" ]
  then
    if [[ "$base1" != *sink ]]
    then
      logerror "example <$base1> must be sink connector example when using a java producer !"
      exit 1
    fi
  fi

  if [ ! -z "$OUTPUT_FOLDER" ]
  then
    output_folder="$OUTPUT_FOLDER"
    log "ğŸ“‚ Output folder is $output_folder (set with OUTPUT_FOLDER environment variable)"
  else
    output_folder="reproduction-models"
    log "ğŸ“‚ Output folder is default $output_folder (you can change it by setting OUTPUT_FOLDER environment variable)"
  fi

  repro_dir=$root_folder/$output_folder/$final_dir
  mkdir -p $repro_dir
  tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)
  trap 'rm -rf $tmp_dir' EXIT

  description_kebab_case="${description// /-}"
  description_kebab_case=$(echo "$description_kebab_case" | tr '[:upper:]' '[:lower:]')
  repro_test_file="$repro_dir/$filename-repro-$description_kebab_case.$extension"

  # determining the docker-compose file from from test_file
  docker_compose_file=$(grep "environment" "$test_file" | grep DIR | grep start.sh | cut -d "/" -f 7 | cut -d '"' -f 1 | tail -n1 | xargs)
  docker_compose_file="${test_file_directory}/${docker_compose_file}"

  log "âœ¨ Creating file $repro_test_file"
  rm -f $repro_test_file
  cp $test_file $repro_test_file

  if [ "${docker_compose_file}" != "" ] && [ ! -f "${docker_compose_file}" ]
  then
    set +e
    grep 'DOCKER_COMPOSE_FILE_OVERRIDE=$1' "$test_file"
    if [ $? -eq 0 ]
    then
      # it means it is an environment example
      # need to create the docker-compose file
      docker_compose_file=""
      docker_compose_test_file="$repro_dir/docker-compose.repro-$description_kebab_case.yml"
      log "âœ¨ Creating empty file $docker_compose_test_file"

      echo "---" > $docker_compose_test_file
      echo "version: '3.5'" >> $docker_compose_test_file
      echo "" >> $docker_compose_test_file
      echo "# override the services here, example " >> $docker_compose_test_file
      echo "# services:" >> $docker_compose_test_file
      echo "#    connect:" >> $docker_compose_test_file
      echo "#      environment:" >> $docker_compose_test_file
      echo "#        CONNECT_BOOTSTRAP_SERVERS: \"broker:9092\"" >> $docker_compose_test_file

      docker_compose_test_file_name=$(basename -- "$docker_compose_test_file")
      cp $test_file $tmp_dir/tmp_file
      line=$(grep -n 'DOCKER_COMPOSE_FILE_OVERRIDE=$1' $test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line-1)) $tmp_dir/tmp_file; echo "DOCKER_COMPOSE_FILE_OVERRIDE=../../$output_folder/$final_dir/$docker_compose_test_file_name"; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $repro_test_file
    else
      docker_compose_file=""
      logwarn "ğŸ“ Could not determine docker-compose override file from $test_file !"
    fi
    set -e
  fi

  if [ "${docker_compose_file}" != "" ] && [ -f "${docker_compose_file}" ]
  then
    filename=$(basename -- "${docker_compose_file}")
    extension="${filename##*.}"
    filename="${filename%.*}"

    docker_compose_test_file="$repro_dir/$filename.repro-$description_kebab_case.$extension"
    log "âœ¨ Creating file $docker_compose_test_file"
    rm -f $docker_compose_test_file
    cp ${docker_compose_file} $docker_compose_test_file

    docker_compose_test_file_name=$(basename -- "$docker_compose_test_file")
  fi

  if [ "${docker_compose_file}" != "" ]
  then
    filename=$(basename -- "${docker_compose_file}")
    sed -e "s|$filename|$docker_compose_test_file_name|g" \
      $test_file > $repro_test_file
  fi

  set +e
  echo "#!/bin/bash" > $tmp_dir/intro
  echo "###############################################" >> $tmp_dir/intro
  echo "# ğŸ—“ï¸ date: `date`" >> $tmp_dir/intro
  echo "# ğŸ‘¤ author: `whoami`" >> $tmp_dir/intro
  echo "# ğŸ’¡ description: $description" >> $tmp_dir/intro
  if [[ $description =~ ^[0-9]{6} ]]
  then
    numbers="${BASH_REMATCH[0]}"
    echo "# ğŸ”® ticket: https://confluent.zendesk.com/agent/tickets/$numbers" >> $tmp_dir/intro
  fi
  echo "# ğŸ™‹ how to use: https://github.com/confluentinc/kafka-docker-playground-internal/tree/master#how-to-use" >> $tmp_dir/intro
  string=$(grep "Quickly test " README.md)
  url=$(echo "$string" | grep -oE 'https?://[^ ]+')
  url=${url//)/}

  if [[ $url =~ "http" ]]
  then
    short_url=$(echo $url | cut -d '#' -f 1)
    echo "# ğŸŒ documentation: $short_url" >> $tmp_dir/intro
  fi
  echo "# ğŸ³ playground website: https://kafka-docker-playground.io" >> $tmp_dir/intro
  echo "# ğŸ’¬ comments:" >> $tmp_dir/intro
  echo "#" >> $tmp_dir/intro
  echo "###############################################" >> $tmp_dir/intro
  echo "" >> $tmp_dir/intro

  cat $tmp_dir/intro > $tmp_dir/tmp_file
  cat $repro_test_file | grep -v "#!/bin/bash" >> $tmp_dir/tmp_file
  mv $tmp_dir/tmp_file $repro_test_file

  for file in README.md docker-compose*.yml keyfile.json stop.sh .gitignore sql-datagen
  do
    if [ -f $file ]
    then
      cd $repro_dir > /dev/null
      ln -sf ../../$dir2/$file .
      cd - > /dev/null
    fi
  done

  if [ "$producer" != "none" ]
  then
    case "${producer}" in
      avro)
        echo "               \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\"," > $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.avro.AvroConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter
      ;;
      avro-with-key)
        echo "               \"key.converter\": \"io.confluent.connect.avro.AvroConverter\"," > $tmp_dir/key_converter
        echo "               \"key.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.avro.AvroConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter
      ;;
      json-schema)
        echo "               \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\"," > $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.json.JsonSchemaConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter
      ;;
      json-schema-with-key)
        echo "               \"key.converter\": \"io.confluent.connect.json.JsonSchemaConverter\"," > $tmp_dir/key_converter
        echo "               \"key.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.json.JsonSchemaConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter
      ;;
      protobuf)
        echo "               \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\"," > $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.protobuf.ProtobufConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter
      ;;
      protobuf-with-key)
        echo "               \"key.converter\": \"io.confluent.connect.protobuf.ProtobufConverter\"," > $tmp_dir/key_converter
        echo "               \"key.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.protobuf.ProtobufConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter
      ;;
      none)
      ;;
      *)
        logerror "producer name not valid ! Should be one of avro, avro-with-key, json-schema, json-schema-with-key, protobuf or protobuf-with-key"
        exit 1
      ;;
    esac
    original_topic_name=$(grep "\"topics\"" $repro_test_file | cut -d "\"" -f 4 | head -1)
    if [ "$original_topic_name" != "" ]
    then
      tmp=$(echo $original_topic_name | tr '-' '\-')
      sed -e "s|$tmp|$topic_name|g" \
          $repro_test_file > /tmp/tmp

      mv /tmp/tmp $repro_test_file
      # log "âœ¨ Replacing topic $original_topic_name with $topic_name"
    fi

    for((i=1;i<=$nb_producers;i++)); do
      # looks like there is a maximum size for hostname in docker (container init caused: sethostname: invalid argument: unknown)
      producer_hostname=""
      producer_hostname="producer-repro-$description_kebab_case"
      producer_hostname=${producer_hostname:0:21}
      if [ $nb_producers -eq 1 ]
      then
        producer_hostname="${producer_hostname}"
      else
        producer_hostname="${producer_hostname}$i"
      fi

      rm -rf $producer_hostname
      mkdir -p $repro_dir/$producer_hostname/
      cp -Ra ${test_file_directory}/../../other/schema-format-$producer/producer/* $repro_dir/$producer_hostname/

      if [[ -n "$schema_file_key" ]]
      then
        if config_has_key "editor"
        then
          editor=$(config_get "editor")
          log "âœ¨ Copy and paste the schema you want to use for the key, save and close the file to continue"
          if [ "$editor" = "code" ]
          then
            code --wait $tmp_dir/key_schema
          else
            $editor $tmp_dir/key_schema
          fi
        else
          if [[ $(type code 2>&1) =~ "not found" ]]
          then
            logerror "Could not determine an editor to use as default code is not found - you can change editor by updating config.ini"
            exit 1
          else
            log "âœ¨ Copy and paste the schema you want to use for the key, save and close the file to continue"
            code --wait $tmp_dir/key_schema
          fi
        fi

        case "${producer}" in
          avro-with-key)
            original_namespace=$(cat $tmp_dir/key_schema | jq -r .namespace)
            if [ "$original_namespace" != "null" ]
            then
              sed -e "s|$original_namespace|com.github.vdesabou|g" \
                  $tmp_dir/key_schema  > /tmp/tmp

              mv /tmp/tmp $tmp_dir/key_schema
              log "âœ¨ Replacing namespace $original_namespace with com.github.vdesabou"
            else
              # need to add namespace
              cp $tmp_dir/key_schema /tmp/tmp
              line=2
              { head -n $(($line-1)) /tmp/tmp; echo "    \"namespace\": \"com.github.vdesabou\","; tail -n +$line /tmp/tmp; } > $tmp_dir/key_schema
            fi
            # replace record name with MyKey
            jq '.name = "MyKey"' $tmp_dir/key_schema > /tmp/tmp
            mv /tmp/tmp $tmp_dir/key_schema

            cp $tmp_dir/key_schema $repro_dir/$producer_hostname/src/main/resources/schema/mykey.avsc
          ;;
          json-schema-with-key)
            # replace title name with ID
            jq '.title = "ID"' $tmp_dir/key_schema > /tmp/tmp
            mv /tmp/tmp $tmp_dir/key_schema

            cp $tmp_dir/key_schema $repro_dir/$producer_hostname/src/main/resources/schema/Id.json
          ;;
          protobuf-with-key)
            original_package=$(grep "package " $tmp_dir/key_schema | cut -d " " -f 2 | cut -d ";" -f 1 | head -1)
            if [ "$original_package" != "" ]
            then
              sed -e "s|$original_package|com.github.vdesabou|g" \
                  $tmp_dir/key_schema  > /tmp/tmp

              mv /tmp/tmp $tmp_dir/key_schema
              log "âœ¨ Replacing package $original_package with com.github.vdesabou"
            else
              # need to add package
              cp $tmp_dir/key_schema /tmp/tmp
              line=2
              { head -n $(($line-1)) /tmp/tmp; echo "package com.github.vdesabou;"; tail -n +$line /tmp/tmp; } > $tmp_dir/key_schema
            fi

            original_java_outer_classname=$(grep "java_outer_classname" $tmp_dir/key_schema | cut -d "\"" -f 2 | cut -d "\"" -f 1 | head -1)
            if [ "$original_java_outer_classname" != "" ]
            then
              sed -e "s|$original_java_outer_classname|IdImpl|g" \
                  $tmp_dir/key_schema  > /tmp/tmp

              mv /tmp/tmp $tmp_dir/key_schema
              log "âœ¨ Replacing java_outer_classname $original_java_outer_classname with IdImpl"
            else
              # need to add java_outer_classname
              cp $tmp_dir/key_schema /tmp/tmp
              line=3
              { head -n $(($line-1)) /tmp/tmp; echo "option java_outer_classname = \"IdImpl\";"; tail -n +$line /tmp/tmp; } > $tmp_dir/key_schema
            fi

            cp $tmp_dir/key_schema $repro_dir/$producer_hostname/src/main/resources/schema/Id.proto
          ;;

          none)
          ;;
          *)
            logerror "producer name not valid ! Should be one of avro, avro-with-key, json-schema, json-schema-with-key, protobuf or protobuf-with-key"
            exit 1
          ;;
        esac
      fi

      if [[ -n "$schema_file_value" ]]
      then
        if config_has_key "editor"
        then
          editor=$(config_get "editor")
          log "âœ¨ Copy and paste the schema you want to use for the value, save and close the file to continue"
          if [ "$editor" = "code" ]
          then
            code --wait $tmp_dir/value_schema
          else
            $editor $tmp_dir/value_schema
          fi
        else
          if [[ $(type code 2>&1) =~ "not found" ]]
          then
            logerror "Could not determine an editor to use as default code is not found - you can change editor by updating config.ini"
            exit 1
          else
            log "âœ¨ Copy and paste the schema you want to use for the value, save and close the file to continue"
            code --wait $tmp_dir/value_schema
          fi
        fi

        case "${producer}" in
          avro|avro-with-key)
            original_namespace=$(cat $tmp_dir/value_schema | jq -r .namespace)
            if [ "$original_namespace" != "null" ]
            then
              sed -e "s|$original_namespace|com.github.vdesabou|g" \
                  $tmp_dir/value_schema  > /tmp/tmp

              mv /tmp/tmp $tmp_dir/value_schema
              log "âœ¨ Replacing namespace $original_namespace with com.github.vdesabou"
            else
              # need to add namespace
              cp $tmp_dir/value_schema /tmp/tmp
              line=2
              { head -n $(($line-1)) /tmp/tmp; echo "    \"namespace\": \"com.github.vdesabou\","; tail -n +$line /tmp/tmp; } > $tmp_dir/value_schema
            fi
            # replace record name with Customer
            jq '.name = "Customer"' $tmp_dir/value_schema > /tmp/tmp
            mv /tmp/tmp $tmp_dir/value_schema

            cp $tmp_dir/value_schema $repro_dir/$producer_hostname/src/main/resources/schema/customer.avsc
          ;;
          json-schema|json-schema-with-key)
            # replace title name with Customer
            jq '.title = "Customer"' $tmp_dir/value_schema > /tmp/tmp
            mv /tmp/tmp $tmp_dir/value_schema

            cp $tmp_dir/value_schema $repro_dir/$producer_hostname/src/main/resources/schema/Customer.json
          ;;
          protobuf|protobuf-with-key)
            original_package=$(grep "package " $tmp_dir/value_schema | cut -d " " -f 2 | cut -d ";" -f 1 | head -1)
            if [ "$original_package" != "" ]
            then
              sed -e "s|$original_package|com.github.vdesabou|g" \
                  $tmp_dir/value_schema  > /tmp/tmp

              mv /tmp/tmp $tmp_dir/value_schema
              log "âœ¨ Replacing package $original_package with com.github.vdesabou"
            else
              # need to add package
              cp $tmp_dir/value_schema /tmp/tmp
              line=2
              { head -n $(($line-1)) /tmp/tmp; echo "package com.github.vdesabou;"; tail -n +$line /tmp/tmp; } > $tmp_dir/value_schema
            fi

            original_java_outer_classname=$(grep "java_outer_classname" $tmp_dir/value_schema | cut -d "\"" -f 2 | cut -d "\"" -f 1 | head -1)
            if [ "$original_java_outer_classname" != "" ]
            then
              sed -e "s|$original_java_outer_classname|CustomerImpl|g" \
                  $tmp_dir/value_schema  > /tmp/tmp

              mv /tmp/tmp $tmp_dir/value_schema
              log "âœ¨ Replacing java_outer_classname $original_java_outer_classname with CustomerImpl"
            else
              # need to add java_outer_classname
              cp $tmp_dir/value_schema /tmp/tmp
              line=3
              { head -n $(($line-1)) /tmp/tmp; echo "option java_outer_classname = \"CustomerImpl\";"; tail -n +$line /tmp/tmp; } > $tmp_dir/value_schema
            fi

            cp $tmp_dir/value_schema $repro_dir/$producer_hostname/src/main/resources/schema/Customer.proto
          ;;

          none)
          ;;
          *)
            logerror "producer name not valid ! Should be one of avro, avro-with-key, json-schema, json-schema-with-key, protobuf or protobuf-with-key"
            exit 1
          ;;
        esac
      fi

      # update docker compose with producer container
      if [[ "$dir1" = *connect ]]
      then
        get_producer_heredoc
      fi

      if [[ "$dir1" = *ccloud ]]
      then
        get_producer_ccloud_heredoc
      fi
    done

    if [ "${docker_compose_file}" != "" ]
    then
      cp $docker_compose_test_file $tmp_dir/tmp_file
      line=$(grep -n 'services:' $docker_compose_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/producer; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $docker_compose_test_file

    else

      logwarn "As docker-compose override file could not be determined, you will need to add this manually:"
      cat $tmp_dir/producer
    fi

    for((i=1;i<=$nb_producers;i++)); do
      log "âœ¨ Adding Java $producer producer in $repro_dir/$producer_hostname"
      producer_hostname=""
      producer_hostname="producer-repro-$description_kebab_case"
      producer_hostname=${producer_hostname:0:21}

      if [ $nb_producers -eq 1 ]
      then
        producer_hostname="${producer_hostname}"
      else
        producer_hostname="${producer_hostname}$i"
      fi

      list="$list $producer_hostname"

    done
    get_producer_build_heredoc
    # log "âœ¨ Adding command to build jar for $producer_hostname to $repro_test_file"
    cp $repro_test_file $tmp_dir/tmp_file
    line=$(grep -n '${DIR}/../../environment' $repro_test_file | cut -d ":" -f 1 | tail -n1)

    { head -n $(($line-1)) $tmp_dir/tmp_file; cat $tmp_dir/build_producer; tail -n +$line $tmp_dir/tmp_file; } > $repro_test_file

    kafka_cli_producer_error=0
    kafka_cli_producer_eof=0
    line_kafka_cli_producer=$(egrep -n "kafka-console-producer|kafka-avro-console-producer|kafka-json-schema-console-producer|kafka-protobuf-console-producer" $repro_test_file | cut -d ":" -f 1 | tail -n1)
    if [ $? != 0 ] || [ "$line_kafka_cli_producer" == "" ]
    then
        logwarn "Could not find kafka cli producer!"
        kafka_cli_producer_error=1
    fi
    set +e
    egrep "kafka-console-producer|kafka-avro-console-producer|kafka-json-schema-console-producer|kafka-protobuf-console-producer" $repro_test_file | grep EOF > /dev/null
    if [ $? = 0 ]
    then
        kafka_cli_producer_eof=1

        sed -n "$line_kafka_cli_producer,$(($line_kafka_cli_producer + 10))p" $repro_test_file > /tmp/tmp
        tmp=$(grep -n "^EOF" /tmp/tmp | cut -d ":" -f 1 | tail -n1)
        if [ $tmp == "" ]
        then
          logwarn "Could not determine EOF for kafka cli producer!"
          kafka_cli_producer_error=1
        fi
        line_kafka_cli_producer_end=$(($line_kafka_cli_producer + $tmp))
    fi
    set -e
    if [ $kafka_cli_producer_error = 1 ]
    then
      get_producer_fixthis_heredoc
    fi

    for((i=1;i<=$nb_producers;i++)); do
      producer_hostname=""
      producer_hostname="producer-repro-$description_kebab_case"
      producer_hostname=${producer_hostname:0:21}

      if [ $nb_producers -eq 1 ]
      then
        producer_hostname="${producer_hostname}"
      else
        producer_hostname="${producer_hostname}$i"
      fi
      get_producer_run_heredoc
    done
    if [ $kafka_cli_producer_error = 1 ]
    then
      get_producer_fixthis_heredoc
    fi
    # log "âœ¨ Adding command to run producer to $repro_test_file"
    cp $repro_test_file $tmp_dir/tmp_file

    if [ $kafka_cli_producer_error == 1 ]
    then
        { head -n $(($line-1)) $tmp_dir/tmp_file; cat $tmp_dir/java_producer; tail -n +$line $tmp_dir/tmp_file; } > $repro_test_file
    else
      if [ $kafka_cli_producer_eof == 0 ]
      then
        line_kafka_cli_producer_end=$(($line_kafka_cli_producer + 1))
      fi
      { head -n $(($line_kafka_cli_producer - 2)) $tmp_dir/tmp_file; cat $tmp_dir/java_producer; tail -n +$line_kafka_cli_producer_end $tmp_dir/tmp_file; } > $repro_test_file
    fi

    # deal with converters

    sink_key_converter=$(grep "\"key.converter\"" $repro_test_file | cut -d '"' -f 4)
    if [ "$sink_key_converter" == "" ]
    then
      log "ğŸ’± Sink connector is using default key.converter, i.e org.apache.kafka.connect.storage.StringConverter"
    else
      if [ "$sink_key_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
      then
        # check schemas.enable
        sink_key_json_converter_schemas_enable=$(grep "\"key.converter.schemas.enable\"" $repro_test_file | cut -d '"' -f 4)
        if [ "$sink_key_json_converter_schemas_enable" == "" ]
        then
          log "ğŸ’± Sink connector is using key.converter $sink_key_converter with schemas.enable=true"
        else
          log "ğŸ’± Sink connector is using key.converter $sink_key_converter with schemas.enable=$sink_key_json_converter_schemas_enable"
        fi
      else
        log "ğŸ’± Sink connector is using key.converter $sink_key_converter"
      fi
    fi

    sink_value_converter=$(grep "\"value.converter\"" $repro_test_file | cut -d '"' -f 4)
    if [ "$sink_value_converter" == "" ]
    then
      log "ğŸ’± Sink connector is using default value.converter, i.e io.confluent.connect.avro.AvroConverter"
    else
      if [ "$sink_value_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
      then
        # check schemas.enable
        sink_value_json_converter_schemas_enable=$(grep "\"value.converter.schemas.enable\"" $repro_test_file | cut -d '"' -f 4)
        if [ "$sink_value_json_converter_schemas_enable" == "" ]
        then
          log "ğŸ’± Sink connector is using value.converter $sink_value_converter with schemas.enable=true"
        else
          log "ğŸ’± Sink connector is using value.converter $sink_value_converter with schemas.enable=$sink_value_json_converter_schemas_enable"
        fi
      else
        log "ğŸ’± Sink connector is using value.converter $sink_value_converter"
      fi
    fi

    if [ "$sink_value_converter" == "" ]
    then
      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $repro_test_file; cat $tmp_dir/value_converter; tail -n +$(($line+1)) $repro_test_file; } > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file
    else
      # remove existing value.converter
      grep -vwE "\"value.converter" $repro_test_file > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file

      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $repro_test_file; cat $tmp_dir/value_converter; tail -n +$(($line+1)) $repro_test_file; } > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file
    fi
    log "ğŸ”® Changing Sink connector value.converter to use same as producer:"
    cat $tmp_dir/value_converter

    if [ "$sink_key_converter" == "" ]
    then
      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $repro_test_file; cat $tmp_dir/key_converter; tail -n +$(($line+1)) $repro_test_file; } > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file
    else
      # remove existing key.converter
      grep -vwE "\"key.converter" $repro_test_file > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file

      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $repro_test_file; cat $tmp_dir/key_converter; tail -n +$(($line+1)) $repro_test_file; } > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file
    fi
    log "ğŸ”® Changing Sink connector key.converter to use same as producer:"
    cat $tmp_dir/key_converter
  fi

  if [[ -n "$add_custom_smt" ]]
  then
    custom_smt_name=""
    custom_smt_name="MyCustomSMT-$description_kebab_case"
    custom_smt_name=${custom_smt_name:0:18}
    mkdir -p $repro_dir/$custom_smt_name/
    cp -Ra ../../other/custom-smt/MyCustomSMT/* $repro_dir/$custom_smt_name/

    get_custom_smt_build_heredoc
    # log "âœ¨ Adding command to build jar for $custom_smt_name to $repro_test_file"
    cp $repro_test_file $tmp_dir/tmp_file
    line=$(grep -n '${DIR}/../../environment' $repro_test_file | cut -d ":" -f 1 | tail -n1)

    { head -n $(($line-1)) $tmp_dir/tmp_file; cat $tmp_dir/build_custom_smt; tail -n +$line $tmp_dir/tmp_file; } > $repro_test_file

    connector_paths=$(grep "CONNECT_PLUGIN_PATH" "${docker_compose_file}" | grep -v "KSQL_CONNECT_PLUGIN_PATH" | cut -d ":" -f 2  | tr -s " " | head -1)
    if [ "$connector_paths" == "" ]
    then
      logerror "not a connector test"
      exit 1
    else
      #  Loop on all connectors in CONNECT_PLUGIN_PATH and install custom SMT jar in lib folder
      my_array_connector_tag=($(echo $CONNECTOR_TAG | tr "," "\n"))
      for connector_path in ${connector_paths//,/ }
      do
        echo "log \"ğŸ“‚ Copying custom jar to connector folder $connector_path/lib/\"" >> $tmp_dir/build_custom_docker_cp_smt
        echo "docker cp $repro_dir/$custom_smt_name/target/MyCustomSMT-1.0.0-SNAPSHOT-jar-with-dependencies.jar connect:$connector_path/lib/" >> $tmp_dir/build_custom_docker_cp_smt
      done
      echo "log \"â™»ï¸ Restart connect worker to load\"" >> $tmp_dir/build_custom_docker_cp_smt
      echo "docker restart connect" >> $tmp_dir/build_custom_docker_cp_smt
      echo "sleep 45" >> $tmp_dir/build_custom_docker_cp_smt
    fi

    cp $repro_test_file $tmp_dir/tmp_file
    line=$(grep -n '${DIR}/../../environment' $repro_test_file | cut -d ":" -f 1 | tail -n1)

    { head -n $(($line+2)) $tmp_dir/tmp_file; cat $tmp_dir/build_custom_docker_cp_smt; tail -n +$(($line+2)) $tmp_dir/tmp_file; } > $repro_test_file

    existing_transforms=$(grep "\"transforms\"" $repro_test_file | cut -d '"' -f 4)
    if [ "$existing_transforms" == "" ]
    then
      echo "              \"transforms\": \"MyCustomSMT\"," >> $tmp_dir/build_custom_smt_json_config
      echo "              \"transforms.MyCustomSMT.type\": \"com.github.vdesabou.kafka.connect.transforms.MyCustomSMT\"," >> $tmp_dir/build_custom_smt_json_config

      cp $repro_test_file $tmp_dir/tmp_file
      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/build_custom_smt_json_config; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $repro_test_file
    else
      log "ğŸ¤– Connector is using existing transforms $existing_transforms, the new custom SMT will be added to the list."

      # remove existing transforms
      grep -vwE "\"transforms\"" $repro_test_file > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file

      echo "              \"transforms\": \"MyCustomSMT,$existing_transforms\"," >> $tmp_dir/build_custom_smt_json_config
      echo "              \"transforms.MyCustomSMT.type\": \"com.github.vdesabou.kafka.connect.transforms.MyCustomSMT\"," >> $tmp_dir/build_custom_smt_json_config

      cp $repro_test_file $tmp_dir/tmp_file
      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/build_custom_smt_json_config; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $repro_test_file
    fi

  fi
  if [[ -n "$sink_file" ]]
  then
    if [[ $sink_file == *"@"* ]]
    then
      sink_file=$(echo "$sink_file" | cut -d "@" -f 2)
    fi
    test_sink_file_directory="$(dirname "${sink_file}")"

    # docker-compose part
    # determining the docker-compose file from from test_file
    docker_compose_sink_file=$(grep "environment" "$sink_file" | grep DIR | grep start.sh | cut -d "/" -f 7 | cut -d '"' -f 1 | tail -n1 | xargs)
    docker_compose_sink_file="${test_sink_file_directory}/${docker_compose_sink_file}"
    cp $docker_compose_test_file /tmp/1.yml
    cp $docker_compose_sink_file /tmp/2.yml
    yq ". *= load(\"/tmp/1.yml\")" /tmp/2.yml > $docker_compose_test_file

    connector_paths=$(grep "CONNECT_PLUGIN_PATH" "${docker_compose_file}" | grep -v "KSQL_CONNECT_PLUGIN_PATH" | cut -d ":" -f 2  | tr -s " " | head -1)
    sink_connector_paths=$(grep "CONNECT_PLUGIN_PATH" "${docker_compose_sink_file}" | grep -v "KSQL_CONNECT_PLUGIN_PATH" | cut -d ":" -f 2  | tr -s " " | head -1)
    if [ "$sink_connector_paths" == "" ]
    then
      logerror "cannot find CONNECT_PLUGIN_PATH in  ${docker_compose_sink_file}"
      exit 1
    else
      tmp_new_connector_paths="$connector_paths,$sink_connector_paths"
      new_connector_paths=$(echo "$tmp_new_connector_paths" | sed 's/ //g')
      cp $docker_compose_test_file /tmp/1.yml

      yq -i ".services.connect.environment.CONNECT_PLUGIN_PATH = \"$new_connector_paths\"" /tmp/1.yml
      cp /tmp/1.yml $docker_compose_test_file
    fi


    # sh part

    line_final_source=$(grep -n 'source ${DIR}/../../scripts/utils.sh' $repro_test_file | cut -d ":" -f 1 | tail -n1)
    line_final_environment=$(grep -n '${DIR}/../../environment' $repro_test_file | cut -d ":" -f 1 | tail -n1)
    line_sink_source=$(grep -n 'source ${DIR}/../../scripts/utils.sh' $sink_file | cut -d ":" -f 1 | tail -n1)

    line_sink_environment=$(grep -n '${DIR}/../../environment' $sink_file | cut -d ":" -f 1 | tail -n1)

    # get converter info
    source_key_converter=$(grep "\"key.converter\"" $repro_test_file | cut -d '"' -f 4)
    if [ "$source_key_converter" == "" ]
    then
      log "ğŸ’± Source connector is using default key.converter, i.e org.apache.kafka.connect.storage.StringConverter"
    else
      if [ "$source_key_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
      then
        # check schemas.enable
        source_key_json_converter_schemas_enable=$(grep "\"key.converter.schemas.enable\"" $repro_test_file | cut -d '"' -f 4)
        if [ "$source_key_json_converter_schemas_enable" == "" ]
        then
          log "ğŸ’± Source connector is using key.converter $source_key_converter with schemas.enable=true"
        else
          log "ğŸ’± Source connector is using key.converter $source_key_converter with schemas.enable=$source_key_json_converter_schemas_enable"
        fi
      else
        log "ğŸ’± Source connector is using key.converter $source_key_converter"
      fi
    fi

    source_value_converter=$(grep "\"value.converter\"" $repro_test_file | cut -d '"' -f 4)
    if [ "$source_value_converter" == "" ]
    then
      log "ğŸ’± Source connector is using default value.converter, i.e io.confluent.connect.avro.AvroConverter"
    else
      if [ "$source_value_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
      then
        # check schemas.enable
        source_value_json_converter_schemas_enable=$(grep "\"value.converter.schemas.enable\"" $repro_test_file | cut -d '"' -f 4)
        if [ "$source_value_json_converter_schemas_enable" == "" ]
        then
          log "ğŸ’± Source connector is using value.converter $source_value_converter with schemas.enable=true"
        else
          log "ğŸ’± Source connector is using value.converter $source_value_converter with schemas.enable=$source_value_json_converter_schemas_enable"
        fi
      else
        log "ğŸ’± Source connector is using value.converter $source_value_converter"
      fi
    fi

    sink_key_converter=$(grep "\"key.converter\"" $sink_file | cut -d '"' -f 4)
    if [ "$sink_key_converter" == "" ]
    then
      log "ğŸ’± Sink connector is using default key.converter, i.e org.apache.kafka.connect.storage.StringConverter"
    else
      if [ "$sink_key_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
      then
        # check schemas.enable
        sink_key_json_converter_schemas_enable=$(grep "\"key.converter.schemas.enable\"" $sink_file | cut -d '"' -f 4)
        if [ "$sink_key_json_converter_schemas_enable" == "" ]
        then
          log "ğŸ’± Sink connector is using key.converter $sink_key_converter with schemas.enable=true"
        else
          log "ğŸ’± Sink connector is using key.converter $sink_key_converter with schemas.enable=$sink_key_json_converter_schemas_enable"
        fi
      else
        log "ğŸ’± Sink connector is using key.converter $sink_key_converter"
      fi
    fi

    sink_value_converter=$(grep "\"value.converter\"" $sink_file | cut -d '"' -f 4)
    if [ "$sink_value_converter" == "" ]
    then
      log "ğŸ’± Sink connector is using default value.converter, i.e io.confluent.connect.avro.AvroConverter"
    else
      if [ "$sink_value_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
      then
        # check schemas.enable
        sink_value_json_converter_schemas_enable=$(grep "\"value.converter.schemas.enable\"" $sink_file | cut -d '"' -f 4)
        if [ "$sink_value_json_converter_schemas_enable" == "" ]
        then
          log "ğŸ’± Sink connector is using value.converter $sink_value_converter with schemas.enable=true"
        else
          log "ğŸ’± Sink connector is using value.converter $sink_value_converter with schemas.enable=$sink_value_json_converter_schemas_enable"
        fi
      else
        log "ğŸ’± Sink connector is using value.converter $sink_value_converter"
      fi
    fi

    sed -n "$(($line_sink_source+1)),$(($line_sink_environment-1))p" $sink_file > $tmp_dir/pre_sink
    cp $repro_test_file $tmp_dir/tmp_file

    { head -n $(($line_final_environment-1)) $tmp_dir/tmp_file; cat $tmp_dir/pre_sink; tail -n +$line_final_environment $tmp_dir/tmp_file; } > $repro_test_file

    sed -n "$(($line_sink_environment+1)),$ p" $sink_file > $tmp_dir/tmp_file

    # deal with converters
    set +e
    if [ "$source_value_converter" == "" ] && [ "$sink_value_converter" == "" ]
    then
      # do nothing
      :
    else
      grep "\"value.converter" $repro_test_file > $tmp_dir/source_value_converter
      if [ "$sink_value_converter" == "" ]
      then
        line=$(grep -n 'connector.class' $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)

        { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/source_value_converter; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $tmp_dir/tmp_file2
        cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file
      else
        # remove existing value.converter
        grep -vwE "\"value.converter" $tmp_dir/tmp_file > $tmp_dir/tmp_file2
        cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file

        line=$(grep -n 'connector.class' $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)

        { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/source_value_converter; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $tmp_dir/tmp_file2
        cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file
      fi
      log "ğŸ”® Changing Sink connector value.converter to use same as source:"
      cat $tmp_dir/source_value_converter
    fi
    if [ "$source_key_converter" == "" ] && [ "$sink_key_converter" == "" ]
    then
      # do nothing
      :
    else
      grep "\"key.converter" $repro_test_file > $tmp_dir/source_key_converter
      if [ "$sink_key_converter" == "" ]
      then
        line=$(grep -n 'connector.class' $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)

        { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/source_key_converter; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $tmp_dir/tmp_file2
        cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file
      else
        # remove existing key.converter
        grep -vwE "\"key.converter" $tmp_dir/tmp_file > $tmp_dir/tmp_file2
        cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file

        line=$(grep -n 'connector.class' $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)

        { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/source_key_converter; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $tmp_dir/tmp_file2
        cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file
      fi
      log "ğŸ”® Changing Sink connector key.converter to use same as source:"
      cat $tmp_dir/source_key_converter
    fi
    set -e
    # need to remove cli which produces and change topic
    kafka_cli_producer_error=0
    kafka_cli_producer_eof=0
    line_kafka_cli_producer=$(egrep -n "kafka-console-producer|kafka-avro-console-producer|kafka-json-schema-console-producer|kafka-protobuf-console-producer" $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)
    if [ $? != 0 ]
    then
        logwarn "Could not find kafka cli producer!"
        kafka_cli_producer_error=1
    fi
    set +e
    egrep "kafka-console-producer|kafka-avro-console-producer|kafka-json-schema-console-producer|kafka-protobuf-console-producer" $tmp_dir/tmp_file | grep EOF > /dev/null
    if [ $? = 0 ]
    then
        kafka_cli_producer_eof=1

        sed -n "$line_kafka_cli_producer,$(($line_kafka_cli_producer + 10))p" $tmp_dir/tmp_file > /tmp/tmp
        tmp=$(grep -n "^EOF" /tmp/tmp | cut -d ":" -f 1 | tail -n1)
        if [ $tmp == "" ]
        then
          logwarn "Could not determine EOF for kafka cli producer!"
          kafka_cli_producer_error=1
        fi
        line_kafka_cli_producer_end=$(($line_kafka_cli_producer + $tmp))
    fi

    if [ $kafka_cli_producer_error == 0 ]
    then
      if [ $kafka_cli_producer_eof == 0 ]
      then
        line_kafka_cli_producer_end=$(($line_kafka_cli_producer + 1))
      fi
      { head -n $(($line_kafka_cli_producer - 2)) $tmp_dir/tmp_file; tail -n +$line_kafka_cli_producer_end $tmp_dir/tmp_file; } >  $tmp_dir/tmp_file2
      cat  $tmp_dir/tmp_file2 >> $repro_test_file
    fi
    set -e

    awk -F'--topic ' '{print $2}' $repro_test_file > $tmp_dir/tmp
    sed '/^$/d' $tmp_dir/tmp > $tmp_dir/tmp2
    original_topic_name=$(head -1 $tmp_dir/tmp2 | cut -d " " -f1)

    if [ "$original_topic_name" != "" ]
    then
      cp $repro_test_file $tmp_dir/tmp_file
      line=$(grep -n '"topics"' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      echo "              \"topics\": \"$original_topic_name\"," > $tmp_dir/topic_line
      { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/topic_line; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $repro_test_file
    else

      logwarn "Could not find original topic name! "
      logwarn "You would need to change topics config for sink by yourself."
    fi
  fi

  cat $repro_test_file > $tmp_dir/tmp_file

  echo "" >> $tmp_dir/tmp_file

  echo "#################################################################################################" >> $tmp_dir/tmp_file
  echo "# ğŸ§  below is a list of cli commands that are helpful at the end of an example" >> $tmp_dir/tmp_file
  echo "# ğŸ§  for full documentation, visit https://kafka-docker-playground.io/#/cli !" >> $tmp_dir/tmp_file
  echo "#################################################################################################" >> $tmp_dir/tmp_file
  echo "" >> $tmp_dir/tmp_file
  echo "# ğŸ•µï¸ to check logs (see https://kafka-docker-playground.io/#/cli?id=%f0%9f%95%b5%ef%b8%8f-logs)" >> $tmp_dir/tmp_file
  echo "# Example: check logs" >> $tmp_dir/tmp_file
  echo "# playground container logs --container connect" >> $tmp_dir/tmp_file
  echo "# playground container logs --container connect --open" >> $tmp_dir/tmp_file
  echo "" >> $tmp_dir/tmp_file
  echo "# ğŸ˜´ use this command if you want to wait for a specific message to appear in logs" >> $tmp_dir/tmp_file
  echo "# playground container logs --container connect --wait-for-log \"<text to search>\" --max-wait 600" >> $tmp_dir/tmp_file
  echo "" >> $tmp_dir/tmp_file
  echo "# ğŸ¢ use this command if you want to wait for connector consumer lag to be zero" >> $tmp_dir/tmp_file
  echo "# playground connector show-lag --wait-for-zero-lag" >> $tmp_dir/tmp_file

  echo "exit 0" >> $tmp_dir/tmp_file
  echo "" >> $tmp_dir/tmp_file
  echo "" >> $tmp_dir/tmp_file
  # echo ": '" >> $tmp_dir/tmp_file

  echo "#################################################################################################" >> $tmp_dir/tmp_file
  echo "# ğŸš€ below is a list of snippets that can help you to build your example !" >> $tmp_dir/tmp_file
  echo "# ğŸš€ for full documentation, visit https://kafka-docker-playground.io/#/ !" >> $tmp_dir/tmp_file
  echo "#################################################################################################" >> $tmp_dir/tmp_file
  echo "" >> $tmp_dir/tmp_file
  if [[ "$base1" == *sink ]]
  then
    cat $root_folder/scripts/cli/snippets/sink.sh | grep -v "#!/bin/bash" >> $tmp_dir/tmp_file
  fi

  # echo "'" >> $tmp_dir/tmp_file
  mv $tmp_dir/tmp_file $repro_test_file

  chmod u+x $repro_test_file
  repro_test_filename=$(basename -- "$repro_test_file")

  log "ğŸŒŸ Command to run generated example"
  echo "playground run -f $repro_dir/$repro_test_filename"
  echo "playground run -f $repro_dir/$repro_test_filename" > /tmp/playground-run

  if config_has_key "editor"
  then
    editor=$(config_get "editor")
    log "ğŸ“– Opening ${repro_test_filename} using configured editor $editor"
    $editor $repro_dir/$repro_test_filename
  else
    if [[ $(type code 2>&1) =~ "not found" ]]
    then
      logerror "Could not determine an editor to use as default code is not found - you can change editor by updating config.ini"
      exit 1
    else
      log "ğŸ“– Opening ${repro_test_filename} with code (default) - you can change editor by updating config.ini"
      code $repro_dir/$repro_test_filename
    fi
  fi

  # run command specifics:

  flag_list=""
  if [[ -n "$tag" ]]
  then
    flag_list="--tag=$tag"
  fi

  if [[ -n "$connector_tag" ]]
  then
    flag_list="$flag_list --connector-tag=$connector_tag"
  fi

  if [[ -n "$connector_zip" ]]
  then
    if [[ $connector_zip == *"@"* ]]
    then
      connector_zip=$(echo "$connector_zip" | cut -d "@" -f 2)
    fi
    flag_list="$flag_list --connector-zip=$connector_zip"
  fi

  if [[ -n "$connector_jar" ]]
  then
    if [[ $connector_jar == *"@"* ]]
    then
      connector_jar=$(echo "$connector_jar" | cut -d "@" -f 2)
    fi
    flag_list="$flag_list --connector-jar=$connector_jar"
  fi

  if [[ -n "$enable_ksqldb" ]]
  then
    force_enable --enable_ksqldb ENABLE_KSQLDB
  fi

  if [[ -n "$enable_c3" ]]
  then
    force_enable --enable-control-center ENABLE_CONTROL_CENTER
  fi

  if [[ -n "$enable_conduktor" ]]
  then
    force_enable --enable-conduktor ENABLE_CONDUKTOR
  fi

  if [[ -n "$enable_multiple_brokers" ]]
  then
    force_enable --enable-multiple-broker ENABLE_KAFKA_NODES
  fi

  if [[ -n "$enable_multiple_connect_workers" ]]
  then
    force_enable --enable-multiple-connect-workers ENABLE_CONNECT_NODES
    cp $docker_compose_test_file /tmp/playground-backup-docker-compose.yml
    yq -i '.services.connect2 = .services.connect' /tmp/playground-backup-docker-compose.yml
    yq -i '.services.connect3 = .services.connect' /tmp/playground-backup-docker-compose.yml
    cp /tmp/playground-backup-docker-compose.yml $docker_compose_test_file
  fi

  if [[ -n "$enable_jmx_grafana" ]]
  then
    force_enable --enable-jmx-grafana ENABLE_JMX_GRAFANA
  fi

  if [[ -n "$enable_kcat" ]]
  then
    force_enable --enable-kcat ENABLE_KCAT
  fi

  if [[ -n "$enable_sr_maven_plugin_app" ]]
  then
    force_enable --enable-sr-maven-plugin-app ENABLE_SR_MAVEN_PLUGIN_NODE
  fi

  if [[ -n "$enable_sql_datagen" ]]
  then
    force_enable --enable-sql-datagen SQL_DATAGEN
  fi

  log "ğŸ•¹ï¸ Ready? Run it now?"
  check_if_continue
  playground run -f $repro_dir/$repro_test_filename $flag_list ${other_args[*]}
}

# :command.function
playground_get_docker_compose_command() {
  # src/get_docker_compose_command.sh
  # keep TAG, CONNECT TAG and ORACLE_IMAGE
  export TAG=$(docker inspect -f '{{.Config.Image}}' broker 2> /dev/null | cut -d ":" -f 2)
  export CONNECT_TAG=$(docker inspect -f '{{.Config.Image}}' connect 2> /dev/null | cut -d ":" -f 2)
  export ORACLE_IMAGE=$(docker inspect -f '{{.Config.Image}}' oracle 2> /dev/null)

  if [ ! -f /tmp/playground-command ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1
  fi

  sed -e "s|up -d|config|g" \
      /tmp/playground-command > /tmp/playground-command-config

  bash /tmp/playground-command-config

}

# :command.function
playground_get_properties_command() {
  # src/get_properties_command.sh
  container="${args[--container]}"

  log "Displaying properties file for $container"
  # see heredocs.sh
  get_properties_command_heredoc "$container"
}

# :command.function
playground_schema_get_command() {
  # src/schema_get_command.sh
  subject="${args[--subject]}"
  deleted="${args[--deleted]}"

  ret=$(get_sr_url_and_security)

  sr_url=$(echo "$ret" | cut -d "@" -f 1)
  sr_security=$(echo "$ret" | cut -d "@" -f 2)

  tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)
  trap 'rm -rf $tmp_dir' EXIT
  #log "tmp_dir is $tmp_dir"

  if [[ ! -n "$subject" ]]
  then
      log "âœ¨ --subject flag was not provided, applying command to all subjects"
      if [[ -n "$deleted" ]]
      then
          subject=$(playground get-subject-list)
          echo "$subject" > $tmp_dir/subjects-all
          log "ğŸ§Ÿ deleted subjects are included"
          subject=$(playground get-subject-list --deleted)
          echo "$subject" > $tmp_dir/subjects-deleted-tmp

          sort $tmp_dir/subjects-all $tmp_dir/subjects-deleted-tmp | uniq -u > $tmp_dir/subjects-deleted
      else
          subject=$(playground get-subject-list)
      fi
      if [ "$subject" == "" ]
      then
          logerror "âŒ No subject found !"
          exit 1
      fi
  fi

  maybe_include_deleted=""
  if [[ -n "$deleted" ]]
  then
      maybe_include_deleted="?deleted=true"
  fi

  found=0
  items=($subject)
  for subject in ${items[@]}
  do
      versions=$(curl $sr_security -s "${sr_url}/subjects/${subject}/versions$maybe_include_deleted")

      for version in $(echo "${versions}" | jq -r '.[]')
      do
          schema_type=$(curl $sr_security -s "${sr_url}/subjects/${subject}/versions/${version}$maybe_include_deleted" | jq -r .schemaType)
          id=$(curl $sr_security -s "${sr_url}/subjects/${subject}/versions/${version}$maybe_include_deleted" | jq -r .id)
          case "${schema_type}" in
          JSON|null)
              schema=$(curl $sr_security -s "${sr_url}/subjects/${subject}/versions/${version}/schema$maybe_include_deleted" | jq .)
          ;;
          PROTOBUF)
              schema=$(curl $sr_security -s "${sr_url}/subjects/${subject}/versions/${version}/schema$maybe_include_deleted")
          ;;
          esac

          if [ -f $tmp_dir/subjects-deleted ] && grep "${subject}" $tmp_dir/subjects-deleted
          then
              log "ğŸ§Ÿ (deleted) subject ${subject} ğŸ’¯ version ${version} (id $id)"
          else
              log "ğŸ”° subject ${subject} ğŸ’¯ version ${version} (id $id)"
          fi
          found=1

          echo "${schema}"
      done
  done

  if [[ -n "$subject" ]]
  then
      if [ $found -eq 0 ]
      then
          logerror "âŒ No schema found !"
          exit 1
      fi
  fi
}

# :command.function
playground_schema_register_command() {
  # src/schema_register_command.sh
  subject="${args[--subject]}"
  schema="${args[--input]}"
  verbose="${args[--verbose]}"

  ret=$(get_sr_url_and_security)

  sr_url=$(echo "$ret" | cut -d "@" -f 1)
  sr_security=$(echo "$ret" | cut -d "@" -f 2)

  tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)
  trap 'rm -rf $tmp_dir' EXIT
  #log "tmp_dir is $tmp_dir"
  schema_file=$tmp_dir/value_schema

  if [ "$schema" = "-" ]
  then
      schema_content=$(cat "$schema")
      echo "$schema_content" > $schema_file
  else
      if [[ $schema == @* ]]
      then
          # this is a schema file
          argument_schema_file=$(echo "$schema" | cut -d "@" -f 2)
          cp $argument_schema_file $schema_file
      elif [ -f $schema ]
      then
          cp $schema $schema_file
      else
          schema_content=$schema
          echo "$schema_content" > $schema_file
      fi
  fi

  if grep -q "proto3" $schema_file
  then
      log "ğŸ”® schema was identified as protobuf"
      schema_type=PROTOBUF
  elif grep -q "\"type\"\s*:\s*\"object\"" $schema_file
  then
      log "ğŸ”® schema was identified as json schema"
      schema_type=JSON
  elif grep -q "\"type\"\s*:\s*\"record\"" $schema_file
  then
      log "ğŸ”® schema was identified as avro"
      schema_type=AVRO
  else
      logerror "âŒ no known schema could be identified"
      exit 1
  fi

  json="{\"schemaType\":\"$schema_type\"}"

  content=$(cat $schema_file | tr -d '\n' | tr -s ' ')
  json_new=$(echo $json | jq --arg content "$content" '. + { "schema": $content }')

  # check if schema already exists
  # https://docs.confluent.io/platform/current/schema-registry/develop/api.html#post--subjects-(string-%20subject)
  curl_output=$(curl $sr_security --request POST -s "${sr_url}/subjects/${subject}" \
  --header 'Content-Type: application/vnd.schemaregistry.v1+json' \
  --data "$json_new" | jq .)
  ret=$?
  if [ $ret -eq 0 ]
  then
      error_code=$(echo "$curl_output" | jq -r .error_code)
      if [ "$error_code" != "null" ]
      then
          if [ "$error_code" != "40403" ]
          then
              message=$(echo "$curl_output" | jq -r .message)
              logerror "Command failed with error code $error_code"
              logerror "$message"
              exit 1
          fi
      else
          id=$(echo "$curl_output" | jq -r .id)
          version=$(echo "$curl_output" | jq -r .version)
          log "ğŸšª Skipping as schema already exists with id $id (version $version)"
          exit 0
      fi
  else
      logerror "âŒ curl request failed with error code $ret!"
      exit 1
  fi

  log "âºï¸ Registering schema to subject ${subject}"
  if [[ -n "$verbose" ]]
  then
      set -x
  fi
  curl $sr_security --request POST -s "${sr_url}/subjects/${subject}/versions" \
      --header 'Content-Type: application/vnd.schemaregistry.v1+json' \
      --data "$json_new" | jq .

}

# :command.function
playground_schema_get_compatibility_command() {
  # src/schema_get_compatibility_command.sh
  subject="${args[--subject]}"

  ret=$(get_sr_url_and_security)

  sr_url=$(echo "$ret" | cut -d "@" -f 1)
  sr_security=$(echo "$ret" | cut -d "@" -f 2)

  log "ğŸ›¡ï¸ Get compatibility for subject ${subject}"
  curl_output=$(curl $sr_security -s -H "Content-Type: application/vnd.schemaregistry.v1+json" "${sr_url}/config/${subject}")
  ret=$?
  if [ $ret -eq 0 ]
  then
      error_code=$(echo "$curl_output" | jq -r .error_code)
      if [ "$error_code" != "null" ]
      then
          message=$(echo "$curl_output" | jq -r .message)
          logerror "Command failed with error code $error_code"
          logerror "$message"
          exit 1
      else
          compatibilityLevel=$(echo "$curl_output" | jq -r .compatibilityLevel)
          echo "$compatibilityLevel"
      fi
  else
      logerror "âŒ curl request failed with error code $ret!"
      exit 1
  fi
}

# :command.function
playground_schema_set_compatibility_command() {
  # src/schema_set_compatibility_command.sh
  subject="${args[--subject]}"
  compatibility="${args[--compatibility]}"

  ret=$(get_sr_url_and_security)

  sr_url=$(echo "$ret" | cut -d "@" -f 1)
  sr_security=$(echo "$ret" | cut -d "@" -f 2)

  log "ğŸ›¡ï¸ Set compatibility for subject ${subject} to $compatibility"
  curl_output=$(curl $sr_security -s -X PUT -H "Content-Type: application/vnd.schemaregistry.v1+json" --data "{\"compatibility\": \"$compatibility\"}" "${sr_url}/config/${subject}" | jq .)
  ret=$?
  if [ $ret -eq 0 ]
  then
      error_code=$(echo "$curl_output" | jq -r .error_code)
      if [ "$error_code" != "null" ]
      then
          message=$(echo "$curl_output" | jq -r .message)
          logerror "Command failed with error code $error_code"
          logerror "$message"
          exit 1
      else
          compatibilityLevel=$(echo "$curl_output" | jq -r .compatibilityLevel)
          echo "$compatibilityLevel"
      fi
  else
      logerror "âŒ curl request failed with error code $ret!"
      exit 1
  fi
}

# :command.function
playground_schema_get_mode_command() {
  # src/schema_get_mode_command.sh
  subject="${args[--subject]}"

  ret=$(get_sr_url_and_security)

  sr_url=$(echo "$ret" | cut -d "@" -f 1)
  sr_security=$(echo "$ret" | cut -d "@" -f 2)

  log "ğŸ” Get mode for subject ${subject}"
  curl_output=$(curl $sr_security -s -H "Content-Type: application/vnd.schemaregistry.v1+json" "${sr_url}/mode/${subject}")
  ret=$?
  if [ $ret -eq 0 ]
  then
      error_code=$(echo "$curl_output" | jq -r .error_code)
      if [ "$error_code" != "null" ]
      then
          message=$(echo "$curl_output" | jq -r .message)
          logerror "Command failed with error code $error_code"
          logerror "$message"
          exit 1
      else
          mode=$(echo "$curl_output" | jq -r .mode)
          echo "$mode"
      fi
  else
      logerror "âŒ curl request failed with error code $ret!"
      exit 1
  fi
}

# :command.function
playground_schema_set_mode_command() {
  # src/schema_set_mode_command.sh
  subject="${args[--subject]}"
  mode="${args[--mode]}"

  ret=$(get_sr_url_and_security)

  sr_url=$(echo "$ret" | cut -d "@" -f 1)
  sr_security=$(echo "$ret" | cut -d "@" -f 2)

  log "ğŸ” Set mode for subject ${subject} to $mode"
  curl_output=$(curl $sr_security -s -X PUT -H "Content-Type: application/vnd.schemaregistry.v1+json" --data "{\"mode\": \"$mode\"}" "${sr_url}/mode/${subject}" | jq .)
  ret=$?
  if [ $ret -eq 0 ]
  then
      error_code=$(echo "$curl_output" | jq -r .error_code)
      if [ "$error_code" != "null" ]
      then
          message=$(echo "$curl_output" | jq -r .message)
          logerror "Command failed with error code $error_code"
          logerror "$message"
          exit 1
      else
          mode=$(echo "$curl_output" | jq -r .mode)
          echo "$mode"
      fi
  else
      logerror "âŒ curl request failed with error code $ret!"
      exit 1
  fi
}

# :command.function
playground_schema_delete_command() {
  # src/schema_delete_command.sh
  subject="${args[--subject]}"
  version="${args[--version]}"
  permanent="${args[--permanent]}"

  ret=$(get_sr_url_and_security)

  sr_url=$(echo "$ret" | cut -d "@" -f 1)
  sr_security=$(echo "$ret" | cut -d "@" -f 2)

  if [[ -n "$version" ]]
  then
      if [[ ! -n "$subject" ]]
      then
          logerror "âŒ --version is set without --subject being set"
          exit 1
      fi
  fi

  # https://docs.confluent.io/platform/current/schema-registry/develop/api.html#delete--subjects-(string-%20subject)-versions-(versionId-%20version)
  if [[ -n "$subject" ]]
  then
      if [[ -n "$version" ]]
      then
          log "ğŸ§Ÿ Soft deleting ğŸ’¯ version ${version} from subject ğŸ”° ${subject}"
          curl $sr_security -X DELETE -s "${sr_url}/subjects/${subject}/versions/${version}" | jq .
          if [[ -n "$permanent" ]]
          then
              log "ğŸ’€ Hard deleting ğŸ’¯ version ${version} from subject ğŸ”° ${subject}"
              curl $sr_security -X DELETE -s "${sr_url}/subjects/${subject}/versions/${version}?permanent=true" | jq .
          fi
      else
          logwarn "--version is not set, deleting all versions !"
          log "ğŸ§Ÿ Soft deleting subject ğŸ”° ${subject}"
          curl $sr_security -X DELETE -s "${sr_url}/subjects/${subject}" | jq .
          if [[ -n "$permanent" ]]
          then
              log "ğŸ’€ Hard deleting  subject ğŸ”° ${subject}"
              curl $sr_security -X DELETE -s "${sr_url}/subjects/${subject}?permanent=true" | jq .
          fi
      fi
  fi
}

# :command.function
playground_debug_install_vscode_extension_command() {
  # src/debug_install_vscode_extension_command.sh
  tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)
  trap 'rm -rf $tmp_dir' EXIT

  extension_dir=$tmp_dir/extension

  mkdir $extension_dir
  cd $extension_dir

  log "ğŸª„ Installing Shell Script Command Completion extension"

  curl -s -L https://tetradresearch.gallery.vsassets.io/_apis/public/gallery/publisher/tetradresearch/extension//vscode-h2o/latest/assetbyname/Microsoft.VisualStudio.Services.VSIXPackage -o extension.zip
  unzip extension.zip > /dev/null 2>&1

  if [ ! -f extension/out/cacheFetcher.js ]
  then
    logerror "âŒ cacheFetcher.js is not present !"
    exit 1
  fi

  if grep 'https://raw.githubusercontent.com/yamaton/h2o-curated-data/main/${kind}/json/${name}.json' extension/out/cacheFetcher.js
  then
      sed -i -E -e "s|https://raw.githubusercontent.com/yamaton/h2o-curated-data/main/\${kind}/json/\${name}.json|https://raw.githubusercontent.com/vdesabou/kafka-docker-playground/master/scripts/cli/playground.json|g" extension/out/cacheFetcher.js > /dev/null 2>&1
      zip -r extension.zip extension > /dev/null 2>&1
      mv extension.zip extension.vsix

      set +e
      code --uninstall-extension extension.vsix > /dev/null 2>&1

      code --install-extension extension.vsix > /dev/null 2>&1
      if [ $? -eq 0 ]
      then
          log "ğŸ‘ extension is now installed"
      else
          logerror "âŒ Failed to install Shell Script Command Completion extension"
      fi
  else
    logerror "âŒ cannot retrieve experimental url"
    exit 1
  fi

}

# :command.function
playground_debug_enable_remote_debugging_command() {
  # src/debug_enable_remote_debugging_command.sh
  IGNORE_CHECK_FOR_DOCKER_COMPOSE=true

  container="${args[--container]}"

  log "Enable remote debugging for $container"

  # For ccloud case
  if [ -f /tmp/delta_configs/env.delta ]
  then
       source /tmp/delta_configs/env.delta
  fi

  # keep TAG, CONNECT TAG and ORACLE_IMAGE
  export TAG=$(docker inspect -f '{{.Config.Image}}' broker 2> /dev/null | cut -d ":" -f 2)
  export CONNECT_TAG=$(docker inspect -f '{{.Config.Image}}' connect 2> /dev/null | cut -d ":" -f 2)
  export ORACLE_IMAGE=$(docker inspect -f '{{.Config.Image}}' oracle 2> /dev/null)

  if [ ! -f /tmp/playground-command ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1
  fi

  # see heredocs.sh
  get_remote_debugging_command_heredoc "$container"

  bash /tmp/playground-command-debugging

  log "If you use Visual Studio Code:"
  log "Edit .vscode/launch.json with"

  log "
  {
      \"version\": \"0.2.0\",
      \"configurations\": [

          {
              \"type\": \"java\",
              \"name\": \"Debug $component container\",
              \"request\": \"attach\",
              \"hostName\": \"127.0.0.1\",
              \"port\": 5005,
              \"timeout\": 30000
          }
      ]
  }
  "

  log "See https://kafka-docker-playground.io/#/reusables?id=âœ¨-remote-debugging"
}

# :command.function
playground_debug_testssl_command() {
  # src/debug_testssl_command.sh
  arguments="${args[arguments]}"

  log "ğŸ” Testing TLS/SSL encryption with arguments $arguments"
  docker run --rm -ti  drwetter/testssl.sh $arguments
}

# :command.function
playground_debug_generate_diagnostics_command() {
  # src/debug_generate_diagnostics_command.sh
  container="${args[--container]}"
  tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)
  trap 'rm -rf $tmp_dir' EXIT

  if [[ "$container" == "connect" ]] || [[ "$container" == "broker" ]]
  then
      log "â›‘ï¸ Creating diagnostics bundle for container ${container}"
      log "â³ please wait..."
  else
      logerror "âŒ only connect and broker containers are supported"
      exit 1
  fi

  docker exec $container curl -L https://packages.confluent.io/tools/diagnostics-bundle/diagnostics-bundle-1.0.0.jar -o /tmp/diagnostics-bundle-1.0.0.jar > /dev/null 2>&1

  fifo_path="$tmp_dir/collect_fifo"
  mkfifo "$fifo_path"

  set +e
  docker exec $container java -jar /tmp/diagnostics-bundle-1.0.0.jar collect > "$fifo_path" 2>&1 &

  # Loop through each line in the named pipe
  while read -r line
  do
      echo "$line"
      echo "$line" >> $tmp_dir/result.log

  done < "$fifo_path"

  nb=$(grep -c "Diagnostics output has been zipped and written to" $tmp_dir/result.log)
  if [ $nb -eq 0 ]
  then
      logerror "âŒ Failed to generate bundle"
      cat $tmp_dir/result.log
      exit 1
  fi
  bundle_file=$(cat $tmp_dir/result.log | grep "Diagnostics output has been zipped and written to" | cut -d ":" -f 4 | sed 's/ //g')
  bundle_file_filename=$(basename -- "$bundle_file")
  log "â›‘ï¸ diagnostics bundle is available at ${bundle_file_filename}"
  docker cp ${container}:${bundle_file} ${bundle_file_filename}
}

# :command.function
playground_debug_thread_dump_command() {
  # src/debug_thread_dump_command.sh
  container="${args[--container]}"
  filename="/tmp/thread-dump-$container-`date '+%Y-%m-%d-%H-%M-%S'`.log"

  set +e
  docker exec $container type jstack > /dev/null 2>&1
  if [ $? != 0 ]
  then
      logerror "âŒ jstack is not installed on container $container"
      exit 1
  fi
  set -e
  log "ğŸ¯ Taking thread dump on container ${container} for pid 1"
  docker exec $container jstack 1 > "$filename" 2>&1
  if [ $? -eq 0 ]
  then
      if config_has_key "editor"
      then
          editor=$(config_get "editor")
          log "ğŸ“– Opening ${filename} using configured editor $editor"
          $editor $filename
      else
          if [[ $(type code 2>&1) =~ "not found" ]]
          then
              logerror "Could not determine an editor to use as default code is not found - you can change editor by updating config.ini"
              exit 1
          else
              log "ğŸ“– Opening ${filename} with code (default) - you can change editor by updating config.ini"
              code $filename
          fi
      fi
  else
      logerror "âŒ Failed to take thread dump"
  fi
}

# :command.function
playground_debug_heap_dump_command() {
  # src/debug_heap_dump_command.sh
  container="${args[--container]}"
  filename="heap-dump-$container-`date '+%Y-%m-%d-%H-%M-%S'`.hprof"

  set +e
  docker exec $container type jmap > /dev/null 2>&1
  if [ $? != 0 ]
  then
      logerror "âŒ jmap is not installed on container $container"
      exit 1
  fi
  set -e
  log "ğŸ¯ Taking heap dump on container ${container} for pid 1"
  docker exec $container jmap -dump:live,format=b,file=/tmp/${filename} 1
  if [ $? -eq 0 ]
  then
      log "ğŸ‘» heap dump is available at ${filename}"
      docker cp ${container}:/tmp/${filename} ${filename}
      # if [[ $(type -f wireshark 2>&1) =~ "not found" ]]
      # then
      #     logwarn "ğŸ¦ˆ wireshark is not installed, grab it at https://www.wireshark.org/"
      #     exit 0
      # else
      #     log "ğŸ¦ˆ Opening ${filename} with wireshark"
      #     wireshark ${filename}
      # fi

  else
      logerror "âŒ Failed to take heap dump"
  fi

}

# :command.function
playground_debug_tcp_dump_command() {
  # src/debug_tcp_dump_command.sh
  container="${args[--container]}"
  port="${args[--port]}"
  duration="${args[--duration]}"
  filename="tcp-dump-$container-$port-`date '+%Y-%m-%d-%H-%M-%S'`.pcap"

  set +e
  docker exec $container type tcpdump > /dev/null 2>&1
  if [ $? != 0 ]
  then
      logwarn "tcpdump is not installed on container $container, attempting to install it"

      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
      dir1=$(echo ${DIR_CLI%/*})
      root_folder=$(echo ${dir1%/*})
      IGNORE_CHECK_FOR_DOCKER_COMPOSE=true
      source $root_folder/scripts/utils.sh
      if [[ "$TAG" == *ubi8 ]] || version_gt $TAG_BASE "5.9.0"
      then
        if [ `uname -m` = "arm64" ]
        then
          docker exec --privileged --user root $container bash -c "rpm -i --nosignature https://rpmfind.net/linux/centos/8-stream/AppStream/aarch64/os/Packages/tcpdump-4.9.3-2.el8.aarch64.rpm"
        else
          docker exec --privileged --user root $container bash -c "curl http://mirror.centos.org/centos/8-stream/AppStream/x86_64/os/Packages/tcpdump-4.9.3-1.el8.x86_64.rpm -o tcpdump-4.9.3-1.el8.x86_64.rpm && rpm -Uvh tcpdump-4.9.3-1.el8.x86_64.rpm"
        fi
      else
        docker exec --privileged --user root $container bash -c "apt-get update && echo bind-utils openssl unzip findutils net-tools nc jq which iptables iproute tree | xargs -n 1 apt-get install --force-yes -y && rm -rf /var/lib/apt/lists/*"
      fi
  fi
  docker exec $container type tcpdump > /dev/null 2>&1
  if [ $? != 0 ]
  then
      logerror "âŒ tcpdump could not be installed"
      exit 1
  fi
  set -e

  set +e
  docker exec --privileged --user root ${container} bash -c "killall tcpdump" > /dev/null 2>&1
  set -e

  if [[ -n "$port" ]]
  then
    log "ğŸ•µï¸â€â™‚ï¸ Taking tcp dump on container ${container} and port ${port} for ${duration} seconds..."
    docker exec -d --privileged --user root ${container} bash -c "tcpdump -w /tmp/${filename} port ${port}"
  else
    log "ğŸ•µï¸â€â™‚ï¸ Taking tcp dump on container ${container} and all ports for ${duration} seconds..."
    docker exec -d --privileged --user root ${container} bash -c "tcpdump -w /tmp/${filename}"
  fi

  if [ $? -eq 0 ]
  then
      playground container get-ip-addresses
      sleep $duration
      set +e
      docker exec --privileged --user root ${container} bash -c "killall tcpdump" > /dev/null 2>&1
      set -e
      log "ğŸŒ¶ï¸ tcp dump is available at ${filename}"
      docker cp ${container}:/tmp/${filename} ${filename}
      if [[ $(type -f wireshark 2>&1) =~ "not found" ]]
      then
          logwarn "ğŸ¦ˆ wireshark is not installed, grab it at https://www.wireshark.org/"
          exit 0
      else
          log "ğŸ¦ˆ Opening ${filename} with wireshark"
          wireshark ${filename}
      fi

  else
      logerror "âŒ Failed to take tcp dump"
  fi

}

# :command.function
playground_debug_block_traffic_command() {
  # src/debug_block_traffic_command.sh
  container="${args[--container]}"
  port="${args[--port]}"
  destination="${args[--destination]}"
  action="${args[--action]}"

  set +e
  docker exec $container type iptables > /dev/null 2>&1
  if [ $? != 0 ]
  then
      logwarn "iptables is not installed on container $container, attempting to install it"

      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
      dir1=$(echo ${DIR_CLI%/*})
      root_folder=$(echo ${dir1%/*})
      IGNORE_CHECK_FOR_DOCKER_COMPOSE=true
      source $root_folder/scripts/utils.sh

      if [[ "$TAG" == *ubi8 ]] || version_gt $TAG_BASE "5.9.0"
      then
        docker exec --privileged --user root $container bash -c "yum -y install --disablerepo='Confluent*' iptables"
      else
        docker exec --privileged --user root $container bash -c "apt-get update && echo iptables | xargs -n 1 apt-get install --force-yes -y && rm -rf /var/lib/apt/lists/*"
      fi
  fi
  docker exec $container type iptables > /dev/null 2>&1
  if [ $? != 0 ]
  then
      logerror "âŒ iptables could not be installed"
      exit 1
  fi
  set -e

  ip_pattern="^([0-9]{1,3}\.){3}[0-9]{1,3}$"

  function get_container_ip() {
      local container_ip=$(docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' "$1")
      if [ $? -eq 0 ]
      then
          echo "$container_ip"
      fi
  }

  function get_ip_by_nslookup() {
      local ip_address=$(nslookup "$1" | awk '/^Address: / { print $2 }')
      if [ $? -eq 0 ]
      then
          echo "$ip_address"
      fi
  }

  ip=""
  if [[ $destination =~ $ip_pattern ]]
  then
      ip=$destination
  else
      ip_address=$(get_container_ip "$destination")
      if [[ -n $ip_address ]]
      then
          ip=$ip_address
      else
          log "ğŸŒ Using nslookup to get IP address..."
          ip_address=$(get_ip_by_nslookup "$destination")
          if [[ -n $ip_address ]]
          then
              ip=$ip_address
          else
              logerror "âŒ Unable to retrieve IP address for $destination using nslookup"
              exit 1
          fi
      fi
  fi

  case "${action}" in
      start)
          action="A"
          if [[ -n "$port" ]]
          then
              log "ğŸš« Blocking traffic on container ${container} and port ${port} for destination ${destination} (${ip})"
          else
              log "ğŸš« Blocking traffic on container ${container} for all ports for destination ${destination} (${ip})"
          fi
      ;;
      stop)
          action="D"

          if [[ -n "$port" ]]
          then
              log "ğŸŸ¢ Unblocking traffic on container ${container} and port ${port} for destination ${destination} (${ip})"
          else
              log "ğŸŸ¢ Unblocking traffic on container ${container} for all ports from destination ${destination} (${ip})"
          fi
      ;;
      *)
          logerror "should not happen"
          exit 1
      ;;
  esac

  if [[ -n "$port" ]]
  then
    docker exec --privileged --user root ${container} bash -c "iptables -${action} INPUT -p tcp -s ${ip} --dport ${port} -j DROP"
  else
    docker exec --privileged --user root ${container} bash -c "iptables -${action} INPUT -p tcp -s ${ip} -j DROP"
  fi

  log "Output of command iptables-save"
  docker exec --privileged --user root ${container} bash -c "iptables-save"

}

# :command.function
playground_debug_flight_recorder_command() {
  # src/debug_flight_recorder_command.sh
  container="${args[--container]}"
  action="${args[--action]}"
  filename="flight-recorder-$container-`date '+%Y-%m-%d-%H-%M-%S'`.jfr"

  set +e
  docker exec $container type jcmd > /dev/null 2>&1
  if [ $? != 0 ]
  then
      logwarn "jcmd is not installed on container $container, attempting to install it"

      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
      dir1=$(echo ${DIR_CLI%/*})
      root_folder=$(echo ${dir1%/*})
      IGNORE_CHECK_FOR_DOCKER_COMPOSE=true
      source $root_folder/scripts/utils.sh

      if [[ "$TAG" == *ubi8 ]] || version_gt $TAG_BASE "5.9.0"
      then
        docker exec --privileged --user root $container bash -c "yum -y install --disablerepo='Confluent*' openjdk"
      else
        docker exec --privileged --user root $container bash -c "apt-get update && echo openjdk | xargs -n 1 apt-get install --force-yes -y && rm -rf /var/lib/apt/lists/*"
      fi
  fi
  docker exec $container type jcmd > /dev/null 2>&1
  if [ $? != 0 ]
  then
      logerror "âŒ jcmd could not be installed"
      exit 1
  fi
  set -e

  case "${action}" in
      start)
          set +e
          output=$(docker exec ${container} jcmd 1 JFR.check)
          echo "$output" | grep "running" | grep "dump1"
          if [ $? -eq 0 ]
          then
              logwarn "ğŸ›©ï¸ flight recorder is already started !"
              exit 0
          fi
          set -e

          docker exec ${container} jcmd 1 JFR.start name=dump1 filename=/tmp/${filename}
          if [ $? -eq 0 ]
          then
              log "ğŸ›©ï¸ flight recorder is now started"
          else
              logerror "âŒ Failed to start flight recorder"
          fi
      ;;
      stop)
          set +e
          output=$(docker exec ${container} jcmd 1 JFR.check)
          echo "$output" | grep "running" | grep "dump1"
          if [ $? -ne 0 ]
          then
              logerror "ğŸ›©ï¸ flight recorder is not started !"
              exit 1
          fi
          set -e
          docker exec ${container} jcmd 1 JFR.stop name=dump1 filename=/tmp/${filename}
          if [ $? -eq 0 ]
          then
              log "ğŸ›©ï¸ flight recorder is available at ${filename}"
              log "use JDK Mission Control JMC (https://jdk.java.net/jmc/) to open it"
              docker cp ${container}:/tmp/${filename} ${filename}
          else
              logerror "âŒ Failed to stop flight recorder"
          fi
      ;;
      *)
          logerror "should not happen"
          exit 1
      ;;
  esac
}

# :command.function
playground_debug_log_level_get_command() {
  # src/debug_log_level_get_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  package="${args[--package]}"

  if [[ -n "$package" ]]
  then
    log "ğŸ§¬ Get log level for package $package"
    curl $security -s "$connect_url/admin/loggers/$package"
  else
    log "ğŸ§¬ Get log level for all packages"
    curl $security -s "$connect_url/admin/loggers" | jq .
  fi
}

# :command.function
playground_debug_log_level_set_command() {
  # src/debug_log_level_set_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  package="${args[--package]}"
  level="${args[--level]}"

  current_level=$(curl $security -s "$connect_url/admin/loggers/$package" | jq -r '.level')

  if [ "$current_level" != "$level" ]
  then
      log "ğŸ§¬ Set log level for package $package to $level"
      curl $security -s --request PUT \
      --url "$connect_url/admin/loggers/$package" \
      --header 'Accept: application/json' \
      --header 'Content-Type: application/json' \
      --data "{
      \"level\": \"$level\"
      }" | jq .

      playground debug log-level get -p "$package"
  else
      log "ğŸ§¬â­ï¸ Skipping as log level for package $package was already set to $level"
  fi
}

# :command.function
playground_get_jmx_metrics_command() {
  # src/get_jmx_metrics_command.sh
  IGNORE_CHECK_FOR_DOCKER_COMPOSE=true

  component="${args[--component]}"
  domain="${args[--domain]}"
  open="${args[--open]}"

  case "${component}" in
    zookeeper|broker|schema-registry|connect)
    ;;
    *)
      logerror "ERROR: component name not valid ! Should be one of zookeeper, broker, schema-registry or connect"
      exit 1
    ;;
  esac

  get_jmx_metrics "$component" "$domain" "$open"
}

# :command.function
playground_container_recreate_command() {
  # src/container_recreate_command.sh
  ignore_current_versions="${args[--ignore-current-versions]}"

  export IGNORE_CHECK_FOR_DOCKER_COMPOSE=true

  if [[ ! -n "$ignore_current_versions" ]]
  then
    # keep TAG and CONNECT_TAG
    export TAG=$(docker inspect -f '{{.Config.Image}}' broker 2> /dev/null | cut -d ":" -f 2)
    export CONNECT_TAG=$(docker inspect -f '{{.Config.Image}}' connect 2> /dev/null | cut -d ":" -f 2)
  fi

  export ORACLE_IMAGE=$(docker inspect -f '{{.Config.Image}}' oracle 2> /dev/null)

  if [ ! -f /tmp/playground-command ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1
  fi
  set +e
  log "ğŸ’« Recreate container(s)"
  bash /tmp/playground-command
}

# :command.function
playground_container_get_ip_addresses_command() {
  # src/container_get_ip_addresses_command.sh
  log "Get IP address of running containers"
  docker inspect -f '{{.Name}} - {{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' $(docker ps -aq)
}

# :command.function
playground_container_kill_all_command() {
  # src/container_kill_all_command.sh
  log "ğŸ’€ Kill all docker containers"
  docker rm -f $(docker ps -qa) > /dev/null 2>&1
}

# :command.function
playground_container_logs_command() {
  # src/container_logs_command.sh
  container="${args[--container]}"
  open="${args[--open]}"
  log="${args[--wait-for-log]}"
  max_wait="${args[--max-wait]}"

  if [[ -n "$open" ]]
  then
    filename="/tmp/${container}-`date '+%Y-%m-%d-%H-%M-%S'`.log"
    docker container logs "$container" > "$filename" 2>&1
    if [ $? -eq 0 ]
    then
      if config_has_key "editor"
      then
        editor=$(config_get "editor")
        log "ğŸ“– Opening ${filename} using configured editor $editor"
        $editor $filename
      else
        if [[ $(type code 2>&1) =~ "not found" ]]
        then
          logerror "Could not determine an editor to use as default code is not found - you can change editor by updating config.ini"
          exit 1
        else
          log "ğŸ“– Opening ${filename} with code (default) - you can change editor by updating config.ini"
          code $filename
        fi
      fi
    else
      logerror "Failed to get logs using container logs $container"
    fi
  elif [[ -n "$log" ]]
  then
    wait_for_log "$log" "$container" "$max_wait"
  else

    docker container logs --tail=200 -f "$container"
  fi
}

# :command.function
playground_container_ssh_command() {
  # src/container_ssh_command.sh
  container="${args[--container]}"
  shell="${args[--shell]}"

  docker exec -it "$container" "$shell"
}

# :command.function
playground_container_exec_command() {
  # src/container_exec_command.sh
  container="${args[--container]}"
  command="${args[--command]}"
  root="${args[--root]}"
  shell="${args[--shell]}"

  if [[ -n "$root" ]]
  then
    log "Executing command as root in container $container with $shell"
    docker exec --privileged --user root $container $shell -c "$command"
  else
    log "Executing command in container $container with $shell"
    docker exec $container $shell -c "$command"
  fi

}

# :command.function
playground_container_restart_command() {
  # src/container_restart_command.sh
  container="${args[--container]}"

  log "Restarting docker container ${container}"
  docker restart ${container}
}

# :command.function
playground_container_pause_command() {
  # src/container_pause_command.sh
  container="${args[--container]}"

  log "Pausing docker container ${container}"
  docker pause ${container}
}

# :command.function
playground_container_resume_command() {
  # src/container_resume_command.sh
  container="${args[--container]}"

  log "Resuming docker container ${container}"
  docker unpause ${container}
}

# :command.function
playground_container_kill_command() {
  # src/container_kill_command.sh
  container="${args[--container]}"

  log "Killing docker container ${container}"
  docker kill ${container}
}

# :command.function
playground_topic_get_number_records_command() {
  # src/topic_get_number_records_command.sh
  topic="${args[--topic]}"

  ret=$(get_security_broker "--command-config")

  container=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  if [[ ! -n "$topic" ]]
  then
      log "âœ¨ --topic flag was not provided, applying command to all topics"
      topic=$(playground get-topic-list --skip-connect-internal-topics)
      if [ "$topic" == "" ]
      then
          logerror "âŒ No topic found !"
          exit 1
      fi
  fi

  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  items=($topic)
  for topic in ${items[@]}
  do
      log "ğŸ’¯ Get number of records in topic $topic"
      set +e
      playground topic describe --topic $topic > /tmp/result.log 2>/tmp/result.log
      grep "does not exist" /tmp/result.log > /dev/null 2>&1
      if [ $? == 0 ]
      then
          logwarn "topic $topic does not exist !"
          continue
      fi
      set +e
      if [[ "$environment" == "environment" ]]
      then
          ret=$(get_sr_url_and_security)

          sr_url=$(echo "$ret" | cut -d "@" -f 1)
          sr_security=$(echo "$ret" | cut -d "@" -f 2)

          value_type=""
          version=$(curl $sr_security -s "${sr_url}/subjects/${topic}-value/versions/1" | jq -r .version)
          if [ "$version" != "null" ]
          then
          schema_type=$(curl $sr_security -s "${sr_url}/subjects/${topic}-value/versions/1"  | jq -r .schemaType)
          case "${schema_type}" in
              JSON)
              value_type="json-schema"
              ;;
              PROTOBUF)
              value_type="protobuf"
              ;;
              null)
              value_type="avro"
              ;;
          esac
          fi

          if [ ! -f /tmp/delta_configs/librdkafka.delta ]
          then
              logerror "ERROR: /tmp/delta_configs/librdkafka.delta has not been generated"
              exit 1
          fi
          tr -d '"' < /tmp/delta_configs/librdkafka.delta > /tmp/delta_configs/librdkafka_no_quotes_tmp.delta
          sr_url=$(grep "schema.registry.url=" /tmp/delta_configs/librdkafka_no_quotes_tmp.delta | cut -d "=" -f2)
          sr_url_hostname=$(echo $sr_url | cut -d "/" -f 3)
          sr_auth=$(grep "basic.auth.user.info=" /tmp/delta_configs/librdkafka_no_quotes_tmp.delta | cut -d "=" -f2)
          sr_username=$(echo $sr_auth | cut -d ":" -f 1)
          sr_password=$(echo $sr_auth | cut -d ":" -f 2)
          # sr_password_url_encoded=$(urlencode $sr_password)
          grep -v "basic.auth.user.info" /tmp/delta_configs/librdkafka_no_quotes_tmp.delta > /tmp/delta_configs/librdkafka_no_quotes.delta

          case "${value_type}" in
          avro)
          docker run -i --network=host \
                  -v /tmp/delta_configs/librdkafka_no_quotes.delta:/tmp/configuration/ccloud.properties \
              confluentinc/cp-kcat:latest kcat \
                  -F /tmp/configuration/ccloud.properties \
                  -C -t $topic \
                  -s value=avro \
                  -r https://$sr_username:$sr_password@$sr_url_hostname \
                  -e -q > /tmp/result.log 2>/dev/null
              ;;
          *)
          docker run -i --network=host \
                  -v /tmp/delta_configs/librdkafka_no_quotes.delta:/tmp/configuration/ccloud.properties \
              confluentinc/cp-kcat:latest kcat \
                  -F /tmp/configuration/ccloud.properties \
                  -C -t $topic \
                  -e -q > /tmp/result.log 2>/dev/null
          ;;
          esac
          wc -l /tmp/result.log | awk '{print $1}'
      else
          if ! version_gt $TAG_BASE "6.9.9" && [ "$security" != "" ]
          then
              # GetOffsetShell does not support security before 7.x
              ret=$(get_security_broker "--consumer.config")
              container=$(echo "$ret" | cut -d "@" -f 1)
              security=$(echo "$ret" | cut -d "@" -f 2)
              set +e
              docker exec $container timeout 15 kafka-console-consumer --bootstrap-server broker:9092 --topic $topic $security --from-beginning --timeout-ms 15000 2>/dev/null | wc -l | tr -d ' '
              set -e
          else
              docker exec $container kafka-run-class kafka.tools.GetOffsetShell --broker-list broker:9092 $security --topic $topic --time -1 | awk -F ":" '{sum += $3} END {print sum}'
          fi
      fi
  done
}

# :command.function
playground_topic_display_consumer_offsets_command() {
  # src/topic_display_consumer_offsets_command.sh
  ret=$(get_security_broker "--consumer.config")

  container=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  log "Display content of __consumer_offsets topic, press crtl-c to stop..."
  if [[ "$environment" == "environment" ]]
  then
      if [ -f /tmp/delta_configs/env.delta ]
      then
          source /tmp/delta_configs/env.delta
      else
          logerror "ERROR: /tmp/delta_configs/env.delta has not been generated"
          exit 1
      fi
      if [ ! -f /tmp/delta_configs/ak-tools-ccloud.delta ]
      then
          logerror "ERROR: /tmp/delta_configs/ak-tools-ccloud.delta has not been generated"
          exit 1
      fi

      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
      dir1=$(echo ${DIR_CLI%/*})
      root_folder=$(echo ${dir1%/*})
      IGNORE_CHECK_FOR_DOCKER_COMPOSE=true
      source $root_folder/scripts/utils.sh

      docker run --rm -v /tmp/delta_configs/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SASL_JAAS_CONFIG="$SASL_JAAS_CONFIG" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-topics --describe --topic $topic --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties
  else
      docker exec -i $container kafka-console-consumer --bootstrap-server broker:9092 --topic __consumer_offsets --from-beginning --formatter "kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter" $security | grep -v "_confluent-controlcenter"
  fi

}

# :command.function
playground_topic_list_command() {
  # src/topic_list_command.sh
  log "ğŸ”˜ List of topics (internal topics are excluded)"
  playground get-topic-list --skip-connect-internal-topics
}

# :command.function
playground_topic_describe_command() {
  # src/topic_describe_command.sh
  topic="${args[--topic]}"

  ret=$(get_security_broker "--command-config")

  container=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  if [[ ! -n "$topic" ]]
  then
      log "âœ¨ --topic flag was not provided, applying command to all topics"
      topic=$(playground get-topic-list --skip-connect-internal-topics)
      if [ "$topic" == "" ]
      then
          logerror "âŒ No topic found !"
          exit 1
      fi
  fi

  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  items=($topic)
  for topic in ${items[@]}
  do
      log "ğŸ” Describing topic $topic"
      if [[ "$environment" == "environment" ]]
      then
          if [ -f /tmp/delta_configs/env.delta ]
          then
              source /tmp/delta_configs/env.delta
          else
              logerror "ERROR: /tmp/delta_configs/env.delta has not been generated"
              exit 1
          fi
          if [ ! -f /tmp/delta_configs/ak-tools-ccloud.delta ]
          then
              logerror "ERROR: /tmp/delta_configs/ak-tools-ccloud.delta has not been generated"
              exit 1
          fi

          DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
          dir1=$(echo ${DIR_CLI%/*})
          root_folder=$(echo ${dir1%/*})
          IGNORE_CHECK_FOR_DOCKER_COMPOSE=true
          source $root_folder/scripts/utils.sh

          docker run --rm -v /tmp/delta_configs/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-topics --describe --topic $topic --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties
      else
          docker exec $container kafka-topics --describe --topic $topic --bootstrap-server broker:9092 $security
      fi
  done
}

# :command.function
playground_topic_set_schema_compatibility_command() {
  # src/topic_set_schema_compatibility_command.sh
  topic="${args[--topic]}"
  compatibility="${args[--compatibility]}"

  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  ret=$(get_sr_url_and_security)

  sr_url=$(echo "$ret" | cut -d "@" -f 1)
  sr_security=$(echo "$ret" | cut -d "@" -f 2)

  if [[ ! -n "$topic" ]]
  then
      logwarn "--topic flag was not provided, applying command to all topics"
      check_if_continue
      topic=$(playground get-topic-list --skip-connect-internal-topics)
      if [ "$topic" == "" ]
      then
          logerror "âŒ No topic found !"
          exit 1
      fi
  fi

  items=($topic)
  for topic in ${items[@]}
  do
    log "ğŸ›¡ï¸ Set compatibility for subject ${topic}-value to $compatibility"
    curl $sr_security -X PUT -H "Content-Type: application/vnd.schemaregistry.v1+json" --data "{\"compatibility\": \"$compatibility\"}" "${sr_url}/config/${topic}-value"
  done
}

# :command.function
playground_topic_consume_command() {
  # src/topic_consume_command.sh
  topic="${args[--topic]}"
  verbose="${args[--verbose]}"
  max_messages="${args[--max-messages]}"
  grep_string="${args[--grep]}"
  min_expected_messages="${args[--min-expected-messages]}"
  timeout="${args[--timeout]}"
  tail="${args[--tail]}"
  timestamp_field="${args[--plot-latencies-timestamp-field]}"
  subject="${args[--subject]}"
  max_characters="${args[--max-characters]}"

  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  ret=$(get_sr_url_and_security)

  sr_url=$(echo "$ret" | cut -d "@" -f 1)
  sr_security=$(echo "$ret" | cut -d "@" -f 2)

  bootstrap_server="broker:9092"
  container="connect"
  sr_url_cli="http://schema-registry:8081"
  security=""
  if [[ "$environment" == *"ssl"* ]]
  then
      sr_url_cli="https://schema-registry:8081"
      security="--property schema.registry.ssl.truststore.location=/etc/kafka/secrets/kafka.client.truststore.jks --property schema.registry.ssl.truststore.password=confluent --property schema.registry.ssl.keystore.location=/etc/kafka/secrets/kafka.client.keystore.jks --property schema.registry.ssl.keystore.password=confluent --consumer.config /etc/kafka/secrets/client_without_interceptors.config"
  elif [[ "$environment" == "rbac-sasl-plain" ]]
  then
      sr_url_cli="http://schema-registry:8081"
      security="--property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info=clientAvroCli:clientAvroCli --consumer.config /etc/kafka/secrets/client_without_interceptors.config"
  elif [[ "$environment" == "ldap-authorizer-sasl-plain" ]]
  then
      sr_url_cli="http://schema-registry:8081"
      security="--group test-consumer-group --consumer.config /service/kafka/users/alice.properties"
  elif [[ "$environment" == "kerberos" ]]
  then
      container="client"
      sr_url_cli="http://schema-registry:8081"
      security="--consumer.config /etc/kafka/consumer.properties"

      docker exec -i client kinit -k -t /var/lib/secret/kafka-connect.key connect
  elif [[ "$environment" == "environment" ]]
  then
    if [ -f /tmp/delta_configs/env.delta ]
    then
        source /tmp/delta_configs/env.delta
    else
        logerror "ERROR: /tmp/delta_configs/env.delta has not been generated"
        exit 1
    fi
    if [ ! -f /tmp/delta_configs/ak-tools-ccloud.delta ]
    then
        logerror "ERROR: /tmp/delta_configs/ak-tools-ccloud.delta has not been generated"
        exit 1
    fi
    DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
    dir1=$(echo ${DIR_CLI%/*})
    root_folder=$(echo ${dir1%/*})
    IGNORE_CHECK_FOR_DOCKER_COMPOSE=true
    source $root_folder/scripts/utils.sh
  fi

  if [[ -n "$timeout" ]] && [ "$timeout" != "60" ]
  then
    if [[ ! -n "$min_expected_messages" ]]
    then
      logerror "âŒ --timeout was provided without specifying --min-expected-messages"
      exit 1
    fi
  fi

  if [[ ! -n "$topic" ]]
  then
      if [[ -n "$min_expected_messages" ]]
      then
        logerror "--min-expected-messages was provided without specifying --topic"
        exit 1
      fi
      if [[ -n "$subject" ]]
      then
        logerror "--subject was provided without specifying --topic"
        exit 1
      fi
      if [[ -n "$tail" ]]
      then
        logerror "--tail was provided without specifying --topic"
        exit 1
      fi
      if [[ -n "$timestamp_field" ]]
      then
        logerror "--plot-latencies-timestamp-field was provided without specifying --topic"
        exit 1
      fi
      log "âœ¨ --topic flag was not provided, applying command to all topics"
      topic=$(playground get-topic-list --skip-connect-internal-topics)
      if [ "$topic" == "" ]
      then
          logerror "âŒ no topic found !"
          exit 1
      fi
  fi

  items=($topic)
  for topic in ${items[@]}
  do
    if [ ! -n "$tail" ]
    then
      if [[ -n "$min_expected_messages" ]]
      then

        start_time=$(date +%s)

        while true; do
          nb_messages=$(playground topic get-number-records -t $topic | tail -1)

          if [[ ! $nb_messages =~ ^[0-9]+$ ]]
          then
            echo $nb_messages | grep "does not exist" > /dev/null 2>&1
            if [ $? == 0 ]
            then
              logwarn "âŒ topic $topic does not exist !"
            else
              logwarn "âŒ problem while getting number of messages: $nb_messages"
            fi
            exit 1
          fi

          if [ $nb_messages -ge $min_expected_messages ]
          then
            break
          fi

          current_time=$(date +%s)
          elapsed_time=$((current_time - start_time))

          if [ $elapsed_time -ge $timeout ]
          then
            logerror "âŒ overall timeout of $timeout seconds exceeded. --min-expected-messages is set with $min_expected_messages but topic $topic contains $nb_messages messages"
            exit 1
          fi

          sleep 1
        done
      else
        nb_messages=$(playground topic get-number-records -t $topic | tail -1)

        if [[ ! $nb_messages =~ ^[0-9]+$ ]]
        then
          echo $nb_messages | grep "does not exist" > /dev/null 2>&1
          if [ $? == 0 ]
          then
            logwarn "âŒ topic $topic does not exist !"
          else
            logwarn "âŒ problem while getting number of messages: $nb_messages"
          fi
          break
        fi
      fi
    fi

    if [ -n "$tail" ]
    then
      log "âœ¨ Tailing content of topic $topic"
    elif [[ -n "$max_messages" ]] && [ $nb_messages -ge $max_messages ] && [[ ! -n "$timestamp_field" ]]
    then
      log "âœ¨ Display content of topic $topic, it contains $nb_messages messages, but displaying only --max-messages=$max_messages"
      nb_messages=$max_messages
    else
      log "âœ¨ Display content of topic $topic, it contains $nb_messages messages"
    fi

    if [[ -n "$grep_string" ]]
    then
      logwarn "--grep is set so only matched results will be displayed !"
    fi

    if [[ -n "$timestamp_field" ]]
    then
      log "ğŸ“ˆ plotting results.."
    fi
    key_type=""
    version=$(curl $sr_security -s "${sr_url}/subjects/${topic}-key/versions/latest" | jq -r .version)
    if [ "$version" != "null" ]
    then
      schema_type=$(curl $sr_security -s "${sr_url}/subjects/${topic}-key/versions/latest" | jq -r .schemaType)
      case "${schema_type}" in
        JSON)
          key_type="json-schema"
        ;;
        PROTOBUF)
          key_type="protobuf"
        ;;
        null)
          key_type="avro"
        ;;
      esac
    fi

    if [ "$key_type" != "" ]
    then
      log "ğŸ”®ğŸ”° topic is using $key_type for key"
      playground schema get --subject ${topic}-key
    else
      log "ğŸ”®ğŸ™… topic is not using any schema for key"
    fi

    if [[ -n "$subject" ]]
    then
      log "ğŸ“› subject is set with $subject"
      value_subject="${subject}"
    else
      value_subject="${topic}-value"
    fi

    value_type=""
    version=$(curl $sr_security -s "${sr_url}/subjects/${value_subject}/versions/latest" | jq -r .version)
    if [ "$version" != "null" ]
    then
      schema_type=$(curl $sr_security -s "${sr_url}/subjects/${value_subject}/versions/latest"  | jq -r .schemaType)
      case "${schema_type}" in
        JSON)
          value_type="json-schema"
        ;;
        PROTOBUF)
          value_type="protobuf"
        ;;
        null)
          value_type="avro"
        ;;
      esac
    fi

    if [ "$value_type" != "" ]
    then
      log "ğŸ”®ğŸ”° topic is using $value_type for value"
      playground schema get --subject ${value_subject}
    else
      log "ğŸ”®ğŸ™… topic is not using any schema for value"
    fi

    type=""
    tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)
    trap 'rm -rf $tmp_dir' EXIT
    fifo_path="$tmp_dir/kafka_output_fifo"
    mkfifo "$fifo_path"

    nottailing1=""
    nottailing2=""
    if [ ! -n "$tail" ]
    then
      nottailing1="--from-beginning --max-messages $nb_messages"
      if [[ ! -n "$timestamp_field" ]]
      then
        nottailing2="timeout $timeout"
      fi
    fi

    if [ "$max_messages" != "10" ]
    then
      nottailing2=""
    fi
    if [[ -n "$verbose" ]]
    then
        set -x
    fi
    case "${value_type}" in
      avro|protobuf|json-schema)
          if [ "$key_type" == "avro" ] || [ "$key_type" == "protobuf" ] || [ "$key_type" == "json-schema" ]
          then
              if [[ "$environment" == "environment" ]]
              then
                docker run -i --rm -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/etc/kafka/tools-log4j.properties" -e value_type=$value_type -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" -e SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} $nottailing2 kafka-$value_type-console-consumer --bootstrap-server $BOOTSTRAP_SERVERS --topic $topic --consumer-property ssl.endpoint.identification.algorithm=https --consumer-property sasl.mechanism=PLAIN --consumer-property security.protocol=SASL_SSL --consumer-property sasl.jaas.config="$SASL_JAAS_CONFIG" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" --property schema.registry.url=$SCHEMA_REGISTRY_URL --property print.schema.ids=true --property schema.id.separator="|schema_id=" --property print.partition=true --property print.offset=true --property print.headers=true --property headers.separator=, --property headers.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.timestamp=true --property print.key=true --property key.separator="|" --skip-message-on-error $security $nottailing1 > "$fifo_path" 2>&1 &
              else
                docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/etc/kafka/tools-log4j.properties" $container $nottailing2 kafka-$value_type-console-consumer -bootstrap-server $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic  --property print.schema.ids=true --property schema.id.separator="|schema_id=" --property print.partition=true --property print.offset=true --property print.headers=true --property headers.separator=, --property headers.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.timestamp=true --property print.key=true --property key.separator="|" --skip-message-on-error $security $nottailing1 > "$fifo_path" 2>&1 &
              fi
          else
              if [[ "$environment" == "environment" ]]
              then
                docker run -i --rm -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/etc/kafka/tools-log4j.properties" -e value_type=$value_type -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" -e SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} $nottailing2 kafka-$value_type-console-consumer --bootstrap-server $BOOTSTRAP_SERVERS --topic $topic --consumer-property ssl.endpoint.identification.algorithm=https --consumer-property sasl.mechanism=PLAIN --consumer-property security.protocol=SASL_SSL --consumer-property sasl.jaas.config="$SASL_JAAS_CONFIG" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" --property schema.registry.url=$SCHEMA_REGISTRY_URL --property print.schema.ids=true --property schema.id.separator="|schema_id=" --property print.partition=true --property print.offset=true --property print.headers=true --property headers.separator=, --property headers.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.timestamp=true --property print.key=true --property key.separator="|" --property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer --skip-message-on-error $security $nottailing1 > "$fifo_path" 2>&1 &
              else
                docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/etc/kafka/tools-log4j.properties" $container $nottailing2  kafka-$value_type-console-consumer --bootstrap-server $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic --property print.partition=true  --property print.schema.ids=true --property schema.id.separator="|schema_id=" --property print.offset=true --property print.headers=true --property headers.separator=, --property headers.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.timestamp=true --property print.key=true --property key.separator="|" --property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer --skip-message-on-error $security $nottailing1 > "$fifo_path" 2>&1 &
              fi
          fi
          ;;
      *)
        if [[ "$environment" == "environment" ]]
        then
          docker run -i --rm -v /tmp/delta_configs/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} $nottailing2 kafka-console-consumer --bootstrap-server $BOOTSTRAP_SERVERS --topic $topic --consumer.config /tmp/configuration/ccloud.properties --property print.partition=true --property print.offset=true --property print.headers=true --property headers.separator=, --property headers.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.timestamp=true --property print.key=true --property key.separator="|" $security $nottailing1 > "$fifo_path" 2>&1 &
        else
          docker exec $container $nottailing2 kafka-console-consumer --bootstrap-server $bootstrap_server --topic $topic --property print.partition=true --property print.offset=true --property print.headers=true --property headers.separator=, --property headers.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.timestamp=true --property print.key=true --property key.separator="|" $security $nottailing1 > "$fifo_path" 2>&1  &
        fi
      ;;
    esac
    set +x
    # Detect the platform (macOS or Linux) and set the date command accordingly
    if [[ "$(uname)" == "Darwin" ]]; then
      # macOS
      date_command="date -r "
    else
      # Linux
      date_command="date -d @"
    fi

    if [[ -n "$timestamp_field" ]]
    then
      rm -rf /tmp/latency
      mkdir -p /tmp/latency
      latency_csv="/tmp/latency/latency.csv"
      latency_png="/tmp/latency/latency.png"
    fi
    found=0
    first_record=1
    is_base64=0
    # Loop through each line in the named pipe
    while read -r line
    do
      display_line=1
      if [[ $line =~ "CreateTime:" ]]
      then
        # Extract the timestamp from the line
        timestamp_ms=$(echo "$line" | cut -d ":" -f 2 | cut -d "|" -f 1)
        # Convert milliseconds to seconds
        timestamp_sec=$((timestamp_ms / 1000))
        milliseconds=$((timestamp_ms % 1000))
        readable_date="$(${date_command}${timestamp_sec} "+%Y-%m-%d %H:%M:%S.${milliseconds}")"
        line_with_date=$(echo "$line" | sed -E "s/CreateTime:[0-9]{13}/CreateTime: ${readable_date}/")

        if [ $first_record -eq 1 ]
        then
          payload=$(echo "$line" | cut -d "|" -f 6)

          if [ ${#payload} -lt 1000 ]
          then
            # check if it is base64 encoded
            set +e
            base64=$(echo "$payload" | tr -d '"' | base64 --decode 2>/dev/null)

            if [[ "$OSTYPE" == "darwin"* ]]
            then
              if [ "$base64" != "" ]
              then
                logwarn "ğŸ¤– Data is base64 encoded, payload will be decoded"
                is_base64=1
              fi
            else
              if [ $? == 0 ]
              then
                logwarn "ğŸ¤– Data is base64 encoded, payload will be decoded"
                is_base64=1
              fi
            fi
            set -e
          fi

          first_record=0
        fi

        if [ $is_base64 -eq 1 ]
        then
          base64=$(echo "$payload" | tr -d '"' | base64 --decode)
          line_with_date=$(echo "$line_with_date" | awk -v new_value="$base64" 'BEGIN {FS=OFS="|"} {$6=new_value}1')
        fi

        if [[ -n "$grep_string" ]]
        then
          if [[ $line =~ "$grep_string" ]]
          then
            log "âœ… found $grep_string in topic $topic"
            found=1
          else
            display_line=0
          fi
        fi

        if [[ ! -n "$timestamp_field" ]]
        then
          if [ $display_line -eq 1 ]
          then
            payload=$(echo "$line_with_date" | cut -d "|" -f 6)
            if [ ${#payload} -lt $max_characters ]
            then
              echo "$line_with_date"
            else
              echo "$line_with_date" | cut -c 1-$max_characters | awk "{print \$0 \"...<truncated, only showing first $max_characters characters, out of ${#payload}>...\"}"
            fi
          fi
        fi

        if [[ -n "$timestamp_field" ]]
        then
          payload=$(echo "$line" | cut -d "|" -f 6)
          # JSON is invalid
          if ! echo "$payload" | jq -e .  > /dev/null 2>&1
          then
              logerror "--plot-latencies-timestamp-field is set but value content is not in json representation"
              exit 1
          else
            timestamp_source=$(echo "$payload" | jq -r .${timestamp_field})
            echo "$readable_date,$timestamp_ms,$timestamp_source" >> $latency_csv
          fi
        fi
      elif [[ $line =~ "Processed a total of" ]]
      then
        continue
      else
        if [[ -n "$grep_string" ]]
        then
          if [[ $line =~ "$grep_string" ]]
          then
            log "âœ… found $grep_string in topic $topic"
            found=1
          else
            display_line=0
          fi
        fi

        if [ $display_line -eq 1 ]
        then
          payload=$(echo "$line" | cut -d "|" -f 6)
          if [ ${#payload} -lt $max_characters ]
          then
            echo "$line"
          else
            echo "$line" | cut -c 1-$max_characters | awk "{print \$0 \"...<truncated, only showing first $max_characters characters, out of ${#payload}>...\"}"
          fi
        fi
      fi
    done < "$fifo_path"

    if [[ -n "$grep_string" ]]
    then
      if [ $found != 1 ]
      then
        logerror "âŒ could not find $grep_string in topic $topic"
        exit 1
      fi
    fi
  done

  if [[ -n "$timestamp_field" ]]
  then
    log "Plot data using gnuplot, see ${latency_png}"
    docker run --rm -i -v /tmp/latency:/work remuslazar/gnuplot -e \
    "
    set grid;
    set datafile separator ',';
    set timefmt \"%Y-%m-%d %H:%M:%S.%s\";
    set format x '%H:%M:%S';
    set term png size 1200,600;
    set output 'latency.png';
    set xdata time;
    set autoscale;
    set xlabel 'Time';
    set ylabel 'Latency in ms';
    plot 'latency.csv' using 1:(\$2-\$3) with points;"

    # open $latency_csv
    open $latency_png
  fi
}

# :command.function
playground_topic_produce_command() {
  # src/topic_produce_command.sh
  topic="${args[--topic]}"
  verbose="${args[--verbose]}"
  nb_messages="${args[--nb-messages]}"
  nb_partitions="${args[--nb-partitions]}"
  schema="${args[--input]}"
  key="${args[--key]}"
  headers="${args[--headers]}"
  forced_value="${args[--forced-value]}"
  generate_only="${args[--generate-only]}"
  tombstone="${args[--tombstone]}"
  compatibility="${args[--compatibility]}"
  value_subject_name_strategy="${args[--value-subject-name-strategy]}"
  validate="${args[--validate]}"
  record_size="${args[--record-size]}"
  # Convert the space delimited string to an array
  eval "validate_config=(${args[--validate-config]})"
  eval "producer_property=(${args[--producer-property]})"

  tmp_dir=$(mktemp -d -t ci-XXXXXXXXXX)
  trap 'rm -rf $tmp_dir' EXIT
  #log "tmp_dir is $tmp_dir"
  schema_file=$tmp_dir/value_schema

  if [ "$schema" = "-" ]
  then
      if [[ ! -n "$tombstone" ]]
      then
          # stdin
          schema_content=$(cat "$schema")
          echo "$schema_content" > $schema_file
      fi
  else
      if [[ $schema == @* ]]
      then
          # this is a schema file
          argument_schema_file=$(echo "$schema" | cut -d "@" -f 2)
          cp $argument_schema_file $schema_file
      elif [ -f $schema ]
      then
          cp $schema $schema_file
      else
          schema_content=$schema
          echo "$schema_content" > $schema_file
      fi
  fi

  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  ret=$(get_sr_url_and_security)

  sr_url=$(echo "$ret" | cut -d "@" -f 1)
  sr_security=$(echo "$ret" | cut -d "@" -f 2)

  bootstrap_server="broker:9092"
  container="connect"
  sr_url_cli="http://schema-registry:8081"
  security=""
  if [[ "$environment" == *"ssl"* ]]
  then
      sr_url_cli="https://schema-registry:8081"
      security="--property schema.registry.ssl.truststore.location=/etc/kafka/secrets/kafka.client.truststore.jks --property schema.registry.ssl.truststore.password=confluent --property schema.registry.ssl.keystore.location=/etc/kafka/secrets/kafka.client.keystore.jks --property schema.registry.ssl.keystore.password=confluent --producer.config /etc/kafka/secrets/client_without_interceptors.config"
  elif [[ "$environment" == "rbac-sasl-plain" ]]
  then
      sr_url_cli="http://schema-registry:8081"
      security="--property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info=clientAvroCli:clientAvroCli --producer.config /etc/kafka/secrets/client_without_interceptors.config"
  elif [[ "$environment" == "ldap-authorizer-sasl-plain" ]]
  then
      sr_url_cli="http://schema-registry:8081"
      security="--producer.config /service/kafka/users/alice.properties"
  elif [[ "$environment" == "sasl-plain" ]]
  then
      sr_url_cli="http://schema-registry:8081"
      security="--producer.config /tmp/client.properties"
  elif [[ "$environment" == "kerberos" ]]
  then
      container="client"
      sr_url_cli="http://schema-registry:8081"
      security="--producer.config /etc/kafka/producer.properties"

      docker exec -i client kinit -k -t /var/lib/secret/kafka-connect.key connect
  elif [[ "$environment" == "environment" ]]
  then
    if [ -f /tmp/delta_configs/env.delta ]
    then
        source /tmp/delta_configs/env.delta
    else
        logerror "ERROR: /tmp/delta_configs/env.delta has not been generated"
        exit 1
    fi
    if [ ! -f /tmp/delta_configs/ak-tools-ccloud.delta ]
    then
        logerror "ERROR: /tmp/delta_configs/ak-tools-ccloud.delta has not been generated"
        exit 1
    fi
  fi

  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  root_folder=$(echo ${dir1%/*})
  IGNORE_CHECK_FOR_DOCKER_COMPOSE=true
  source $root_folder/scripts/utils.sh

  if [[ -n "$tombstone" ]]
  then
      if [[ ! -n "$key" ]]
      then
          logerror "âŒ --tombstone is set but not --key !"
          exit 1
      fi
      if ! version_gt $CONNECT_TAG "7.1.99"
      then
          logerror "âŒ --tombstone is set but it can be produced only with CP 7.2+"
          exit 1
      fi
      log "ğŸ§Ÿ Sending tombstone for key $key in topic $topic"
      if [[ -n "$verbose" ]]
      then
          set -x
      fi
      if [[ "$environment" == "environment" ]]
      then
          echo "$key|NULL" | docker run -i --rm -v /tmp/delta_configs/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-console-producer --broker-list $BOOTSTRAP_SERVERS --topic $topic --producer.config /tmp/configuration/ccloud.properties $security --property parse.key=true --property key.separator="|" --property null.marker=NULL
      else
          echo "$key|NULL" | docker exec -i $container kafka-console-producer --broker-list $bootstrap_server --topic $topic $security --property parse.key=true --property key.separator="|" --property null.marker=NULL
      fi
      # nothing else to do
      exit 0
  fi

  if [[ -n "$headers" ]]
  then
      if ! version_gt $CONNECT_TAG "7.1.99"
      then
          logerror "âŒ --headers is set but it can be produced only with CP 7.2+"
          exit 1
      fi
  fi

  if grep -q "proto3" $schema_file
  then
      log "ğŸ”® schema was identified as protobuf"
      schema_type=protobuf
  elif grep -q "\"type\"\s*:\s*\"object\"" $schema_file
  then
      log "ğŸ”® schema was identified as json schema"
      schema_type=json-schema
  elif grep -q "_meta" $schema_file
  then
      log "ğŸ”® schema was identified as json"
      schema_type=json
  elif grep -q "CREATE TABLE" $schema_file
  then
      log "ğŸ”® schema was identified as sql"
      schema_type=sql
  elif grep -q "\"type\"\s*:\s*\"record\"" $schema_file
  then
      log "ğŸ”® schema was identified as avro"
      schema_type=avro
  else
      log "ğŸ“¢ no known schema could be identified, payload will be sent as raw data"
      schema_type=raw
  fi
  log "âœ¨ generating data..."
  if [ "$schema_type" == "protobuf" ]
  then
      nb_max_messages_to_generate=50
  else
      nb_max_messages_to_generate=1000
  fi
  if [ $nb_messages -lt $nb_max_messages_to_generate ]
  then
      nb_messages_to_generate=$nb_messages
  else
      nb_messages_to_generate=$nb_max_messages_to_generate
  fi
  if [[ -n "$validate" ]]
  then
      if [ $nb_messages != 1 ]
      then
          logwarn "--validate is set, ignoring --nb-messages"
          nb_messages=1
      fi
  fi
  input_file=""

  if [[ -n "$forced_value" ]]
  then
      log "â˜¢ï¸ --forced-value is set"
      echo "$forced_value" > $tmp_dir/out.json
  else
      SECONDS=0
      case "${schema_type}" in
          json|sql)
              # https://github.com/MaterializeInc/datagen
              set +e
              docker run --rm -i -v $schema_file:/app/schema.$schema_type materialize/datagen -s schema.$schema_type -n $nb_messages_to_generate --dry-run > $tmp_dir/result.log

              nb=$(grep -c "Payload: " $tmp_dir/result.log)
              if [ $nb -eq 0 ]
              then
                  logerror "âŒ materialize/datagen failed to produce $schema_type "
                  cat $tmp_dir/result.log
                  exit 1
              fi
              set -e
              cat $tmp_dir/result.log | grep "Payload: " | sed 's/Payload: //' > $tmp_dir/out.json
          ;;
          avro)
              docker run --rm -v $tmp_dir:/tmp/ vdesabou/avro-tools random /tmp/out.avro --schema-file /tmp/value_schema --count $nb_messages_to_generate
              docker run --rm -v $tmp_dir:/tmp/ vdesabou/avro-tools tojson /tmp/out.avro > $tmp_dir/out.json
          ;;
          json-schema)
              docker run --rm -v $tmp_dir:/tmp/ -e NB_MESSAGES=$nb_messages_to_generate vdesabou/json-schema-faker > $tmp_dir/out.json
          ;;
          protobuf)
              # https://github.com/JasonkayZK/mock-protobuf.js
              docker run --rm -v $tmp_dir:/tmp/ -v $schema_file:/app/schema.proto -e NB_MESSAGES=$nb_messages_to_generate vdesabou/protobuf-faker  > $tmp_dir/out.json
          ;;
          raw)
              if jq -e . >/dev/null 2>&1 <<< "$(cat "$schema_file")"
              then
                  log "ğŸ’« payload is single json, it will be sent as one record"
                  jq -c . "$schema_file" > $tmp_dir/minified.json
                  input_file=$tmp_dir/minified.json
              else
                  log "ğŸ’« payload is not single json, one record per line will be sent"
                  input_file=$schema_file
              fi
          ;;
          *)
              logerror "âŒ schema_type name not valid ! Should be one of raw, json, avro, json-schema or protobuf"
              exit 1
          ;;
      esac
  fi

  if [ "$input_file" = "" ]
  then
      input_file=$tmp_dir/out.json
  fi
  output_file=$tmp_dir/out_final.json
  record_size_temp_file_line=$tmp_dir/line.json
  record_size_temp_file_output=$tmp_dir/output.json

  max_batch=300000
  lines_count=0
  stop=0
  counter=1
  while [ $stop != 1 ]
  do
      while IFS= read -r line
      do
          if [[ $line == *"%g"* ]]
          then
              line=${line/\%g/$counter}
          fi

          if [ $record_size != 0 ]
          then
              if ! echo "$line" | jq -e .  > /dev/null 2>&1
              then
                  echo "${line}PLACEHOLDER" > $record_size_temp_file_output
              else
                  echo $line > $record_size_temp_file_line
                  new_value="PLACEHOLDER"

                  first_string_field=$(echo "$line" | jq -r 'path(.. | select(type == "string")) | .[-1]' | tail -1)

                  log "ğŸ”® Replacing first string field $first_string_field value with long payload"
                  jq -c --arg new_val "$new_value" ".${first_string_field} |= \$new_val" $record_size_temp_file_line > $record_size_temp_file_output
              fi

              # The size needed for the new_value
              size_with_placeholder=$(wc -c < $record_size_temp_file_output)

              # The size needed for the new_value
              new_value_size=$((record_size - size_with_placeholder))

              if [[ $new_value_size -gt 0 ]]
              then
                  # Create a string of '-' characters with length equivalent to new_value_size
                  new_value_string=$(LC_ALL=C tr -dc 'a-zA-Z0-9' < /dev/urandom | head -c$new_value_size)

                  echo -n "$new_value_string" > temp.txt

                  # Replace placeholder with the content of temp.txt file in $record_size_temp_file_output
                  # Perl can handle very large arguments and perform replacement effectively
                  perl -pi -e 'BEGIN{undef $/;} s/PLACEHOLDER/`cat temp.txt`/gse' $record_size_temp_file_output

                  cat $record_size_temp_file_output >> "$output_file"
                  # Remove temp file
                  rm temp.txt
              else
                  log "âŒ record-size is too small"
                  exit 1
              fi
          else
              echo "$line" >> "$output_file"
          fi

          lines_count=$((lines_count+1))
          if [ $lines_count -ge $max_batch ]
          then
              stop=1
              break
          fi
          if [ $lines_count -ge $nb_messages ]
          then
              stop=1
              break
          fi
          counter=$((counter+1))
      done < "$input_file"
  done

  nb_generated_messages=$(wc -l < $output_file)
  nb_generated_messages=${nb_generated_messages// /}

  if [ "$nb_generated_messages" == "0" ]
  then
      logerror "âŒ records could not be generated!"
      exit 1
  fi

  value_str=""
  if [[ -n "$forced_value" ]]
  then
      value_str=" based on --forced-value "
  fi

  ELAPSED="took: $((($SECONDS / 60) % 60))min $(($SECONDS % 60))sec"

  size_limit_to_show=2500
  if [ $record_size -gt $size_limit_to_show ]
  then
      log "âœ¨ $nb_generated_messages records were generated$value_str (only showing first 1 as record size is $record_size), $ELAPSED"
      log "âœ¨ only showing first $size_limit_to_show characters"
      head -n 1 "$output_file" | cut -c 1-${size_limit_to_show} | awk "{print \$0 \"...<truncated, only showing first $size_limit_to_show characters, out of $record_size>...\"}"
  else
      if (( nb_generated_messages < 10 ))
      then
          log "âœ¨ $nb_generated_messages records were generated$value_str"
          cat "$output_file"
      else
          log "âœ¨ $nb_generated_messages records were generated$value_str (only showing first 10), $ELAPSED"
          head -n 10 "$output_file"
      fi
  fi

  if [[ -n "$generate_only" ]]
  then
    log "ğŸšª --generate-only is set, exiting now."
    exit 0
  fi

  if [[ -n "$validate" ]]
  then
      log "âœ”ï¸ --validate is set, validating schema now..."

      if [ "$schema_type" == "json-schema" ]
      then
          log "âœ¨ also validating with https://github.com/jriester/PythonScripts/blob/master/json_type_validator.py"
          curl -s -L https://raw.githubusercontent.com/jriester/PythonScripts/master/json_type_validator.py -o /tmp/json_type_validator.py
          docker run -i --rm -v "/tmp/json_type_validator.py:/tmp/json_type_validator.py" -v "$schema_file:/tmp/schema" python:3.7-slim python /tmp/json_type_validator.py -f /tmp/schema
      fi

      set +e
      log "ğŸ— Building jar for schema-validator"
      docker run -i --rm -e TAG=$TAG_BASE -v "${root_folder}/scripts/cli/src/schema-validator":/usr/src/mymaven -v "$HOME/.m2":/root/.m2 -v "$root_folder/scripts/settings.xml:/tmp/settings.xml" -v "${root_folder}/scripts/cli/src/schema-validator/target:/usr/src/mymaven/target" -w /usr/src/mymaven maven:3.6.1-jdk-11 mvn -s /tmp/settings.xml -Dkafka.tag=$TAG package > /tmp/result.log 2>&1
      if [ $? != 0 ]
      then
          logerror "ERROR: failed to build java component schema-validator"
          tail -500 /tmp/result.log
          exit 1
      fi
      set -e

      docker cp ${root_folder}/scripts/cli/src/schema-validator/target/schema-validator-1.0.0-jar-with-dependencies.jar connect:/tmp/schema-validator-1.0.0-jar-with-dependencies.jar > /dev/null 2>&1
      docker cp $schema_file connect:/tmp/schema > /dev/null 2>&1
      docker cp $tmp_dir/out.json connect:/tmp/message.json > /dev/null 2>&1
      env_list=""
      for conf in "${validate_config[@]}"
      do
          case "${conf}" in

              "connect.meta.data=false")
                  env_list="$env_list -e KAFKA_CONNECT_META_DATA=false"
              ;;

              # avro specifics
              "scrub.invalid.names=true")
                  env_list="$env_list -e KAFKA_SCRUB_INVALID_NAMES=true"
              ;;
              "enhanced.avro.schema.support=true")
                  env_list="$env_list -e KAFKA_ENHANCED_AVRO_SCHEMA_SUPPORT=true"
              ;;

              # json-schema specifics
              "use.optional.for.nonrequired=true")
                  env_list="$env_list -e KAFKA_USE_OPTIONAL_FOR_NONREQUIRED=true"
              ;;
              "ignore.default.for.nullables=true")
                  env_list="$env_list -e KAFKA_IGNORE_DEFAULT_FOR_NULLABLES=true"
              ;;
              "generalized.sum.type.support=true")
                  env_list="$env_list -e KAFKA_GENERALIZED_SUM_TYPE_SUPPORT=true"
              ;;

              # protobuf specifics
              "enhanced.protobuf.schema.support=true")
                  env_list="$env_list -e KAFKA_ENHANCED_PROTOBUF_SCHEMA_SUPPORT=true"
              ;;
              "generate.index.for.unions=false")
                  env_list="$env_list -e KAFKA_GENERATE_INDEX_FOR_UNIONS=false"
              ;;
              "int.for.enums=true")
                  env_list="$env_list -e KAFKA_INT_FOR_ENUMS=true"
              ;;
              "optional.for.nullables=true")
                  env_list="$env_list -e KAFKA_OPTIONAL_FOR_NULLABLES=true"
              ;;
              "generate.struct.for.nulls=true")
                  env_list="$env_list -e KAFKA_GENERATE_STRUCT_FOR_NULLS=true"
              ;;
              "wrapper.for.nullables=true")
                  env_list="$env_list -e KAFKA_WRAPPER_FOR_NULLABLES=true"
              ;;
              "wrapper.for.raw.primitives=false")
                  env_list="$env_list -e KAFKA_WRAPPER_FOR_RAW_PRIMITIVES=false"
              ;;
              *)
                  logerror "default (none of above)"
              ;;
          esac
      done

      docker exec $env_list -e SCHEMA_TYPE=$schema_type connect bash -c "java -jar /tmp/schema-validator-1.0.0-jar-with-dependencies.jar" > $tmp_dir/result.log
      set +e
      nb=$(grep -c "ERROR" $tmp_dir/result.log)
      if [ $nb -ne 0 ]
      then
          logerror "âŒ schema is not valid according to $schema_type converter"
          cat $tmp_dir/result.log
          exit 1
      else
          log "ğŸ‘Œ schema is valid according to $schema_type converter"
      fi
      set -e
  fi

  playground topic get-number-records --topic $topic > $tmp_dir/result.log 2>$tmp_dir/result.log
  set +e
  grep "does not exist" $tmp_dir/result.log > /dev/null 2>&1
  if [ $? == 0 ]
  then
      log "âœ¨ topic $topic does not exist, it will be created.."
      if [[ "$environment" == "environment" ]]
      then
          if [ "$nb_partitions" != "" ]
          then
              log "â›… creating topic in confluent cloud with $nb_partitions partitions"
              playground topic create --topic $topic --nb-partitions $nb_partitions
          else
              log "â›… creating topic in confluent cloud"
              playground topic create --topic $topic
          fi
      else
          if [ "$nb_partitions" != "" ]
          then
              log "--nb-partitions is set, creating topic with $nb_partitions partitions"
              playground topic create --topic $topic --nb-partitions $nb_partitions
          else
              playground topic create --topic $topic
          fi
      fi
  else
      if [ "$nb_partitions" != "" ]
      then
          logwarn "--nb-partitions is set, re-creating topic with $nb_partitions partitions ?"
          check_if_continue
          playground topic delete --topic $topic
          playground topic create --topic $topic --nb-partitions $nb_partitions
      else
          log "ğŸ’¯ Get number of records in topic $topic"
          tail -1 $tmp_dir/result.log
      fi
  fi

  if [ "$compatibility" != "" ]
  then
      playground topic set-schema-compatibility --topic $topic --compatibility $compatibility
  fi

  case "${schema_type}" in
      avro|json-schema|protobuf)

      ;;
      *)
          if [[ -n "$validate" ]]
          then
              logerror "âŒ --validate is set but $schema_type is used. This is only valid for avro|json-schema|protobuf"
              exit 1
          fi
          if [[ -n "$value_subject_name_strategy" ]]
          then
              logerror "âŒ --value-subject-name-strategy is set but $schema_type is used. This is only valid for avro|json-schema|protobuf"
              exit 1

          fi
      ;;
  esac

  if [[ -n "$key" ]]
  then
      if [[ $key =~ ^([^0-9]*)([0-9]+)([^0-9]*)$ ]]; then
          prefix="${BASH_REMATCH[1]}"
          number="${BASH_REMATCH[2]}"
          suffix="${BASH_REMATCH[3]}"

          log "ğŸ—ï¸ key $key is set with a number $number, it will be used as starting point"
          while read -r line
          do
              new_key="${prefix}${number}${suffix}"
              echo "${new_key}|${line}" >> "$tmp_dir/tempfile"
              number=$((number + 1))
          done < "$output_file"

          mv "$tmp_dir/tempfile" "$output_file"
      else
          counter=1
          log "ğŸ—ï¸ key is set with a string $key, it will be used for all records"
          while read -r line
          do
              if [[ $key == *"%g"* ]]
              then
                  key=${key/\%g/$counter}
              fi
              echo "${key}|${line}" >> "$tmp_dir/tempfile"
          done < "$output_file"

          mv "$tmp_dir/tempfile" "$output_file"
      fi
  fi

  if [[ -n "$headers" ]]
  then
      log "ğŸš headers are set $headers"
      while read line
      do
          echo "${headers}|${line}" >> $tmp_dir/tempfile
      done < $output_file

      mv $tmp_dir/tempfile $output_file
  fi

  producer_properties=""

  if [ $record_size -gt 1048576 ]
  then
      log "âœ¨ record-size $record_size is greater than 1Mb (1048576), setting --producer-property max.request.size=$((record_size + 1000)) and --producer-property buffer.memory=67108864"
      producer_properties="--producer-property max.request.size=$((record_size + 1000)) --producer-property buffer.memory=67108864"
      log "âœ¨ topic $topic max.message.bytes is also set to $((record_size + 1000))"
      playground topic alter --topic $topic --add-config max.message.bytes=$((record_size + 1000))
  fi

  for producer_prop in "${producer_property[@]}"
  do
      producer_properties="$producer_properties --producer-property $producer_prop"
  done

  if [ "$producer_properties" != "" ]
  then
      log "Following producer properties will be used: $producer_properties"
  fi

  set -e
  SECONDS=0
  log "ğŸ“¤ producing $nb_messages records to topic $topic"
  if [ $nb_messages -gt $max_batch ]
  then
      log "âœ¨ it will be done in batches of maximum $max_batch records"
  fi
  nb_messages_sent=0
  nb_messages_to_send=0
  stop=0
  should_stop=0
  while [ $stop != 1 ]
  do
      if [ $((nb_messages_sent + nb_generated_messages)) -le $nb_messages ]
      then
          nb_messages_to_send=$nb_generated_messages
      else
          nb_messages_to_send=$((nb_messages - nb_messages_sent))
          should_stop=1
      fi
      if [ $nb_messages_to_send -eq 0 ]
      then
          stop=1
          continue
      fi
      if [ $nb_messages -gt $max_batch ]
      then
          log "ğŸ“¤ producing a batch of $nb_messages_to_send records to topic $topic"
          log "ğŸ’¯ $nb_messages_sent/$nb_messages records sent so far..."
      fi
      case "${schema_type}" in
          json|sql|raw)
              if [[ "$environment" == "environment" ]]
              then
                  if [[ -n "$key" ]]
                  then
                      if [[ -n "$headers" ]]
                      then
                          if [[ -n "$verbose" ]]
                          then
                              set -x
                          fi
                          head -n $nb_messages_to_send $output_file | docker run -i --rm -v /tmp/delta_configs/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-console-producer --broker-list $BOOTSTRAP_SERVERS --topic $topic --producer.config /tmp/configuration/ccloud.properties $security $producer_properties --property parse.key=true --property key.separator="|" --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":"
                      else
                          if [[ -n "$verbose" ]]
                          then
                              set -x
                          fi
                          head -n $nb_messages_to_send $output_file | docker run -i --rm -v /tmp/delta_configs/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-console-producer --broker-list $BOOTSTRAP_SERVERS --topic $topic --producer.config /tmp/configuration/ccloud.properties $security $producer_properties --property parse.key=true --property key.separator="|"

                      fi
                  else
                      if [[ -n "$headers" ]]
                      then
                          if [[ -n "$verbose" ]]
                          then
                              set -x
                          fi
                          head -n $nb_messages_to_send $output_file | docker run -i --rm -v /tmp/delta_configs/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-console-producer --broker-list $BOOTSTRAP_SERVERS --topic $topic --producer.config /tmp/configuration/ccloud.properties $security $producer_properties --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":"
                      else
                          if [[ -n "$verbose" ]]
                          then
                              set -x
                          fi
                          head -n $nb_messages_to_send $output_file | docker run -i --rm -v /tmp/delta_configs/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-console-producer --broker-list $BOOTSTRAP_SERVERS --topic $topic --producer.config /tmp/configuration/ccloud.properties $security $producer_properties
                      fi
                  fi
              else
                  if [[ -n "$key" ]]
                  then
                      if [[ -n "$headers" ]]
                      then
                          if [[ -n "$verbose" ]]
                          then
                              set -x
                          fi
                          head -n $nb_messages_to_send $output_file | docker exec -i $container kafka-console-producer --broker-list $bootstrap_server --topic $topic $security $producer_properties --property parse.key=true --property key.separator="|" --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":"
                      else
                          if [[ -n "$verbose" ]]
                          then
                              set -x
                          fi
                          head -n $nb_messages_to_send $output_file | docker exec -i $container kafka-console-producer --broker-list $bootstrap_server --topic $topic $security $producer_properties --property parse.key=true --property key.separator="|"
                      fi
                  else
                      if [[ -n "$headers" ]]
                      then
                          if [[ -n "$verbose" ]]
                          then
                              set -x
                          fi
                          head -n $nb_messages_to_send $output_file | docker exec -i $container kafka-console-producer --broker-list $bootstrap_server --topic $topic $security $producer_properties --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":"
                      else
                          if [[ -n "$verbose" ]]
                          then
                              set -x
                          fi
                          head -n $nb_messages_to_send $output_file | docker exec -i $container kafka-console-producer --broker-list $bootstrap_server --topic $topic $security $producer_properties
                      fi
                  fi
              fi
          ;;
          *)
              value_subject_name_strategy_property=""
              if [[ -n "$value_subject_name_strategy" ]]
              then
                  value_subject_name_strategy_property="--property value.subject.name.strategy=io.confluent.kafka.serializers.subject.$value_subject_name_strategy"
              fi
              if [[ "$environment" == "environment" ]]
              then
                  if [[ -n "$key" ]]
                  then
                      if [[ -n "$headers" ]]
                      then
                          if [[ -n "$verbose" ]]
                          then
                              set -x
                          fi
                          head -n $nb_messages_to_send $output_file | docker run -i --rm -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/etc/kafka/tools-log4j.properties" -e schema_type=$schema_type -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" -e SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-$schema_type-console-producer --broker-list $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config="$SASL_JAAS_CONFIG" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema="$(cat $schema_file)" --property parse.key=true --property key.separator="|" --property key.serializer=org.apache.kafka.common.serialization.StringSerializer --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":" $value_subject_name_strategy_property $producer_properties
                      else
                          if [[ -n "$verbose" ]]
                          then
                              set -x
                          fi
                          head -n $nb_messages_to_send $output_file | docker run -i --rm -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/etc/kafka/tools-log4j.properties" -e schema_type=$schema_type -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" -e SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-$schema_type-console-producer --broker-list $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config="$SASL_JAAS_CONFIG" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema="$(cat $schema_file)" --property parse.key=true --property key.separator="|" --property key.serializer=org.apache.kafka.common.serialization.StringSerializer $value_subject_name_strategy_property $producer_properties
                      fi
                  else
                      if [[ -n "$headers" ]]
                      then
                          if [[ -n "$verbose" ]]
                          then
                              set -x
                          fi
                          head -n $nb_messages_to_send $output_file | docker run -i --rm -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/etc/kafka/tools-log4j.properties" -e schema_type=$schema_type -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" -e SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-$schema_type-console-producer --broker-list $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config="$SASL_JAAS_CONFIG" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema="$(cat $schema_file)" --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":" $value_subject_name_strategy_property $producer_properties
                      else
                          if [[ -n "$verbose" ]]
                          then
                              set -x
                          fi
                          head -n $nb_messages_to_send $output_file | docker run -i --rm -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/etc/kafka/tools-log4j.properties" -e schema_type=$schema_type -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" -e SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-$schema_type-console-producer --broker-list $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config="$SASL_JAAS_CONFIG" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema="$(cat $schema_file)" $value_subject_name_strategy_property $producer_properties
                      fi
                  fi
              else
                  if [[ -n "$key" ]]
                  then
                      if [[ -n "$headers" ]]
                      then
                          if [[ -n "$verbose" ]]
                          then
                              set -x
                          fi
                          head -n $nb_messages_to_send $output_file | docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/etc/kafka/tools-log4j.properties" -i $container kafka-$schema_type-console-producer --broker-list $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema="$(cat $schema_file)" --property parse.key=true --property key.separator="|" --property key.serializer=org.apache.kafka.common.serialization.StringSerializer --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":" $value_subject_name_strategy_property $producer_properties
                      else
                          if [[ -n "$verbose" ]]
                          then
                              set -x
                          fi
                          head -n $nb_messages_to_send $output_file | docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/etc/kafka/tools-log4j.properties" -i $container kafka-$schema_type-console-producer --broker-list $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema="$(cat $schema_file)" --property parse.key=true --property key.separator="|" --property key.serializer=org.apache.kafka.common.serialization.StringSerializer $value_subject_name_strategy_property $producer_properties
                      fi
                  else
                      if [[ -n "$headers" ]]
                      then
                          if [[ -n "$verbose" ]]
                          then
                              set -x
                          fi
                          head -n $nb_messages_to_send $output_file | docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/etc/kafka/tools-log4j.properties" -i $container kafka-$schema_type-console-producer --broker-list $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema="$(cat $schema_file)" --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":" $value_subject_name_strategy_property $producer_properties
                      else
                          if [[ -n "$verbose" ]]
                          then
                              set -x
                          fi
                          head -n $nb_messages_to_send $output_file | docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS="-Dlog4j.configuration=file:/etc/kafka/tools-log4j.properties" -i $container kafka-$schema_type-console-producer --broker-list $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema="$(cat $schema_file)" $value_subject_name_strategy_property $producer_properties
                      fi
                  fi
              fi
          ;;
      esac
      if [[ -n "$verbose" ]]
      then
          set +x
      fi
      # Increment the number of sent messages
      nb_messages_sent=$((nb_messages_sent + nb_messages_to_send))
      if [ $should_stop -eq 1 ]
      then
          stop=1
      fi
  done
  ELAPSED="took: $((($SECONDS / 60) % 60))min $(($SECONDS % 60))sec"
  log "ğŸ“¤ produced $nb_messages records to topic $topic, $ELAPSED"
  set +x
  playground topic get-number-records --topic $topic
}

# :command.function
playground_topic_create_command() {
  # src/topic_create_command.sh
  topic="${args[--topic]}"
  nb_partitions="${args[--nb-partitions]}"

  ret=$(get_security_broker "--command-config")

  container=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  environment=`get_environment_used`

  if [ "$nb_partitions" == "" ]
  then
      nb_partitions=1
  fi

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  playground topic get-number-records --topic $topic > /tmp/result.log 2>/tmp/result.log
  set +e
  grep "does not exist" /tmp/result.log > /dev/null 2>&1
  if [ $? == 0 ]
  then
      set -e
      log "ğŸ†• Creating topic $topic"
      if [[ "$environment" == "environment" ]]
      then
          if [ -f /tmp/delta_configs/env.delta ]
          then
              source /tmp/delta_configs/env.delta
          else
              logerror "ERROR: /tmp/delta_configs/env.delta has not been generated"
              exit 1
          fi
          if [ ! -f /tmp/delta_configs/ak-tools-ccloud.delta ]
          then
              logerror "ERROR: /tmp/delta_configs/ak-tools-ccloud.delta has not been generated"
              exit 1
          fi

          DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
          dir1=$(echo ${DIR_CLI%/*})
          root_folder=$(echo ${dir1%/*})
          IGNORE_CHECK_FOR_DOCKER_COMPOSE=true
          source $root_folder/scripts/utils.sh

          docker run --rm -v /tmp/delta_configs/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-topics --create --topic $topic --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties --partitions $nb_partitions ${other_args[*]}
      else
          docker exec $container kafka-topics --create --topic $topic --bootstrap-server broker:9092 --partitions $nb_partitions $security ${other_args[*]}
      fi
  else
      logerror "âŒ topic $topic already exist !"
      exit 1
  fi
}

# :command.function
playground_topic_delete_command() {
  # src/topic_delete_command.sh
  topic="${args[--topic]}"

  ret=$(get_security_broker "--command-config")

  container=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  playground topic get-number-records --topic $topic > /tmp/result.log 2>/tmp/result.log
  set +e
  grep "does not exist" /tmp/result.log > /dev/null 2>&1
  if [ $? == 0 ]
  then
      logwarn "âŒ topic $topic does not exist !"
      exit 1
  fi
  set -e

  log "âŒ Deleting topic $topic"
  if [[ "$environment" == "environment" ]]
  then
      if [ -f /tmp/delta_configs/env.delta ]
      then
          source /tmp/delta_configs/env.delta
      else
          logerror "ERROR: /tmp/delta_configs/env.delta has not been generated"
          exit 1
      fi
      if [ ! -f /tmp/delta_configs/ak-tools-ccloud.delta ]
      then
          logerror "ERROR: /tmp/delta_configs/ak-tools-ccloud.delta has not been generated"
          exit 1
      fi

      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
      dir1=$(echo ${DIR_CLI%/*})
      root_folder=$(echo ${dir1%/*})
      IGNORE_CHECK_FOR_DOCKER_COMPOSE=true
      source $root_folder/scripts/utils.sh

      docker run --rm -v /tmp/delta_configs/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-topics --delete --topic $topic --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties
  else
      docker exec $container kafka-topics --delete --topic $topic --bootstrap-server broker:9092 $security
  fi
}

# :command.function
playground_topic_alter_command() {
  # src/topic_alter_command.sh
  topic="${args[--topic]}"

  ret=$(get_security_broker "--command-config")

  container=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  environment=`get_environment_used`

  if [ "$environment" == "error" ]
  then
    logerror "File containing restart command /tmp/playground-command does not exist!"
    exit 1

  fi

  playground topic get-number-records --topic $topic > /tmp/result.log 2>/tmp/result.log
  set +e
  grep "does not exist" /tmp/result.log > /dev/null 2>&1
  if [ $? == 0 ]
  then
      logwarn "ğŸ†• topic $topic does not exist, creating it..."
      playground topic create --topic $topic

      playground topic alter --topic $topic ${other_args[*]}
  else
      log "ğŸª› Altering topic $topic"
      if [[ "$environment" == "environment" ]]
      then
          if [ -f /tmp/delta_configs/env.delta ]
          then
              source /tmp/delta_configs/env.delta
          else
              logerror "ERROR: /tmp/delta_configs/env.delta has not been generated"
              exit 1
          fi
          if [ ! -f /tmp/delta_configs/ak-tools-ccloud.delta ]
          then
              logerror "ERROR: /tmp/delta_configs/ak-tools-ccloud.delta has not been generated"
              exit 1
          fi

          DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
          dir1=$(echo ${DIR_CLI%/*})
          root_folder=$(echo ${dir1%/*})
          IGNORE_CHECK_FOR_DOCKER_COMPOSE=true
          source $root_folder/scripts/utils.sh

          docker run --rm -v /tmp/delta_configs/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-configs --alter --entity-type topics --entity-name $topic --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties ${other_args[*]}
      else
          docker exec $container kafka-configs --alter --entity-type topics --entity-name $topic --bootstrap-server broker:9092 $security ${other_args[*]}
      fi
  fi
  set -e

}

# :command.function
playground_ccloud_connector_status_command() {
  # src/ccloud_connector_status_command.sh
  ret=$(get_ccloud_connect)

  environment=$(echo "$ret" | cut -d "@" -f 1)
  cluster=$(echo "$ret" | cut -d "@" -f 2)
  authorization=$(echo "$ret" | cut -d "@" -f 3)

  connector="${args[--connector]}"

  if [[ ! -n "$connector" ]]
  then
      set +e
      log "âœ¨ --connector flag was not provided, applying command to all ccloud connectors"
      connector=$(playground get-ccloud-connector-list)
      if [ $? -ne 0 ]
      then
          logerror "âŒ Could not get list of connectors"
          echo "$connector"
          exit 1
      fi
      if [ "$connector" == "" ]
      then
          logerror "ğŸ’¤ No ccloud connector is running !"
          exit 1
      fi
      set -e
  fi

  items=($connector)
  for connector in ${items[@]}
  do
      log "ğŸ§© Displaying connector status for $connector"
      curl -s --request GET "https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/status" --header "authorization: Basic $authorization" | jq .
  done
}

# :command.function
playground_ccloud_connector_plugins_command() {
  # src/ccloud_connector_plugins_command.sh
  ret=$(get_ccloud_connect)

  environment=$(echo "$ret" | cut -d "@" -f 1)
  cluster=$(echo "$ret" | cut -d "@" -f 2)
  authorization=$(echo "$ret" | cut -d "@" -f 3)

  log "ğŸ§© Displaying all connector plugins installed"
  curl -s --request GET "https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connector-plugins" \
  --header "authorization: Basic $authorization" | jq -r '.[] | [.class , .version , .type] | @tsv' | column -t

}

# :command.function
playground_ccloud_connector_pause_command() {
  # src/ccloud_connector_pause_command.sh
  ret=$(get_ccloud_connect)

  environment=$(echo "$ret" | cut -d "@" -f 1)
  cluster=$(echo "$ret" | cut -d "@" -f 2)
  authorization=$(echo "$ret" | cut -d "@" -f 3)

  connector="${args[--connector]}"

  if [[ ! -n "$connector" ]]
  then
      set +e
      log "âœ¨ --connector flag was not provided, applying command to all ccloud connectors"
      connector=$(playground get-ccloud-connector-list)
      if [ $? -ne 0 ]
      then
          logerror "âŒ Could not get list of connectors"
          echo "$connector"
          exit 1
      fi
      if [ "$connector" == "" ]
      then
          logerror "ğŸ’¤ No ccloud connector is running !"
          exit 1
      fi
      set -e
  fi

  items=($connector)
  for connector in ${items[@]}
  do
      log "â¸ï¸ Pausing ccloud connector $connector"
      curl -s --request PUT "https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/pause" --header "authorization: Basic $authorization" | jq .

      sleep 3
      playground ccloud-connector status --connector $connector
  done

}

# :command.function
playground_ccloud_connector_resume_command() {
  # src/ccloud_connector_resume_command.sh
  ret=$(get_ccloud_connect)

  environment=$(echo "$ret" | cut -d "@" -f 1)
  cluster=$(echo "$ret" | cut -d "@" -f 2)
  authorization=$(echo "$ret" | cut -d "@" -f 3)

  connector="${args[--connector]}"

  if [[ ! -n "$connector" ]]
  then
      set +e
      log "âœ¨ --connector flag was not provided, applying command to all ccloud connectors"
      connector=$(playground get-ccloud-connector-list)
      if [ $? -ne 0 ]
      then
          logerror "âŒ Could not get list of connectors"
          echo "$connector"
          exit 1
      fi
      if [ "$connector" == "" ]
      then
          logerror "ğŸ’¤ No ccloud connector is running !"
          exit 1
      fi
      set -e
  fi

  items=($connector)
  for connector in ${items[@]}
  do
      log "â¯ï¸ Resuming ccloud connector $connector"
      curl -s --request PUT "https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/resume" --header "authorization: Basic $authorization" | jq .

      sleep 3
      playground ccloud-connector status --connector $connector
  done

}

# :command.function
playground_ccloud_connector_delete_command() {
  # src/ccloud_connector_delete_command.sh
  ret=$(get_ccloud_connect)

  environment=$(echo "$ret" | cut -d "@" -f 1)
  cluster=$(echo "$ret" | cut -d "@" -f 2)
  authorization=$(echo "$ret" | cut -d "@" -f 3)

  connector="${args[--connector]}"

  if [[ ! -n "$connector" ]]
  then
      logwarn "--connector flag was not provided, applying command to all ccloud connectors"
      check_if_continue
      connector=$(playground get-ccloud-connector-list)
      if [ $? -ne 0 ]
      then
          logerror "âŒ Could not get list of connectors"
          echo "$connector"
          exit 1
      fi
      if [ "$connector" == "" ]
      then
          logerror "ğŸ’¤ No ccloud connector is running !"
          exit 1
      fi
      set -e
  fi

  items=($connector)
  for connector in ${items[@]}
  do
      log "âŒ Deleting ccloud connector $connector"
      curl -s --request DELETE "https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector" --header "authorization: Basic $authorization" | jq .
  done
}

# :command.function
playground_ccloud_connector_show_lag_command() {
  # src/ccloud_connector_show_lag_command.sh
  ret=$(get_ccloud_connect)

  environment=$(echo "$ret" | cut -d "@" -f 1)
  cluster=$(echo "$ret" | cut -d "@" -f 2)
  authorization=$(echo "$ret" | cut -d "@" -f 3)

  connector="${args[--connector]}"
  wait_for_zero_lag="${args[--wait-for-zero-lag]}"

  if [[ ! -n "$connector" ]]
  then
      set +e
      log "âœ¨ --connector flag was not provided, applying command to all ccloud connectors"
      connector=$(playground get-ccloud-connector-list)
      if [ $? -ne 0 ]
      then
          logerror "âŒ Could not get list of connectors"
          echo "$connector"
          exit 1
      fi
      if [ "$connector" == "" ]
      then
          logerror "ğŸ’¤ No ccloud connector is running !"
          exit 1
      fi
      set -e
  fi

  if [ -f /tmp/delta_configs/env.delta ]
  then
      source /tmp/delta_configs/env.delta
  else
      logerror "ERROR: /tmp/delta_configs/env.delta has not been generated"
      exit 1
  fi
  if [ ! -f /tmp/delta_configs/ak-tools-ccloud.delta ]
  then
      logerror "ERROR: /tmp/delta_configs/ak-tools-ccloud.delta has not been generated"
      exit 1
  fi

  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  root_folder=$(echo ${dir1%/*})
  IGNORE_CHECK_FOR_DOCKER_COMPOSE=true
  source $root_folder/scripts/utils.sh

  items=($connector)
  for connector in ${items[@]}
  do
      type=$(curl -s --request GET "https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector?expand=status" --header "authorization: Basic $authorization" | jq -r '.type')
      if [ "$type" != "sink" ]
      then
          logwarn "â­ï¸ Skipping $type connector $connector, it must be a sink to show the lag"
          continue

      fi
      connectorId=$(get_ccloud_connector_lcc $connector)

      if [[ -n "$wait_for_zero_lag" ]]
      then
          CHECK_INTERVAL=5
          SECONDS=0
          while true
          do
              lag_output=$(docker run --rm -v /tmp/delta_configs/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SASL_JAAS_CONFIG="$SASL_JAAS_CONFIG" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-consumer-groups --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties --group connect-$connectorId --describe)

              set +e
              echo "$lag_output" | awk -F" " '{ print $6 }' | grep "-"
              if [ $? -eq 0 ]
              then
                  logwarn "ğŸ¢ consumer lag for connector $connector ($connectorId) is not set"
                  echo "$lag_output" | awk -F" " '{ print $3,$4,$5,$6 }'
                  sleep $CHECK_INTERVAL
              else
                  total_lag=$(echo "$lag_output" | grep -v "PARTITION" | awk -F" " '{sum+=$6;} END{print sum;}')
                  if [ $total_lag -ne 0 ]
                  then
                      log "ğŸ¢ consumer lag for connector $connector ($connectorId) is $total_lag"
                      echo "$lag_output" | awk -F" " '{ print $3,$4,$5,$6 }'
                      sleep $CHECK_INTERVAL
                  else
                      ELAPSED="took: $((($SECONDS / 60) % 60))min $(($SECONDS % 60))sec"
                      log "ğŸ consumer lag for connector $connector ($connectorId) is 0 ! $ELAPSED"
                      break
                  fi
              fi
          done
      else
          log "ğŸ¢ Show lag for sink connector $connector ($connectorId)"
          docker run --rm -v /tmp/delta_configs/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SASL_JAAS_CONFIG="$SASL_JAAS_CONFIG" ${CP_CONNECT_IMAGE}:${CONNECT_TAG} kafka-consumer-groups --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties --group connect-$connectorId --describe
      fi
  done

}

# :command.function
playground_ccloud_connector_show_config_command() {
  # src/ccloud_connector_show_config_command.sh
  ret=$(get_ccloud_connect)

  environment=$(echo "$ret" | cut -d "@" -f 1)
  cluster=$(echo "$ret" | cut -d "@" -f 2)
  authorization=$(echo "$ret" | cut -d "@" -f 3)

  connector="${args[--connector]}"

  if [[ ! -n "$connector" ]]
  then
      set +e
      log "âœ¨ --connector flag was not provided, applying command to all ccloud connectors"
      connector=$(playground get-ccloud-connector-list)
      if [ $? -ne 0 ]
      then
          logerror "âŒ Could not get list of connectors"
          echo "$connector"
          exit 1
      fi
      if [ "$connector" == "" ]
      then
          logerror "ğŸ’¤ No ccloud connector is running !"
          exit 1
      fi
      set -e
  fi

  items=($connector)
  for connector in ${items[@]}
  do
      log "ğŸ§° Current config for ccloud connector $connector"
      json_config=$(curl $security -s -X GET -H "Content-Type: application/json" "https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/config" --header "authorization: Basic $authorization")
      echo "playground ccloud-connector create-or-update --connector $connector << EOF"
      echo "$json_config" | jq -S . | sed 's/\$/\\$/g'
      echo "EOF"
  done
}

# :command.function
playground_ccloud_connector_show_config_parameters_command() {
  # src/ccloud_connector_show_config_parameters_command.sh
  ret=$(get_ccloud_connect)

  environment=$(echo "$ret" | cut -d "@" -f 1)
  cluster=$(echo "$ret" | cut -d "@" -f 2)
  authorization=$(echo "$ret" | cut -d "@" -f 3)

  connector="${args[--connector]}"
  open="${args[--open]}"
  force_refresh="${args[--force-refresh]}"
  only_show_file_path="${args[--only-show-file-path]}"

  if [[ ! -n "$connector" ]]
  then
      set +e
      log "âœ¨ --connector flag was not provided, applying command to all ccloud connectors"
      connector=$(playground get-ccloud-connector-list)
      if [ $? -ne 0 ]
      then
          logerror "âŒ Could not get list of connectors"
          echo "$connector"
          exit 1
      fi
      if [ "$connector" == "" ]
      then
          logerror "ğŸ’¤ No ccloud connector is running !"
          exit 1
      fi
      set -e
  fi

  if [ -f /tmp/delta_configs/env.delta ]
  then
      source /tmp/delta_configs/env.delta
  else
      logerror "ERROR: /tmp/delta_configs/env.delta has not been generated"
      exit 1
  fi
  if [ ! -f /tmp/delta_configs/ak-tools-ccloud.delta ]
  then
      logerror "ERROR: /tmp/delta_configs/ak-tools-ccloud.delta has not been generated"
      exit 1
  fi

  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  root_folder=$(echo ${dir1%/*})
  IGNORE_CHECK_FOR_DOCKER_COMPOSE=true
  source $root_folder/scripts/utils.sh

  items=($connector)
  for connector in ${items[@]}
  do
      json_config=$(curl -s --request GET "https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/config" --header "authorization: Basic $authorization")
      connector_class=$(echo "$json_config" | jq -r '."connector.class"')
      set +e
      curl_output=$(curl -s --request GET "https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connector-plugins" --header "authorization: Basic $authorization")
      ret=$?
      set -e
      if [ $ret -eq 0 ]
      then
          current_group=""
          rows=()
          for row in $(echo "$curl_output" | jq -r '.[] | @base64'); do
              _jq() {
                  echo ${row} | base64 --decode | jq -r ${1}
              }

              class=$(_jq '.class')
          done
      else
          logerror "âŒ curl request failed with error code $ret!"
          exit 1
      fi

      filename="/tmp/config-$connector_class.txt"

      class=$(echo $connector_class | rev | cut -d '.' -f 1 | rev)
      log "ğŸ”© getting parameters for connector $connector ($class)"

      if [[ -n "$force_refresh" ]]
      then
          if [ -f $filename ]
          then
              rm -f $filename
          fi
      fi
      if [ ! -f $filename ]
      then
          set +e
          curl_output=$(curl -s --request PUT -H "Content-Type: application/json" --data "$json_config" "https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connector-plugins/$connector_class/config/validate" --header "authorization: Basic $authorization")
          ret=$?
          set -e
          if [ $ret -eq 0 ]
          then
              error_code=$(echo "$curl_output" | jq -r .error_code)
              if [ "$error_code" != "null" ]
              then
                  message=$(echo "$curl_output" | jq -r .message)
                  logerror "Command failed with error code $error_code"
                  logerror "$message"
              else
                  if ! echo "$curl_output" | jq -e .  > /dev/null 2>&1
                  then
                      set +e
                      json_file=/tmp/json
                      echo "$curl_output" > $json_file
                      jq_output=$(jq . "$json_file" 2>&1)
                      error_line=$(echo "$jq_output" | grep -oE 'parse error.*at line [0-9]+' | grep -oE '[0-9]+')

                      if [[ -n "$error_line" ]]; then
                          logerror "âŒ Invalid JSON at line $error_line"
                      fi
                      set -e

                      if [[ $(type -f bat 2>&1) =~ "not found" ]]
                      then
                          cat -n $json_file
                      else
                          bat $json_file --highlight-line $error_line
                      fi

                      exit 1
                  fi

                  current_group=""
                  rows=()
                  for row in $(echo "$curl_output" | jq -r '.configs[] | @base64'); do
                      _jq() {
                          echo ${row} | base64 --decode | jq -r ${1}
                      }

                      group=$(_jq '.definition.group')
                      if [[ "$group" == "Common" || "$group" == "Transforms" || "$group" == "Error Handling" || "$group" == "Topic Creation" || "$group" == "offsets.topic" || "$group" == "Exactly Once Support" || "$group" == "Predicates" || "$group" == "Confluent Licensing" ]] ; then
                          continue
                      fi

                      if [ "$group" != "$current_group" ]
                      then
                          echo -e "==========================" >> $filename
                          echo -e "$group"                     >> $filename
                          echo -e "==========================" >> $filename
                          current_group=$group
                      fi

                      param=$(_jq '.definition.name')
                      default=$(_jq '.definition.default_value')
                      type=$(_jq '.definition.type')
                      required=$(_jq '.definition.required')
                      importance=$(_jq '.definition.importance')
                      description=$(_jq '.definition.documentation')

                      echo -e "ğŸ”˜ $param" >> $filename
                      echo -e "" >> $filename
                      echo -e "$description" >> $filename
                      echo -e "" >> $filename
                      echo -e "\t - Type: $type" >> $filename
                      echo -e "\t - Default: $default" >> $filename
                      echo -e "\t - Importance: $importance" >> $filename
                      echo -e "\t - Required: $required" >> $filename
                      echo -e "" >> $filename
                  done
              fi
          else
              logerror "âŒ curl request failed with error code $ret!"
              exit 1
          fi
      fi

      if [[ -n "$open" ]]
      then
          if config_has_key "editor"
          then
              editor=$(config_get "editor")
          log "ğŸ“– Opening ${filename} using configured editor $editor"
          $editor $filename
          else
              if [[ $(type code 2>&1) =~ "not found" ]]
              then
              logerror "Could not determine an editor to use as default code is not found - you can change editor by updating config.ini"
              exit 1
              else
              log "ğŸ“– Opening ${filename} with code (default) - you can change editor by updating config.ini"
              code $filename
              fi
          fi
      else
          if [[ -n "$only_show_file_path" ]]
          then
              echo "$filename"
          else
              cat $filename
          fi
      fi
  done
}

# :command.function
playground_ccloud_connector_create_or_update_command() {
  # src/ccloud_connector_create_or_update_command.sh
  json=${args[json]}

  if [ "$json" = "-" ]
  then
      # stdin
      json_content=$(cat "$json")
  else
      json_content=$json
  fi

  json_file=/tmp/json
  trap 'rm -f /tmp/json' EXIT
  echo "$json_content" > $json_file

  # JSON is invalid
  if ! echo "$json_content" | jq -e . > /dev/null 2>&1
  then
      set +e
      jq_output=$(jq . "$json_file" 2>&1)
      error_line=$(echo "$jq_output" | grep -oE 'parse error.*at line [0-9]+' | grep -oE '[0-9]+')

      if [[ -n "$error_line" ]]; then
          logerror "âŒ Invalid JSON at line $error_line"
      fi
      set -e

      if [[ $(type -f bat 2>&1) =~ "not found" ]]
      then
          cat -n $json_file
      else
          bat $json_file --highlight-line $error_line
      fi

      exit 1
  fi

  ret=$(get_ccloud_connect)

  environment=$(echo "$ret" | cut -d "@" -f 1)
  cluster=$(echo "$ret" | cut -d "@" -f 2)
  authorization=$(echo "$ret" | cut -d "@" -f 3)

  connector="${args[--connector]}"

  is_create=1
  connectors=$(playground get-ccloud-connector-list)
  items=($connectors)
  for con in ${items[@]}
  do
      if [[ "$con" == "$connector" ]]
      then
          is_create=0
      fi
  done

  if [ $is_create == 1 ]
  then
      log "ğŸ› ï¸ Creating connector $connector"
  else
      log "ğŸ”„ Updating connector $connector"
  fi

  set +e
  curl_output=$(curl $security -s -X PUT \
       -H "Content-Type: application/json" \
       -H "authorization: Basic $authorization" \
       --data @$json_file \
       https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/config)

  ret=$?
  set -e
  if [ $ret -eq 0 ]
  then
      error_code=$(echo "$curl_output" | jq -r .error_code)
      if [ "$error_code" != "null" ]
      then
          message=$(echo "$curl_output" | jq -r .message)
          logerror "Command failed with error code $error_code"
          logerror "$message"
          exit 1
      else
          if [ $is_create == 1 ]
          then
              log "âœ… Connector $connector was successfully created"
              if [ -z "$GITHUB_RUN_NUMBER" ]
              then
                  log "ğŸ’ˆ Configuration is "
                  echo "$json_content" | jq -S .
              fi
              log "ğŸ¥ Waiting a few seconds to get new status"
          else
              log "âœ… Connector $connector was successfully updated"
              if [ -z "$GITHUB_RUN_NUMBER" ]
              then
                  log "ğŸ’ˆ Configuration is "
                  echo "$json_content" | jq -S .
              fi
              log "ğŸ¥ Waiting a few seconds to get new status"
          fi
          sleep 8
          playground ccloud-connector status --connector $connector
      fi
  else
      logerror "âŒ curl request failed with error code $ret!"
      exit 1
  fi
}

# :command.function
playground_connector_status_command() {
  # src/connector_status_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  connector="${args[--connector]}"

  if [[ ! -n "$connector" ]]
  then
      log "âœ¨ --connector flag was not provided, applying command to all connectors"
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          logerror "ğŸ’¤ No connector is running !"
          exit 1
      fi
  fi

  items=($connector)
  for connector in ${items[@]}
  do
      set +e
      log "ğŸ§© Displaying connector status for $connector"
      printf "%-30s %-12s %-60s %-50s\n" "Name" "Status" "Tasks" "Stack Trace"
      echo "-----------------------------------------------------------------------------------------------------------------------------"
      status=$(curl -s $security "$connect_url/connectors/$connector/status" | jq -r '.connector.state')

      if [ "$status" == "RUNNING" ]
      then
          status="âœ… RUNNING"
      elif [ "$status" == "PAUSED" ]
      then
          status="â¸ï¸  PAUSED"
      elif [ "$status" == "FAILED" ]
      then
          status="âŒ FAILED"
      else
          status="ğŸ¤” UNKNOWN"
      fi

      tasks=$(curl -s $security "$connect_url/connectors/$connector/status" | jq -r '.tasks[] | "\(.id):\(.state)[\(.worker_id)]"' | tr '\n' ',' | sed 's/,$/\n/' | sed 's/:8083//g' | sed 's/:8283//g' | sed 's/:8383//g')

      if [[ "$tasks" == *"RUNNING"* ]]
      then
          tasks="${tasks//RUNNING/ğŸŸ¢ RUNNING}"
      elif [[ "$tasks" == *"PAUSED"* ]]
      then
          tasks="${tasks//PAUSED/â¸ï¸  PAUSED}"
      elif [[ "$tasks" == *"FAILED"* ]]
      then
          tasks="${tasks//FAILED/ğŸ›‘ FAILED}"
      else
          tasks="ğŸ¤” N/A"
      fi

      stacktrace_connector=$(curl -s $security "$connect_url/connectors/$connector/status" | jq -r '.connector.trace | select(length > 0)')
      stacktrace_tasks=$(curl -s $security "$connect_url/connectors/$connector/status" | jq -r '.tasks[].trace | select(length > 0)')
      stacktrace=""
      if [ "$stacktrace_connector" != "" ]
      then
          stacktrace="connector: $stacktrace_connector"
      fi

      if [ "$stacktrace_tasks" != "" ]
      then
          stacktrace="$stacktrace tasks: $stacktrace_tasks"
      fi

      if [ -z "$stacktrace" ]
      then
          stacktrace="-"
      fi

      printf "%-30s %-12s %-30s %-50s\n" "$connector" "$status" "$tasks" "$stacktrace"
      echo "-------------------------------------------------------------------------------------------------------------"
  done
}

# :command.function
playground_connector_plugins_command() {
  # src/connector_plugins_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  log "ğŸ§© Displaying all connector plugins installed"
  curl $security -s -X GET -H "Content-Type: application/json" "$connect_url/connector-plugins" | jq -r '.[] | [.class , .version , .type] | @tsv' | column -t
}

# :command.function
playground_connector_pause_command() {
  # src/connector_pause_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  connector="${args[--connector]}"

  if [[ ! -n "$connector" ]]
  then
      log "âœ¨ --connector flag was not provided, applying command to all connectors"
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          logerror "ğŸ’¤ No connector is running !"
          exit 1
      fi
  fi

  items=($connector)
  for connector in ${items[@]}
  do
      log "â¸ï¸ Pausing connector $connector"
      curl $security -s -X PUT -H "Content-Type: application/json" "$connect_url/connectors/$connector/pause" | jq .

      sleep 1
      playground connector status --connector $connector
  done
}

# :command.function
playground_connector_versions_command() {
  # src/connector_versions_command.sh
  if [ ! -f /tmp/playground-run ]
  then
      logerror "File containing re-run command /tmp/playground-run does not exist!"
      logerror "Make sure to use <playground run> command !"
      exit 1
  fi

  test_file=$(cat /tmp/playground-run | awk '{ print $4}')

  if [ ! -f $test_file ]
  then

      logerror "File $test_file retrieved from /tmp/playground-run does not exist!"
      logerror "Make sure to use <playground run> command !"
      exit 1
  fi

  # determining the docker-compose file from from test_file
  docker_compose_file=$(grep "environment" "$test_file" | grep DIR | grep start.sh | cut -d "/" -f 7 | cut -d '"' -f 1 | tail -n1 | xargs)
  test_file_directory="$(dirname "${test_file}")"
  docker_compose_file="${test_file_directory}/${docker_compose_file}"

  if [ "${docker_compose_file}" != "" ] && [ ! -f "${docker_compose_file}" ]
  then
      logwarn "Skipping as docker-compose override file could not be detemined"
      exit 0
  fi

  connector_paths=$(grep "CONNECT_PLUGIN_PATH" "${docker_compose_file}" | grep -v "KSQL_CONNECT_PLUGIN_PATH" | cut -d ":" -f 2  | tr -s " " | head -1)
  if [ "$connector_paths" == "" ]
  then
      logwarn "Skipping as it is not an example with connector"
      exit 0
  else
      current_tag=$(docker inspect -f '{{.Config.Image}}' broker 2> /dev/null | cut -d ":" -f 2)
      log "ğŸ¯ Version currently used for confluent platform"
      echo "$current_tag"

      my_array_connector_tag=($(echo $CONNECTOR_TAG | tr "," "\n"))
      for connector_path in ${connector_paths//,/ }
      do
          full_connector_name=$(basename "$connector_path")
          connector_name=$(echo "$full_connector_name" | cut -d'-' -f2-)

          connectors=(
          "$connector_name"
          )

          output_format="\"ğŸ”¢ v\" + .version + \" - ğŸ“… release date: \" + .release_date"

          curl -s -S 'https://api.hub.confluent.io/api/plugins?per_page=100000' | jq '. | sort_by(.release_date) | reverse | .' > /tmp/allmanis.json

          connectors_string=""
          delim=""
          for conn in "${connectors[@]}"; do
              connectors_string="$connectors_string$delim\"$conn\""
              delim=","
          done

          latest=$(jq '.[] | select(IN(.name; '"${connectors_string}"')) | '"${output_format}"'' /tmp/allmanis.json)

          rm /tmp/allmanis.json

          DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
          dir1=$(echo ${DIR_CLI%/*})
          root_folder=$(echo ${dir1%/*})

          manifest_file="$root_folder/confluent-hub/$full_connector_name/manifest.json"
          if [ -f $manifest_file ]
          then
              version=$(cat $manifest_file | jq -r '.version')
              release_date=$(cat $manifest_file | jq -r '.release_date')
          else
              logerror "file $manifest_file does not exist"
              exit 1
          fi

          current="\"ğŸ”¢ v$version - ğŸ“… release date: $release_date\""
          if [ "$current" == "$latest" ]
          then
              log "ğŸ‘» Version currently used for $full_connector_name is latest"
              echo "$current"
          else
              log "ğŸ—¯ï¸ Version currently used for $full_connector_name is not latest"
              log "Current"
              echo "$current"
              log "Latest on Hub"
              echo "$latest"
          fi

      done
  fi
}

# :command.function
playground_connector_restart_command() {
  # src/connector_restart_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  connector="${args[--connector]}"

  if [[ ! -n "$connector" ]]
  then
      log "âœ¨ --connector flag was not provided, applying command to all connectors"
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          logerror "ğŸ’¤ No connector is running !"
          exit 1
      fi
  fi

  tag=$(docker ps --format '{{.Image}}' | egrep 'confluentinc/cp-.*-connect-base:' | awk -F':' '{print $2}')
  if [ $? != 0 ] || [ "$tag" == "" ]
  then
      logerror "Could not find current CP version from docker ps"
      exit 1
  fi

  items=($connector)
  for connector in ${items[@]}
  do
      log "ğŸ”„ Restarting connector $connector"
      if ! version_gt $tag "6.9.9"
      then
          task_ids=$(curl $security -s -X GET "$connect_url/connectors/$connector/tasks" | jq -r '.[].id.task')

          for task_id in $task_ids
          do
              log "ğŸ¤¹â€â™‚ï¸ Restart task $task_id"
              curl $security -s -X POST -H "Content-Type: application/json" "$connect_url/connectors/$connector/tasks/$task_id/restart"
          done
      else
          curl $security -s -X POST -H "Content-Type: application/json" "$connect_url/connectors/$connector/restart?includeTasks=true&onlyFailed=false" | jq .
      fi
  done
  sleep 3
  playground connector status --connector $connector
}

# :command.function
playground_connector_resume_command() {
  # src/connector_resume_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  connector="${args[--connector]}"

  if [[ ! -n "$connector" ]]
  then
      log "âœ¨ --connector flag was not provided, applying command to all connectors"
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          logerror "ğŸ’¤ No connector is running !"
          exit 1
      fi
  fi

  items=($connector)
  for connector in ${items[@]}
  do
      log "â¯ï¸ Resuming connector $connector"
      curl $security -s -X PUT -H "Content-Type: application/json" "$connect_url/connectors/$connector/resume"  | jq .

      sleep 1
      playground connector status --connector $connector
  done
}

# :command.function
playground_connector_delete_command() {
  # src/connector_delete_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  connector="${args[--connector]}"

  if [[ ! -n "$connector" ]]
  then
      logwarn "--connector flag was not provided, applying command to all connectors"
      check_if_continue
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          logerror "ğŸ’¤ No connector is running !"
          exit 1
      fi
  fi

  items=($connector)
  for connector in ${items[@]}
  do
      log "âŒ Deleting connector $connector"
      curl $security -s -X DELETE "$connect_url/connectors/$connector" | jq .
  done
}

# :command.function
playground_connector_show_lag_command() {
  # src/connector_show_lag_command.sh
  connector="${args[--connector]}"
  wait_for_zero_lag="${args[--wait-for-zero-lag]}"

  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  if [[ ! -n "$connector" ]]
  then
      log "âœ¨ --connector flag was not provided, applying command to all connectors"
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          logerror "ğŸ’¤ No connector is running !"
          exit 1
      fi
  fi

  ret=$(get_security_broker "--command-config")

  container=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  items=($connector)
  for connector in ${items[@]}
  do
    type=$(curl -s $security "$connect_url/connectors/$connector/status" | jq -r '.type')
    if [ "$type" != "sink" ]
    then
      logwarn "â­ï¸ Skipping $type connector $connector, it must be a sink to show the lag"
      continue

    fi

    if [[ -n "$wait_for_zero_lag" ]]
    then
      CHECK_INTERVAL=5
      SECONDS=0
      while true
      do
        lag_output=$(docker exec $container kafka-consumer-groups --bootstrap-server broker:9092 --group connect-$connector --describe $security)

        set +e
        echo "$lag_output" | awk -F" " '{ print $6 }' | grep "-"
        if [ $? -eq 0 ]
        then
          logwarn "ğŸ¢ consumer lag for connector $connector is not set"
          echo "$lag_output" | awk -F" " '{ print $3,$4,$5,$6 }'
          sleep $CHECK_INTERVAL
        else
          total_lag=$(echo "$lag_output" | grep -v "PARTITION" | awk -F" " '{sum+=$6;} END{print sum;}')
          if [ $total_lag -ne 0 ]
          then
              log "ğŸ¢ consumer lag for connector $connector is $total_lag"
              echo "$lag_output" | awk -F" " '{ print $3,$4,$5,$6 }'
              sleep $CHECK_INTERVAL
          else
              ELAPSED="took: $((($SECONDS / 60) % 60))min $(($SECONDS % 60))sec"
              log "ğŸ consumer lag for connector $connector is 0 ! $ELAPSED"
              break
          fi
        fi
      done
    else
      log "ğŸ¢ Show lag for sink connector $connector"
      docker exec $container kafka-consumer-groups --bootstrap-server broker:9092 --group connect-$connector --describe $security
    fi
  done
}

# :command.function
playground_connector_show_config_command() {
  # src/connector_show_config_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  connector="${args[--connector]}"

  if [[ ! -n "$connector" ]]
  then
      log "âœ¨ --connector flag was not provided, applying command to all connectors"
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          logerror "ğŸ’¤ No connector is running !"
          exit 1
      fi
  fi

  items=($connector)
  for connector in ${items[@]}
  do
      log "ğŸ§° Current config for connector $connector"
      json_config=$(curl $security -s -X GET -H "Content-Type: application/json" "$connect_url/connectors/$connector/config")
      echo "playground connector create-or-update --connector $connector << EOF"
      echo "$json_config" | jq -S . | sed 's/\$/\\$/g'
      echo "EOF"
  done
}

# :command.function
playground_connector_show_config_parameters_command() {
  # src/connector_show_config_parameters_command.sh
  open="${args[--open]}"
  force_refresh="${args[--force-refresh]}"
  only_show_file_path="${args[--only-show-file-path]}"

  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  connector="${args[--connector]}"

  if [[ ! -n "$connector" ]]
  then
      log "âœ¨ --connector flag was not provided, applying command to all connectors"
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          logerror "ğŸ’¤ No connector is running !"
          exit 1
      fi
  fi

  items=($connector)
  for connector in ${items[@]}
  do
      json_config=$(curl $security -s -X GET -H "Content-Type: application/json" "$connect_url/connectors/$connector/config")
      connector_class=$(echo "$json_config" | jq -r '."connector.class"')
      version="unknown"
      set +e
      curl_output=$(curl $security -s -X GET \
          -H "Content-Type: application/json" \
          $connect_url/connector-plugins/)
      ret=$?
      set -e
      if [ $ret -eq 0 ]
      then
          current_group=""
          rows=()
          for row in $(echo "$curl_output" | jq -r '.[] | @base64'); do
              _jq() {
                  echo ${row} | base64 --decode | jq -r ${1}
              }

              class=$(_jq '.class')

              if [ "$class" != "$connector_class" ]
              then
                  version=$(_jq '.version')
              fi
          done
      else
          logerror "âŒ curl request failed with error code $ret!"
          exit 1
      fi

      filename="/tmp/config-$connector_class-$version.txt"

      class=$(echo $connector_class | rev | cut -d '.' -f 1 | rev)
      log "ğŸ”© getting parameters for connector $connector ($class) and version $version"

      if [[ -n "$force_refresh" ]]
      then
          if [ -f $filename ]
          then
              rm -f $filename
          fi
      fi
      if [ ! -f $filename ]
      then
          set +e
          curl_output=$(curl $security -s -X PUT \
              -H "Content-Type: application/json" \
              --data "$json_config" \
              $connect_url/connector-plugins/$connector_class/config/validate)
          ret=$?
          set -e
          if [ $ret -eq 0 ]
          then
              error_code=$(echo "$curl_output" | jq -r .error_code)
              if [ "$error_code" != "null" ]
              then
                  message=$(echo "$curl_output" | jq -r .message)
                  logerror "Command failed with error code $error_code"
                  logerror "$message"
              else
                  if ! echo "$curl_output" | jq -e .  > /dev/null 2>&1
                  then
                      set +e
                      json_file=/tmp/json
                      echo "$curl_output" > $json_file
                      jq_output=$(jq . "$json_file" 2>&1)
                      error_line=$(echo "$jq_output" | grep -oE 'parse error.*at line [0-9]+' | grep -oE '[0-9]+')

                      if [[ -n "$error_line" ]]; then
                          logerror "âŒ Invalid JSON at line $error_line"
                      fi
                      set -e

                      if [[ $(type -f bat 2>&1) =~ "not found" ]]
                      then
                          cat -n $json_file
                      else
                          bat $json_file --highlight-line $error_line
                      fi

                      exit 1
                  fi

                  current_group=""
                  rows=()
                  for row in $(echo "$curl_output" | jq -r '.configs[] | @base64'); do
                      _jq() {
                          echo ${row} | base64 --decode | jq -r ${1}
                      }

                      group=$(_jq '.definition.group')
                      if [[ "$group" == "Common" || "$group" == "Transforms" || "$group" == "Error Handling" || "$group" == "Topic Creation" || "$group" == "offsets.topic" || "$group" == "Exactly Once Support" || "$group" == "Predicates" || "$group" == "Confluent Licensing" ]] ; then
                          continue
                      fi

                      if [ "$group" != "$current_group" ]
                      then
                          echo -e "==========================" >> $filename
                          echo -e "$group"                     >> $filename
                          echo -e "==========================" >> $filename
                          current_group=$group
                      fi

                      param=$(_jq '.definition.name')
                      default=$(_jq '.definition.default_value')
                      type=$(_jq '.definition.type')
                      required=$(_jq '.definition.required')
                      importance=$(_jq '.definition.importance')
                      description=$(_jq '.definition.documentation')

                      echo -e "ğŸ”˜ $param" >> $filename
                      echo -e "" >> $filename
                      echo -e "$description" >> $filename
                      echo -e "" >> $filename
                      echo -e "\t - Type: $type" >> $filename
                      echo -e "\t - Default: $default" >> $filename
                      echo -e "\t - Importance: $importance" >> $filename
                      echo -e "\t - Required: $required" >> $filename
                      echo -e "" >> $filename
                  done
              fi
          else
              logerror "âŒ curl request failed with error code $ret!"
              exit 1
          fi
      fi

      if [[ -n "$open" ]]
      then
          if config_has_key "editor"
          then
              editor=$(config_get "editor")
          log "ğŸ“– Opening ${filename} using configured editor $editor"
          $editor $filename
          else
              if [[ $(type code 2>&1) =~ "not found" ]]
              then
              logerror "Could not determine an editor to use as default code is not found - you can change editor by updating config.ini"
              exit 1
              else
              log "ğŸ“– Opening ${filename} with code (default) - you can change editor by updating config.ini"
              code $filename
              fi
          fi
      else
          if [[ -n "$only_show_file_path" ]]
          then
              echo "$filename"
          else
              cat $filename
          fi
      fi
  done
}

# :command.function
playground_connector_log_level_command() {
  # src/connector_log_level_command.sh
  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  level="${args[--level]}"
  connector="${args[--connector]}"

  if [[ ! -n "$connector" ]]
  then
      log "âœ¨ --connector flag was not provided, applying command to all connectors"
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          logerror "ğŸ’¤ No connector is running !"
          exit 1
      fi
  fi

  log "ğŸ”° also setting io.confluent.kafka.schemaregistry.client.rest.RestService (to see schema registry rest requests) to $level"
  playground debug log-level set -p "io.confluent.kafka.schemaregistry.client.rest.RestService" -l $level
  log "ğŸ”— also setting org.apache.kafka.connect.runtime.TransformationChain (to see records before and after SMTs) to $level"
  playground debug log-level set -p "org.apache.kafka.connect.runtime.TransformationChain" -l $level

  items=($connector)
  for connector in ${items[@]}
  do
      tmp=$(curl -s $security "$connect_url/connectors/$connector" | jq -r '.config."connector.class"')
      package="${tmp%.*}"
      # log "ğŸ§¬ Set log level for connector $connector to $level"
      playground debug log-level set -p "$package" -l $level
  done
}

# :command.function
playground_connector_create_or_update_command() {
  # src/connector_create_or_update_command.sh
  json=${args[json]}
  level=${args[--level]}
  package=${args[--package]}

  if [ "$json" = "-" ]
  then
      # stdin
      json_content=$(cat "$json")
  else
      json_content=$json
  fi

  json_file=/tmp/json
  trap 'rm -f /tmp/json' EXIT
  echo "$json_content" > $json_file

  # JSON is invalid
  if ! echo "$json_content" | jq -e .  > /dev/null 2>&1
  then
      set +e
      jq_output=$(jq . "$json_file" 2>&1)
      error_line=$(echo "$jq_output" | grep -oE 'parse error.*at line [0-9]+' | grep -oE '[0-9]+')

      if [[ -n "$error_line" ]]; then
          logerror "âŒ Invalid JSON at line $error_line"
      fi
      set -e

      if [[ $(type -f bat 2>&1) =~ "not found" ]]
      then
          cat -n $json_file
      else
          bat $json_file --highlight-line $error_line
      fi

      exit 1
  fi

  ret=$(get_connect_url_and_security)

  connect_url=$(echo "$ret" | cut -d "@" -f 1)
  security=$(echo "$ret" | cut -d "@" -f 2)

  connector="${args[--connector]}"

  is_create=1
  connectors=$(playground get-connector-list)
  items=($connectors)
  for con in ${items[@]}
  do
      if [[ "$con" == "$connector" ]]
      then
          is_create=0
      fi
  done

  if [ $is_create == 1 ]
  then
      log "ğŸ› ï¸ Creating connector $connector"
  else
      log "ğŸ”„ Updating connector $connector"
  fi

  set +e
  curl_output=$(curl $security -s -X PUT \
       -H "Content-Type: application/json" \
       --data "$json_content" \
       $connect_url/connectors/$connector/config)
  ret=$?
  set -e
  if [ $ret -eq 0 ]
  then
      error_code=$(echo "$curl_output" | jq -r .error_code)
      if [ "$error_code" != "null" ]
      then
          message=$(echo "$curl_output" | jq -r .message)
          logerror "Command failed with error code $error_code"
          logerror "$message"
          exit 1
      else
          if [[ -n "$level" ]]
          then
              if [[ -n "$package" ]]
              then
                  playground debug log-level set --level $level --package $package
              else
                  playground connector log-level --connector $connector --level $level
              fi
          fi
          if [ $is_create == 1 ]
          then
              log "âœ… Connector $connector was successfully created"
              if [ -z "$GITHUB_RUN_NUMBER" ]
              then
                  log "ğŸ’ˆ Configuration is "
                  echo "$json_content" | jq -S .
              fi
              log "ğŸ¥ Waiting a few seconds to get new status"
          else
              log "âœ… Connector $connector was successfully updated"
              if [ -z "$GITHUB_RUN_NUMBER" ]
              then
                  log "ğŸ’ˆ Configuration is "
                  echo "$json_content" | jq -S .
              fi
              log "ğŸ¥ Waiting a few seconds to get new status"
          fi
          sleep 8
          playground connector status --connector $connector
      fi
  else
      logerror "âŒ curl request failed with error code $ret!"
      exit 1
  fi
}

# :command.parse_requirements
parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --version | -v)
        version_command
        exit
        ;;

      --help | -h)
        long_usage=yes
        playground_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v docker >/dev/null 2>&1; then
    deps['docker']="$(command -v docker | head -n1)"
  else
    printf "missing dependency: docker\n" >&2
    printf "%s\n" "visit https://docs.docker.com/get-docker to install" >&2
    exit 1
  fi

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    help)
      action="help"
      shift
      playground_help_parse_requirements "$@"
      shift $#
      ;;

    status)
      action="status"
      shift
      playground_status_parse_requirements "$@"
      shift $#
      ;;

    get-connector-list)
      action="get-connector-list"
      shift
      playground_get_connector_list_parse_requirements "$@"
      shift $#
      ;;

    get-ccloud-connector-list)
      action="get-ccloud-connector-list"
      shift
      playground_get_ccloud_connector_list_parse_requirements "$@"
      shift $#
      ;;

    get-kafka-region-list)
      action="get-kafka-region-list"
      shift
      playground_get_kafka_region_list_parse_requirements "$@"
      shift $#
      ;;

    get-topic-list)
      action="get-topic-list"
      shift
      playground_get_topic_list_parse_requirements "$@"
      shift $#
      ;;

    get-subject-list)
      action="get-subject-list"
      shift
      playground_get_subject_list_parse_requirements "$@"
      shift $#
      ;;

    get-examples-list-with-fzf)
      action="get-examples-list-with-fzf"
      shift
      playground_get_examples_list_with_fzf_parse_requirements "$@"
      shift $#
      ;;

    get-zip-or-jar-with-fzf)
      action="get-zip-or-jar-with-fzf"
      shift
      playground_get_zip_or_jar_with_fzf_parse_requirements "$@"
      shift $#
      ;;

    get-any-file-with-fzf)
      action="get-any-file-with-fzf"
      shift
      playground_get_any_file_with_fzf_parse_requirements "$@"
      shift $#
      ;;

    get-playground-repro-export-with-fzf)
      action="get-playground-repro-export-with-fzf"
      shift
      playground_get_playground_repro_export_with_fzf_parse_requirements "$@"
      shift $#
      ;;

    get-predefined-schemas)
      action="get-predefined-schemas"
      shift
      playground_get_predefined_schemas_parse_requirements "$@"
      shift $#
      ;;

    bashly-reload)
      action="bashly-reload"
      shift
      playground_bashly_reload_parse_requirements "$@"
      shift $#
      ;;

    run)
      action="run"
      shift
      playground_run_parse_requirements "$@"
      shift $#
      ;;

    re-run)
      action="re-run"
      shift
      playground_re_run_parse_requirements "$@"
      shift $#
      ;;

    run-ccloud)
      action="run-ccloud"
      shift
      playground_run_ccloud_parse_requirements "$@"
      shift $#
      ;;

    update-version)
      action="update-version"
      shift
      playground_update_version_parse_requirements "$@"
      shift $#
      ;;

    open)
      action="open"
      shift
      playground_open_parse_requirements "$@"
      shift $#
      ;;

    stop)
      action="stop"
      shift
      playground_stop_parse_requirements "$@"
      shift $#
      ;;

    open-docs)
      action="open-docs"
      shift
      playground_open_docs_parse_requirements "$@"
      shift $#
      ;;

    repro)
      action="repro"
      shift
      playground_repro_parse_requirements "$@"
      shift $#
      ;;

    get-docker-compose)
      action="get-docker-compose"
      shift
      playground_get_docker_compose_parse_requirements "$@"
      shift $#
      ;;

    get-properties)
      action="get-properties"
      shift
      playground_get_properties_parse_requirements "$@"
      shift $#
      ;;

    schema)
      action="schema"
      shift
      playground_schema_parse_requirements "$@"
      shift $#
      ;;

    debug)
      action="debug"
      shift
      playground_debug_parse_requirements "$@"
      shift $#
      ;;

    get-jmx-metrics)
      action="get-jmx-metrics"
      shift
      playground_get_jmx_metrics_parse_requirements "$@"
      shift $#
      ;;

    container)
      action="container"
      shift
      playground_container_parse_requirements "$@"
      shift $#
      ;;

    topic)
      action="topic"
      shift
      playground_topic_parse_requirements "$@"
      shift $#
      ;;

    ccloud-connector)
      action="ccloud-connector"
      shift
      playground_ccloud_connector_parse_requirements "$@"
      shift $#
      ;;

    connector)
      action="connector"
      shift
      playground_connector_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.user_filter
  filter_error=$(filter_docker_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_help_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_help_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="help"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        if [[ -z ${args['command']+x} ]]; then

          args['command']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_status_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_status_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="status"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_connector_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_connector_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-connector-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_ccloud_connector_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_ccloud_connector_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v confluent >/dev/null 2>&1; then
    deps['confluent']="$(command -v confluent | head -n1)"
  else
    printf "missing dependency: confluent\n" >&2
    printf "%s\n" "visit https://docs.confluent.io/confluent-cli/current/overview.html to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="get-ccloud-connector-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_kafka_region_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_kafka_region_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v confluent >/dev/null 2>&1; then
    deps['confluent']="$(command -v confluent | head -n1)"
  else
    printf "missing dependency: confluent\n" >&2
    printf "%s\n" "visit https://docs.confluent.io/confluent-cli/current/overview.html to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="get-kafka-region-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_topic_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_topic_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-topic-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --skip-connect-internal-topics)

        # :flag.case_no_arg
        args['--skip-connect-internal-topics']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_subject_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_subject_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-subject-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --deleted)

        # :flag.case_no_arg
        args['--deleted']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_examples_list_with_fzf_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_examples_list_with_fzf_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-examples-list-with-fzf"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --without-repro)

        # :flag.case_no_arg
        args['--without-repro']=1
        shift
        ;;

      # :flag.case
      --sink-only)

        # :flag.case_no_arg
        args['--sink-only']=1
        shift
        ;;

      # :flag.case
      --ccloud-only)

        # :flag.case_no_arg
        args['--ccloud-only']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        if [[ -z ${args['cur']+x} ]]; then

          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_zip_or_jar_with_fzf_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_zip_or_jar_with_fzf_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-zip-or-jar-with-fzf"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --type)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--type']="$2"
          shift
          shift
        else
          printf "%s\n" "--type requires an argument: --type TYPE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        if [[ -z ${args['cur']+x} ]]; then

          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.whitelist_filter
  if [[ ${args['--type']} ]] && [[ ! ${args['--type']} =~ ^(zip|jar)$ ]]; then
    printf "%s\n" "--type must be one of: zip, jar" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_get_any_file_with_fzf_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_any_file_with_fzf_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-any-file-with-fzf"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        if [[ -z ${args['cur']+x} ]]; then

          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_playground_repro_export_with_fzf_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_playground_repro_export_with_fzf_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-playground-repro-export-with-fzf"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        if [[ -z ${args['cur']+x} ]]; then

          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_predefined_schemas_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_predefined_schemas_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-predefined-schemas"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        if [[ -z ${args['cur']+x} ]]; then

          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_bashly_reload_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_bashly_reload_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v bashly >/dev/null 2>&1; then
    deps['bashly']="$(command -v bashly | head -n1)"
  else
    printf "missing dependency: bashly\n" >&2
    printf "%s\n" "visit https://bashly.dannyb.co/installation/ to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="bashly-reload"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_run_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_run_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v fzf >/dev/null 2>&1; then
    deps['fzf']="$(command -v fzf | head -n1)"
  else
    printf "missing dependency: fzf\n" >&2
    printf "%s\n" "visit https://github.com/junegunn/fzf#installation to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="run"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --file | -f)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--file, -f FILE" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--file']="$2"
          shift
          shift
        else
          printf "%s\n" "--file requires an argument: --file, -f FILE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --open | -o)

        # :flag.case_no_arg
        args['--open']=1
        shift
        ;;

      # :flag.case
      --tag)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_minimal_cp_version "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--tag TAG" "$(validate_minimal_cp_version "$2")" >&2
            exit 1
          fi

          args['--tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--tag requires an argument: --tag TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-tag)
        # :flag.conflicts
        if [[ -n "${args['--connector-zip']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-zip" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector-tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-tag requires an argument: --connector-tag CONNECTOR_TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-zip)
        # :flag.conflicts
        if [[ -n "${args['--connector-tag']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-tag" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--connector-zip CONNECTOR_ZIP" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--connector-zip']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-zip requires an argument: --connector-zip CONNECTOR_ZIP" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-jar)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--connector-jar CONNECTOR_JAR" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--connector-jar']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-jar requires an argument: --connector-jar CONNECTOR_JAR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --enable-ksqldb)

        # :flag.case_no_arg
        args['--enable-ksqldb']=1
        shift
        ;;

      # :flag.case
      --enable-control-center)

        # :flag.case_no_arg
        args['--enable-control-center']=1
        shift
        ;;

      # :flag.case
      --enable-conduktor)

        # :flag.case_no_arg
        args['--enable-conduktor']=1
        shift
        ;;

      # :flag.case
      --enable-multiple-brokers)

        # :flag.case_no_arg
        args['--enable-multiple-brokers']=1
        shift
        ;;

      # :flag.case
      --enable-multiple-connect-workers)

        # :flag.case_no_arg
        args['--enable-multiple-connect-workers']=1
        shift
        ;;

      # :flag.case
      --enable-jmx-grafana)

        # :flag.case_no_arg
        args['--enable-jmx-grafana']=1
        shift
        ;;

      # :flag.case
      --enable-kcat)

        # :flag.case_no_arg
        args['--enable-kcat']=1
        shift
        ;;

      # :flag.case
      --enable-sr-maven-plugin-app)

        # :flag.case_no_arg
        args['--enable-sr-maven-plugin-app']=1
        shift
        ;;

      # :flag.case
      --enable-sql-datagen)

        # :flag.case_no_arg
        args['--enable-sql-datagen']=1
        shift
        ;;

      --)
        shift
        other_args+=("$@")
        break
        ;;

      -?*)
        other_args+=("$1")
        shift
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_catch_all
        other_args+=("$1")
        shift

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--file']+x} ]]; then
    printf "missing required flag: --file, -f FILE\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_re_run_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_re_run_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v fzf >/dev/null 2>&1; then
    deps['fzf']="$(command -v fzf | head -n1)"
  else
    printf "missing dependency: fzf\n" >&2
    printf "%s\n" "visit https://github.com/junegunn/fzf#installation to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="re-run"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --clear)

        # :flag.case_no_arg
        args['--clear']=1
        shift
        ;;

      # :flag.case
      --tag)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_minimal_cp_version "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--tag TAG" "$(validate_minimal_cp_version "$2")" >&2
            exit 1
          fi

          args['--tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--tag requires an argument: --tag TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-tag)
        # :flag.conflicts
        if [[ -n "${args['--connector-zip']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-zip" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector-tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-tag requires an argument: --connector-tag CONNECTOR_TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-zip)
        # :flag.conflicts
        if [[ -n "${args['--connector-tag']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-tag" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--connector-zip CONNECTOR_ZIP" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--connector-zip']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-zip requires an argument: --connector-zip CONNECTOR_ZIP" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-jar)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--connector-jar CONNECTOR_JAR" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--connector-jar']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-jar requires an argument: --connector-jar CONNECTOR_JAR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --enable-ksqldb)

        # :flag.case_no_arg
        args['--enable-ksqldb']=1
        shift
        ;;

      # :flag.case
      --enable-control-center)

        # :flag.case_no_arg
        args['--enable-control-center']=1
        shift
        ;;

      # :flag.case
      --enable-conduktor)

        # :flag.case_no_arg
        args['--enable-conduktor']=1
        shift
        ;;

      # :flag.case
      --enable-multiple-brokers)

        # :flag.case_no_arg
        args['--enable-multiple-brokers']=1
        shift
        ;;

      # :flag.case
      --enable-multiple-connect-workers)

        # :flag.case_no_arg
        args['--enable-multiple-connect-workers']=1
        shift
        ;;

      # :flag.case
      --enable-jmx-grafana)

        # :flag.case_no_arg
        args['--enable-jmx-grafana']=1
        shift
        ;;

      # :flag.case
      --enable-kcat)

        # :flag.case_no_arg
        args['--enable-kcat']=1
        shift
        ;;

      # :flag.case
      --enable-sr-maven-plugin-app)

        # :flag.case_no_arg
        args['--enable-sr-maven-plugin-app']=1
        shift
        ;;

      # :flag.case
      --enable-sql-datagen)

        # :flag.case_no_arg
        args['--enable-sql-datagen']=1
        shift
        ;;

      --)
        shift
        other_args+=("$@")
        break
        ;;

      -?*)
        other_args+=("$1")
        shift
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_catch_all
        other_args+=("$1")
        shift

        ;;

    esac
  done

}

# :command.parse_requirements
playground_run_ccloud_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_run_ccloud_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v fzf >/dev/null 2>&1; then
    deps['fzf']="$(command -v fzf | head -n1)"
  else
    printf "missing dependency: fzf\n" >&2
    printf "%s\n" "visit https://github.com/junegunn/fzf#installation to install" >&2
    exit 1
  fi

  if command -v confluent >/dev/null 2>&1; then
    deps['confluent']="$(command -v confluent | head -n1)"
  else
    printf "missing dependency: confluent\n" >&2
    printf "%s\n" "visit https://docs.confluent.io/confluent-cli/current/overview.html to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="run-ccloud"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --file | -f)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--file, -f FILE" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--file']="$2"
          shift
          shift
        else
          printf "%s\n" "--file requires an argument: --file, -f FILE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --open | -o)

        # :flag.case_no_arg
        args['--open']=1
        shift
        ;;

      # :flag.case
      --tag)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_minimal_cp_version "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--tag TAG" "$(validate_minimal_cp_version "$2")" >&2
            exit 1
          fi

          args['--tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--tag requires an argument: --tag TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-tag)
        # :flag.conflicts
        if [[ -n "${args['--connector-zip']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-zip" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector-tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-tag requires an argument: --connector-tag CONNECTOR_TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-zip)
        # :flag.conflicts
        if [[ -n "${args['--connector-tag']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-tag" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--connector-zip CONNECTOR_ZIP" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--connector-zip']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-zip requires an argument: --connector-zip CONNECTOR_ZIP" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-jar)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--connector-jar CONNECTOR_JAR" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--connector-jar']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-jar requires an argument: --connector-jar CONNECTOR_JAR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --enable-control-center)

        # :flag.case_no_arg
        args['--enable-control-center']=1
        shift
        ;;

      # :flag.case
      --enable-conduktor)

        # :flag.case_no_arg
        args['--enable-conduktor']=1
        shift
        ;;

      # :flag.case
      --enable-kcat)

        # :flag.case_no_arg
        args['--enable-kcat']=1
        shift
        ;;

      # :flag.case
      --cluster-cloud)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--cluster-cloud']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-cloud requires an argument: --cluster-cloud CLUSTER-CLOUD" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-type)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--cluster-type']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-type requires an argument: --cluster-type CLUSTER-TYPE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-region)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--cluster-region']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-region requires an argument: --cluster-region CLUSTER-REGION" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-environment)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--cluster-environment CLUSTER-ENVIRONMENT" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--cluster-environment']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-environment requires an argument: --cluster-environment CLUSTER-ENVIRONMENT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-name)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--cluster-name CLUSTER-NAME" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--cluster-name']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-name requires an argument: --cluster-name CLUSTER-NAME" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-creds)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--cluster-creds CLUSTER-CREDS" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--cluster-creds']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-creds requires an argument: --cluster-creds CLUSTER-CREDS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-schema-registry-creds)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--cluster-schema-registry-creds CLUSTER-SCHEMA-REGISTRY-CREDS" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--cluster-schema-registry-creds']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-schema-registry-creds requires an argument: --cluster-schema-registry-creds CLUSTER-SCHEMA-REGISTRY-CREDS" >&2
          exit 1
        fi
        ;;

      --)
        shift
        other_args+=("$@")
        break
        ;;

      -?*)
        other_args+=("$1")
        shift
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_catch_all
        other_args+=("$1")
        shift

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--file']+x} ]]; then
    printf "missing required flag: --file, -f FILE\n" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--cluster-cloud']} ]] && [[ ! ${args['--cluster-cloud']} =~ ^(aws|gcp|azure)$ ]]; then
    printf "%s\n" "--cluster-cloud must be one of: aws, gcp, azure" >&2
    exit 1
  fi
  if [[ ${args['--cluster-type']} ]] && [[ ! ${args['--cluster-type']} =~ ^(basic|standard|dedicated)$ ]]; then
    printf "%s\n" "--cluster-type must be one of: basic, standard, dedicated" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_update_version_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_update_version_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="update-version"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --tag)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_minimal_cp_version "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--tag TAG" "$(validate_minimal_cp_version "$2")" >&2
            exit 1
          fi

          args['--tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--tag requires an argument: --tag TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-tag)
        # :flag.conflicts
        if [[ -n "${args['--connector-zip']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-zip" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector-tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-tag requires an argument: --connector-tag CONNECTOR_TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-zip)
        # :flag.conflicts
        if [[ -n "${args['--connector-tag']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-tag" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--connector-zip CONNECTOR_ZIP" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--connector-zip']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-zip requires an argument: --connector-zip CONNECTOR_ZIP" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-jar)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--connector-jar CONNECTOR_JAR" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--connector-jar']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-jar requires an argument: --connector-jar CONNECTOR_JAR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_open_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_open_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v fzf >/dev/null 2>&1; then
    deps['fzf']="$(command -v fzf | head -n1)"
  else
    printf "missing dependency: fzf\n" >&2
    printf "%s\n" "visit https://github.com/junegunn/fzf#installation to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="open"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --file | -f)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--file, -f FILE" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--file']="$2"
          shift
          shift
        else
          printf "%s\n" "--file requires an argument: --file, -f FILE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_stop_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_stop_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="stop"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_open_docs_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_open_docs_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="open-docs"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --only-show-url)

        # :flag.case_no_arg
        args['--only-show-url']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_repro_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_repro_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.environment_variables_filter
  # :command.environment_variables_default
  export OUTPUT_FOLDER="${OUTPUT_FOLDER:-reproduction-models}"

  # :command.dependencies_filter
  if command -v fzf >/dev/null 2>&1; then
    deps['fzf']="$(command -v fzf | head -n1)"
  else
    printf "missing dependency: fzf\n" >&2
    printf "%s\n" "visit https://github.com/junegunn/fzf#installation to install" >&2
    exit 1
  fi

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    export)
      action="export"
      shift
      playground_repro_export_parse_requirements "$@"
      shift $#
      ;;

    import)
      action="import"
      shift
      playground_repro_import_parse_requirements "$@"
      shift $#
      ;;

    bootstrap)
      action="bootstrap"
      shift
      playground_repro_bootstrap_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_repro_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_repro_export_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_repro_export_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v git >/dev/null 2>&1; then
    deps['git']="$(command -v git | head -n1)"
  else
    printf "missing dependency: git\n" >&2
    printf "%s\n" "visit https://git-scm.com/downloads to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="repro export"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --all)

        # :flag.case_no_arg
        args['--all']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_repro_import_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_repro_import_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="repro import"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --file | -f)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--file, -f FILE" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--file']="$2"
          shift
          shift
        else
          printf "%s\n" "--file requires an argument: --file, -f FILE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_repro_bootstrap_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_repro_bootstrap_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="repro bootstrap"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --tag)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_minimal_cp_version "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--tag TAG" "$(validate_minimal_cp_version "$2")" >&2
            exit 1
          fi

          args['--tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--tag requires an argument: --tag TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-tag)
        # :flag.conflicts
        if [[ -n "${args['--connector-zip']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-zip" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector-tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-tag requires an argument: --connector-tag CONNECTOR_TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-zip)
        # :flag.conflicts
        if [[ -n "${args['--connector-tag']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-tag" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--connector-zip CONNECTOR_ZIP" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--connector-zip']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-zip requires an argument: --connector-zip CONNECTOR_ZIP" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-jar)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--connector-jar CONNECTOR_JAR" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--connector-jar']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-jar requires an argument: --connector-jar CONNECTOR_JAR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --enable-ksqldb)

        # :flag.case_no_arg
        args['--enable-ksqldb']=1
        shift
        ;;

      # :flag.case
      --enable-control-center)

        # :flag.case_no_arg
        args['--enable-control-center']=1
        shift
        ;;

      # :flag.case
      --enable-conduktor)

        # :flag.case_no_arg
        args['--enable-conduktor']=1
        shift
        ;;

      # :flag.case
      --enable-multiple-brokers)

        # :flag.case_no_arg
        args['--enable-multiple-brokers']=1
        shift
        ;;

      # :flag.case
      --enable-multiple-connect-workers)

        # :flag.case_no_arg
        args['--enable-multiple-connect-workers']=1
        shift
        ;;

      # :flag.case
      --enable-jmx-grafana)

        # :flag.case_no_arg
        args['--enable-jmx-grafana']=1
        shift
        ;;

      # :flag.case
      --enable-kcat)

        # :flag.case_no_arg
        args['--enable-kcat']=1
        shift
        ;;

      # :flag.case
      --enable-sr-maven-plugin-app)

        # :flag.case_no_arg
        args['--enable-sr-maven-plugin-app']=1
        shift
        ;;

      # :flag.case
      --enable-sql-datagen)

        # :flag.case_no_arg
        args['--enable-sql-datagen']=1
        shift
        ;;

      # :flag.case
      --cluster-type)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--cluster-type']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-type requires an argument: --cluster-type CLUSTER-TYPE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-region)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--cluster-region']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-region requires an argument: --cluster-region CLUSTER-REGION" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-environment)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--cluster-environment CLUSTER-ENVIRONMENT" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--cluster-environment']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-environment requires an argument: --cluster-environment CLUSTER-ENVIRONMENT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-name)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--cluster-name CLUSTER-NAME" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--cluster-name']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-name requires an argument: --cluster-name CLUSTER-NAME" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-creds)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--cluster-creds CLUSTER-CREDS" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--cluster-creds']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-creds requires an argument: --cluster-creds CLUSTER-CREDS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-schema-registry-creds)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--cluster-schema-registry-creds CLUSTER-SCHEMA-REGISTRY-CREDS" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--cluster-schema-registry-creds']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-schema-registry-creds requires an argument: --cluster-schema-registry-creds CLUSTER-SCHEMA-REGISTRY-CREDS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --file | -f)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--file, -f FILE" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--file']="$2"
          shift
          shift
        else
          printf "%s\n" "--file requires an argument: --file, -f FILE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --description | -d)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--description, -d DESCRIPTION" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--description']="$2"
          shift
          shift
        else
          printf "%s\n" "--description requires an argument: --description, -d DESCRIPTION" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --producer | -p)
        # :flag.conflicts
        if [[ -n "${args['--pipeline']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--pipeline" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--producer']="$2"
          shift
          shift
        else
          printf "%s\n" "--producer requires an argument: --producer, -p PRODUCER-TYPE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --nb-producers | -n)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_integer "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--nb-producers, -n NB-PRODUCERS" "$(validate_integer "$2")" >&2
            exit 1
          fi

          args['--nb-producers']="$2"
          shift
          shift
        else
          printf "%s\n" "--nb-producers requires an argument: --nb-producers, -n NB-PRODUCERS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --producer-schema-key)

        # :flag.case_no_arg
        args['--producer-schema-key']=1
        shift
        ;;

      # :flag.case
      --producer-schema-value)

        # :flag.case_no_arg
        args['--producer-schema-value']=1
        shift
        ;;

      # :flag.case
      --custom-smt)

        # :flag.case_no_arg
        args['--custom-smt']=1
        shift
        ;;

      # :flag.case
      --pipeline)
        # :flag.conflicts
        if [[ -n "${args['--producer']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--producer" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_file_exists_with_trick "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--pipeline SINK_FILE" "$(validate_file_exists_with_trick "$2")" >&2
            exit 1
          fi

          args['--pipeline']="$2"
          shift
          shift
        else
          printf "%s\n" "--pipeline requires an argument: --pipeline SINK_FILE" >&2
          exit 1
        fi
        ;;

      --)
        shift
        other_args+=("$@")
        break
        ;;

      -?*)
        other_args+=("$1")
        shift
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_catch_all
        other_args+=("$1")
        shift

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--file']+x} ]]; then
    printf "missing required flag: --file, -f FILE\n" >&2
    exit 1
  fi
  if [[ -z ${args['--description']+x} ]]; then
    printf "missing required flag: --description, -d DESCRIPTION\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--producer']:-} ]] || args['--producer']="none"
  [[ -n ${args['--nb-producers']:-} ]] || args['--nb-producers']=""

  # :command.whitelist_filter
  if [[ ${args['--cluster-type']} ]] && [[ ! ${args['--cluster-type']} =~ ^(basic|standard|dedicated)$ ]]; then
    printf "%s\n" "--cluster-type must be one of: basic, standard, dedicated" >&2
    exit 1
  fi
  if [[ ${args['--producer']} ]] && [[ ! ${args['--producer']} =~ ^(none|avro|avro-with-key|protobuf|protobuf-with-key|json-schema|json-schema-with-key)$ ]]; then
    printf "%s\n" "--producer must be one of: none, avro, avro-with-key, protobuf, protobuf-with-key, json-schema, json-schema-with-key" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_get_docker_compose_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_docker_compose_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-docker-compose"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_properties_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_properties_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-properties"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_schema_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_schema_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    get)
      action="get"
      shift
      playground_schema_get_parse_requirements "$@"
      shift $#
      ;;

    register)
      action="register"
      shift
      playground_schema_register_parse_requirements "$@"
      shift $#
      ;;

    get-compatibility)
      action="get-compatibility"
      shift
      playground_schema_get_compatibility_parse_requirements "$@"
      shift $#
      ;;

    set-compatibility)
      action="set-compatibility"
      shift
      playground_schema_set_compatibility_parse_requirements "$@"
      shift $#
      ;;

    get-mode)
      action="get-mode"
      shift
      playground_schema_get_mode_parse_requirements "$@"
      shift $#
      ;;

    set-mode)
      action="set-mode"
      shift
      playground_schema_set_mode_parse_requirements "$@"
      shift $#
      ;;

    delete)
      action="delete"
      shift
      playground_schema_delete_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_schema_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_schema_get_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_schema_get_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="schema get"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --subject)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--subject requires an argument: --subject SUBJECT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --deleted)

        # :flag.case_no_arg
        args['--deleted']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_schema_register_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_schema_register_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="schema register"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --subject)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--subject requires an argument: --subject SUBJECT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --input)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--input']="$2"
          shift
          shift
        else
          printf "%s\n" "--input requires an argument: --input INPUT" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--subject']+x} ]]; then
    printf "missing required flag: --subject SUBJECT\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--input']:-} ]] || args['--input']="-"

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_schema_get_compatibility_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_schema_get_compatibility_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="schema get-compatibility"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --subject)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--subject requires an argument: --subject SUBJECT" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--subject']+x} ]]; then
    printf "missing required flag: --subject SUBJECT\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_schema_set_compatibility_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_schema_set_compatibility_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="schema set-compatibility"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --subject)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--subject requires an argument: --subject SUBJECT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --compatibility)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--compatibility']="$2"
          shift
          shift
        else
          printf "%s\n" "--compatibility requires an argument: --compatibility COMPATIBILITY" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--subject']+x} ]]; then
    printf "missing required flag: --subject SUBJECT\n" >&2
    exit 1
  fi
  if [[ -z ${args['--compatibility']+x} ]]; then
    printf "missing required flag: --compatibility COMPATIBILITY\n" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--compatibility']} ]] && [[ ! ${args['--compatibility']} =~ ^(BACKWARD|BACKWARD_TRANSITIVE|FORWARD|FORWARD_TRANSITIVE|FULL|FULL_TRANSITIVE|NONE)$ ]]; then
    printf "%s\n" "--compatibility must be one of: BACKWARD, BACKWARD_TRANSITIVE, FORWARD, FORWARD_TRANSITIVE, FULL, FULL_TRANSITIVE, NONE" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_schema_get_mode_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_schema_get_mode_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="schema get-mode"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --subject)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--subject requires an argument: --subject SUBJECT" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--subject']+x} ]]; then
    printf "missing required flag: --subject SUBJECT\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_schema_set_mode_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_schema_set_mode_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="schema set-mode"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --subject)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--subject requires an argument: --subject SUBJECT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --mode)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--mode']="$2"
          shift
          shift
        else
          printf "%s\n" "--mode requires an argument: --mode MODE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--subject']+x} ]]; then
    printf "missing required flag: --subject SUBJECT\n" >&2
    exit 1
  fi
  if [[ -z ${args['--mode']+x} ]]; then
    printf "missing required flag: --mode MODE\n" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--mode']} ]] && [[ ! ${args['--mode']} =~ ^(IMPORT|READONLY|READWRITE)$ ]]; then
    printf "%s\n" "--mode must be one of: IMPORT, READONLY, READWRITE" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_schema_delete_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_schema_delete_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="schema delete"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --subject)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--subject requires an argument: --subject SUBJECT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --version)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_integer "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--version VERSION" "$(validate_integer "$2")" >&2
            exit 1
          fi

          args['--version']="$2"
          shift
          shift
        else
          printf "%s\n" "--version requires an argument: --version VERSION" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --permanent)

        # :flag.case_no_arg
        args['--permanent']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_debug_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    install-vscode-extension)
      action="install-vscode-extension"
      shift
      playground_debug_install_vscode_extension_parse_requirements "$@"
      shift $#
      ;;

    enable-remote-debugging)
      action="enable-remote-debugging"
      shift
      playground_debug_enable_remote_debugging_parse_requirements "$@"
      shift $#
      ;;

    testssl)
      action="testssl"
      shift
      playground_debug_testssl_parse_requirements "$@"
      shift $#
      ;;

    generate-diagnostics)
      action="generate-diagnostics"
      shift
      playground_debug_generate_diagnostics_parse_requirements "$@"
      shift $#
      ;;

    thread-dump)
      action="thread-dump"
      shift
      playground_debug_thread_dump_parse_requirements "$@"
      shift $#
      ;;

    heap-dump)
      action="heap-dump"
      shift
      playground_debug_heap_dump_parse_requirements "$@"
      shift $#
      ;;

    tcp-dump)
      action="tcp-dump"
      shift
      playground_debug_tcp_dump_parse_requirements "$@"
      shift $#
      ;;

    block-traffic)
      action="block-traffic"
      shift
      playground_debug_block_traffic_parse_requirements "$@"
      shift $#
      ;;

    flight-recorder)
      action="flight-recorder"
      shift
      playground_debug_flight_recorder_parse_requirements "$@"
      shift $#
      ;;

    log-level)
      action="log-level"
      shift
      playground_debug_log_level_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_debug_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_debug_install_vscode_extension_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_install_vscode_extension_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v code >/dev/null 2>&1; then
    deps['code']="$(command -v code | head -n1)"
  else
    printf "missing dependency: code\n" >&2
    printf "%s\n" "visit https://code.visualstudio.com/docs/setup/mac#_launching-from-the-command-line to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="debug install-vscode-extension"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_debug_enable_remote_debugging_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_enable_remote_debugging_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug enable-remote-debugging"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_debug_testssl_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_testssl_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug testssl"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        if [[ -z ${args['arguments']+x} ]]; then

          args['arguments']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_debug_generate_diagnostics_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_generate_diagnostics_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug generate-diagnostics"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_debug_thread_dump_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_thread_dump_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug thread-dump"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_debug_heap_dump_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_heap_dump_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug heap-dump"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_debug_tcp_dump_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_tcp_dump_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug tcp-dump"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --port)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_integer "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--port PORT" "$(validate_integer "$2")" >&2
            exit 1
          fi

          args['--port']="$2"
          shift
          shift
        else
          printf "%s\n" "--port requires an argument: --port PORT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --duration)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_integer "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--duration DURATION" "$(validate_integer "$2")" >&2
            exit 1
          fi

          args['--duration']="$2"
          shift
          shift
        else
          printf "%s\n" "--duration requires an argument: --duration DURATION" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"
  [[ -n ${args['--duration']:-} ]] || args['--duration']="30"

}

# :command.parse_requirements
playground_debug_block_traffic_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_block_traffic_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug block-traffic"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --destination)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--destination']="$2"
          shift
          shift
        else
          printf "%s\n" "--destination requires an argument: --destination DESTINATION" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --port)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_integer "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--port PORT" "$(validate_integer "$2")" >&2
            exit 1
          fi

          args['--port']="$2"
          shift
          shift
        else
          printf "%s\n" "--port requires an argument: --port PORT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --action)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--action']="$2"
          shift
          shift
        else
          printf "%s\n" "--action requires an argument: --action ACTION" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--destination']+x} ]]; then
    printf "missing required flag: --destination DESTINATION\n" >&2
    exit 1
  fi
  if [[ -z ${args['--action']+x} ]]; then
    printf "missing required flag: --action ACTION\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

  # :command.whitelist_filter
  if [[ ${args['--action']} ]] && [[ ! ${args['--action']} =~ ^(start|stop)$ ]]; then
    printf "%s\n" "--action must be one of: start, stop" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_debug_flight_recorder_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_flight_recorder_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug flight-recorder"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --action)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--action']="$2"
          shift
          shift
        else
          printf "%s\n" "--action requires an argument: --action ACTION" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--action']+x} ]]; then
    printf "missing required flag: --action ACTION\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

  # :command.whitelist_filter
  if [[ ${args['--action']} ]] && [[ ! ${args['--action']} =~ ^(start|stop)$ ]]; then
    printf "%s\n" "--action must be one of: start, stop" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_debug_log_level_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_log_level_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    get)
      action="get"
      shift
      playground_debug_log_level_get_parse_requirements "$@"
      shift $#
      ;;

    set)
      action="set"
      shift
      playground_debug_log_level_set_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_debug_log_level_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.user_filter
  filter_error=$(filter_connect_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_debug_log_level_get_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_log_level_get_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug log-level get"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --package | -p)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--package, -p PACKAGE" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--package']="$2"
          shift
          shift
        else
          printf "%s\n" "--package requires an argument: --package, -p PACKAGE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_debug_log_level_set_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_debug_log_level_set_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug log-level set"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --package | -p)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--package, -p PACKAGE" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--package']="$2"
          shift
          shift
        else
          printf "%s\n" "--package requires an argument: --package, -p PACKAGE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --level | -l)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--level']="$2"
          shift
          shift
        else
          printf "%s\n" "--level requires an argument: --level, -l LEVEL" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--package']+x} ]]; then
    printf "missing required flag: --package, -p PACKAGE\n" >&2
    exit 1
  fi
  if [[ -z ${args['--level']+x} ]]; then
    printf "missing required flag: --level, -l LEVEL\n" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--level']} ]] && [[ ! ${args['--level']} =~ ^(INFO|WARN|DEBUG|TRACE)$ ]]; then
    printf "%s\n" "--level must be one of: INFO, WARN, DEBUG, TRACE" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_get_jmx_metrics_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_get_jmx_metrics_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  if command -v java >/dev/null 2>&1; then
    deps['java']="$(command -v java | head -n1)"
  else
    printf "missing dependency: java\n" >&2
    printf "%s\n" "visit https://openjdk.org/install/ to install" >&2
    exit 1
  fi

  # :command.command_filter
  action="get-jmx-metrics"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --component | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--component']="$2"
          shift
          shift
        else
          printf "%s\n" "--component requires an argument: --component, -c COMPONENT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --open | -o)

        # :flag.case_no_arg
        args['--open']=1
        shift
        ;;

      # :flag.case
      --domain | -d)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--domain']="$2"
          shift
          shift
        else
          printf "%s\n" "--domain requires an argument: --domain, -d DOMAIN" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--component']:-} ]] || args['--component']="connect"

  # :command.whitelist_filter
  if [[ ${args['--component']} ]] && [[ ! ${args['--component']} =~ ^(zookeeper|broker|connect|schema-registry)$ ]]; then
    printf "%s\n" "--component must be one of: zookeeper, broker, connect, schema-registry" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_container_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    recreate)
      action="recreate"
      shift
      playground_container_recreate_parse_requirements "$@"
      shift $#
      ;;

    get-ip-addresses)
      action="get-ip-addresses"
      shift
      playground_container_get_ip_addresses_parse_requirements "$@"
      shift $#
      ;;

    kill-all)
      action="kill-all"
      shift
      playground_container_kill_all_parse_requirements "$@"
      shift $#
      ;;

    logs)
      action="logs"
      shift
      playground_container_logs_parse_requirements "$@"
      shift $#
      ;;

    ssh)
      action="ssh"
      shift
      playground_container_ssh_parse_requirements "$@"
      shift $#
      ;;

    exec)
      action="exec"
      shift
      playground_container_exec_parse_requirements "$@"
      shift $#
      ;;

    restart)
      action="restart"
      shift
      playground_container_restart_parse_requirements "$@"
      shift $#
      ;;

    pause)
      action="pause"
      shift
      playground_container_pause_parse_requirements "$@"
      shift $#
      ;;

    resume)
      action="resume"
      shift
      playground_container_resume_parse_requirements "$@"
      shift $#
      ;;

    kill)
      action="kill"
      shift
      playground_container_kill_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_container_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_container_recreate_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_recreate_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container recreate"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --ignore-current-versions)

        # :flag.case_no_arg
        args['--ignore-current-versions']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_container_get_ip_addresses_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_get_ip_addresses_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container get-ip-addresses"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_container_kill_all_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_kill_all_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container kill-all"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_container_logs_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_logs_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container logs"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --open | -o)
        # :flag.conflicts
        if [[ -n "${args['--wait-for-log']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--wait-for-log" >&2
          exit 1
        fi

        # :flag.case_no_arg
        args['--open']=1
        shift
        ;;

      # :flag.case
      --wait-for-log | -w)
        # :flag.conflicts
        if [[ -n "${args['--open']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--open" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--wait-for-log, -w LOG" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--wait-for-log']="$2"
          shift
          shift
        else
          printf "%s\n" "--wait-for-log requires an argument: --wait-for-log, -w LOG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --max-wait | -m)
        # :flag.conflicts
        if [[ -n "${args['--open']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--open" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_integer "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--max-wait, -m MAX_WAIT" "$(validate_integer "$2")" >&2
            exit 1
          fi

          args['--max-wait']="$2"
          shift
          shift
        else
          printf "%s\n" "--max-wait requires an argument: --max-wait, -m MAX_WAIT" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"
  [[ -n ${args['--max-wait']:-} ]] || args['--max-wait']="600"

}

# :command.parse_requirements
playground_container_ssh_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_ssh_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container ssh"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --shell | -s)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--shell']="$2"
          shift
          shift
        else
          printf "%s\n" "--shell requires an argument: --shell, -s SHELL" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"
  [[ -n ${args['--shell']:-} ]] || args['--shell']="bash"

  # :command.whitelist_filter
  if [[ ${args['--shell']} ]] && [[ ! ${args['--shell']} =~ ^(bash|sh|ksh|zsh)$ ]]; then
    printf "%s\n" "--shell must be one of: bash, sh, ksh, zsh" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_container_exec_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_exec_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container exec"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --command)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--command COMMAND" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--command']="$2"
          shift
          shift
        else
          printf "%s\n" "--command requires an argument: --command COMMAND" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --root)

        # :flag.case_no_arg
        args['--root']=1
        shift
        ;;

      # :flag.case
      --shell)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--shell']="$2"
          shift
          shift
        else
          printf "%s\n" "--shell requires an argument: --shell SHELL" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--command']+x} ]]; then
    printf "missing required flag: --command COMMAND\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"
  [[ -n ${args['--shell']:-} ]] || args['--shell']="bash"

  # :command.whitelist_filter
  if [[ ${args['--shell']} ]] && [[ ! ${args['--shell']} =~ ^(bash|sh|ksh|zsh)$ ]]; then
    printf "%s\n" "--shell must be one of: bash, sh, ksh, zsh" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_container_restart_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_restart_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container restart"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_container_pause_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_pause_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container pause"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_container_resume_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_resume_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container resume"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_container_kill_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_container_kill_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container kill"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--container']="$2"
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_topic_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    get-number-records)
      action="get-number-records"
      shift
      playground_topic_get_number_records_parse_requirements "$@"
      shift $#
      ;;

    display-consumer-offsets)
      action="display-consumer-offsets"
      shift
      playground_topic_display_consumer_offsets_parse_requirements "$@"
      shift $#
      ;;

    list)
      action="list"
      shift
      playground_topic_list_parse_requirements "$@"
      shift $#
      ;;

    describe)
      action="describe"
      shift
      playground_topic_describe_parse_requirements "$@"
      shift $#
      ;;

    set-schema-compatibility)
      action="set-schema-compatibility"
      shift
      playground_topic_set_schema_compatibility_parse_requirements "$@"
      shift $#
      ;;

    consume)
      action="consume"
      shift
      playground_topic_consume_parse_requirements "$@"
      shift $#
      ;;

    produce)
      action="produce"
      shift
      playground_topic_produce_parse_requirements "$@"
      shift $#
      ;;

    create)
      action="create"
      shift
      playground_topic_create_parse_requirements "$@"
      shift $#
      ;;

    delete)
      action="delete"
      shift
      playground_topic_delete_parse_requirements "$@"
      shift $#
      ;;

    alter)
      action="alter"
      shift
      playground_topic_alter_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_topic_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_topic_get_number_records_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_get_number_records_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic get-number-records"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_topic_display_consumer_offsets_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_display_consumer_offsets_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic display-consumer-offsets"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_topic_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_topic_describe_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_describe_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic describe"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_topic_set_schema_compatibility_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_set_schema_compatibility_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic set-schema-compatibility"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --compatibility)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--compatibility']="$2"
          shift
          shift
        else
          printf "%s\n" "--compatibility requires an argument: --compatibility COMPATIBILITY" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--compatibility']+x} ]]; then
    printf "missing required flag: --compatibility COMPATIBILITY\n" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--compatibility']} ]] && [[ ! ${args['--compatibility']} =~ ^(BACKWARD|BACKWARD_TRANSITIVE|FORWARD|FORWARD_TRANSITIVE|FULL|FULL_TRANSITIVE|NONE)$ ]]; then
    printf "%s\n" "--compatibility must be one of: BACKWARD, BACKWARD_TRANSITIVE, FORWARD, FORWARD_TRANSITIVE, FULL, FULL_TRANSITIVE, NONE" >&2
    exit 1
  fi

  # :command.user_filter
  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_topic_consume_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_consume_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic consume"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --max-messages)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_integer "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--max-messages MAX-MESSAGES" "$(validate_integer "$2")" >&2
            exit 1
          fi

          args['--max-messages']="$2"
          shift
          shift
        else
          printf "%s\n" "--max-messages requires an argument: --max-messages MAX-MESSAGES" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --min-expected-messages)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_integer "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--min-expected-messages MIN-EXPECTED-MESSAGES" "$(validate_integer "$2")" >&2
            exit 1
          fi

          args['--min-expected-messages']="$2"
          shift
          shift
        else
          printf "%s\n" "--min-expected-messages requires an argument: --min-expected-messages MIN-EXPECTED-MESSAGES" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --grep)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--grep']="$2"
          shift
          shift
        else
          printf "%s\n" "--grep requires an argument: --grep GREP" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --timeout)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_integer "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--timeout TIMEOUT" "$(validate_integer "$2")" >&2
            exit 1
          fi

          args['--timeout']="$2"
          shift
          shift
        else
          printf "%s\n" "--timeout requires an argument: --timeout TIMEOUT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --tail)
        # :flag.conflicts
        for conflict in --min-expected-messages --max-messages; do
          if [[ -n "${args[$conflict]:-}" ]]; then
            printf "conflicting options: %s cannot be used with %s\n" "$key" "$conflict" >&2
            exit 1
          fi
        done

        # :flag.case_no_arg
        args['--tail']=1
        shift
        ;;

      # :flag.case
      --plot-latencies-timestamp-field)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--plot-latencies-timestamp-field']="$2"
          shift
          shift
        else
          printf "%s\n" "--plot-latencies-timestamp-field requires an argument: --plot-latencies-timestamp-field TIMESTAMP" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --subject)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--subject requires an argument: --subject SUBJECT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --max-characters)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_integer "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--max-characters MAX-CHARACTERS" "$(validate_integer "$2")" >&2
            exit 1
          fi

          args['--max-characters']="$2"
          shift
          shift
        else
          printf "%s\n" "--max-characters requires an argument: --max-characters MAX-CHARACTERS" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--max-messages']:-} ]] || args['--max-messages']="10"
  [[ -n ${args['--min-expected-messages']:-} ]] || args['--min-expected-messages']=""
  [[ -n ${args['--grep']:-} ]] || args['--grep']=""
  [[ -n ${args['--timeout']:-} ]] || args['--timeout']="60"
  [[ -n ${args['--max-characters']:-} ]] || args['--max-characters']="2500"

  # :command.user_filter
  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_topic_produce_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_produce_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic produce"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --input)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--input']="$2"
          shift
          shift
        else
          printf "%s\n" "--input requires an argument: --input INPUT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --nb-messages)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_integer "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--nb-messages NB-MESSAGES" "$(validate_integer "$2")" >&2
            exit 1
          fi

          args['--nb-messages']="$2"
          shift
          shift
        else
          printf "%s\n" "--nb-messages requires an argument: --nb-messages NB-MESSAGES" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --nb-partitions)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_integer "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--nb-partitions NB-PARTITIONS" "$(validate_integer "$2")" >&2
            exit 1
          fi

          args['--nb-partitions']="$2"
          shift
          shift
        else
          printf "%s\n" "--nb-partitions requires an argument: --nb-partitions NB-PARTITIONS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --compatibility)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--compatibility']="$2"
          shift
          shift
        else
          printf "%s\n" "--compatibility requires an argument: --compatibility COMPATIBILITY" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --value-subject-name-strategy)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--value-subject-name-strategy']="$2"
          shift
          shift
        else
          printf "%s\n" "--value-subject-name-strategy requires an argument: --value-subject-name-strategy VALUE-SUBJECT-NAME-STRATEGY" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --key)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--key']="$2"
          shift
          shift
        else
          printf "%s\n" "--key requires an argument: --key KEY" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --headers)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--headers']="$2"
          shift
          shift
        else
          printf "%s\n" "--headers requires an argument: --headers HEADERS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --forced-value)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--forced-value']="$2"
          shift
          shift
        else
          printf "%s\n" "--forced-value requires an argument: --forced-value FORCED-VALUE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --generate-only)

        # :flag.case_no_arg
        args['--generate-only']=1
        shift
        ;;

      # :flag.case
      --tombstone)

        # :flag.case_no_arg
        args['--tombstone']=1
        shift
        ;;

      # :flag.case
      --validate)

        # :flag.case_no_arg
        args['--validate']=1
        shift
        ;;

      # :flag.case
      --validate-config)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          if [[ -z ${args['--validate-config']+x} ]]; then
            args['--validate-config']="\"$2\""
          else
            args['--validate-config']="${args[--validate-config]} \"$2\""
          fi
          shift
          shift
        else
          printf "%s\n" "--validate-config requires an argument: --validate-config VALIDATE-CONFIG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --producer-property)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          if [[ -z ${args['--producer-property']+x} ]]; then
            args['--producer-property']="\"$2\""
          else
            args['--producer-property']="${args[--producer-property]} \"$2\""
          fi
          shift
          shift
        else
          printf "%s\n" "--producer-property requires an argument: --producer-property PRODUCER-PROPERTY" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --record-size)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_integer "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--record-size RECORD-SIZE" "$(validate_integer "$2")" >&2
            exit 1
          fi

          args['--record-size']="$2"
          shift
          shift
        else
          printf "%s\n" "--record-size requires an argument: --record-size RECORD-SIZE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--topic']+x} ]]; then
    printf "missing required flag: --topic, -t TOPIC\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--input']:-} ]] || args['--input']="-"
  [[ -n ${args['--nb-messages']:-} ]] || args['--nb-messages']="1"
  [[ -n ${args['--nb-partitions']:-} ]] || args['--nb-partitions']=""
  [[ -n ${args['--record-size']:-} ]] || args['--record-size']="0"

  # :command.whitelist_filter
  if [[ ${args['--compatibility']} ]] && [[ ! ${args['--compatibility']} =~ ^(BACKWARD|BACKWARD_TRANSITIVE|FORWARD|FORWARD_TRANSITIVE|FULL|FULL_TRANSITIVE|NONE)$ ]]; then
    printf "%s\n" "--compatibility must be one of: BACKWARD, BACKWARD_TRANSITIVE, FORWARD, FORWARD_TRANSITIVE, FULL, FULL_TRANSITIVE, NONE" >&2
    exit 1
  fi
  if [[ ${args['--value-subject-name-strategy']} ]] && [[ ! ${args['--value-subject-name-strategy']} =~ ^(TopicNameStrategy|RecordNameStrategy|TopicRecordNameStrategy)$ ]]; then
    printf "%s\n" "--value-subject-name-strategy must be one of: TopicNameStrategy, RecordNameStrategy, TopicRecordNameStrategy" >&2
    exit 1
  fi
  eval "input_array=(${args[--validate-config]})"
  for i in "${input_array[@]}"; do
    if [[ ! $i =~ ^(scrub.invalid.names=true|enhanced.avro.schema.support=true|connect.meta.data=false|object.additional.properties=false|use.optional.for.nonrequired=true|ignore.default.for.nullables=true|generalized.sum.type.support=true|enhanced.protobuf.schema.support=true|generate.index.for.unions=false|int.for.enums=true|optional.for.nullables=true|generate.struct.for.nulls=true|wrapper.for.nullables=true|wrapper.for.raw.primitives=false)$ ]]; then
      printf "%s\n" "--validate-config must be one of: scrub.invalid.names=true, enhanced.avro.schema.support=true, connect.meta.data=false, object.additional.properties=false, use.optional.for.nonrequired=true, ignore.default.for.nullables=true, generalized.sum.type.support=true, enhanced.protobuf.schema.support=true, generate.index.for.unions=false, int.for.enums=true, optional.for.nullables=true, generate.struct.for.nulls=true, wrapper.for.nullables=true, wrapper.for.raw.primitives=false" >&2
      exit 1
    fi
  done

  # :command.user_filter
  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_topic_create_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_create_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic create"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --nb-partitions)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_integer "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--nb-partitions NB-PARTITIONS" "$(validate_integer "$2")" >&2
            exit 1
          fi

          args['--nb-partitions']="$2"
          shift
          shift
        else
          printf "%s\n" "--nb-partitions requires an argument: --nb-partitions NB-PARTITIONS" >&2
          exit 1
        fi
        ;;

      --)
        shift
        other_args+=("$@")
        break
        ;;

      -?*)
        other_args+=("$1")
        shift
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_catch_all
        other_args+=("$1")
        shift

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--topic']+x} ]]; then
    printf "missing required flag: --topic, -t TOPIC\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--nb-partitions']:-} ]] || args['--nb-partitions']=""

}

# :command.parse_requirements
playground_topic_delete_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_delete_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic delete"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--topic']+x} ]]; then
    printf "missing required flag: --topic, -t TOPIC\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_topic_alter_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_topic_alter_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic alter"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      --)
        shift
        other_args+=("$@")
        break
        ;;

      -?*)
        other_args+=("$1")
        shift
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_catch_all
        other_args+=("$1")
        shift

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--topic']+x} ]]; then
    printf "missing required flag: --topic, -t TOPIC\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_ccloud_connector_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_ccloud_connector_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.environment_variables_filter

  if [[ -z "${CLOUD_API_KEY:-}" ]]; then
    printf "missing required environment variable: CLOUD_API_KEY\n" >&2
    exit 1
  fi
  if [[ -z "${CLOUD_API_SECRET:-}" ]]; then
    printf "missing required environment variable: CLOUD_API_SECRET\n" >&2
    exit 1
  fi

  # :command.dependencies_filter
  if command -v confluent >/dev/null 2>&1; then
    deps['confluent']="$(command -v confluent | head -n1)"
  else
    printf "missing dependency: confluent\n" >&2
    printf "%s\n" "visit https://docs.confluent.io/confluent-cli/current/overview.html to install" >&2
    exit 1
  fi

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    status)
      action="status"
      shift
      playground_ccloud_connector_status_parse_requirements "$@"
      shift $#
      ;;

    plugins)
      action="plugins"
      shift
      playground_ccloud_connector_plugins_parse_requirements "$@"
      shift $#
      ;;

    pause)
      action="pause"
      shift
      playground_ccloud_connector_pause_parse_requirements "$@"
      shift $#
      ;;

    resume)
      action="resume"
      shift
      playground_ccloud_connector_resume_parse_requirements "$@"
      shift $#
      ;;

    delete)
      action="delete"
      shift
      playground_ccloud_connector_delete_parse_requirements "$@"
      shift $#
      ;;

    show-lag)
      action="show-lag"
      shift
      playground_ccloud_connector_show_lag_parse_requirements "$@"
      shift $#
      ;;

    show-config)
      action="show-config"
      shift
      playground_ccloud_connector_show_config_parse_requirements "$@"
      shift $#
      ;;

    show-config-parameters)
      action="show-config-parameters"
      shift
      playground_ccloud_connector_show_config_parameters_parse_requirements "$@"
      shift $#
      ;;

    create-or-update)
      action="create-or-update"
      shift
      playground_ccloud_connector_create_or_update_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_ccloud_connector_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.user_filter
  filter_error=$(filter_ccloud_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_ccloud_connector_status_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_ccloud_connector_status_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="ccloud-connector status"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_ccloud_connector_plugins_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_ccloud_connector_plugins_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="ccloud-connector plugins"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_ccloud_connector_pause_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_ccloud_connector_pause_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="ccloud-connector pause"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_ccloud_connector_resume_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_ccloud_connector_resume_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="ccloud-connector resume"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_ccloud_connector_delete_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_ccloud_connector_delete_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="ccloud-connector delete"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_ccloud_connector_show_lag_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_ccloud_connector_show_lag_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="ccloud-connector show-lag"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --wait-for-zero-lag)

        # :flag.case_no_arg
        args['--wait-for-zero-lag']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_ccloud_connector_show_config_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_ccloud_connector_show_config_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="ccloud-connector show-config"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_ccloud_connector_show_config_parameters_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_ccloud_connector_show_config_parameters_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="ccloud-connector show-config-parameters"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --open | -o)

        # :flag.case_no_arg
        args['--open']=1
        shift
        ;;

      # :flag.case
      --force-refresh)

        # :flag.case_no_arg
        args['--force-refresh']=1
        shift
        ;;

      # :flag.case
      --only-show-file-path)

        # :flag.case_no_arg
        args['--only-show-file-path']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_ccloud_connector_create_or_update_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_ccloud_connector_create_or_update_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="ccloud-connector create-or-update"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        if [[ -z ${args['json']+x} ]]; then

          args['json']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--connector']+x} ]]; then
    printf "missing required flag: --connector, -c CONNECTOR\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['json']:-} ]] || args['json']="-"

}

# :command.parse_requirements
playground_connector_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    status)
      action="status"
      shift
      playground_connector_status_parse_requirements "$@"
      shift $#
      ;;

    plugins)
      action="plugins"
      shift
      playground_connector_plugins_parse_requirements "$@"
      shift $#
      ;;

    pause)
      action="pause"
      shift
      playground_connector_pause_parse_requirements "$@"
      shift $#
      ;;

    versions)
      action="versions"
      shift
      playground_connector_versions_parse_requirements "$@"
      shift $#
      ;;

    restart)
      action="restart"
      shift
      playground_connector_restart_parse_requirements "$@"
      shift $#
      ;;

    resume)
      action="resume"
      shift
      playground_connector_resume_parse_requirements "$@"
      shift $#
      ;;

    delete)
      action="delete"
      shift
      playground_connector_delete_parse_requirements "$@"
      shift $#
      ;;

    show-lag)
      action="show-lag"
      shift
      playground_connector_show_lag_parse_requirements "$@"
      shift $#
      ;;

    show-config)
      action="show-config"
      shift
      playground_connector_show_config_parse_requirements "$@"
      shift $#
      ;;

    show-config-parameters)
      action="show-config-parameters"
      shift
      playground_connector_show_config_parameters_parse_requirements "$@"
      shift $#
      ;;

    log-level)
      action="log-level"
      shift
      playground_connector_log_level_parse_requirements "$@"
      shift $#
      ;;

    create-or-update)
      action="create-or-update"
      shift
      playground_connector_create_or_update_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_connector_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

  filter_error=$(filter_connect_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_status_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_status_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector status"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_plugins_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_plugins_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector plugins"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_pause_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_pause_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector pause"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_versions_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_versions_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector versions"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_restart_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_restart_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector restart"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_resume_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_resume_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector resume"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_delete_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_delete_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector delete"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_show_lag_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_show_lag_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector show-lag"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --wait-for-zero-lag)

        # :flag.case_no_arg
        args['--wait-for-zero-lag']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_show_config_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_show_config_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector show-config"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_show_config_parameters_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_show_config_parameters_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector show-config-parameters"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --open | -o)

        # :flag.case_no_arg
        args['--open']=1
        shift
        ;;

      # :flag.case
      --force-refresh)

        # :flag.case_no_arg
        args['--force-refresh']=1
        shift
        ;;

      # :flag.case
      --only-show-file-path)

        # :flag.case_no_arg
        args['--only-show-file-path']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_log_level_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_log_level_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector log-level"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --level | -l)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--level']="$2"
          shift
          shift
        else
          printf "%s\n" "--level requires an argument: --level, -l LEVEL" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--level']+x} ]]; then
    printf "missing required flag: --level, -l LEVEL\n" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--level']} ]] && [[ ! ${args['--level']} =~ ^(INFO|WARN|DEBUG|TRACE)$ ]]; then
    printf "%s\n" "--level must be one of: INFO, WARN, DEBUG, TRACE" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_create_or_update_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    case "${1:-}" in
      --help | -h)
        long_usage=yes
        playground_connector_create_or_update_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector create-or-update"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --level | -l)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then

          args['--level']="$2"
          shift
          shift
        else
          printf "%s\n" "--level requires an argument: --level, -l LEVEL" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --package | -p)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          # :flag.validations
          if [[ -n $(validate_not_empty "$2") ]]; then
            printf "validation error in %s:\n%s\n" "--package, -p PACKAGE" "$(validate_not_empty "$2")" >&2
            exit 1
          fi

          args['--package']="$2"
          shift
          shift
        else
          printf "%s\n" "--package requires an argument: --package, -p PACKAGE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        if [[ -z ${args['json']+x} ]]; then

          args['json']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--connector']+x} ]]; then
    printf "missing required flag: --connector, -c CONNECTOR\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['json']:-} ]] || args['json']="-"

  # :command.whitelist_filter
  if [[ ${args['--level']} ]] && [[ ! ${args['--level']} =~ ^(INFO|WARN|DEBUG|TRACE)$ ]]; then
    printf "%s\n" "--level must be one of: INFO, WARN, DEBUG, TRACE" >&2
    exit 1
  fi

}

# :command.initialize
initialize() {
  version="1.0.0"
  long_usage=''
  set -e

  # src/initialize.sh

  if [ -z $CONFIG_FILE ]
  then
      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
      dir1=$(echo ${DIR_CLI%/*})
      root_folder=$(echo ${dir1%/*})

      CONFIG_FILE=$root_folder/scripts/cli/config.ini

      # log "ğŸ“ Loading default config.ini $CONFIG_FILE as CONFIG_FILE environment variable is not set"
  # else
      # log "ğŸ“ Loading config.ini $CONFIG_FILE from CONFIG_FILE environment variable"
  fi
}

# :command.run
run() {
  declare -A args=()
  declare -A deps=()
  declare -a other_args=()
  declare -a input=()
  normalize_input "$@"
  parse_requirements "${input[@]}"

  case "$action" in
    "help") playground_help_command ;;
    "status") playground_status_command ;;
    "get-connector-list") playground_get_connector_list_command ;;
    "get-ccloud-connector-list") playground_get_ccloud_connector_list_command ;;
    "get-kafka-region-list") playground_get_kafka_region_list_command ;;
    "get-topic-list") playground_get_topic_list_command ;;
    "get-subject-list") playground_get_subject_list_command ;;
    "get-examples-list-with-fzf") playground_get_examples_list_with_fzf_command ;;
    "get-zip-or-jar-with-fzf") playground_get_zip_or_jar_with_fzf_command ;;
    "get-any-file-with-fzf") playground_get_any_file_with_fzf_command ;;
    "get-playground-repro-export-with-fzf") playground_get_playground_repro_export_with_fzf_command ;;
    "get-predefined-schemas") playground_get_predefined_schemas_command ;;
    "bashly-reload") playground_bashly_reload_command ;;
    "run") playground_run_command ;;
    "re-run") playground_re_run_command ;;
    "run-ccloud") playground_run_ccloud_command ;;
    "update-version") playground_update_version_command ;;
    "open") playground_open_command ;;
    "stop") playground_stop_command ;;
    "open-docs") playground_open_docs_command ;;
    "repro") playground_repro_command ;;
    "repro export") playground_repro_export_command ;;
    "repro import") playground_repro_import_command ;;
    "repro bootstrap") playground_repro_bootstrap_command ;;
    "get-docker-compose") playground_get_docker_compose_command ;;
    "get-properties") playground_get_properties_command ;;
    "schema") playground_schema_command ;;
    "schema get") playground_schema_get_command ;;
    "schema register") playground_schema_register_command ;;
    "schema get-compatibility") playground_schema_get_compatibility_command ;;
    "schema set-compatibility") playground_schema_set_compatibility_command ;;
    "schema get-mode") playground_schema_get_mode_command ;;
    "schema set-mode") playground_schema_set_mode_command ;;
    "schema delete") playground_schema_delete_command ;;
    "debug") playground_debug_command ;;
    "debug install-vscode-extension") playground_debug_install_vscode_extension_command ;;
    "debug enable-remote-debugging") playground_debug_enable_remote_debugging_command ;;
    "debug testssl") playground_debug_testssl_command ;;
    "debug generate-diagnostics") playground_debug_generate_diagnostics_command ;;
    "debug thread-dump") playground_debug_thread_dump_command ;;
    "debug heap-dump") playground_debug_heap_dump_command ;;
    "debug tcp-dump") playground_debug_tcp_dump_command ;;
    "debug block-traffic") playground_debug_block_traffic_command ;;
    "debug flight-recorder") playground_debug_flight_recorder_command ;;
    "debug log-level") playground_debug_log_level_command ;;
    "debug log-level get") playground_debug_log_level_get_command ;;
    "debug log-level set") playground_debug_log_level_set_command ;;
    "get-jmx-metrics") playground_get_jmx_metrics_command ;;
    "container") playground_container_command ;;
    "container recreate") playground_container_recreate_command ;;
    "container get-ip-addresses") playground_container_get_ip_addresses_command ;;
    "container kill-all") playground_container_kill_all_command ;;
    "container logs") playground_container_logs_command ;;
    "container ssh") playground_container_ssh_command ;;
    "container exec") playground_container_exec_command ;;
    "container restart") playground_container_restart_command ;;
    "container pause") playground_container_pause_command ;;
    "container resume") playground_container_resume_command ;;
    "container kill") playground_container_kill_command ;;
    "topic") playground_topic_command ;;
    "topic get-number-records") playground_topic_get_number_records_command ;;
    "topic display-consumer-offsets") playground_topic_display_consumer_offsets_command ;;
    "topic list") playground_topic_list_command ;;
    "topic describe") playground_topic_describe_command ;;
    "topic set-schema-compatibility") playground_topic_set_schema_compatibility_command ;;
    "topic consume") playground_topic_consume_command ;;
    "topic produce") playground_topic_produce_command ;;
    "topic create") playground_topic_create_command ;;
    "topic delete") playground_topic_delete_command ;;
    "topic alter") playground_topic_alter_command ;;
    "ccloud-connector") playground_ccloud_connector_command ;;
    "ccloud-connector status") playground_ccloud_connector_status_command ;;
    "ccloud-connector plugins") playground_ccloud_connector_plugins_command ;;
    "ccloud-connector pause") playground_ccloud_connector_pause_command ;;
    "ccloud-connector resume") playground_ccloud_connector_resume_command ;;
    "ccloud-connector delete") playground_ccloud_connector_delete_command ;;
    "ccloud-connector show-lag") playground_ccloud_connector_show_lag_command ;;
    "ccloud-connector show-config") playground_ccloud_connector_show_config_command ;;
    "ccloud-connector show-config-parameters") playground_ccloud_connector_show_config_parameters_command ;;
    "ccloud-connector create-or-update") playground_ccloud_connector_create_or_update_command ;;
    "connector") playground_connector_command ;;
    "connector status") playground_connector_status_command ;;
    "connector plugins") playground_connector_plugins_command ;;
    "connector pause") playground_connector_pause_command ;;
    "connector versions") playground_connector_versions_command ;;
    "connector restart") playground_connector_restart_command ;;
    "connector resume") playground_connector_resume_command ;;
    "connector delete") playground_connector_delete_command ;;
    "connector show-lag") playground_connector_show_lag_command ;;
    "connector show-config") playground_connector_show_config_command ;;
    "connector show-config-parameters") playground_connector_show_config_parameters_command ;;
    "connector log-level") playground_connector_log_level_command ;;
    "connector create-or-update") playground_connector_create_or_update_command ;;
  esac
}

initialize
run "$@"
