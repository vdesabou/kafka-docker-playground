#!/usr/bin/env bash
# This script was generated by bashly 1.3.1 (https://bashly.dev)
# Modifying it manually is not recommended

# :wrapper.bash3_bouncer
if ((BASH_VERSINFO[0] < 4 || (BASH_VERSINFO[0] == 4 && BASH_VERSINFO[1] < 2))); then
  printf "bash version 4 or higher is required\n" >&2
  exit 1
fi

# :command.master_script

# :command.version_command
version_command() {
  echo "$version"
}

# :command.usage
playground_usage() {
  if [[ -n $long_usage ]]; then
    echo
    echo $'██████  ██       █████  ██    ██  ██████  ██████   ██████  ██    ██ ███    ██ ██████  '
    echo $'██   ██ ██      ██   ██  ██  ██  ██       ██   ██ ██    ██ ██    ██ ████   ██ ██   ██ '
    echo $'██████  ██      ███████   ████   ██   ███ ██████  ██    ██ ██    ██ ██ ██  ██ ██   ██ '
    echo $'██      ██      ██   ██    ██    ██    ██ ██   ██ ██    ██ ██    ██ ██  ██ ██ ██   ██ '
    echo $'██      ███████ ██   ██    ██     ██████  ██   ██  ██████   ██████  ██   ████ ██████  '
    echo

  else
    printf "playground - 🧠 CLI for Kafka Docker Playground 🐳\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground [OPTIONS] COMMAND\n"
  printf "  playground [COMMAND] --help | -h\n"
  printf "  playground --version\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   Show help about a command\n" "$(green "help")                                      "
  printf "  %s   🗺️ Show a status\n" "$(green "status")                                    "
  printf "  %s   ⚙️ Configure CLI\n" "$(green "config")                                    "
  printf "  %s   🧞‍♂️  AI\n" "$(green "ai")                                        "
  printf "  %s   💰  Retrieve ccloud costs for a range of dates\n" "$(green "ccloud-costs")                              "
  printf "  %s   👛  Retrieve ccloud costs for each month since last year\n" "$(green "ccloud-costs-history")                      "
  echo
  printf "%s\n" "$(bold "Run commands:")"
  printf "  %s   🕹️ Run any example !\n" "$(green "run")                                       "
  printf "  %s   ⚡ Simply re-run last example you ran with <playground run>\n" "$(green "re-run")                                    "
  printf "  %s   🤖 get CI result for current example\n" "$(green "get-ci-result")                             "
  printf "  %s   🏰 Get an history of the examples which were run with run command and run it again\n" "$(green "history")                                   "
  printf "  %s   🌩️  Switch to ccloud environment.\n" "$(green "switch-ccloud")                             "
  printf "  %s   💺  Switch back from previous environment before switch-ccloud was called.\n" "$(green "switch-back")                               "
  printf "  %s   ✨ Update current confluent platform components (all with --tag or only connect with --connect-tag) or connector(s) with new version(s)\n" "$(green "update-version")                            "
  printf "  %s   👐 When --file is not provided, simply open last example you ran with <playground run>\n" "$(green "open")                                      "
  printf "  %s   🛑 Stop currently running example\n" "$(green "stop")                                      "
  printf "  %s   🧨 Remove all docker images (including docker volumes)\n" "$(green "remove-all-docker-images")                  "
  printf "  %s   🧹 Remove all Confluent Platform docker images related to a version installed locally (a confirmation will be required for every version present)\n" "$(green "remove-cp-docker-images")                   "
  printf "  %s   🔄 Refresh (pull from Docker) all Confluent Platform docker images related to a version installed locally\n" "$(green "refresh-cp-docker-images")                  "
  printf "  %s   🧼 playground is actively caching ccloud details (https://kafka-docker-playground.io/#/how-to-use?id=%%f0%%9f%%8c%%a4%%ef%%b8%%8f-confluent-cloud-examples)\n" "$(green "cleanup-cloud-details")                     "
  printf "  %s   🧑‍🎓 Open Confluent documentation of currently running example\n" "$(green "open-docs")                                 "
  printf "  %s   📜 Open playground changelog (https://kafka-docker-playground.io/#/changelog)\n" "$(green "open-changelog")                            "
  printf "  %s   🧹 Cleanup cloud resources that were created by running examples from the playground\n" "$(green "cleanup-cloud-resources")                   "
  echo
  printf "%s\n" "$(bold "Repro commands:")"
  printf "  %s   👷‍♂️ Reproduction model commands\n" "$(green "repro")                                     "
  printf "  %s   📤 Export as tgz file uncommitted reproduction models from the folder of current reproduction model\n" "$(green "repro export")                              "
  printf "  %s   📥 Import tgz file which was created with export command\n" "$(green "repro import")                              "
  printf "  %s   🛠  Bootstrap reproduction model, just run <playground repro bootstrap> !\n" "$(green "repro bootstrap")                           "
  echo
  printf "%s\n" "$(bold "Kafka commands:")"
  printf "  %s   🐋 Get docker-compose\n" "$(green "get-docker-compose")                        "
  printf "  %s   🔢 Get JMX metrics from a container\n" "$(green "get-jmx-metrics")                           "
  echo
  printf "%s\n" "$(bold "Schema commands:")"
  printf "  %s   🔰 Schema commands\n" "$(green "schema")                                    "
  printf "  %s   🔰 Get all schemas versions for specified subject (if --subject is not specified, all subjects will be used)\n" "$(green "schema get")                                "
  printf "  %s   ⏺️ Register a schema in specified subject\n" "$(green "schema register")                           "
  printf "  %s   🛡️ Get subject-level compatibility\n" "$(green "schema get-compatibility")                  "
  printf "  %s   🛡️ Set subject-level compatibility\n" "$(green "schema set-compatibility")                  "
  printf "  %s   🔏 Get subject-level mode\n" "$(green "schema get-mode")                           "
  printf "  %s   🔏 Set subject-level mode\n" "$(green "schema set-mode")                           "
  printf "  %s   🧽 Set normalize at schema registry level\n" "$(green "schema set-normalize")                      "
  printf "  %s   🧟 Delete schema\n" "$(green "schema delete")                             "
  printf "  %s   🪄 Derive a schema based on payload\n" "$(green "schema derive-schema")                      "
  echo
  printf "%s\n" "$(bold "TCP Proxy commands:")"
  printf "  %s   🏚 Zazkia TCP Proxy commands\n" "$(green "tcp-proxy")                                 "
  printf "  %s   💗 Start the TCP proxy and automatically replace connector config with zazkia hostname and port 49998\n" "$(green "tcp-proxy start")                           "
  printf "  %s   🧲 Get Zazkia active TCP connections config and stats\n" "$(green "tcp-proxy get-connections")                 "
  printf "  %s   ⏲️ Add milliseconds delay to service response.\n" "$(green "tcp-proxy delay")                           "
  printf "  %s   💔 Break sending the response to the client.\n" "$(green "tcp-proxy break")                           "
  printf "  %s   ❌ Close the Zazkia active TCP connections\n" "$(green "tcp-proxy close-connection")                "
  printf "  %s   🧹 Close all Zazkia TCP connections which are in error state (close all with error button in Zazkia UI)\n" "$(green "tcp-proxy close-all-connection-with-error") "
  printf "  %s   🙅‍♂️ Change whether new connections can be accepted\n" "$(green "tcp-proxy toggle-accept-connections")       "
  printf "  %s   ✅ Change whether reading data from the client is enabled.\n" "$(green "tcp-proxy toggle-reads-client")             "
  printf "  %s   ✅ Change whether reading data from the service is enabled.\n" "$(green "tcp-proxy toggle-reads-service")            "
  printf "  %s   ✅ Change whether writing data to the client is enabled.\n" "$(green "tcp-proxy toggle-writes-client")            "
  printf "  %s   ✅ Change whether reading data to the service is enabled.\n" "$(green "tcp-proxy toggle-writes-service")           "
  printf "  %s   🌐 Just open Zazkia UI (http://localhost:9191) in your browser\n" "$(green "tcp-proxy open-ui")                         "
  echo
  printf "%s\n" "$(bold "Tools commands:")"
  printf "  %s   🧰 Tools commands\n" "$(green "tools")                                     "
  printf "  %s   🪄 Install a slightly modified version of \"Shell Script Command Completion\" Visual Studio Code extension (https://marketplace.visualstudio.com/items?itemName=tetradresearch.vscode-h2o)\n" "$(green "tools install-vscode-extension")            "
  printf "  %s   🔖 Read provided avro file\n" "$(green "tools read-avro-file")                      "
  printf "  %s   🔖 Read provided parquet file\n" "$(green "tools read-parquet-file")                   "
  printf "  %s   🔐 Generate keys and certificates used for SSL\n" "$(green "tools certs-create")                        "
  echo
  printf "%s\n" "$(bold "Debug commands:")"
  printf "  %s   🐞 Debug commands\n" "$(green "debug")                                     "
  printf "  %s   ✨ Enable java remote debugging for container\n" "$(green "debug enable-remote-debugging")             "
  printf "  %s   🔐 Testing TLS/SSL encryption using https://testssl.sh/\n" "$(green "debug testssl")                             "
  printf "  %s   ⛑️ Generate a diagnostic bundle with Diagnostics Bundle Tool\n" "$(green "debug generate-diagnostics")                "
  printf "  %s   🎯 Take a java thread dump\n" "$(green "debug thread-dump")                         "
  printf "  %s   👻 Take a heap dump\n" "$(green "debug heap-dump")                           "
  printf "  %s   🕵️‍♂️ Take a tcp dump (sniffing network)\n" "$(green "debug tcp-dump")                            "
  printf "  %s   🚫 Blocking traffic using iptables\n" "$(green "debug block-traffic")                       "
  printf "  %s   🤎 JVM arguments for SSL, Kerberos or Class Loading\n" "$(green "debug java-debug")                          "
  printf "  %s   ✂️ jscissors is an instrumentation framework and can help to analyse control flow and perform some specific logging\n" "$(green "debug jscissors")                           "
  printf "  %s   🛩️ Record flight recorder\n" "$(green "debug flight-recorder")                     "
  printf "  %s   🧬 Set log level for any package\n" "$(green "debug log-level")                           "
  echo
  printf "%s\n" "$(bold "Container commands:")"
  printf "  %s   🐳 Container commands\n" "$(green "container")                                 "
  printf "  %s   📝 Get properties file from a container\n" "$(green "container get-properties")                  "
  printf "  %s   💫 Recreate container(s)\n" "$(green "container recreate")                        "
  printf "  %s   🖥️  Get ip address of running containers\n" "$(green "container get-ip-addresses")                "
  printf "  %s   💀 Kill all containers\n" "$(green "container kill-all")                        "
  printf "  %s   🕵️  Tail and follow container logs\n" "$(green "container logs")                            "
  printf "  %s   🔥 Display all ERROR/FATAL logs in all containers. Useful for quick troubleshooting\n" "$(green "container display-error-all-containers")    "
  printf "  %s   🛬 SSH into container\n" "$(green "container ssh")                             "
  printf "  %s   🤎 Change java JDK version using Azul JDK (https://www.azul.com/downloads/#downloads-table-zulu)\n" "$(green "container change-jdk")                      "
  printf "  %s   🪄 Execute command in a container\n" "$(green "container exec")                            "
  printf "  %s   🔁 Restart a container\n" "$(green "container restart")                         "
  printf "  %s   ⏸️  Pause a container\n" "$(green "container pause")                           "
  printf "  %s   ⏯️  Resume a container\n" "$(green "container resume")                          "
  printf "  %s   🔫 Kill a container\n" "$(green "container kill")                            "
  printf "  %s   📦  Set environment variable(s) for a container\n" "$(green "container set-environment-variables")       "
  echo
  printf "%s\n" "$(bold "Topic commands:")"
  printf "  %s   🗳 Topic commands\n" "$(green "topic")                                     "
  printf "  %s   💯 Get number of records in a topic\n" "$(green "topic get-number-records")                  "
  printf "  %s   📭 Display content of __consumer_offsets topic\n" "$(green "topic display-consumer-offsets")            "
  printf "  %s   🔘 List topics\n" "$(green "topic list")                                "
  printf "  %s   🔬 Describe topic\n" "$(green "topic describe")                            "
  printf "  %s   🛡️ Change topic's schema compatibility\n" "$(green "topic set-schema-compatibility")            "
  printf "  %s   📥 Consume topic from beginning\n" "$(green "topic consume")                             "
  printf "  %s   📤 Produce to a topic\n" "$(green "topic produce")                             "
  printf "  %s   🆕 Create topic\n" "$(green "topic create")                              "
  printf "  %s   ❌ Delete topic and associated schema/subject if applicable\n" "$(green "topic delete")                              "
  printf "  %s   🪛 Alter topic config\n" "$(green "topic alter")                               "
  echo
  printf "%s\n" "$(bold "Connector-Plugin commands:")"
  printf "  %s   🔌 Connector-plugin commands\n" "$(green "connector-plugin")                          "
  printf "  %s   ☕ List jars for a connector plugin from confluent hub https://www.confluent.io/hub/ Search for specific class and display method signatures\n" "$(green "connector-plugin search-jar")               "
  printf "  %s   💯 List versions for a connector plugin from confluent hub https://www.confluent.io/hub/\n" "$(green "connector-plugin versions")                 "
  printf "  %s   🆕 List last updated connector plugins from confluent hub https://www.confluent.io/hub/\n" "$(green "connector-plugin display-last-updated")     "
  printf "  %s   🧑‍💻 Open source code url in your browser\n" "$(green "connector-plugin sourcecode")               "
  echo
  printf "%s\n" "$(bold "Connector commands:")"
  printf "  %s   🔗 Connector commands\n" "$(green "connector")                                 "
  printf "  %s   🧩 Show status of all connectors\n" "$(green "connector status")                          "
  printf "  %s   🅾️ Specific Oracle CDC Xstream commands\n" "$(green "connector oracle-cdc-xstream")              "
  printf "  %s   💈 Handle source and sink connectors offsets\n" "$(green "connector offsets")                         "
  printf "  %s   🎨 Show all connector plugins installed. You can also display transforms, converters and predicates using --all flag\n" "$(green "connector plugins")                         "
  printf "  %s   ⏸️  Pause connector\n" "$(green "connector pause")                           "
  printf "  %s   🧞 Get current and latest versions available on Confluent Hub for connector(s) used in example\n" "$(green "connector versions")                        "
  printf "  %s   🧑‍💻 open source code url for connector(s) used in example\n" "$(green "connector sourcecode")                      "
  printf "  %s   ♻️  Restart connector\n" "$(green "connector restart")                         "
  printf "  %s   🛑 Stop connector (only available if CP > 7.5)\n" "$(green "connector stop")                            "
  printf "  %s   ⏯️  Resume connector\n" "$(green "connector resume")                          "
  printf "  %s   🗑️  Delete connector\n" "$(green "connector delete")                          "
  printf "  %s   🐢 Show lag of sink connector\n" "$(green "connector show-lag")                        "
  printf "  %s   🧰 Show current connector config that was applied\n" "$(green "connector show-config")                     "
  printf "  %s   🔩 Show all possible configuration parameters of connector\n" "$(green "connector show-config-parameters")          "
  printf "  %s   🗜️ Easily select config from all possible configuration parameters of connector\n" "$(green "connector select-config")                   "
  printf "  %s   🔌 useful snippets\n" "$(green "connector snippets")                        "
  printf "  %s   🧑‍🎓 Open connector documentation of currently running conector(s)\n" "$(green "connector open-docs")                       "
  printf "  %s   🧬 Set connect log level\n" "$(green "connector log-level")                       "
  printf "  %s   🕵️  Tail and follow connect logs\n" "$(green "connector logs")                            "
  printf "  %s   🤖 Open Fully Managed connector in browser (Confluent Cloud dashboard)\n" "$(green "connector open-ccloud-connector-in-browser")"
  printf "  %s   🧩 Run Kafka Connector Migration Utility (see https://github.com/confluentinc/connect-migration-utility/) on running connect cluster\n" "$(green "connector connect-migration-utility")       "
  printf "  %s   🧑‍🎨  Create or update connector\n" "$(green "connector create-or-update")                "
  printf "  %s   🛠️ Update connector configuration by opening current connector config in text editor set with playground config editor <editor> (default is code). Once file is saved, the new configuration is updated.\n" "$(green "connector update")                          "
  echo
  printf "%s\n" "$(bold "EC2 commands:")"
  printf "  %s   ✨ Create and manage AWS EC2 instances (using Cloud Formation) to run kafka-docker-playground\n" "$(green "ec2")                                       "
  printf "  %s   👷 Create kafka-docker-playground EC2 instance using AWS Cloud Formation\n" "$(green "ec2 create")                                "
  printf "  %s   ❌ Delete an EC2 instance created with Cloud Formation\n" "$(green "ec2 delete")                                "
  printf "  %s   👨‍💻 Open an EC2 instance using Visual Studio code\n" "$(green "ec2 open")                                  "
  printf "  %s   🔘 List all EC2 instance\n" "$(green "ec2 list")                                  "
  printf "  %s   🔴 Stop an EC2 instance\n" "$(green "ec2 stop")                                  "
  printf "  %s   🟢 Start an EC2 instance\n" "$(green "ec2 start")                                 "
  printf "  %s   ↔️ Synchronize reproduction-models folder bewteen local and ec2 instance\n" "$(green "ec2 sync-repro-folder")                     "
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "Global Options:")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--vvv, -v")"
    printf "    🐛 set verbose output (set -x)\n    \n    ❗ it can print sensitive information ❗\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--output-level, -o LEVEL")"
    printf "    ❕Log level used by all commands\n    \n    Default is INFO (all INFO, WARN and ERROR will be printed in command output)\n"
    printf "    %s\n" "Allowed: INFO, WARN, ERROR"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo
    printf "  %s\n" "$(magenta "--version")"
    printf "    Show version number\n"
    echo

  fi
}

# :command.usage
playground_help_usage() {
  printf "playground help - Show help about a command\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground help [COMMAND]\n"
  printf "  playground help --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "COMMAND")"
    printf "    🆘 Help command\n"
    echo

  fi
}

# :command.usage
playground_status_usage() {
  printf "playground status - 🗺️ Show a status\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground status\n"
  printf "  playground status --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_docker_ports_usage() {
  printf "playground get-docker-ports - Return some completion for docker ports\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-docker-ports\n"
  printf "  playground get-docker-ports --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_connector_list_usage() {
  printf "playground get-connector-list - Return some completion for connector list\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-connector-list\n"
  printf "  playground get-connector-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_ec2_instance_list_usage() {
  printf "playground get-ec2-instance-list - Return some completion for ec2 instance list\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-ec2-instance-list [CUR]\n"
  printf "  playground get-ec2-instance-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_ec2_cloudformation_list_usage() {
  printf "playground get-ec2-cloudformation-list - Return some completion for ec2 cloudformation list\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-ec2-cloudformation-list [CUR]\n"
  printf "  playground get-ec2-cloudformation-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_zazkia_connection_list_usage() {
  printf "playground get-zazkia-connection-list - Return some completion for zazkia connections list\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-zazkia-connection-list\n"
  printf "  playground get-zazkia-connection-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_generate_fzf_find_files_usage() {
  printf "playground generate-fzf-find-files - force call to generate_fzf_find_files\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground generate-fzf-find-files\n"
  printf "  playground generate-fzf-find-files --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_generate_tag_list_usage() {
  printf "playground generate-tag-list - generate the confluent platform tag list\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground generate-tag-list\n"
  printf "  playground generate-tag-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_generate_connector_plugin_list_usage() {
  printf "playground generate-connector-plugin-list - generate the confluent hub plugin list\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground generate-connector-plugin-list\n"
  printf "  playground generate-connector-plugin-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_generate_kafka_region_list_usage() {
  printf "playground generate-kafka-region-list - generate the confluent kafka region list\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground generate-kafka-region-list\n"
  printf "  playground generate-kafka-region-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_connector_plugin_usage() {
  printf "playground get-connector-plugin - Return some completion for connector plugin\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-connector-plugin [CUR]\n"
  printf "  playground get-connector-plugin --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_ccloud_environment_list_usage() {
  printf "playground get-ccloud-environment-list - Return some completion for ccloud environment\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-ccloud-environment-list [CUR]\n"
  printf "  playground get-ccloud-environment-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_ccloud_cluster_list_usage() {
  printf "playground get-ccloud-cluster-list - Return some completion for ccloud cluster\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-ccloud-cluster-list [CUR]\n"
  printf "  playground get-ccloud-cluster-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_tag_list_usage() {
  printf "playground get-tag-list - Return some completion for confluent platform tag\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-tag-list [CUR] [OPTIONS]\n"
  printf "  playground get-tag-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connect-only")"
    printf "    connect only\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_kafka_region_list_usage() {
  printf "playground get-kafka-region-list - Return some completion for confluent cloud kafka cluster region list\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-kafka-region-list [CUR]\n"
  printf "  playground get-kafka-region-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_topic_list_usage() {
  printf "playground get-topic-list - Return some completion for topic list\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-topic-list [OPTIONS]\n"
  printf "  playground get-topic-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--skip-connect-internal-topics")"
    printf "\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_subject_list_usage() {
  printf "playground get-subject-list - Return some completion for subject list\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-subject-list [OPTIONS]\n"
  printf "  playground get-subject-list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--deleted")"
    printf "    🧟 Include soft deleted schemas\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_examples_list_with_fzf_usage() {
  printf "playground get-examples-list-with-fzf - Return some completion for examples list\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-examples-list-with-fzf [CUR] [OPTIONS]\n"
  printf "  playground get-examples-list-with-fzf --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--without-repro")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--sink-only")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--ccloud-only")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-only")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--repro-only")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--environment-only")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--fully-managed-connector-only")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--ksql-only")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--schema-registry-only")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--rest-proxy-only")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--academy-only")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--other-playgrounds-only")"
    printf "\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_zip_or_jar_with_fzf_usage() {
  printf "playground get-zip-or-jar-with-fzf - Return some completion for zip or jar list\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-zip-or-jar-with-fzf [CUR] [OPTIONS]\n"
  printf "  playground get-zip-or-jar-with-fzf --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--type TYPE")"
    printf "\n"
    printf "    %s\n" "Allowed: zip, jar"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_specific_file_extension_usage() {
  printf "playground get-specific-file-extension - Return some completion for extension provided\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-specific-file-extension [CUR] [OPTIONS]\n"
  printf "  playground get-specific-file-extension --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--extension EXTENSION")"
    printf "\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_any_file_with_fzf_usage() {
  printf "playground get-any-file-with-fzf - Return some completion for any files\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-any-file-with-fzf [CUR]\n"
  printf "  playground get-any-file-with-fzf --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_playground_repro_export_with_fzf_usage() {
  printf "playground get-playground-repro-export-with-fzf - Return some completion for export tgz files\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-playground-repro-export-with-fzf [CUR]\n"
  printf "  playground get-playground-repro-export-with-fzf --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_get_predefined_schemas_usage() {
  printf "playground get-predefined-schemas - Return some completion for predefined schemas\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-predefined-schemas [CUR]\n"
  printf "  playground get-predefined-schemas --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "CUR")"
    printf "    correspond to completion $cur\n"
    echo

  fi
}

# :command.usage
playground_update_cache_versions_usage() {
  printf "playground update-cache-versions\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground update-cache-versions\n"
  printf "  playground update-cache-versions --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_environment_variables
    printf "%s\n" "$(bold "Environment Variables:")"

    # :environment_variable.usage
    printf "  %s\n" "$(cyan "GH_TOKEN")"
    printf "    GH_TOKEN\n"
    echo

  fi
}

# :command.usage
playground_update_readme_usage() {
  printf "playground update-readme\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground update-readme [OPTIONS]\n"
  printf "  playground update-readme --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--tags TAGS")"
    printf "    💯 list of tags\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--generate-for-kb")"
    printf "\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_environment_variables
    printf "%s\n" "$(bold "Environment Variables:")"

    # :environment_variable.usage
    printf "  %s\n" "$(cyan "GH_TOKEN")"
    printf "    GH_TOKEN\n"
    echo

  fi
}

# :command.usage
playground_force_ci_usage() {
  printf "playground force-ci\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground force-ci [FILENAME] [OPTIONS]\n"
  printf "  playground force-ci --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--all")"
    printf "\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--force")"
    printf "\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "FILENAME")"
    printf "    pattern of file to remove. A confirmation will be asked\n"
    echo

  fi
}

# :command.usage
playground_update_docs_usage() {
  printf "playground update-docs\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground update-docs\n"
  printf "  playground update-docs --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_bashly_reload_usage() {
  printf "playground bashly-reload\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground bashly-reload\n"
  printf "  playground bashly-reload --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_state_usage() {
  printf "playground state\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground state COMMAND\n"
  printf "  playground state [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_state_show_usage() {
  printf "playground state show - Show the entire playground.ini file\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground state show\n"
  printf "  playground state show --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_state_get_usage() {
  printf "playground state get - Read a value from the playground.ini file\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground state get KEY\n"
  printf "  playground state get --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "KEY")"
    printf "    playground.ini key\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground state get hello\n"
    printf "  playground state get user.name\n"
    echo

  fi
}

# :command.usage
playground_state_set_usage() {
  printf "playground state set - Save a value in the playground.ini file\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground state set KEY VALUE\n"
  printf "  playground state set --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "KEY")"
    printf "    playground.ini key\n"
    echo

    # :argument.usage
    printf "  %s\n" "$(blue "VALUE")"
    printf "    playground.ini value\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground state set hello world\n"
    printf "  playground state set user.email me@example.com\n"
    echo

  fi
}

# :command.usage
playground_state_del_usage() {
  printf "playground state del - Remove a value from the playground.ini file\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground state del KEY\n"
  printf "  playground state del --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "KEY")"
    printf "    playground.ini key\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground state del hello\n"
    printf "  playground state del user.name\n"
    echo

  fi
}

# :command.usage
playground_config_usage() {
  printf "playground config - ⚙️ Configure CLI\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground config COMMAND\n"
  printf "  playground config [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   editor to use to open files\n" "$(green "editor")                          "
  printf "  %s   📂 list of folders where to search for zip or jar\n" "$(green "folder_zip_or_jar")               "
  printf "  %s   copy to clipboard connector config (only working on MacOS)\n" "$(green "clipboard")                       "
  printf "  %s   when running a fully managed connector example, it opens the connector in browser\n" "$(green "open-ccloud-connector-in-browser")"
  printf "  %s   when running an example with --enable-jmx-grafana flag, it opens grafana in browser\n" "$(green "open-grafana-in-browser")         "
  printf "  %s   when running an example, always call playground container kill-all first. If set to false, it will call playground stop instead.\n" "$(green "container-kill-all-before-run")   "
  printf "  %s   when running an example, always check if repo version is older than 3 days, if disabled, it will skip this check.\n" "$(green "check-and-update-repo-version")   "
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_config_show_usage() {
  printf "playground config show - Show the entire playground_config.ini file\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground config show\n"
  printf "  playground config show --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_config_get_usage() {
  printf "playground config get - Read a value from the playground_config.ini file\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground config get KEY\n"
  printf "  playground config get --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "KEY")"
    printf "    Config key\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground config get hello\n"
    printf "  playground config get user.name\n"
    echo

  fi
}

# :command.usage
playground_config_set_usage() {
  printf "playground config set - Save a value in the playground_config.ini file\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground config set KEY VALUE\n"
  printf "  playground config set --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "KEY")"
    printf "    playground_config.ini key\n"
    echo

    # :argument.usage
    printf "  %s\n" "$(blue "VALUE")"
    printf "    playground_config.ini value\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground config set hello world\n"
    printf "  playground config set user.email me@example.com\n"
    echo

  fi
}

# :command.usage
playground_config_editor_usage() {
  printf "playground config editor - editor to use to open files\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground config editor EDITOR\n"
  printf "  playground config editor --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "EDITOR")"
    printf "    editor\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground config editor vi\n"
    printf "  playground config editor code\n"
    echo

  fi
}

# :command.usage
playground_config_folder_zip_or_jar_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground config folder_zip_or_jar\n\n"
    printf "  📂 list of folders where to search for zip or jar\n  current folder is always included\n  \n  default is ~ (home dir)\n\n"
  else
    printf "playground config folder_zip_or_jar - 📂 list of folders where to search for zip or jar\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground config folder_zip_or_jar FOLDER...\n"
  printf "  playground config folder_zip_or_jar --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "FOLDER...")"
    printf "    folder\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground config folder_zip_or_jar ~/Downloads\n  ~/Documents/github/kafka-connect-*\n"
    printf "  playground config folder_zip_or_jar ~/Downloads\n"
    echo

  fi
}

# :command.usage
playground_config_clipboard_usage() {
  printf "playground config clipboard - copy to clipboard connector config (only working on MacOS)\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground config clipboard [ENABLED]\n"
  printf "  playground config clipboard --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "ENABLED")"
    printf "\n"
    printf "    %s\n" "Default: true"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground config clipboard false\n"
    printf "  playground config clipboard true\n"
    echo

  fi
}

# :command.usage
playground_config_open_ccloud_connector_in_browser_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground config open-ccloud-connector-in-browser\n\n"
    printf "  when running a fully managed connector example, it opens the connector in\n  browser\n\n"
  else
    printf "playground config open-ccloud-connector-in-browser - when running a fully managed connector example, it opens the connector in browser\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground config open-ccloud-connector-in-browser COMMAND\n"
  printf "  playground config open-ccloud-connector-in-browser [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   automatically open the connector in browser\n" "$(green "automatically")"
  printf "  %s   browser to use\n" "$(green "browser")      "
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_config_open_ccloud_connector_in_browser_automatically_usage() {
  printf "playground config open-ccloud-connector-in-browser automatically - automatically open the connector in browser\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground config open-ccloud-connector-in-browser automatically [AUTOMATICALLY]\n"
  printf "  playground config open-ccloud-connector-in-browser automatically --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "AUTOMATICALLY")"
    printf "\n"
    printf "    %s\n" "Default: true"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground config open-ccloud-connector-in-browser automatically false\n"
    printf "  playground config open-ccloud-connector-in-browser automatically true\n"
    echo

  fi
}

# :command.usage
playground_config_open_ccloud_connector_in_browser_browser_usage() {
  printf "playground config open-ccloud-connector-in-browser browser - browser to use\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground config open-ccloud-connector-in-browser browser [BROWSER]\n"
  printf "  playground config open-ccloud-connector-in-browser browser --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "BROWSER")"
    printf "\n"
    printf "    %s\n" "Default: "
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground config open-ccloud-connector-in-browser browser Safari\n"
    echo

  fi
}

# :command.usage
playground_config_open_grafana_in_browser_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground config open-grafana-in-browser\n\n"
    printf "  when running an example with --enable-jmx-grafana flag, it opens grafana in\n  browser\n\n"
  else
    printf "playground config open-grafana-in-browser - when running an example with --enable-jmx-grafana flag, it opens grafana in browser\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground config open-grafana-in-browser COMMAND\n"
  printf "  playground config open-grafana-in-browser [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   automatically open grafana in browser\n" "$(green "automatically")"
  printf "  %s   browser to use\n" "$(green "browser")      "
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_config_open_grafana_in_browser_automatically_usage() {
  printf "playground config open-grafana-in-browser automatically - automatically open grafana in browser\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground config open-grafana-in-browser automatically [AUTOMATICALLY]\n"
  printf "  playground config open-grafana-in-browser automatically --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "AUTOMATICALLY")"
    printf "\n"
    printf "    %s\n" "Default: true"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground config open-grafana-in-browser automatically false\n"
    printf "  playground config open-grafana-in-browser automatically true\n"
    echo

  fi
}

# :command.usage
playground_config_open_grafana_in_browser_browser_usage() {
  printf "playground config open-grafana-in-browser browser - browser to use\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground config open-grafana-in-browser browser [BROWSER]\n"
  printf "  playground config open-grafana-in-browser browser --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "BROWSER")"
    printf "\n"
    printf "    %s\n" "Default: "
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground config open-grafana-in-browser browser Safari\n"
    echo

  fi
}

# :command.usage
playground_config_container_kill_all_before_run_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground config container-kill-all-before-run\n\n"
    printf "  when running an example, always call playground container kill-all first. If\n  set to false, it will call playground stop instead.\n\n"
  else
    printf "playground config container-kill-all-before-run - when running an example, always call playground container kill-all first. If set to false, it will call playground stop instead.\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground config container-kill-all-before-run [ENABLED]\n"
  printf "  playground config container-kill-all-before-run --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "ENABLED")"
    printf "\n"
    printf "    %s\n" "Default: false"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground config container-kill-all-before-run false\n"
    printf "  playground config container-kill-all-before-run true\n"
    echo

  fi
}

# :command.usage
playground_config_check_and_update_repo_version_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground config check-and-update-repo-version\n\n"
    printf "  when running an example, always check if repo version is older than 3 days, if\n  disabled, it will skip this check.\n\n"
  else
    printf "playground config check-and-update-repo-version - when running an example, always check if repo version is older than 3 days, if disabled, it will skip this check.\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground config check-and-update-repo-version [ENABLED]\n"
  printf "  playground config check-and-update-repo-version --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "ENABLED")"
    printf "\n"
    printf "    %s\n" "Default: true"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground config check-and-update-repo-version false\n"
    printf "  playground config check-and-update-repo-version true\n"
    echo

  fi
}

# :command.usage
playground_ai_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground ai\n\n"
    printf "  🧞‍♂️  AI\n  \n  It is using Gemini CI (https://google-gemini.github.io/gemini-cli/) in\n  interactive mode.\n  \n  MCP servers are available:\n  \n  1. mcp-playground-cli - \n  \n    Tools:\n    - playground_command_help:\n        Get detailed help for playground commands\n    - playground_command_suggest:\n        Get command suggestions and completions for the Kafka Docker Playground\n  CLI\n    - playground_command_validate:\n        Validate a complete playground command and suggest corrections\n  \n  2. mcp-kafka - Kafka MCP Server (https://docs.tuannvm.com/kafka-mcp-server)\n  \n    Tools:\n    - cluster_overview:\n        Aggregates high-level cluster health data, such as controller,\n  broker/topic/partition counts, and under-replicated/offline partitions.\n    - consume_messages:\n        Consume a batch of messages from Kafka topics.\n    - describe_configs:\n        Fetches configuration entries for a specific resource (topic or broker).\n    - describe_consumer_group:\n        Shows details for a specific consumer group, including state, members,\n  and optionally partition offsets and lag.\n    - describe_topic:\n        Provides detailed metadata for a specific Kafka topic, including\n  partition leaders, replicas, and ISRs.\n    - list_brokers:\n        Lists the configured Kafka broker addresses.\n    - list_consumer_groups:\n        Enumerates active consumer groups known by the Kafka cluster.\n    - list_topics:\n        Retrieves all topic names along with partition counts and replication\n  factors.\n    - produce_message:\n        Produce a message to a Kafka topic\n  \n    Prompts:\n    - kafka_cluster_overview:\n        Provides a summary of Kafka cluster health and metrics\n    - kafka_consumer_lag_report:\n        Provide a detailed report on consumer lag across all consumer groups\n    - kafka_health_check:\n        Run a comprehensive health check on the Kafka cluster\n    - kafka_under_replicated_partitions:\n        List topics and partitions where ISR count is less than replication\n  factor\n  \n  3. mcp-ccloud - Confluent Cloud MCP Server\n  (https://github.com/confluentinc/mcp-confluent)\n  \n    Tools:\n    - add-tags-to-topic:\n        Assign existing tags to Kafka topics in Confluent Cloud.\n    - alter-topic-config:\n        Alter topic configuration in Confluent Cloud.\n    - create-connector:\n        Create a new connector. Returns the new connector information if\n  successful.\n    - create-topic-tags:\n        Create new tag definitions in Confluent Cloud.\n    - create-topics:\n        Create one or more Kafka topics.\n    - delete-connector:\n        Delete an existing connector. Returns success message if deletion was\n  successful.\n    - delete-tag:\n        Delete a tag definition from Confluent Cloud.\n    - delete-topics:\n        Delete the topic with the given names.\n    - get-topic-config:\n        Retrieve configuration details for a specific Kafka topic.\n    - list-clusters:\n        Get all clusters in the Confluent Cloud environment\n    - list-connectors:\n        Retrieve a list of \"names\" of the active connectors. You can then make a\n  read request for a specific connector by name.\n    - list-environments:\n        Get all environments in Confluent Cloud with pagination support\n    - list-schemas:\n        List all schemas in the Schema Registry.\n    - list-tags:\n        Retrieve all tags with definitions from Confluent Cloud Schema Registry.\n    - list-topics:\n        List all topics in the Kafka cluster.\n    - read-connector:\n        Get information about the connector.\n    - read-environment:\n        Get details of a specific environment by ID\n    - remove-tag-from-entity:\n        Remove tag from an entity in Confluent Cloud.\n    - search-topics-by-name:\n        List all topics in the Kafka cluster matching the specified name.\n    - search-topics-by-tag:\n        List all topics in the Kafka cluster with the specified tag.\n\n"
  else
    printf "playground ai - 🧞‍♂️  AI\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ai [--] [GEMINI CLI ARGUMENTS...]\n"
  printf "  playground ai --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    echo "  GEMINI CLI ARGUMENTS..."
    printf "    arguments to pass to gemini cli, see\n    https://google-gemini.github.io/gemini-cli/docs/cli/configuration.html#command-line-arguments\n    for all options\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground ai --model gemini-1.5-pro-latest --output-format json\n"
    echo

  fi
}

# :command.usage
playground_ccloud_costs_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground ccloud-costs\n\n"
    printf "  💰  Retrieve ccloud costs for a range of dates\n  \n  All you have to do is to be already logged in with confluent CLI. It is using\n  https://docs.confluent.io/cloud/current/billing/overview.html#retrieve-costs-for-a-range-of-dates\n  \n  Cost data can take up to 72 hours to become available.\n  \n  Start date can reach a maximum of one year into the past\n  \n  One month is the maximum window between start and end dates\n  \n  For accuracy, Confluent recommends using a start_date that is at least 72\n  hours prior to the current date and time.\n\n"
  else
    printf "playground ccloud-costs - 💰  Retrieve ccloud costs for a range of dates\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ccloud-costs [OPTIONS]\n"
  printf "  playground ccloud-costs --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--start-date START_DATE")"
    printf "    🗓️ start date in format yyyy-mm-dd\n    \n    Default is 30 days ago\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--end-date END_DATE")"
    printf "    🗓️ end date in format yyyy-mm-dd\n    \n      Default is 3 days ago\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_ccloud_costs_history_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground ccloud-costs-history\n\n"
    printf "  👛  Retrieve ccloud costs for each month since last year\n  \n  All you have to do is to be already logged in with confluent CLI. It is using\n  https://docs.confluent.io/cloud/current/billing/overview.html#retrieve-costs-for-a-range-of-dates\n  \n  By default it will only display total cost in dollars. Use the --detailed flag\n  to see more information.\n\n"
  else
    printf "playground ccloud-costs-history - 👛  Retrieve ccloud costs for each month since last year\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ccloud-costs-history [OPTIONS]\n"
  printf "  playground ccloud-costs-history --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--detailed")"
    printf "    💹 display all details for each month\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_run_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground run\n\n"
    printf "  🕹️ Run any example !\n  \n  🔥 It start an interactive mode where you'll be fully guided !\n  \n  \n  ⛅ When running Confluent Cloud (ccloud) example:\n  \n    All you have to do is to be already logged in with confluent CLI.\n  \n    By default, a new Confluent Cloud environment with a Cluster will be\n  created.\n  \n    You can configure the new cluster by setting:\n  \n    --cluster-type (or CLUSTER_TYPE environment variable): The type of cluster\n  (possible values: basic, standard and dedicated, default basic)\n    --cluster-cloud (or CLUSTER_CLOUD environment variable): The Cloud provider\n  (possible values: aws, gcp and azure, default aws)\n    --cluster-region (or CLUSTER_REGION environment variable): The Cloud region\n  (use confluent kafka region list to get the list, default eu-west-2 for aws,\n  westeurope for azure and europe-west2 for gcp)\n    --cluster-environment (or ENVIRONMENT environment variable) (optional): The\n  environment id where want your new cluster (example: txxxxx)\n  \n    In case you want to use your own existing cluster, you need to setup, in\n  addition to previous ones:\n  \n    --cluster-name (or CLUSTER_NAME environment variable): The cluster name\n    --cluster-creds (or CLUSTER_CREDS environment variable): The Kafka api key\n  and secret to use, it should be separated with colon (example:\n  <API_KEY>:<API_KEY_SECRET>)\n    --cluster-schema-registry-creds (or SCHEMA_REGISTRY_CREDS environment\n  variable) (optional, if not set, new one will be created): The Schema Registry\n  api key and secret to use, it should be separated with colon (example:\n  <SR_API_KEY>:<SR_API_KEY_SECRET>)\n  \n  ❗ this command will kill all containers using \"playground container kill-all\",\n  you can disable this by running \"playground config\n  container-kill-all-before-run false\"\n\n"
  else
    printf "playground run - 🕹️ Run any example !\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground run [OPTIONS]\n"
  printf "  playground run --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--environment ENVIRONMENT")"
    printf "    🔐 The environment to start when running a connector example \n    \n    - plaintext\n    - ccloud\n    - 2way-ssl\n    - kerberos\n    - ldap-authorizer-sasl-plain\n    - ldap-sasl-plain\n    - rbac-sasl-plain\n    - sasl-plain\n    - sasl-scram\n    - sasl-ssl\n    - ssl_kerberos\n    \n    Default is plaintext.\n    This is only supported when example is a connector example\n"
    printf "    %s\n" "Allowed: ccloud, plaintext, sasl-ssl, sasl-plain, 2way-ssl, sasl-scram, kerberos, ssl_kerberos, ldap-authorizer-sasl-plain, ldap-sasl-plain, rbac-sasl-plain"
    printf "    %s\n" "Default: plaintext"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--file, -f FILE")"
    printf "    🔖 Example file to run\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--open, -o")"
    printf "    📖 Opening example files (including docker-compose file) with text editor set\n    with playground config editor <editor> (default is code)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--tag TAG")"
    printf "    🎯 Confluent Platform (CP) version to use. Applies to all components (broker,\n    connect, schema registry, ksqlDB, etc...)\n    \n    It sets TAG environment variable\n    \n    Must be greater or equal to 5.3.0\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connect-tag CONNECT_TAG")"
    printf "    🔗 Confluent Platform (CP) version to use. Applies to connect only.\n    \n    It sets CP_CONNECT_TAG environment variable\n    \n    Must be greater or equal to 5.3.0\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-tag CONNECTOR_TAG")"
    printf "    🔗 Connector version to use\n    \n    By default, for each connector, the latest available version on Confluent\n    Hub is used\n    \n    🎓 Tip: set to \" \" in order to select the version dynamically\n"
    printf "    %s\n" "Conflicts: --connector-zip"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-zip CONNECTOR_ZIP")"
    printf "    🤐 Connector zip to use\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion \n            use playground config folder_zip_or_jar <folder1> <folder2>...\n    (default is home folder and current folder is always included) to configure\n    where to search the files\n            use <option+enter> to use the value you typed manually\n"
    printf "    %s\n" "Conflicts: --connector-tag"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-jar CONNECTOR_JAR")"
    printf "    🤎 Connector jar to use\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion \n            use playground config folder_zip_or_jar <folder1> <folder2>...\n    (default is home folder and current folder is always included) to configure\n    where to search the files\n            use <option+enter> to use the value you typed manually\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-ksqldb")"
    printf "    🚀 Enable ksqlDB \n    \n    ❗ not supported with ccloud examples\n    \n    By default, ksqldb-server and ksqldb-cli containers are not started for\n    every test\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-rest-proxy")"
    printf "    🧲 Enable Rest Proxy\n    \n    ❗ not supported with ccloud examples\n    \n    By default, rest-proxy container is not started for every test\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-control-center")"
    printf "    💠 Enable Control Center\n    \n    By default, control-center container is not started for every test\n    \n    Control Center is reachable at http://127.0.0.1:9021\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-flink")"
    printf "    🐿️ Enable Flink\n    \n    By default, flink is not started for every test\n    \n    Once enabled, the CLI will ask if you need to download any connectors. Based\n    on the response, you can download one or more connectors from Flink maven\n    repository.\n    \n    Flink UI is reacheable using http://127.0.0.1:8081 within the flink child\n    directory. If you enable Flink by starting connector deployment,\n    http://127.0.0.1:18081 will be used.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-conduktor")"
    printf "    🐺 Enable Conduktor Platform\n    \n    By default, Conduktor Platform container is not started for every test\n    \n    Conduktor is reachable at http://127.0.0.1:8080/console (admin/admin)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-multiple-brokers")"
    printf "    3️⃣ Enable multiple brokers\n    \n    By default, there is only one broker node enabled\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-multiple-connect-workers")"
    printf "    🥉 Enable multiple connect worker node\n    \n    By default, there is only one connect worker node enabled\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-jmx-grafana")"
    printf "    Enable Grafana, Prometheus and Pyroscope\n    \n    📊 Grafana is reachable at http://127.0.0.1:3000 (login/password is\n    admin/password)\n    \n    🛡️ Prometheus is reachable at http://127.0.0.1:9090\n    \n    📛 Pyroscope is reachable at http://127.0.0.1:4040\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-kcat")"
    printf "    🐈‍⬛ Enable kcat\n    \n    You can use it with:\n    \n    $ docker exec kcat kcat -b broker:9092 -L\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-sql-datagen")"
    printf "    🌪️ Enable SQL Datagen injection\n    \n    This only works for Oracle, MySql, Postgres and Microsoft Sql Server source\n    connector examples with JDBC and Debezium\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-cloud CLUSTER-CLOUD")"
    printf "    🌤 The cloud provider: aws, gcp or azure. Default is aws\n    \n    🎓 Tip: you can also use CLUSTER_CLOUD environment variable\n"
    printf "    %s\n" "Allowed: aws, gcp, azure"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-type CLUSTER-TYPE")"
    printf "    🔋 The cluster type: basic, standard or dedicated. Default is basic\n    \n    🎓 Tip: you can also use CLUSTER_TYPE environment variable\n"
    printf "    %s\n" "Allowed: basic, standard, dedicated"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-region CLUSTER-REGION")"
    printf "    🗺 The Cloud region. \n    \n    🎓 Tip: you can also use CLUSTER_REGION environment variable\n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-environment CLUSTER-ENVIRONMENT")"
    printf "    🌐 The environment id where want your new cluster (example: txxxxx)\n    \n    ℹ️ Optional, if not set, new environment will be created\n    \n    🎓 Tip: you can also use ENVIRONMENT environment variable\n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-name CLUSTER-NAME")"
    printf "    🎰 The cluster name. \n    \n    ❣️ Only required if you want to use your own existing cluster\n    \n    🎓 Tip: you can also use CLUSTER_NAME environment variable\n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-creds CLUSTER-CREDS")"
    printf "    🔒 The Kafka api key and secret to use, it should be separated with colon\n    (example: <API_KEY>:<API_KEY_SECRET>)\n    \n    ❣️ Only required if you want to use your own existing cluster\n    \n    🎓 Tip: you can also use CLUSTER_CREDS environment variable\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--cluster-schema-registry-creds CLUSTER-SCHEMA-REGISTRY-CREDS")"
    printf "    🔒 The Schema Registry api key and secret to use, it should be separated with\n    colon (example: <SR_API_KEY>:<SR_API_KEY_SECRET>)\n    \n    ℹ️ Optional, if not set, new credentials will be created\n    \n    ❣️ Only required if you want to use your own existing cluster\n    \n    🎓 Tip: you can also use SCHEMA_REGISTRY_CREDS environment variable\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground run (interactive mode)\n"
    echo

  fi
}

# :command.usage
playground_re_run_usage() {
  printf "playground re-run - ⚡ Simply re-run last example you ran with <playground run>\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground re-run\n"
  printf "  playground re-run --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground re-run (interactive mode)\n"
    echo

  fi
}

# :command.usage
playground_get_ci_result_usage() {
  printf "playground get-ci-result - 🤖 get CI result for current example\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-ci-result\n"
  printf "  playground get-ci-result --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_history_usage() {
  printf "playground history - 🏰 Get an history of the examples which were run with run command and run it again\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground history\n"
  printf "  playground history --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_start_environment_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground start-environment\n\n"
    printf "  🔐 Simply start an environment listed in http://tinyurl.com/y4ybbw32:\n  \n  - ccloud\n  - 2way-ssl\n  - kerberos\n  - ldap-authorizer-sasl-plain\n  - ldap-sasl-plain\n  - mdc-kerberos\n  - mdc-plaintext\n  - mdc-sasl-plain\n  - plaintext\n  - rbac-sasl-plain\n  - sasl-plain\n  - sasl-scram\n  - sasl-ssl\n  - ssl_kerberos\n  \n  Note: when running an example with <playground run>, it is already\n  automatically done\n\n"
  else
    printf "playground start-environment - 🔐 Simply start an environment listed in http://tinyurl.com/y4ybbw32:\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground start-environment [OPTIONS]\n"
  printf "  playground start-environment --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--environment ENVIRONMENT")"
    printf "    🔐 The environment to start . \n    \n    - ccloud\n    - 2way-ssl\n    - kerberos\n    - ldap-authorizer-sasl-plain\n    - ldap-sasl-plain\n    - mdc-kerberos\n    - mdc-plaintext\n    - mdc-sasl-plain\n    - plaintext\n    - rbac-sasl-plain\n    - sasl-plain\n    - sasl-scram\n    - sasl-ssl\n    - ssl_kerberos\n    \n    Default is plaintext\n"
    printf "    %s\n" "Allowed: ccloud, 2way-ssl, kerberos, ldap-authorizer-sasl-plain, ldap-sasl-plain, mdc-kerberos, mdc-plaintext, mdc-sasl-plain, plaintext, rbac-sasl-plain, sasl-plain, sasl-scram, sasl-ssl, ssl_kerberos"
    printf "    %s\n" "Default: plaintext"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--wait-for-control-center")"
    printf "    😴 Wait for control-center instead of connect\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--docker-compose-override-file, -f DOCKER-COMPOSE-OVERRIDE-FILE")"
    printf "    🔖 docker-compose override file\n    \n    ❕ It must be absolute full path\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground start-environment\n"
    printf "  playground start-environment --environment rbac-sasl-plain\n"
    echo

  fi
}

# :command.usage
playground_switch_ccloud_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground switch-ccloud\n\n"
    printf "  🌩️  Switch to ccloud environment.\n  \n  It will bootstrap ccloud environment based on your previously ran ccloud\n  example.\n\n"
  else
    printf "playground switch-ccloud - 🌩️  Switch to ccloud environment.\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground switch-ccloud\n"
  printf "  playground switch-ccloud --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_switch_back_usage() {
  printf "playground switch-back - 💺  Switch back from previous environment before switch-ccloud was called.\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground switch-back\n"
  printf "  playground switch-back --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_update_version_usage() {
  printf "playground update-version - ✨ Update current confluent platform components (all with --tag or only connect with --connect-tag) or connector(s) with new version(s)\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground update-version [OPTIONS]\n"
  printf "  playground update-version --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--tag TAG")"
    printf "    🎯 Confluent Platform (CP) version to use. Applies to all components (broker,\n    connect, schema registry, ksqlDB, etc...)\n    \n    It sets TAG environment variable\n    \n    Must be greater or equal to 5.3.0\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connect-tag CONNECT_TAG")"
    printf "    🔗 Confluent Platform (CP) version to use. Applies to connect only.\n    \n    It sets CP_CONNECT_TAG environment variable\n    \n    Must be greater or equal to 5.3.0\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-tag CONNECTOR_TAG")"
    printf "    🔗 Connector version to use\n    \n    By default, for each connector, the latest available version on Confluent\n    Hub is used\n    \n    🎓 Tip: set to \" \" in order to select the version dynamically\n"
    printf "    %s\n" "Conflicts: --connector-zip"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-zip CONNECTOR_ZIP")"
    printf "    🤐 Connector zip to use\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion \n            use playground config folder_zip_or_jar <folder1> <folder2>...\n    (default is home folder and current folder is always included) to configure\n    where to search the files\n            use <option+enter> to use the value you typed manually\n"
    printf "    %s\n" "Conflicts: --connector-tag"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-jar CONNECTOR_JAR")"
    printf "    🤎 Connector jar to use\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion \n            use playground config folder_zip_or_jar <folder1> <folder2>...\n    (default is home folder and current folder is always included) to configure\n    where to search the files\n            use <option+enter> to use the value you typed manually\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground update-version (interactive mode)\n"
    printf "  playground update-version --tag 6.2.0 --connector-tag=2.5.12,10.5.7\n"
    printf "  playground update-version --connect-tag 6.2.0 --connector-tag=2.5.12,10.5.7\n"
    echo

  fi
}

# :command.usage
playground_open_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground open\n\n"
    printf "  👐 When --file is not provided, simply open last example you ran with\n  <playground run>\n  \n  Otherwise, open any file from the playground using --file.\n\n"
  else
    printf "playground open - 👐 When --file is not provided, simply open last example you ran with <playground run>\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground open [OPTIONS]\n"
  printf "  playground open --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--file, -f FILE")"
    printf "    🔎 Search any file and open it.\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n            use <option+enter> to use the value you typed manually\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--open-docker-compose")"
    printf "    🐳 Also open associated docker-compose file for the current example\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_stop_usage() {
  printf "playground stop - 🛑 Stop currently running example\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground stop\n"
  printf "  playground stop --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_remove_all_docker_images_usage() {
  printf "playground remove-all-docker-images - 🧨 Remove all docker images (including docker volumes)\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground remove-all-docker-images\n"
  printf "  playground remove-all-docker-images --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_remove_cp_docker_images_usage() {
  printf "playground remove-cp-docker-images - 🧹 Remove all Confluent Platform docker images related to a version installed locally (a confirmation will be required for every version present)\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground remove-cp-docker-images [OPTIONS]\n"
  printf "  playground remove-cp-docker-images --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--version VERSION")"
    printf "    🔢 Specific version to remove\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_refresh_cp_docker_images_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground refresh-cp-docker-images\n\n"
    printf "  🔄 Refresh (pull from Docker) all Confluent Platform docker images related to a\n  version installed locally\n  \n      It also refreshes images for aws, gcp and azure cli\n\n"
  else
    printf "playground refresh-cp-docker-images - 🔄 Refresh (pull from Docker) all Confluent Platform docker images related to a version installed locally\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground refresh-cp-docker-images [OPTIONS]\n"
  printf "  playground refresh-cp-docker-images --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--version VERSION (required)")"
    printf "    🔢 Specific version to pull\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_cleanup_cloud_details_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground cleanup-cloud-details\n\n"
    printf "  🧼 playground is actively caching ccloud details\n  (https://kafka-docker-playground.io/#/how-to-use?id=%%f0%%9f%%8c%%a4%%ef%%b8%%8f-confluent-cloud-examples)\n     use this command if you notice that the playground is using unexpected\n  ccloud details\n\n"
  else
    printf "playground cleanup-cloud-details - 🧼 playground is actively caching ccloud details (https://kafka-docker-playground.io/#/how-to-use?id=%%f0%%9f%%8c%%a4%%ef%%b8%%8f-confluent-cloud-examples)\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground cleanup-cloud-details\n"
  printf "  playground cleanup-cloud-details --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_open_docs_usage() {
  printf "playground open-docs - 🧑‍🎓 Open Confluent documentation of currently running example\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground open-docs [OPTIONS]\n"
  printf "  playground open-docs --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--only-show-url")"
    printf "    🌐 Only show url\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_open_changelog_usage() {
  printf "playground open-changelog - 📜 Open playground changelog (https://kafka-docker-playground.io/#/changelog)\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground open-changelog [OPTIONS]\n"
  printf "  playground open-changelog --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--only-show-url")"
    printf "    🌐 Only show url\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_cleanup_cloud_resources_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground cleanup-cloud-resources\n\n"
    printf "  🧹 Cleanup cloud resources that were created by running examples from the\n  playground\n  \n  ❗it will remove all resources created by the playground, including topics,\n  connectors, clusters, buckets, redshift cluster, etc...\n\n"
  else
    printf "playground cleanup-cloud-resources - 🧹 Cleanup cloud resources that were created by running examples from the playground\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground cleanup-cloud-resources [OPTIONS]\n"
  printf "  playground cleanup-cloud-resources --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--force")"
    printf "    ☢️ do not ask for confirmation\n    \n    ❗use with caution\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--resource RESOURCE (repeatable)")"
    printf "    🛁 resource to cleanup\n    \n    If not provided, all of them are cleaned up\n    \n    🎓 Tip: you can pass multiple resources by specifying --resource multiple\n    times\n"
    printf "    %s\n" "Allowed: aws, gcp, azure, ccloud, salesforce"
    printf "    %s\n" "Default: aws, gcp, azure, ccloud, salesforce"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_environment_variables
    printf "%s\n" "$(bold "Environment Variables:")"

    # :environment_variable.usage
    printf "  %s\n" "$(cyan "AZ_USER")"
    printf "    Azure user\n"
    echo

    # :environment_variable.usage
    printf "  %s\n" "$(cyan "AZ_PASS")"
    printf "    Azure password\n"
    echo

    # :environment_variable.usage
    printf "  %s\n" "$(cyan "GCP_PROJECT")"
    printf "    GCP project\n"
    echo

    # :environment_variable.usage
    printf "  %s\n" "$(cyan "AWS_ACCESS_KEY_ID")"
    printf "    AWS access key id\n"
    echo

    # :environment_variable.usage
    printf "  %s\n" "$(cyan "AWS_SECRET_ACCESS_KEY")"
    printf "    AWS secret access key\n"
    echo

    # :environment_variable.usage
    printf "  %s\n" "$(cyan "GCP_KEYFILE_CONTENT")"
    printf "    GCP keyfile (generated with \"cat keyfile.json | jq -aRs .\")\n"
    echo

  fi
}

# :command.usage
playground_repro_usage() {
  printf "playground repro - 👷‍♂️ Reproduction model commands\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground repro COMMAND\n"
  printf "  playground repro [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   📤 Export as tgz file uncommitted reproduction models from the folder of current reproduction model\n" "$(green "export")   "
  printf "  %s   📥 Import tgz file which was created with export command\n" "$(green "import")   "
  printf "  %s   🛠  Bootstrap reproduction model, just run <playground repro bootstrap> !\n" "$(green "bootstrap")"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_environment_variables
    printf "%s\n" "$(bold "Environment Variables:")"

    # :environment_variable.usage
    printf "  %s\n" "$(cyan "OUTPUT_FOLDER")"
    printf "    📁 Output folder where to generate bootstrapped files\n"
    printf "    %s\n" "Default: reproduction-models"
    echo

  fi
}

# :command.usage
playground_repro_export_usage() {
  printf "playground repro export - 📤 Export as tgz file uncommitted reproduction models from the folder of current reproduction model\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground repro export [OPTIONS]\n"
  printf "  playground repro export --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--all")"
    printf "    Export all uncommitted reproduction models\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_repro_import_usage() {
  printf "playground repro import - 📥 Import tgz file which was created with export command\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground repro import [OPTIONS]\n"
  printf "  playground repro import --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--file, -f FILE")"
    printf "    🤐 playground_repro_export.tgz file\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion \n            use playground config folder_zip_or_jar <folder1> <folder2>...\n    (default is home folder and current folder is always included) to configure\n    where to search the files\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_repro_bootstrap_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground repro bootstrap\n\n"
    printf "  🛠  Bootstrap reproduction model, just run <playground repro bootstrap> !\n  \n  🔥 HIGHLY RECOMMENDED: start in interactive mode by simple running <playground\n  repro bootstrap> !\n  \n  👉 Check documentation\n  https://kafka-docker-playground.io/#/reusables?id=%%f0%%9f%%9b%%a0-bootstrap-reproduction-model\n\n"
  else
    printf "playground repro bootstrap - 🛠  Bootstrap reproduction model, just run <playground repro bootstrap> !\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground repro bootstrap [OPTIONS]\n"
  printf "  playground repro bootstrap --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--file, -f FILE")"
    printf "    🔖 Example file to use as basis, if not set, currently running example is\n    used\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--description, -d DESCRIPTION")"
    printf "    💭 Description for the reproduction model\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--custom-smt")"
    printf "    🔧 Add a custom SMT (which is a no-op)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--pipeline SINK_FILE (repeatable)")"
    printf "    🔖 Sink example file to use for creating a pipeline. multiple --pipeline\n    flags can be used to create a pipeline with multiple sinks.\n    \n    ❕ It must be absolute full path. \n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    printf "    %s\n" "Conflicts: --producer"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground repro bootstrap (interactive mode)\n"
    echo

  fi
}

# :command.usage
playground_get_docker_compose_usage() {
  printf "playground get-docker-compose - 🐋 Get docker-compose\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-docker-compose\n"
  printf "  playground get-docker-compose --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_schema_usage() {
  printf "playground schema - 🔰 Schema commands\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema COMMAND\n"
  printf "  playground schema [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "Schema commands:")"
  printf "  %s   🔰 Get all schemas versions for specified subject (if --subject is not specified, all subjects will be used)\n" "$(green "get")              "
  printf "  %s   ⏺️ Register a schema in specified subject\n" "$(green "register")         "
  printf "  %s   🛡️ Get subject-level compatibility\n" "$(green "get-compatibility")"
  printf "  %s   🛡️ Set subject-level compatibility\n" "$(green "set-compatibility")"
  printf "  %s   🔏 Get subject-level mode\n" "$(green "get-mode")         "
  printf "  %s   🔏 Set subject-level mode\n" "$(green "set-mode")         "
  printf "  %s   🧽 Set normalize at schema registry level\n" "$(green "set-normalize")    "
  printf "  %s   🧟 Delete schema\n" "$(green "delete")           "
  printf "  %s   🪄 Derive a schema based on payload\n" "$(green "derive-schema")    "
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_schema_get_usage() {
  printf "playground schema get - 🔰 Get all schemas versions for specified subject (if --subject is not specified, all subjects will be used)\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema get [OPTIONS]\n"
  printf "  playground schema get --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--subject SUBJECT")"
    printf "    📛 Subject name\n"
    printf "    %s\n" "Conflicts: id"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--id ID")"
    printf "    💯 Schema id\n"
    printf "    %s\n" "Conflicts: subject, deleted"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--deleted")"
    printf "    🧟 Include soft deleted subjects\n"
    printf "    %s\n" "Conflicts: id"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground schema get\n"
    printf "  playground schema get --subject <SUBJECT>\n"
    printf "  playground schema get --deleted\n"
    echo

  fi
}

# :command.usage
playground_schema_register_usage() {
  printf "playground schema register - ⏺️ Register a schema in specified subject\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema register [OPTIONS]\n"
  printf "  playground schema register --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--subject SUBJECT (required)")"
    printf "    📛 Subject name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--schema SCHEMA")"
    printf "    🔥 You can either:\n    \n    * Set your own schema (avro, json-schema, protobuf) with stdin (see example\n    section).\n    \n    * Use completion to select predefined schemas (or use your own schema file)\n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    printf "    %s\n" "Default: -"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--id ID")"
    printf "    ☢️ Force schema id\n    \n    ❗it will replace any schema which already exists at given id\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--metadata-property METADATA-PROPERTY (repeatable)")"
    printf "    🟡 Add metadata properties to schema contract\n    \n    See docs:\n    https://docs.confluent.io/platform/current/schema-registry/fundamentals/data-contracts.html#metadata-properties\n    \n    🎓 Tip: you can pass multiple properties by specifying --metadata-property\n    multiple times\n    \n    Example: --metadata-property \"metadata1=value\" --metadata-property\n    \"metadata2=value\"\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground schema register --subject test-protobuf << 'EOF'\nsyntax = \"proto3\";\n\npackage com.github.vdesabou;\n\nmessage Customer {\n    int64 count = 1;\n    string first_name = 2;\n    string last_name = 3;\n    string address = 4;\n}\nEOF\n  \n  playground schema register --subject test-avro --metadata-property test=test\n  --metadata-property test2=test << 'EOF'\n{\n    \"type\": \"record\",\n    \"namespace\": \"com.github.vdesabou\",\n    \"name\": \"Customer\",\n    \"fields\": [\n        {\n            \"name\": \"count\",\n            \"type\": \"long\",\n            \"doc\": \"count\"\n        },\n        {\n            \"name\": \"first_name\",\n            \"type\": \"string\",\n            \"doc\": \"First Name of Customer\"\n        },\n        {\n            \"name\": \"last_name\",\n            \"type\": \"string\",\n            \"doc\": \"Last Name of Customer\"\n        },\n        {\n            \"name\": \"address\",\n            \"type\": \"string\",\n            \"doc\": \"Address of Customer\"\n        }\n    ]\n}\nEOF\n"
echo

fi
}

# :command.usage
playground_schema_get_compatibility_usage() {
  printf "playground schema get-compatibility - 🛡️ Get subject-level compatibility\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema get-compatibility [OPTIONS]\n"
  printf "  playground schema get-compatibility --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--subject SUBJECT (required)")"
    printf "    📛 Subject name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_schema_set_compatibility_usage() {
  printf "playground schema set-compatibility - 🛡️ Set subject-level compatibility\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema set-compatibility [OPTIONS]\n"
  printf "  playground schema set-compatibility --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--subject SUBJECT (required)")"
    printf "    📛 Subject name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--compatibility COMPATIBILITY (required)")"
    printf "    Schema Registry compatibility rule\n"
    printf "    %s\n" "Allowed: BACKWARD, BACKWARD_TRANSITIVE, FORWARD, FORWARD_TRANSITIVE, FULL, FULL_TRANSITIVE, NONE"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_schema_get_mode_usage() {
  printf "playground schema get-mode - 🔏 Get subject-level mode\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema get-mode [OPTIONS]\n"
  printf "  playground schema get-mode --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--subject SUBJECT (required)")"
    printf "    📛 Subject name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_schema_set_mode_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground schema set-mode\n\n"
    printf "  🔏 Set subject-level mode\n  \n  To enable mode changes on a Schema Registry cluster, you must also set\n  mode.mutability=true in the Schema Registry properties file before starting\n  Schema Registry\n\n"
  else
    printf "playground schema set-mode - 🔏 Set subject-level mode\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema set-mode [OPTIONS]\n"
  printf "  playground schema set-mode --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--subject SUBJECT (required)")"
    printf "    📛 Subject name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--mode MODE (required)")"
    printf "    Schema Registry mode\n"
    printf "    %s\n" "Allowed: IMPORT, READONLY, READWRITE"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_schema_set_normalize_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground schema set-normalize\n\n"
    printf "  🧽 Set normalize at schema registry level\n  \n  See\n  https://docs.confluent.io/platform/current/schema-registry/fundamentals/serdes-develop/index.html#schema-normalization\n\n"
  else
    printf "playground schema set-normalize - 🧽 Set normalize at schema registry level\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema set-normalize [OPTIONS]\n"
  printf "  playground schema set-normalize --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--value VALUE (required)")"
    printf "    true or false\n"
    printf "    %s\n" "Allowed: true, false"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_schema_delete_usage() {
  printf "playground schema delete - 🧟 Delete schema\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema delete [OPTIONS]\n"
  printf "  playground schema delete --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--subject SUBJECT")"
    printf "    📛 Subject name to delete:\n      \n      if --version is provided, only that version will be deleted. Otherwise the\n    complete subject will be deleted\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--version VERSION")"
    printf "    🔢 Schema version of the provided subject to delete\n    \n    Can only be used when --subject is provided\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--permanent")"
    printf "    💀 Hard delete (default is soft delete)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_schema_derive_schema_usage() {
  printf "playground schema derive-schema - 🪄 Derive a schema based on payload\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground schema derive-schema [OPTIONS]\n"
  printf "  playground schema derive-schema --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--payload PAYLOAD")"
    printf "    📦 Payload to derive schema from\n"
    printf "    %s\n" "Default: -"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--schema-type SCHEMA-TYPE")"
    printf "    🧩 Schema Registry schema \"type\":\n    \n    - AVRO\n    - JSON (json schema)\n    - PROTOBUF\n    \n    Default is AVRO\n"
    printf "    %s\n" "Allowed: AVRO, JSON, PROTOBUF"
    printf "    %s\n" "Default: AVRO"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground schema derive-schema << EOF\n{\"name\": \"Foo\", \"Age\": {\"int\": 12}}\n{\"name\": \"Bar\", \"Age\": {\"string\": \"12\"}}\n{\"sport\": \"Football\"}\n{\"_id\":{\"key\":\"AA\"},\"duration\":{\"numberInt\":\"240\"},\"employeeNumber\":{\"numberInt\":\"12345\"},\"isActive\":\"Y\",\"plannedAbsenceKey\":\"AA\",\"startTimeMin\":{\"numberLong\":\"11599920\"}}\nEOF\n  \n  playground schema derive-schema --payload '{\"sport\": \"Football\"}'\n  --schema-type PROTOBUF\n"
echo

fi
}

# :command.usage
playground_tcp_proxy_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground tcp-proxy\n\n"
    printf "  🏚 Zazkia TCP Proxy commands\n  \n  Simulate TCP connection issues (reset,delay,throttle,corrupt) using\n  emicklei/zazkia (https://github.com/emicklei/zazkia) TCP proxy\n\n"
  else
    printf "playground tcp-proxy - 🏚 Zazkia TCP Proxy commands\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground tcp-proxy COMMAND\n"
  printf "  playground tcp-proxy [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   💗 Start the TCP proxy and automatically replace connector config with zazkia hostname and port 49998\n" "$(green "start")                          "
  printf "  %s   🧲 Get Zazkia active TCP connections config and stats\n" "$(green "get-connections")                "
  printf "  %s   ⏲️ Add milliseconds delay to service response.\n" "$(green "delay")                          "
  printf "  %s   💔 Break sending the response to the client.\n" "$(green "break")                          "
  printf "  %s   ❌ Close the Zazkia active TCP connections\n" "$(green "close-connection")               "
  printf "  %s   🧹 Close all Zazkia TCP connections which are in error state (close all with error button in Zazkia UI)\n" "$(green "close-all-connection-with-error")"
  printf "  %s   🙅‍♂️ Change whether new connections can be accepted\n" "$(green "toggle-accept-connections")      "
  printf "  %s   ✅ Change whether reading data from the client is enabled.\n" "$(green "toggle-reads-client")            "
  printf "  %s   ✅ Change whether reading data from the service is enabled.\n" "$(green "toggle-reads-service")           "
  printf "  %s   ✅ Change whether writing data to the client is enabled.\n" "$(green "toggle-writes-client")           "
  printf "  %s   ✅ Change whether reading data to the service is enabled.\n" "$(green "toggle-writes-service")          "
  printf "  %s   🌐 Just open Zazkia UI (http://localhost:9191) in your browser\n" "$(green "open-ui")                        "
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_tcp_proxy_start_usage() {
  printf "playground tcp-proxy start - 💗 Start the TCP proxy and automatically replace connector config with zazkia hostname and port 49998\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground tcp-proxy start [OPTIONS]\n"
  printf "  playground tcp-proxy start --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--hostname HOSTNAME (required)")"
    printf "    Hostname used by the tcp proxy to forward request\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--port PORT (required)")"
    printf "    Port used by the tcp proxy to forward request\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--throttle-service-response THROTTLE-SERVICE-RESPONSE")"
    printf "    🐌 Throttle service response. This is bytes per second.\n"
    printf "    %s\n" "Default: 0"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--delay-service-response DELAY-SERVICE-RESPONSE")"
    printf "    ⏲️ Add milliseconds delay to service response. Default is 0 ms.\n"
    printf "    %s\n" "Default: 0"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--break-service-response BREAK-SERVICE-RESPONSE")"
    printf "    💔 Percentage of broken connections. Default is 0%%.\n"
    printf "    %s\n" "Default: 0"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--service-response-corrupt")"
    printf "    🦹‍♂️ Corrupt service response with random mangled bytes. By default, there\n    is no corruption.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--skip-automatic-connector-config")"
    printf "    🤖 By default, script will attempt to modify automatically the running\n    connector config to use Zazkia proxy.\n    \n    This flag allows to skip this automatic configuration (only useful if you\n    want to manually update connector config with zazkia tcp proxy details)\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground tcp-proxy start --hostname mysql --port 3306\n"
    echo

  fi
}

# :command.usage
playground_tcp_proxy_get_connections_usage() {
  printf "playground tcp-proxy get-connections - 🧲 Get Zazkia active TCP connections config and stats\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground tcp-proxy get-connections [OPTIONS]\n"
  printf "  playground tcp-proxy get-connections --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connection-id CONNECTION-ID")"
    printf "    🧲 Zazkia TCP connection id\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_tcp_proxy_delay_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground tcp-proxy delay\n\n"
    printf "  ⏲️ Add milliseconds delay to service response.\n  Set it to 0 to remove the delay.\n\n"
  else
    printf "playground tcp-proxy delay - ⏲️ Add milliseconds delay to service response.\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground tcp-proxy delay [OPTIONS]\n"
  printf "  playground tcp-proxy delay --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--delay-service-response DELAY-SERVICE-RESPONSE (required)")"
    printf "    ⏲️ Add milliseconds delay to service response.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connection-id CONNECTION-ID")"
    printf "    🧲 Zazkia TCP connection id\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_tcp_proxy_break_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground tcp-proxy break\n\n"
    printf "  💔 Break sending the response to the client.\n  Set it to 0%% to remove the delay.\n\n"
  else
    printf "playground tcp-proxy break - 💔 Break sending the response to the client.\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground tcp-proxy break [OPTIONS]\n"
  printf "  playground tcp-proxy break --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--break-service-response BREAK-SERVICE-RESPONSE (required)")"
    printf "    💔 Percentage of broken connections.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connection-id CONNECTION-ID")"
    printf "    🧲 Zazkia TCP connection id\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_tcp_proxy_close_connection_usage() {
  printf "playground tcp-proxy close-connection - ❌ Close the Zazkia active TCP connections\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground tcp-proxy close-connection [OPTIONS]\n"
  printf "  playground tcp-proxy close-connection --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connection-id CONNECTION-ID")"
    printf "    🧲 Zazkia TCP connection id\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_tcp_proxy_close_all_connection_with_error_usage() {
  printf "playground tcp-proxy close-all-connection-with-error - 🧹 Close all Zazkia TCP connections which are in error state (close all with error button in Zazkia UI)\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground tcp-proxy close-all-connection-with-error\n"
  printf "  playground tcp-proxy close-all-connection-with-error --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_tcp_proxy_toggle_accept_connections_usage() {
  printf "playground tcp-proxy toggle-accept-connections - 🙅‍♂️ Change whether new connections can be accepted\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground tcp-proxy toggle-accept-connections\n"
  printf "  playground tcp-proxy toggle-accept-connections --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_tcp_proxy_toggle_reads_client_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground tcp-proxy toggle-reads-client\n\n"
    printf "  ✅ Change whether reading data from the client is enabled.\n  \n    See diagram in https://github.com/emicklei/zazkia#how-does-it-work- (or\n  locally http://localhost:9191/help.html)\n\n"
  else
    printf "playground tcp-proxy toggle-reads-client - ✅ Change whether reading data from the client is enabled.\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground tcp-proxy toggle-reads-client [OPTIONS]\n"
  printf "  playground tcp-proxy toggle-reads-client --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connection-id CONNECTION-ID")"
    printf "    🧲 Zazkia TCP connection id\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_tcp_proxy_toggle_reads_service_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground tcp-proxy toggle-reads-service\n\n"
    printf "  ✅ Change whether reading data from the service is enabled.\n  \n    See diagram in https://github.com/emicklei/zazkia#how-does-it-work- (or\n  locally http://localhost:9191/help.html)\n\n"
  else
    printf "playground tcp-proxy toggle-reads-service - ✅ Change whether reading data from the service is enabled.\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground tcp-proxy toggle-reads-service [OPTIONS]\n"
  printf "  playground tcp-proxy toggle-reads-service --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connection-id CONNECTION-ID")"
    printf "    🧲 Zazkia TCP connection id\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_tcp_proxy_toggle_writes_client_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground tcp-proxy toggle-writes-client\n\n"
    printf "  ✅ Change whether writing data to the client is enabled.\n  \n    See diagram in https://github.com/emicklei/zazkia#how-does-it-work- (or\n  locally http://localhost:9191/help.html)\n\n"
  else
    printf "playground tcp-proxy toggle-writes-client - ✅ Change whether writing data to the client is enabled.\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground tcp-proxy toggle-writes-client [OPTIONS]\n"
  printf "  playground tcp-proxy toggle-writes-client --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connection-id CONNECTION-ID")"
    printf "    🧲 Zazkia TCP connection id\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_tcp_proxy_toggle_writes_service_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground tcp-proxy toggle-writes-service\n\n"
    printf "  ✅ Change whether reading data to the service is enabled.\n  \n    See diagram in https://github.com/emicklei/zazkia#how-does-it-work- (or\n  locally http://localhost:9191/help.html)\n\n"
  else
    printf "playground tcp-proxy toggle-writes-service - ✅ Change whether reading data to the service is enabled.\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground tcp-proxy toggle-writes-service [OPTIONS]\n"
  printf "  playground tcp-proxy toggle-writes-service --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connection-id CONNECTION-ID")"
    printf "    🧲 Zazkia TCP connection id\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_tcp_proxy_open_ui_usage() {
  printf "playground tcp-proxy open-ui - 🌐 Just open Zazkia UI (http://localhost:9191) in your browser\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground tcp-proxy open-ui\n"
  printf "  playground tcp-proxy open-ui --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_tools_usage() {
  printf "playground tools - 🧰 Tools commands\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground tools COMMAND\n"
  printf "  playground tools [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   🪄 Install a slightly modified version of \"Shell Script Command Completion\" Visual Studio Code extension (https://marketplace.visualstudio.com/items?itemName=tetradresearch.vscode-h2o)\n" "$(green "install-vscode-extension")"
  printf "  %s   🔖 Read provided avro file\n" "$(green "read-avro-file")          "
  printf "  %s   🔖 Read provided parquet file\n" "$(green "read-parquet-file")       "
  printf "  %s   🔐 Generate keys and certificates used for SSL\n" "$(green "certs-create")            "
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_tools_install_vscode_extension_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground tools install-vscode-extension\n\n"
    printf "  🪄 Install a slightly modified version of \"Shell Script Command Completion\"\n  Visual Studio Code extension\n  (https://marketplace.visualstudio.com/items?itemName=tetradresearch.vscode-h2o)\n  \n  After installation, install \"playground\" command:\n  \n  * Go on a .sh file\n  \n  * Type Ctrl+Shift+P (or ⌘+⇧+P on macOS) and choose \"Shell Completion: Load\n  Command Spec (experimental)\"\" and then type \"playground\"\n  \n  👉 Check documentation\n  https://kafka-docker-playground.io/#/cli?id=%%f0%%9f%%aa%%84-setup-shell-script-command-completion-visual-studio-code-extension\n\n"
  else
    printf "playground tools install-vscode-extension - 🪄 Install a slightly modified version of \"Shell Script Command Completion\" Visual Studio Code extension (https://marketplace.visualstudio.com/items?itemName=tetradresearch.vscode-h2o)\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground tools install-vscode-extension\n"
  printf "  playground tools install-vscode-extension --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground tools install-vscode-extension\n"
    echo

  fi
}

# :command.usage
playground_tools_read_avro_file_usage() {
  printf "playground tools read-avro-file - 🔖 Read provided avro file\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground tools read-avro-file [OPTIONS]\n"
  printf "  playground tools read-avro-file --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--file, -f FILE")"
    printf "    🔖 Avro file to read\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n            use <option+enter> to use the value you typed manually\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_tools_read_parquet_file_usage() {
  printf "playground tools read-parquet-file - 🔖 Read provided parquet file\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground tools read-parquet-file [OPTIONS]\n"
  printf "  playground tools read-parquet-file --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--file, -f FILE")"
    printf "    🔖 Parquet file to read\n    \n    ❕ It must be absolute full path\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n            use <option+enter> to use the value you typed manually\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_tools_certs_create_usage() {
  printf "playground tools certs-create - 🔐 Generate keys and certificates used for SSL\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground tools certs-create [OPTIONS]\n"
  printf "  playground tools certs-create --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container CONTAINER (repeatable)")"
    printf "    🐳 container name\n    \n    🎓 Tip: you can pass multiple containers by specifying --container multiple\n    times\n"
    printf "    %s\n" "Default: broker, broker2, broker3, client, schema-registry, restproxy, connect, connect2, connect3, control-center, clientrestproxy, ksqldb-server, conduktor"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--output-folder FOLDER (required)")"
    printf "    📁 Folder where certificates are created\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_debug_usage() {
  printf "playground debug - 🐞 Debug commands\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug COMMAND\n"
  printf "  playground debug [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   ✨ Enable java remote debugging for container\n" "$(green "enable-remote-debugging")"
  printf "  %s   🔐 Testing TLS/SSL encryption using https://testssl.sh/\n" "$(green "testssl")                "
  printf "  %s   ⛑️ Generate a diagnostic bundle with Diagnostics Bundle Tool\n" "$(green "generate-diagnostics")   "
  printf "  %s   🎯 Take a java thread dump\n" "$(green "thread-dump")            "
  printf "  %s   👻 Take a heap dump\n" "$(green "heap-dump")              "
  printf "  %s   🕵️‍♂️ Take a tcp dump (sniffing network)\n" "$(green "tcp-dump")               "
  printf "  %s   🚫 Blocking traffic using iptables\n" "$(green "block-traffic")          "
  printf "  %s   🤎 JVM arguments for SSL, Kerberos or Class Loading\n" "$(green "java-debug")             "
  printf "  %s   ✂️ jscissors is an instrumentation framework and can help to analyse control flow and perform some specific logging\n" "$(green "jscissors")              "
  printf "  %s   🛩️ Record flight recorder\n" "$(green "flight-recorder")        "
  printf "  %s   🧬 Set log level for any package\n" "$(green "log-level")              "
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_debug_enable_remote_debugging_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug enable-remote-debugging\n\n"
    printf "  ✨ Enable java remote debugging for container\n  \n  👉 Check documentation\n  https://kafka-docker-playground.io/#/reusables?id=%%e2%%9c%%a8-remote-debugging\n\n"
  else
    printf "playground debug enable-remote-debugging - ✨ Enable java remote debugging for container\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug enable-remote-debugging [OPTIONS]\n"
  printf "  playground debug enable-remote-debugging --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER (repeatable)")"
    printf "    🐳 Container name\n    \n    🎓 Tip: you can pass multiple containers by specifying --container multiple\n    times\n"
    printf "    %s\n" "Default: connect"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug enable-remote-debugging\n"
    printf "  playground debug enable-remote-debugging --container broker\n"
    printf "  playground debug enable-remote-debugging -c broker\n"
    printf "  playground debug enable-remote-debugging -c connect -c broker\n"
    printf "  playground debug enable-remote-debugging --container schema-registry\n  --container ksqldb-server --container control-center\n"
    echo

  fi
}

# :command.usage
playground_debug_testssl_usage() {
  printf "playground debug testssl - 🔐 Testing TLS/SSL encryption using https://testssl.sh/\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug testssl [OPTIONS] [--] [TESTSSL ARGUMENTS...]\n"
  printf "  playground debug testssl --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--uri URI (required)")"
    printf "    host|host:port|URL|URL:port   port 443 is default, URL can only contain\n    HTTPS protocol\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    echo "  TESTSSL ARGUMENTS..."
    printf "    arguments to pass to testssl, see https://testssl.sh for all options\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug testssl --uri \"https://google.com\" --fast\n"
    printf "  playground debug testssl --uri \"pkc-xxxx.us-west-2.aws.confluent.cloud:9092\"\n"
    echo

  fi
}

# :command.usage
playground_debug_generate_diagnostics_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug generate-diagnostics\n\n"
    printf "  ⛑️ Generate a diagnostic bundle with Diagnostics Bundle Tool\n  \n  ⚠️ only connect and broker containers are supported for now\n  \n  see\n  https://docs.confluent.io/platform/current/tools/diagnostics-tool.html#collect-diagnostics\n\n"
  else
    printf "playground debug generate-diagnostics - ⛑️ Generate a diagnostic bundle with Diagnostics Bundle Tool\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug generate-diagnostics [OPTIONS]\n"
  printf "  playground debug generate-diagnostics --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER (repeatable)")"
    printf "    🐳 Container name\n    \n    🎓 Tip: you can pass multiple containers by specifying --container multiple\n    times\n"
    printf "    %s\n" "Default: connect"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug generate-diagnostics\n"
    printf "  playground debug generate-diagnostics --container broker\n"
    echo

  fi
}

# :command.usage
playground_debug_thread_dump_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug thread-dump\n\n"
    printf "  🎯 Take a java thread dump\n  \n  🔖 It will save output to a file and open with text editor set with playground\n  config editor <editor> (default is code)\n\n"
  else
    printf "playground debug thread-dump - 🎯 Take a java thread dump\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug thread-dump [OPTIONS]\n"
  printf "  playground debug thread-dump --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER (repeatable)")"
    printf "    🐳 Container name\n    \n    🎓 Tip: you can pass multiple containers by specifying --container multiple\n    times\n"
    printf "    %s\n" "Default: connect"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug thread-dump\n"
    printf "  playground debug thread-dump --container broker\n"
    printf "  playground debug thread-dump -c connect -c broker\n"
    printf "  playground debug thread-dump --container schema-registry --container\n  ksqldb-server\n"
    echo

  fi
}

# :command.usage
playground_debug_heap_dump_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug heap-dump\n\n"
    printf "  👻 Take a heap dump\n  \n  🔖 It will save output to a .hprof file. VisualVM (https://visualvm.github.io/)\n  or MAT (https://www.eclipse.org/mat/) can be used to read the file.\n  \n  It will run a full gc first. If you don't want this, use\n\n"
  else
    printf "playground debug heap-dump - 👻 Take a heap dump\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug heap-dump [OPTIONS]\n"
  printf "  playground debug heap-dump --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER (repeatable)")"
    printf "    🐳 Container name\n    \n    🎓 Tip: you can pass multiple containers by specifying --container multiple\n    times\n"
    printf "    %s\n" "Default: connect"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--live")"
    printf "    🧬 dump only live objects; if not specified, all objects in the heap are\n    dumped\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--histo")"
    printf "    📊 print histogram of java object heap\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug heap-dump\n"
    printf "  playground debug heap-dump --container broker\n"
    printf "  playground debug heap-dump -c connect -c broker\n"
    printf "  playground debug heap-dump --container schema-registry --live\n"
    printf "  playground debug heap-dump -c connect -c broker --histo\n"
    echo

  fi
}

# :command.usage
playground_debug_tcp_dump_usage() {
  printf "playground debug tcp-dump - 🕵️‍♂️ Take a tcp dump (sniffing network)\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug tcp-dump [OPTIONS]\n"
  printf "  playground debug tcp-dump --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER (repeatable)")"
    printf "    🐳 Container name\n    \n    🎓 Tip: you can pass multiple containers by specifying --container multiple\n    times\n"
    printf "    %s\n" "Default: connect"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--port PORT")"
    printf "    Port on which tcp dump should be done, if not set sniffing is done on every\n    port\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--duration DURATION")"
    printf "    Duration of the dump (default is 30 seconds).\n"
    printf "    %s\n" "Default: 30"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug tcp-dump --container control-center --port 9021 --duration 60\n"
    echo

  fi
}

# :command.usage
playground_debug_block_traffic_usage() {
  printf "playground debug block-traffic - 🚫 Blocking traffic using iptables\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug block-traffic [OPTIONS]\n"
  printf "  playground debug block-traffic --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER (repeatable)")"
    printf "    🐳 Container name\n    \n    🎓 Tip: you can pass multiple containers by specifying --container multiple\n    times\n"
    printf "    %s\n" "Default: connect"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--destination DESTINATION (required)")"
    printf "    Destination: it could be an ip address, a container name or a hostname\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--port PORT")"
    printf "    Port on which tcp traffic should be blocked\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--action ACTION (required)")"
    printf "    🟢 start or stop\n"
    printf "    %s\n" "Allowed: start, stop"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug block-traffic --destination google.com --action start\n"
    printf "  playground debug block-traffic --container broker --destination zookeeper\n  --action start\n"
    printf "  playground debug block-traffic -c broker -c connect --destination zookeeper\n  --action start\n"
    printf "  playground debug block-traffic --container schema-registry --destination\n  broker --port 9092 --action start\n"
    printf "  playground debug block-traffic -c connect -c ksqldb-server --destination\n  schema-registry --action stop\n"
    echo

  fi
}

# :command.usage
playground_debug_java_debug_usage() {
  printf "playground debug java-debug - 🤎 JVM arguments for SSL, Kerberos or Class Loading\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug java-debug [OPTIONS]\n"
  printf "  playground debug java-debug --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER (repeatable)")"
    printf "    🐳 Container name\n    \n    🎓 Tip: you can pass multiple containers by specifying --container multiple\n    times\n"
    printf "    %s\n" "Default: connect"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--type TYPE (required)")"
    printf "    - ssl_all: Enable all SSL debugging, i.e -Djavax.net.debug=all\n    - ssl_handshake: Enable SSL handshake debugging, i.e\n    -Djavax.net.debug=ssl:handshake\n    - class_loading: Enable class loading debugging, i.e -verbose:class\n    - kerberos: Enable Kerberos debugging, i.e -Dsun.security.krb5.debug=true\n"
    printf "    %s\n" "Allowed: ssl_all, ssl_handshake, class_loading, kerberos"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--action ACTION")"
    printf "    🟢 enable or disable\n"
    printf "    %s\n" "Allowed: enable, disable"
    printf "    %s\n" "Default: enable"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug java-debug --type class_loading\n"
    printf "  playground debug java-debug --container broker --action start\n"
    echo

  fi
}

# :command.usage
playground_debug_jscissors_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug jscissors\n\n"
    printf "  ✂️ jscissors is an instrumentation framework and can help to analyse control\n  flow and perform some specific logging\n  \n  * Control Flow Tracing: By dynamically instrumenting Java code, the tool\n  meticulously tracks the precise sequence of executed methods at runtime. This\n  capability offers invaluable insights into how an application navigates its\n  logic. The tool provides a way to generate a stack trace when a method is\n  called.\n  * Additional Logging: This enhanced logging capability provides a way to print\n  the input arguments to a method and return value from a method.\n  * Delve into heap area: Generating heap dump at a method call will be crucial\n  to analyze the state of JVM at a given point. The tool has capabilities to\n  generate thread dump as well to track the state of all the threads when a\n  method is called.\n\n"
  else
    printf "playground debug jscissors - ✂️ jscissors is an instrumentation framework and can help to analyse control flow and perform some specific logging\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug jscissors [OPTIONS]\n"
  printf "  playground debug jscissors --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER (repeatable)")"
    printf "    🐳 Container name\n    \n    🎓 Tip: you can pass multiple containers by specifying --container multiple\n    times\n"
    printf "    %s\n" "Default: connect"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--operation OPERATION (repeatable)")"
    printf "    🥼 operation to perform:\n    \n    * VALUES: print method input arguments\n    * RETURN_VALUE: print method return value\n    * THREADS: print thread dump when method is called\n    * HEAP: print heap dump when method is called\n    * STACK: print stack trace when method is called\n    * EXCEPTION_HEAP: print heap dump when an exception is thrown during method\n    execution\n    * DELAY: print time taken for method execution\n    \n    Default values: VALUES, RETURN_VALUE, DELAY and STACK\n    \n    🎓 Tip: you can pass multiple operations by specifying --operation multiple\n    times\n"
    printf "    %s\n" "Allowed: VALUES, RETURN_VALUE, THREADS, HEAP, STACK, EXCEPTION_HEAP, DELAY"
    printf "    %s\n" "Default: VALUES, RETURN_VALUE, DELAY, STACK"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--class CLASS (required)")"
    printf "    class name to instrument (it supports regex like oracle.jdbc.*)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--method METHOD")"
    printf "    method name to instrument (it supports regex like .*find.*)\n"
    printf "    %s\n" "Default: .*"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--action ACTION")"
    printf "    🟢 enable or disable\n"
    printf "    %s\n" "Allowed: enable, disable"
    printf "    %s\n" "Default: enable"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug jscissors\n"
    printf "  playground debug jscissors --container broker\n"
    echo

  fi
}

# :command.usage
playground_debug_flight_recorder_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground debug flight-recorder\n\n"
    printf "  🛩️ Record flight recorder\n  \n  Read more about it at https://www.baeldung.com/java-flight-recorder-monitoring\n  \n  Open the jfr file with JDK Mission Control JMC(https://jdk.java.net/jmc/)\n\n"
  else
    printf "playground debug flight-recorder - 🛩️ Record flight recorder\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug flight-recorder [OPTIONS]\n"
  printf "  playground debug flight-recorder --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER (repeatable)")"
    printf "    🐳 Container name\n    \n    🎓 Tip: you can pass multiple containers by specifying --container multiple\n    times\n"
    printf "    %s\n" "Default: connect"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--action ACTION")"
    printf "    🟢 enable or disable\n"
    printf "    %s\n" "Allowed: enable, disable"
    printf "    %s\n" "Default: enable"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug flight-recorder --action start\n"
    printf "  playground debug flight-recorder --action stop\n"
    echo

  fi
}

# :command.usage
playground_debug_log_level_usage() {
  printf "playground debug log-level - 🧬 Set log level for any package\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug log-level COMMAND\n"
  printf "  playground debug log-level [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   Get log levels\n" "$(green "get")"
  printf "  %s   Set log level for specific logger\n" "$(green "set")"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground debug log-level get\n"
    printf "  playground debug log-level get -p io.confluent.connect.oracle.cdc\n"
    printf "  playground debug log-level get --package io.confluent.connect.oracle.cdc\n"
    printf "  playground debug log-level set -p\n  io.confluent.connect.oracle.cdc.logging.LogUtils -l TRACE\n"
    echo

  fi
}

# :command.usage
playground_debug_log_level_get_usage() {
  printf "playground debug log-level get - Get log levels\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug log-level get [OPTIONS]\n"
  printf "  playground debug log-level get --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--package, -p PACKAGE")"
    printf "    Package name\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_debug_log_level_set_usage() {
  printf "playground debug log-level set - Set log level for specific logger\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground debug log-level set [OPTIONS]\n"
  printf "  playground debug log-level set --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--package, -p PACKAGE (required)")"
    printf "    📦 Package name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--level, -l LEVEL (required)")"
    printf "    ❕Log level\n"
    printf "    %s\n" "Allowed: INFO, WARN, DEBUG, TRACE"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_get_jmx_metrics_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground get-jmx-metrics\n\n"
    printf "  🔢 Get JMX metrics from a container\n  \n  👉 Check documentation\n  https://kafka-docker-playground.io/#/how-to-use?id=%%f0%%9f%%94%%a2-jmx-metrics\n\n"
  else
    printf "playground get-jmx-metrics - 🔢 Get JMX metrics from a container\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground get-jmx-metrics [OPTIONS]\n"
  printf "  playground get-jmx-metrics --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER (repeatable)")"
    printf "    🐳 Container name\n    \n    🎓 Tip: you can pass multiple containers by specifying --container multiple\n    times\n"
    printf "    %s\n" "Default: connect"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--open, -o")"
    printf "    🔖 Save output to a file and open with text editor set with playground config\n    editor <editor> (default is code)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--domain, -d DOMAIN")"
    printf "    Domain name\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground get-jmx-metrics --container connect\n"
    printf "  playground get-jmx-metrics --container connect --domain \"kafka.connect\n  kafka.consumer kafka.producer\"\n"
    printf "  playground get-jmx-metrics -c broker\n"
    printf "  playground get-jmx-metrics -c connect -c broker\n"
    printf "  playground get-jmx-metrics --container schema-registry --container\n  ksqldb-server --open\n"
    printf "  playground get-jmx-metrics -c broker -c connect --domain \"kafka.server\"\n"
    echo

  fi
}

# :command.usage
playground_container_usage() {
  printf "playground container - 🐳 Container commands\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container COMMAND\n"
  printf "  playground container [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   📝 Get properties file from a container\n" "$(green "get-properties")                 "
  echo
  printf "%s\n" "$(bold "Container commands:")"
  printf "  %s   💫 Recreate container(s)\n" "$(green "recreate")                       "
  printf "  %s   🖥️  Get ip address of running containers\n" "$(green "get-ip-addresses")               "
  printf "  %s   💀 Kill all containers\n" "$(green "kill-all")                       "
  printf "  %s   🕵️  Tail and follow container logs\n" "$(green "logs")                           "
  printf "  %s   🔥 Display all ERROR/FATAL logs in all containers. Useful for quick troubleshooting\n" "$(green "display-error-all-containers")   "
  printf "  %s   🛬 SSH into container\n" "$(green "ssh")                            "
  printf "  %s   🤎 Change java JDK version using Azul JDK (https://www.azul.com/downloads/#downloads-table-zulu)\n" "$(green "change-jdk")                     "
  printf "  %s   🪄 Execute command in a container\n" "$(green "exec")                           "
  printf "  %s   🔁 Restart a container\n" "$(green "restart")                        "
  printf "  %s   ⏸️  Pause a container\n" "$(green "pause")                          "
  printf "  %s   ⏯️  Resume a container\n" "$(green "resume")                         "
  printf "  %s   🔫 Kill a container\n" "$(green "kill")                           "
  printf "  %s   📦  Set environment variable(s) for a container\n" "$(green "set-environment-variables")      "
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_get_properties_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container get-properties\n\n"
    printf "  📝 Get properties file from a container\n  \n  👉 Check documentation\n  https://kafka-docker-playground.io/#/how-to-use?id=%%f0%%9f%%93%%9d-see-properties-file\n\n"
  else
    printf "playground container get-properties - 📝 Get properties file from a container\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container get-properties [OPTIONS]\n"
  printf "  playground container get-properties --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER (repeatable)")"
    printf "    🐳 Container name\n    \n    🎓 Tip: you can pass multiple containers by specifying --container multiple\n    times\n"
    printf "    %s\n" "Default: connect"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground get-properties\n"
    printf "  playground get-properties --container broker\n"
    printf "  playground get-properties -c broker\n"
    echo

  fi
}

# :command.usage
playground_container_recreate_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container recreate\n\n"
    printf "  💫 Recreate container(s)\n  \n  👉 Check documentation\n  https://kafka-docker-playground.io/#/how-to-use?id=%%e2%%99%%bb%%ef%%b8%%8f-re-create-containers\n\n"
  else
    printf "playground container recreate - 💫 Recreate container(s)\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container recreate [OPTIONS]\n"
  printf "  playground container recreate --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--ignore-current-versions")"
    printf "    Ignore current confluent platform version\n    \n    By default, the current version is used\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_get_ip_addresses_usage() {
  printf "playground container get-ip-addresses - 🖥️  Get ip address of running containers\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container get-ip-addresses\n"
  printf "  playground container get-ip-addresses --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground get-ip-address-container\n"
    echo

  fi
}

# :command.usage
playground_container_kill_all_usage() {
  printf "playground container kill-all - 💀 Kill all containers\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container kill-all\n"
  printf "  playground container kill-all --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_logs_usage() {
  printf "playground container logs - 🕵️  Tail and follow container logs\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container logs [OPTIONS]\n"
  printf "  playground container logs --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER (repeatable)")"
    printf "    🐳 Container name\n    \n    🎓 Tip: you can pass multiple containers by specifying --container multiple\n    times\n"
    printf "    %s\n" "Default: connect"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--open, -o")"
    printf "    🔖 Save output to a file and open with text editor set with playground config\n    editor <editor> (default is code)\n"
    printf "    %s\n" "Conflicts: --wait-for-log"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--wait-for-log, -w LOG")"
    printf "    😴 Wait until log appears\n"
    printf "    %s\n" "Conflicts: --open"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--max-wait, -m MAX_WAIT")"
    printf "    ⏳ Max time in seconds to wait when using --wait-for-log (default 600s)\n"
    printf "    %s\n" "Default: 600"
    printf "    %s\n" "Conflicts: --open"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground container logs --container connect\n"
    printf "  playground container logs -c connect --open\n"
    printf "  playground container logs -c connect --wait-for-log \"StackOverflowError\"\n"
    printf "  playground container logs -c connect -c broker\n"
    printf "  playground container logs --container schema-registry --container\n  ksqldb-server --open\n"
    printf "  playground container logs -c broker -c connect -c schema-registry\n"
    printf "  playground container logs -c connect -c broker --wait-for-log \"ERROR\"\n  --max-wait 120\n"
    echo

  fi
}

# :command.usage
playground_container_display_error_all_containers_usage() {
  printf "playground container display-error-all-containers - 🔥 Display all ERROR/FATAL logs in all containers. Useful for quick troubleshooting\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container display-error-all-containers\n"
  printf "  playground container display-error-all-containers --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_ssh_usage() {
  printf "playground container ssh - 🛬 SSH into container\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container ssh [OPTIONS]\n"
  printf "  playground container ssh --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER (repeatable)")"
    printf "    🐳 Container name\n    \n    🎓 Tip: you can pass multiple containers by specifying --container multiple\n    times\n"
    printf "    %s\n" "Default: connect"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--shell, -s SHELL")"
    printf "    💾 Shell to use (default is bash)\n"
    printf "    %s\n" "Allowed: bash, sh, ksh, zsh"
    printf "    %s\n" "Default: bash"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground ssh -c connect\n"
    printf "  playground ssh -c connect -s sh\n"
    printf "  playground ssh --container connect --shell sh\n"
    printf "  playground ssh -c broker\n"
    printf "  playground ssh --container schema-registry --shell zsh\n"
    echo

  fi
}

# :command.usage
playground_container_change_jdk_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container change-jdk\n\n"
    printf "  🤎 Change java JDK version using Azul JDK\n  (https://www.azul.com/downloads/#downloads-table-zulu)\n  \n  PS: It works for UBI8 docker images only\n\n"
  else
    printf "playground container change-jdk - 🤎 Change java JDK version using Azul JDK (https://www.azul.com/downloads/#downloads-table-zulu)\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container change-jdk [OPTIONS]\n"
  printf "  playground container change-jdk --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER (repeatable)")"
    printf "    🐳 Container name\n    \n    🎓 Tip: you can pass multiple containers by specifying --container multiple\n    times\n"
    printf "    %s\n" "Default: connect"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--version VERSION (required)")"
    printf "    🤎 JDK version to use\n"
    printf "    %s\n" "Allowed: 8, 11, 17, 21, 22"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground change-jdk --container connect --version 17\n"
    echo

  fi
}

# :command.usage
playground_container_exec_usage() {
  printf "playground container exec - 🪄 Execute command in a container\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container exec [OPTIONS]\n"
  printf "  playground container exec --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER (repeatable)")"
    printf "    🐳 Container name\n    \n    🎓 Tip: you can pass multiple containers by specifying --container multiple\n    times\n"
    printf "    %s\n" "Default: connect"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--command COMMAND (required)")"
    printf "    📲 Command to execute\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--root")"
    printf "    👑 Run command as root\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--shell SHELL")"
    printf "    💾 Shell to use (default is bash)\n"
    printf "    %s\n" "Allowed: bash, sh, ksh, zsh"
    printf "    %s\n" "Default: bash"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground exec -c connect -d \"date\"\n"
    printf "  playground exec -c connect -d \"whoami\" --root\n"
    printf "  playground exec --container connect --command \"whoami\" --shell sh\n"
    printf "  playground exec -c broker -c connect -d \"ps aux\"\n"
    printf "  playground exec --container schema-registry --container ksqldb-server\n  --command \"free -h\"\n"
    printf "  playground exec -c connect -c broker -d \"netstat -tuln\" --root\n"
    echo

  fi
}

# :command.usage
playground_container_restart_usage() {
  printf "playground container restart - 🔁 Restart a container\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container restart [OPTIONS]\n"
  printf "  playground container restart --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER (repeatable)")"
    printf "    🐳 Container name\n    \n    🎓 Tip: you can pass multiple containers by specifying --container multiple\n    times\n"
    printf "    %s\n" "Default: connect"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_pause_usage() {
  printf "playground container pause - ⏸️  Pause a container\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container pause [OPTIONS]\n"
  printf "  playground container pause --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER (repeatable)")"
    printf "    🐳 Container name\n    \n    🎓 Tip: you can pass multiple containers by specifying --container multiple\n    times\n"
    printf "    %s\n" "Default: connect"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_resume_usage() {
  printf "playground container resume - ⏯️  Resume a container\n\n"
  printf "Alias: unpause\n"
  echo

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container resume [OPTIONS]\n"
  printf "  playground container resume --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER (repeatable)")"
    printf "    🐳 Container name\n    \n    🎓 Tip: you can pass multiple containers by specifying --container multiple\n    times\n"
    printf "    %s\n" "Default: connect"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_kill_usage() {
  printf "playground container kill - 🔫 Kill a container\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container kill [OPTIONS]\n"
  printf "  playground container kill --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER (repeatable)")"
    printf "    🐳 Container name\n    \n    🎓 Tip: you can pass multiple containers by specifying --container multiple\n    times\n"
    printf "    %s\n" "Default: connect"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground container kill --container connect\n"
    printf "  playground container kill -c broker\n"
    printf "  playground container kill -c connect -c broker\n"
    printf "  playground container kill --container schema-registry --container\n  ksqldb-server --container control-center\n"
    echo

  fi
}

# :command.usage
playground_container_set_environment_variables_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground container set-environment-variables\n\n"
    printf "  📦  Set environment variable(s) for a container\n  \n  🎓 Tip: you can pass multiple environment variables by specifying --env\n  multiple times\n  \n  Example: --env \"KAFKA_OPTS: -verbose:class\" --env \"CONNECT_LOG4J_LOGGERS:\n  org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR,org.apache.kafka.connect.runtime.rest.RestServer=ERROR\"\n\n"
  else
    printf "playground container set-environment-variables - 📦  Set environment variable(s) for a container\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container set-environment-variables [OPTIONS]\n"
  printf "  playground container set-environment-variables --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--container, -c CONTAINER (repeatable)")"
    printf "    🐳 Container name\n    \n    🎓 Tip: you can pass multiple containers by specifying --container multiple\n    times\n"
    printf "    %s\n" "Default: connect"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--env ENV (repeatable)")"
    printf "    📦 Environment variables to set\n    \n    🎓 Tip: you can pass multiple environment variables by specifying --env\n    multiple times\n"
    printf "    %s\n" "Conflicts: --restore-original-values"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--restore-original-values")"
    printf "    🧽 Restore back original values before any changes was made\n"
    printf "    %s\n" "Conflicts: --env"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_container_wait_for_connect_rest_api_ready_usage() {
  printf "playground container wait-for-connect-rest-api-ready - 🚏 wait-for-connect-rest-api-ready\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground container wait-for-connect-rest-api-ready [OPTIONS]\n"
  printf "  playground container wait-for-connect-rest-api-ready --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--max-wait MAX_WAIT")"
    printf "    ⏳ Max time in seconds to wait\n"
    printf "    %s\n" "Default: 300"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_usage() {
  printf "playground topic - 🗳 Topic commands\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic COMMAND\n"
  printf "  playground topic [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "Topic commands:")"
  printf "  %s   💯 Get number of records in a topic\n" "$(green "get-number-records")      "
  printf "  %s   📭 Display content of __consumer_offsets topic\n" "$(green "display-consumer-offsets")"
  printf "  %s   🔘 List topics\n" "$(green "list")                    "
  printf "  %s   🔬 Describe topic\n" "$(green "describe")                "
  printf "  %s   🛡️ Change topic's schema compatibility\n" "$(green "set-schema-compatibility")"
  printf "  %s   📥 Consume topic from beginning\n" "$(green "consume")                 "
  printf "  %s   📤 Produce to a topic\n" "$(green "produce")                 "
  printf "  %s   🆕 Create topic\n" "$(green "create")                  "
  printf "  %s   ❌ Delete topic and associated schema/subject if applicable\n" "$(green "delete")                  "
  printf "  %s   🪛 Alter topic config\n" "$(green "alter")                   "
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_get_number_records_usage() {
  printf "playground topic get-number-records - 💯 Get number of records in a topic\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic get-number-records [OPTIONS]\n"
  printf "  playground topic get-number-records --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC")"
    printf "    🗳 Topic name\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground get-number-records --topic a-topic\n"
    printf "  playground get-number-records -t a-topic\n"
    echo

  fi
}

# :command.usage
playground_topic_display_consumer_offsets_usage() {
  printf "playground topic display-consumer-offsets - 📭 Display content of __consumer_offsets topic\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic display-consumer-offsets [OPTIONS]\n"
  printf "  playground topic display-consumer-offsets --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_list_usage() {
  printf "playground topic list - 🔘 List topics\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic list\n"
  printf "  playground topic list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_describe_usage() {
  printf "playground topic describe - 🔬 Describe topic\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic describe [OPTIONS]\n"
  printf "  playground topic describe --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC")"
    printf "    🗳 Topic name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_set_schema_compatibility_usage() {
  printf "playground topic set-schema-compatibility - 🛡️ Change topic's schema compatibility\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic set-schema-compatibility [OPTIONS]\n"
  printf "  playground topic set-schema-compatibility --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC")"
    printf "    🗳 Topic name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--compatibility COMPATIBILITY (required)")"
    printf "    Schema Registry compatibility rule\n"
    printf "    %s\n" "Allowed: BACKWARD, BACKWARD_TRANSITIVE, FORWARD, FORWARD_TRANSITIVE, FULL, FULL_TRANSITIVE, NONE"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_consume_usage() {
  printf "playground topic consume - 📥 Consume topic from beginning\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic consume [OPTIONS]\n"
  printf "  playground topic consume --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC")"
    printf "    🗳 Topic name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--max-messages MAX-MESSAGES")"
    printf "    Max number of messages to display (default is 100)\n    \n    You can use -1 to display all messages\n"
    printf "    %s\n" "Default: 100"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--min-expected-messages MIN-EXPECTED-MESSAGES")"
    printf "    Minimum expected number of messages to be present in topic, returns an error\n    if this is not the case\n    \n    Note: --topic should be specified in this case.\n"
    printf "    %s\n" "Default: 0"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--grep GREP")"
    printf "    Verify that topic content contains record which contains specified string\n"
    printf "    %s\n" "Default: "
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--timeout TIMEOUT")"
    printf "    Max number of seconds to wait when --min-expected-messages is used.\n    \n    Default is 60 seconds\n"
    printf "    %s\n" "Default: 60"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--tail")"
    printf "    Tail on logs.\n"
    printf "    %s\n" "Conflicts: --min-expected-messages, --max-messages, --open"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--plot-latencies-timestamp-field TIMESTAMP")"
    printf "    🗳 Timestamp field name that represents when record was created in source\n    system\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--key-subject KEY-SUBJECT")"
    printf "    📛 Subject for key in schema-registry to use (useful when data was produced\n    with --key-subject-name-strategy other than TopicNameStrategy)\n    \n    Note: --topic should be specified in this case.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--value-subject VALUE-SUBJECT")"
    printf "    📛 Subject for value in schema-registry to use (useful when data was produced\n    with --value-subject-name-strategy other than TopicNameStrategy)\n    \n    Note: --topic should be specified in this case.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--max-characters MAX-CHARACTERS")"
    printf "    Max characters per message to display (default is 3000)\n"
    printf "    %s\n" "Default: 3000"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--open, -o")"
    printf "    🔖 Save full dump of topic to a file and open with text editor set with\n    playground config editor <editor> (default is code)\n"
    printf "    %s\n" "Conflicts: --max-characters, --tail, --min-expected-messages"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_produce_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground topic produce\n\n"
    printf "  📤 Produce to a topic\n  \n  See video tutorial https://youtu.be/mbzHCewG_XE\n\n"
  else
    printf "playground topic produce - 📤 Produce to a topic\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic produce [OPTIONS]\n"
  printf "  playground topic produce --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--key KEY")"
    printf "    🗝️ Key to use. If not set, no key is used.\n    \n    🔥 You can either:\n    \n    * Set your own schema (avro, json-schema, protobuf) within single quotes\n    (see examples)\n    \n    * You can also generate json data using json or sql format using syntax from\n    https://github.com/MaterializeInc/datagen\n    \n    * Use completion to select predefined schemas (or use your own schema file)\n    🎓 Tip: use <tab> completion to trigger fzf completion\n    \n    * Directly set payload (\"%%g\" can be used to generate a counter)\n    \n    In case of 'raw' data (i.e not using schema):\n    \n    If the key contain a number, it will be used as starting point and\n    incremented for each record.\n    \n    Example: key1 will start with key1, then key2, etc..\n    Example: mykey-10-suffix will start with mykey-10-suffix then\n    mykey-11-suffix, etc..\n    \n    \"%%g\" can also be used to generate a counter\n    \n    Example: key%%g will start with key1, then key2, etc..\n    \n    Otherwise, the key will be same for all records.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--value VALUE")"
    printf "    🔥 You can either:\n    \n    * Set your own schema (avro, json-schema, protobuf) with stdin (see example\n    section).\n    \n    * You can also generate json data using json or sql format using syntax from\n    https://github.com/MaterializeInc/datagen\n    \n    * Use completion to select predefined schemas (or use your own schema file)\n    🎓 Tip: use <tab> completion to trigger fzf completion\n    \n    * Directly set payload (\"%%g\" can be used to generate a counter)\n"
    printf "    %s\n" "Default: -"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC (required)")"
    printf "    🗳 Topic name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--nb-messages NB-MESSAGES")"
    printf "    💯 Number of messages to produce (default is 1)\n       \n    🎓  - if > <value of --max-nb-messages-per-batch> (default 300000), messages\n    will be sent in batches of <value of --max-nb-messages-per-batch> (default\n    300000) records\n        - if you set it to -1, an infinite number of records will also be sent\n    in batches\n"
    printf "    %s\n" "Default: 1"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--max-nb-messages-per-batch MAX-NB-MESSAGES-PER-BATCH")"
    printf "    🔼 Max number of messages to send per batch when --nb-messages >\n    --max-nb-messages-per-batch\n       if --nb-messages is set to -1, this is the number of messages sent per\n    batch\n       default is 300000\n"
    printf "    %s\n" "Default: 300000"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--max-nb-messages-to-generate MAX-NB-MESSAGES-TO-GENERATE")"
    printf "    🔨 Max number of different messages to generate.\n    \n       - when protobuf is used, default is 50 as protobuf generation is really\n    slow\n       - when --record-size is set, default is 100\n       --when nb-messages is set to -1, default is 1000\n       - otherwise default is 100000\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--sleep-time-between-batch SLEEP-TIME-BETWEEN-BATCH")"
    printf "    💤 Sleep time in seconds between batches\n       default is 0\n"
    printf "    %s\n" "Default: 0"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--nb-partitions NB-PARTITIONS")"
    printf "    🔢 Number of partitions for the topic. (default is 1)\n    \n    ❌ Important: If topic is existing, it will be re-created before producing to\n    topic.\n"
    printf "    %s\n" "Default: 1"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--compression-codec COMPRESSION-CODEC")"
    printf "    🤐 The compression codec: either 'gzip', 'snappy', 'lz4', or 'zstd'\n    If not set, there is no compression\n"
    printf "    %s\n" "Allowed: gzip, snappy, lz4, zstd"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--compatibility COMPATIBILITY")"
    printf "    Schema Registry compatibility rule\n"
    printf "    %s\n" "Allowed: BACKWARD, BACKWARD_TRANSITIVE, FORWARD, FORWARD_TRANSITIVE, FULL, FULL_TRANSITIVE, NONE"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--key-subject-name-strategy KEY-SUBJECT-NAME-STRATEGY")"
    printf "    Key Subject Name Strategy\n"
    printf "    %s\n" "Allowed: TopicNameStrategy, RecordNameStrategy, TopicRecordNameStrategy"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--value-subject-name-strategy VALUE-SUBJECT-NAME-STRATEGY")"
    printf "    Value Subject Name Strategy\n"
    printf "    %s\n" "Allowed: TopicNameStrategy, RecordNameStrategy, TopicRecordNameStrategy"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--headers HEADERS")"
    printf "    🚏 Headers to use for all records. If not set, no header is used.\n    \n    Example: --headers \"header1:value1,header2:value2\"\n    \n    Note: CP 7.2+ is required.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--forced-key FORCED-KEY")"
    printf "    ☢️ Key to use for all records. \n    \n    🎓 Tip: use --generate-only first with avro, json-schema or protobuf to get\n    skeleton of messages and then use --forced-key to send the message you need.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--forced-value FORCED-VALUE")"
    printf "    ☢️ Value to use for all records. \n    \n    🎓 Tip: use --generate-only first with avro, json-schema or protobuf to get\n    skeleton of messages and then use --forced-value to send the message you\n    need.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--generate-only")"
    printf "    🚪 Only generate messages without sending to kafka topic.\n    \n    Used with --forced-value, this is a powerful way to send specific messages.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--tombstone")"
    printf "    ⚰️ Generate tombstone (record with null value). \n    \n    Setting --key is recommended when this flag is used. \n    If not set, the key will also be null, hence generating a null record (both\n    key and value being null)\n    \n    Note: CP 7.2+ is required.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--validate")"
    printf "    ☑️ Validate schema according to connect sink converter used\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--derive-key-schema-as DERIVE-KEY-SCHEMA-AS")"
    printf "    🪄 Use playground schema derive-schema command to deduce schema from key\n    payload\n    \n    Possible values:\n    \n    - AVRO\n    - JSON (json schema)\n    - PROTOBUF\n"
    printf "    %s\n" "Allowed: AVRO, JSON, PROTOBUF"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--derive-value-schema-as DERIVE-VALUE-SCHEMA-AS")"
    printf "    🪄 Use playground schema derive-schema command to deduce schema from value\n    payload\n    \n    Possible values:\n    \n    - AVRO\n    - JSON (json schema)\n    - PROTOBUF\n"
    printf "    %s\n" "Allowed: AVRO, JSON, PROTOBUF"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--no-null")"
    printf "    🪹 Never generate null fields even for optional fields\n    \n    N.B: only work with avro and json-schema\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--consume")"
    printf "    📥 After producing, directly consume topic.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--delete-topic")"
    printf "    ❌ Delete topic and associated schema/subject if applicable before producing\n    data.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--validate-config VALIDATE-CONFIG (repeatable)")"
    printf "    🔩 Converter configuration parameters to use \n    \n    See docs:\n    https://docs.confluent.io/platform/current/schema-registry/connect.html#using-kconnect-long-with-sr\n    \n    🎓 Tip: you can pass multiple parameters by specifying --validate-config\n    multiple times\n"
    printf "    %s\n" "Allowed: scrub.invalid.names=true, enhanced.avro.schema.support=true, connect.meta.data=false, object.additional.properties=false, use.optional.for.nonrequired=true, ignore.default.for.nullables=true, generalized.sum.type.support=true, enhanced.protobuf.schema.support=true, generate.index.for.unions=false, int.for.enums=true, optional.for.nullables=true, generate.struct.for.nulls=true, wrapper.for.nullables=true, wrapper.for.raw.primitives=false"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--producer-property PRODUCER-PROPERTY (repeatable)")"
    printf "    🔩 Producer configuration parameters to use \n    \n    See docs:\n    https://docs.confluent.io/platform/current/installation/configuration/producer-configs.html#cp-config-producer\n    \n    🎓 Tip: you can pass multiple parameters by specifying --producer-property\n    multiple times\n    \n    Example: --producer-property \"max.request.size=990485760\"\n    --producer-property \"client.id=myid\"\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--record-size RECORD-SIZE")"
    printf "    🏋️ Record size in bytes, eg. 1048576 for 1MB\n    \n    📢 If size is > 1Mb, --producer-property max.request.size and topic\n    max.message.bytes will be automatically set to support the record size.\n"
    printf "    %s\n" "Default: 0"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground topic produce --tombstone --topic a-topic --key mykey\n  \n  playground topic produce -t topic-json --nb-messages 10 << 'EOF'\n{\n    \"_meta\": {\n        \"topic\": \"\",\n        \"key\": \"\",\n        \"relationships\": []\n    },\n    \"nested\": {\n        \"phone\": \"faker.phone.imei()\",\n        \"website\": \"faker.internet.domainName()\"\n    },\n    \"id\": \"iteration.index\",\n    \"name\": \"faker.internet.userName()\",\n    \"email\": \"faker.internet.exampleEmail()\",\n    \"phone\": \"faker.phone.imei()\",\n    \"website\": \"faker.internet.domainName()\",\n    \"city\": \"faker.location.city()\",\n    \"company\": \"faker.company.name()\"\n}\nEOF\n  \n  playground topic produce -t topic-avro --nb-messages 10 << 'EOF'\n{\n  \"fields\": [\n    {\n      \"name\": \"count\",\n      \"type\": \"long\"\n    },\n    {\n      \"name\": \"first_name\",\n      \"type\": \"string\"\n    },\n    {\n      \"name\": \"last_name\",\n      \"type\": \"string\"\n    },\n    {\n      \"default\": null,\n      \"name\": \"address\",\n      \"type\": [\n        \"null\",\n        \"string\"\n      ]\n    },\n    {\n      \"name\": \"last_sale_date\",\n      \"type\": {\n        \"logicalType\": \"timestamp-millis\",\n        \"type\": \"long\"\n      }\n    },\n    {\n      \"name\": \"last_sale_price\",\n      \"type\": {\n        \"logicalType\": \"decimal\",\n        \"precision\": 15,\n        \"scale\": 2,\n        \"type\": \"bytes\"\n      }\n    },\n    {\n      \"name\": \"last_connection\",\n      \"type\": {\n        \"logicalType\": \"date\",\n        \"type\": \"int\"\n      }\n    }\n  ],\n  \"name\": \"Customer\",\n  \"namespace\": \"com.github.vdesabou\",\n  \"type\": \"record\"\n}\nEOF\n  \n  playground topic produce -t topic-json-schema --nb-messages 3 << 'EOF'\n{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"additionalProperties\": false,\n  \"$id\": \"http://lh.test/Customer.schema.json\",\n  \"title\": \"Customer\",\n  \"description\": \"Customer description\",\n  \"type\": \"object\",\n  \"properties\": {\n    \"name\": {\n      \"description\": \"Customer name\",\n      \"type\": \"string\",\n      \"maxLength\": 25\n    },\n    \"surname\": {\n      \"description\": \"Customer surname\",\n      \"type\": \"string\",\n      \"minLength\": 2\n    },\n    \"email\": {\n      \"description\": \"Email\",\n      \"type\": \"string\",\n      \"pattern\": \"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$\"\n    }\n  },\n  \"required\": [\n    \"name\",\n    \"surname\"\n  ]\n}\nEOF\n  \n  \n  playground topic produce -t topic-proto --nb-messages 1 << 'EOF'\nsyntax = \"proto3\";\n\npackage com.github.vdesabou;\n\nmessage Customer {\n    int64 count = 1;\n    string first_name = 2;\n    string last_name = 3;\n    string address = 4;\n}\nEOF\n  \n  playground topic produce -t topic-jsql --nb-messages 10 << 'EOF'\nCREATE TABLE \"notused\".\"notused\" (\n  \"id\" int PRIMARY KEY,\n  \"name\" varchar COMMENT 'faker.internet.userName()',\n  \"merchant_id\" int NOT NULL COMMENT 'faker.datatype.number()',\n  \"price\" int COMMENT 'faker.datatype.number()',\n  \"status\" int COMMENT 'faker.datatype.boolean()',\n  \"created_at\" datetime DEFAULT (now())\n);\nEOF\n  \n  playground topic produce -t topic-json --nb-messages 1 --producer-property\n  \"max.request.size=990485760\" < bigjson.json\n  \n  playground topic produce -t topic-string --nb-messages 5000 << 'EOF'\nAd et ut pariatur officia eos.\nNesciunt fugit nam libero ut qui itaque sed earum at itaque nesciunt eveniet\natque.\nQuidem libero quis quod et illum excepturi voluptas et in perspiciatis iusto\nneque.\nQuibusdam commodi explicabo dolores molestiae qui delectus dolorum fugiat\nmolestiae natus assumenda omnis expedita.\nEt sunt aut architecto suscipit fugiat qui voluptate iure vel doloremque eum\nculpa.\nQui enim facilis eos similique aperiam totam eius et at dolor dolores.\nUt sunt quia qui quia consectetur aut reiciendis.\nModi adipisci iusto aut voluptatem dolores laudantium.\nSequi sint quia quibusdam molestias minus et aliquid voluptatum aliquam.\nRerum aut amet quo possimus nihil velit quisquam ut cumque.\nPariatur ad officiis voluptatibus quia vel corporis ea fugit adipisci porro.\nEOF\n  \n  # key and headers\n  # mykey1 %%g can also be used\n  playground topic produce -t topic-json-multiple-lines --nb-messages 10 --key\n  \"mykey1\" --headers \"header1:value1,header2:value2\" << 'EOF'\n{\"u_name\": \"scissors\", \"u_price\": 2.75, \"u_quantity\": 3}\n{\"u_name\": \"tape\", \"u_price\": 0.99, \"u_quantity\": 10}\n{\"u_name\": \"notebooks\", \"u_price\": 1.99, \"u_quantity\": 5}\nEOF\n  \n  # avro key\n  playground topic produce -t topic-avro-with-key --nb-messages 10 --key '\n  {\n    \"fields\": [\n      {\n        \"name\": \"id\",\n        \"type\": \"long\"\n      }\n    ],\n    \"name\": \"Key\",\n    \"namespace\": \"com.github.vdesabou\",\n    \"type\": \"record\"\n  }\n  ' << 'EOF'\n{\n  \"fields\": [\n    {\n      \"doc\": \"count\",\n      \"name\": \"count\",\n      \"type\": \"long\"\n    },\n    {\n      \"doc\": \"First Name of Customer\",\n      \"name\": \"first_name\",\n      \"type\": \"string\"\n    },\n    {\n      \"doc\": \"Last Name of Customer\",\n      \"name\": \"last_name\",\n      \"type\": \"string\"\n    }\n  ],\n  \"name\": \"Customer\",\n  \"namespace\": \"com.github.vdesabou\",\n  \"type\": \"record\"\n}\nEOF\n  \n  # tombstone\n  playground topic produce -t topic-json-multiple-lines --tombstone --key\n  \"mykey1\"\n  \n  # input file\n  playground topic produce -t topic-avro-example3 < avro-schema.avsc\n  \n  # record-size\n  playground topic produce -t topic-avro-example-big-size --nb-messages 3\n  --record-size 10000000 << 'EOF'\n{\n  \"fields\": [\n    {\n      \"doc\": \"count\",\n      \"name\": \"count\",\n      \"type\": \"long\"\n    },\n    {\n      \"doc\": \"First Name of Customer\",\n      \"name\": \"first_name\",\n      \"type\": \"string\"\n    },\n    {\n      \"doc\": \"Last Name of Customer\",\n      \"name\": \"last_name\",\n      \"type\": \"string\"\n    },\n    {\n      \"doc\": \"Address of Customer\",\n      \"name\": \"address\",\n      \"type\": \"string\"\n    }\n  ],\n  \"name\": \"Customer\",\n  \"namespace\": \"com.github.vdesabou\",\n  \"type\": \"record\"\n}\nEOF\n  \n  # validate\n  playground topic produce -t topic-json-schema-validate --nb-messages 3\n  --validate << 'EOF'\n{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"additionalProperties\": false,\n  \"$id\": \"http://lh.test/Customer.schema.json\",\n  \"title\": \"Customer\",\n  \"description\": \"Customer description\",\n  \"type\": \"object\",\n  \"properties\": {\n    \"name\": {\n      \"description\": \"Customer name\",\n      \"type\": \"string\",\n      \"maxLength\": 25\n    },\n    \"surname\": {\n      \"description\": \"Customer surname\",\n      \"type\": \"string\",\n      \"minLength\": 2\n    },\n    \"email\": {\n      \"description\": \"Email\",\n      \"type\": \"string\",\n      \"pattern\": \"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$\"\n    },\n    \"holiday\": {\n      \"oneOf\": [\n        {\n          \"title\": \"Not included\",\n          \"type\": \"null\"\n        },\n        {}\n      ]\n    },\n    \"f2\": {}\n  },\n  \"required\": [\n    \"name\",\n    \"surname\"\n  ]\n}\nEOF\n  \n  #  --value-subject-name-strategy\n  playground topic produce -t topic-avro-example-value-subject-name-strategy\n  --nb-messages 10 --value-subject-name-strategy TopicRecordNameStrategy <<\n  'EOF'\n  {\n    \"fields\": [\n      {\n        \"doc\": \"count\",\n        \"name\": \"count\",\n        \"type\": \"long\"\n      },\n      {\n        \"doc\": \"First Name of Customer\",\n        \"name\": \"first_name\",\n        \"type\": \"string\"\n      },\n      {\n        \"doc\": \"Last Name of Customer\",\n        \"name\": \"last_name\",\n        \"type\": \"string\"\n      },\n      {\n        \"doc\": \"Address of Customer\",\n        \"name\": \"address\",\n        \"type\": \"string\"\n      }\n    ],\n    \"name\": \"Customer\",\n    \"namespace\": \"com.github.vdesabou\",\n    \"type\": \"record\"\n  }\n  EOF\n  \n  # --generate-only\n  playground topic produce -t topic-avro-example-forced-value --nb-messages 10 \n  --generate-only << 'EOF'\n{\n  \"fields\": [\n    {\n      \"doc\": \"count\",\n      \"name\": \"count\",\n      \"type\": \"long\"\n    },\n    {\n      \"doc\": \"First Name of Customer\",\n      \"name\": \"first_name\",\n      \"type\": \"string\"\n    },\n    {\n      \"doc\": \"Last Name of Customer\",\n      \"name\": \"last_name\",\n      \"type\": \"string\"\n    },\n    {\n      \"doc\": \"Address of Customer\",\n      \"name\": \"address\",\n      \"type\": \"string\"\n    },\n    {\n      \"name\": \"createdDate\",\n      \"type\": {\n        \"logicalType\": \"timestamp-millis\",\n        \"type\": \"long\"\n      }\n    },\n    {\n      \"default\": null,\n      \"name\": \"warranty_expiration\",\n      \"type\": [\n        \"null\",\n        {\n          \"logicalType\": \"date\",\n          \"type\": \"int\"\n        }\n      ]\n    }\n  ],\n  \"name\": \"Customer\",\n  \"namespace\": \"com.github.vdesabou\",\n  \"type\": \"record\"\n}\nEOF\n  \n  # --forced-value\n  playground topic produce -t topic-avro-example-forced-value --nb-messages 1\n  --forced-value '{\"count\":4,\"first_name\":\"Vincent\",\"last_name\":\"de\n  Saboulin\",\"address\":\"xxx\",\"createdDate\":1697852606000,\"warranty_expiration\":{\"int\":19653}}'\n  << 'EOF'\n{\n  \"fields\": [\n    {\n      \"doc\": \"count\",\n      \"name\": \"count\",\n      \"type\": \"long\"\n    },\n    {\n      \"doc\": \"First Name of Customer\",\n      \"name\": \"first_name\",\n      \"type\": \"string\"\n    },\n    {\n      \"doc\": \"Last Name of Customer\",\n      \"name\": \"last_name\",\n      \"type\": \"string\"\n    },\n    {\n      \"doc\": \"Address of Customer\",\n      \"name\": \"address\",\n      \"type\": \"string\"\n    },\n    {\n      \"name\": \"createdDate\",\n      \"type\": {\n        \"logicalType\": \"timestamp-millis\",\n        \"type\": \"long\"\n      }\n    },\n    {\n      \"default\": null,\n      \"name\": \"warranty_expiration\",\n      \"type\": [\n        \"null\",\n        {\n          \"logicalType\": \"date\",\n          \"type\": \"int\"\n        }\n      ]\n    }\n  ],\n  \"name\": \"Customer\",\n  \"namespace\": \"com.github.vdesabou\",\n  \"type\": \"record\"\n}\nEOF\n  \n  # json schema references\n  playground topic produce --value\n  /path/to/scripts/cli/predefined-schemas/json-schema/schema-reference/customer.json\n  --reference\n  /path/to/scripts/cli/predefined-schemas/json-schema/schema-reference/address.json\n  --reference\n  /path/to/scripts/cli/predefined-schemas/json-schema/schema-reference/email.json\n  --topic customers\n  \n  # --derive-value-schema-as\n  playground topic produce --topic tocpic --derive-value-schema-as PROTOBUF\n  --derive-key-schema-as PROTOBUF --key '{\"id\": \"1\"}' << 'EOF'\n{\"name\": \"Foo\", \"Age\": {\"int\": 12}}\nEOF\n"
echo

fi
}

# :command.usage
playground_topic_create_usage() {
  printf "playground topic create - 🆕 Create topic\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic create [OPTIONS] [--] [ARGUMENTS...]\n"
  printf "  playground topic create --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC (required)")"
    printf "    🗳 Topic name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--nb-partitions NB-PARTITIONS")"
    printf "    Number of partitions for the topic. (default is 1)\n"
    printf "    %s\n" "Default: 1"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    echo "  ARGUMENTS..."
    printf "    Any arguments to be used with kafka-topics --create\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground topic create --topic atopic\n  playground topic create --topic atopic --nb-partitions 8 --config\n  retention.ms=30000 --config cleanup.policy=compact\n"
    echo

  fi
}

# :command.usage
playground_topic_delete_usage() {
  printf "playground topic delete - ❌ Delete topic and associated schema/subject if applicable\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic delete [OPTIONS]\n"
  printf "  playground topic delete --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC (required)")"
    printf "    🗳 Topic name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--skip-delete-schema")"
    printf "    🔰 Do not delete subject/schema\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_topic_alter_usage() {
  printf "playground topic alter - 🪛 Alter topic config\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground topic alter [OPTIONS] [--] [ARGUMENTS...]\n"
  printf "  playground topic alter --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--topic, -t TOPIC (required)")"
    printf "    🗳 Topic name\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    echo "  ARGUMENTS..."
    printf "    Any arguments to be used with kafka-configs --alter. If the topic does not\n    exist, it is created first.\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground topic alter --topic atopic --add-config max.message.bytes=5242940\n"
    echo

  fi
}

# :command.usage
playground_connector_plugin_usage() {
  printf "playground connector-plugin - 🔌 Connector-plugin commands\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector-plugin COMMAND\n"
  printf "  playground connector-plugin [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   ☕ List jars for a connector plugin from confluent hub https://www.confluent.io/hub/ Search for specific class and display method signatures\n" "$(green "search-jar")          "
  printf "  %s   💯 List versions for a connector plugin from confluent hub https://www.confluent.io/hub/\n" "$(green "versions")            "
  printf "  %s   🆕 List last updated connector plugins from confluent hub https://www.confluent.io/hub/\n" "$(green "display-last-updated")"
  printf "  %s   🧑‍💻 Open source code url in your browser\n" "$(green "sourcecode")          "
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_plugin_search_jar_usage() {
  printf "playground connector-plugin search-jar - ☕ List jars for a connector plugin from confluent hub https://www.confluent.io/hub/ Search for specific class and display method signatures\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector-plugin search-jar [OPTIONS]\n"
  printf "  playground connector-plugin search-jar --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-plugin, -c CONNECTOR-PLUGIN (required)")"
    printf "    🔌 Connector plugin name\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-tag CONNECTOR_TAG")"
    printf "    🔗 Connector version to use\n    \n    By default, for each connector, the latest available version on Confluent\n    Hub is used\n    \n    🎓 Tip: set to \" \" in order to select the version dynamically\n"
    printf "    %s\n" "Conflicts: --connector-zip"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--class CLASS")"
    printf "    ☕ Java class name to search for in all jars\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground connector-plugin search-jar --connector-plugin\n  confluentinc/kafka-connect-s3 --class WebIdentityTokenCredentialsProvider\n"
    echo

  fi
}

# :command.usage
playground_connector_plugin_versions_usage() {
  printf "playground connector-plugin versions - 💯 List versions for a connector plugin from confluent hub https://www.confluent.io/hub/\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector-plugin versions [OPTIONS]\n"
  printf "  playground connector-plugin versions --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-plugin, -c CONNECTOR-PLUGIN (required)")"
    printf "    🔌 Connector plugin name\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--force-refresh")"
    printf "    ☢️ Force refresh.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--last LAST")"
    printf "    🆕 Number of last versions to show\n"
    printf "    %s\n" "Conflicts: --all"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground connector-plugin versions --connector-plugin\n  confluentinc/kafka-connect-s3\n"
    echo

  fi
}

# :command.usage
playground_connector_plugin_display_last_updated_usage() {
  printf "playground connector-plugin display-last-updated - 🆕 List last updated connector plugins from confluent hub https://www.confluent.io/hub/\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector-plugin display-last-updated [OPTIONS]\n"
  printf "  playground connector-plugin display-last-updated --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--days DAYS")"
    printf "    📅 Number of days to look back\n    \n    Default is 3 days\n"
    printf "    %s\n" "Default: 3"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--vendor VENDOR")"
    printf "    🏢 Only display results for this vendor\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground connector-plugin display-last-updated --days 7\n"
    echo

  fi
}

# :command.usage
playground_connector_plugin_sourcecode_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector-plugin sourcecode\n\n"
    printf "  🧑‍💻 Open source code url in your browser\n  \n  You can compare different sourcecode versions by specifying --connector-tag\n  two times, in such case it will open github in comparison mode\n\n"
  else
    printf "playground connector-plugin sourcecode - 🧑‍💻 Open source code url in your browser\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector-plugin sourcecode [OPTIONS]\n"
  printf "  playground connector-plugin sourcecode --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-plugin, -c CONNECTOR-PLUGIN (required)")"
    printf "    🔌 Connector plugin name\n    \n    🎓 Tip: use <tab> completion to trigger fzf completion\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--only-show-url")"
    printf "    🌐 Only show url\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-tag CONNECTOR_TAG (repeatable)")"
    printf "    🔗 Connector version to use\n    \n    By default, for each connector, the latest available version on Confluent\n    Hub is used (for Confluent employees, it will also get latest versions for\n    fully managed connectors)\n    \n    🎓 Tip: set to \" \" in order to select the version dynamically\n    \n    🎓 Tip: you can compare different sourcecode versions by specifying\n    --connector-tag two times, in such case it will open github in comparison\n    mode\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  # will open latest version from hub source code\n  playground connector-plugin sourcecode --connector-plugin\n  confluentinc/kafka-connect-hdfs\n  \n  # will ask you to select a version\n  playground connector-plugin sourcecode --connector-plugin\n  confluentinc/kafka-connect-hdfs --connector-tag \" \"\n  \n  # if you're a confluent employee (make sure to set your aws credentials), it\n  will also work on proprietary connectors and fully managed connectors\n  playground connector-plugin sourcecode --connector-plugin\n  confluentinc/MqttSource\n  \n  # comparison mode:\n  playground connector sourcecode --connector-tag \"10.2.1\" --connector-tag\n  \"10.2.0\"\n  \n  # comparison mode (with versions selection):\n  playground connector sourcecode --connector-tag \" \" --connector-tag \" \"\n"
    echo

  fi
}

# :command.usage
playground_connector_usage() {
  printf "playground connector - 🔗 Connector commands\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector COMMAND\n"
  printf "  playground connector [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   🧩 Show status of all connectors\n" "$(green "status")                          "
  printf "  %s   🅾️ Specific Oracle CDC Xstream commands\n" "$(green "oracle-cdc-xstream")              "
  printf "  %s   💈 Handle source and sink connectors offsets\n" "$(green "offsets")                         "
  printf "  %s   🎨 Show all connector plugins installed. You can also display transforms, converters and predicates using --all flag\n" "$(green "plugins")                         "
  printf "  %s   ⏸️  Pause connector\n" "$(green "pause")                           "
  printf "  %s   🧞 Get current and latest versions available on Confluent Hub for connector(s) used in example\n" "$(green "versions")                        "
  printf "  %s   🧑‍💻 open source code url for connector(s) used in example\n" "$(green "sourcecode")                      "
  printf "  %s   ♻️  Restart connector\n" "$(green "restart")                         "
  printf "  %s   🛑 Stop connector (only available if CP > 7.5)\n" "$(green "stop")                            "
  printf "  %s   ⏯️  Resume connector\n" "$(green "resume")                          "
  printf "  %s   🗑️  Delete connector\n" "$(green "delete")                          "
  printf "  %s   🐢 Show lag of sink connector\n" "$(green "show-lag")                        "
  printf "  %s   🧰 Show current connector config that was applied\n" "$(green "show-config")                     "
  printf "  %s   🔩 Show all possible configuration parameters of connector\n" "$(green "show-config-parameters")          "
  printf "  %s   🗜️ Easily select config from all possible configuration parameters of connector\n" "$(green "select-config")                   "
  printf "  %s   🔌 useful snippets\n" "$(green "snippets")                        "
  printf "  %s   🧑‍🎓 Open connector documentation of currently running conector(s)\n" "$(green "open-docs")                       "
  printf "  %s   🧬 Set connect log level\n" "$(green "log-level")                       "
  printf "  %s   🧩 Run Kafka Connector Migration Utility (see https://github.com/confluentinc/connect-migration-utility/) on running connect cluster\n" "$(green "connect-migration-utility")       "
  printf "  %s   🧑‍🎨  Create or update connector\n" "$(green "create-or-update")                "
  printf "  %s   🛠️ Update connector configuration by opening current connector config in text editor set with playground config editor <editor> (default is code). Once file is saved, the new configuration is updated.\n" "$(green "update")                          "
  echo
  printf "%s\n" "$(bold "Connect commands:")"
  printf "  %s   🕵️  Tail and follow connect logs\n" "$(green "logs")                            "
  printf "  %s   🤖 Open Fully Managed connector in browser (Confluent Cloud dashboard)\n" "$(green "open-ccloud-connector-in-browser")"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground connector status\n"
    printf "  playground connector status --json\n"
    printf "  playground connector resume --connector <connector-name>\n"
    printf "  playground connector pause -c <connector-name>\n"
    printf "  playground connector delete -c <connector-name>\n"
    echo

  fi
}

# :command.usage
playground_connector_status_usage() {
  printf "playground connector status - 🧩 Show status of all connectors\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector status [OPTIONS]\n"
  printf "  playground connector status --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_oracle_cdc_xstream_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector oracle-cdc-xstream\n\n"
    printf "  🅾️ Specific Oracle CDC Xstream commands\n\n"
  else
    printf "playground connector oracle-cdc-xstream - 🅾️ Specific Oracle CDC Xstream commands\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector oracle-cdc-xstream COMMAND\n"
  printf "  playground connector oracle-cdc-xstream [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   ⚙️ Generate and open oracle cdc xstream connector diagnostics, see https://docs.confluent.io/kafka-connectors/oracle-xstream-cdc-source/current/troubleshooting.html#connector-diagnostics-script\n" "$(green "generate-report")"
  printf "  %s   🐞 Execute various SQL commands to debug xstream components\n" "$(green "debug")          "
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_oracle_cdc_xstream_generate_report_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector oracle-cdc-xstream generate-report\n\n"
    printf "  ⚙️ Generate and open oracle cdc xstream connector diagnostics, see\n  https://docs.confluent.io/kafka-connectors/oracle-xstream-cdc-source/current/troubleshooting.html#connector-diagnostics-script\n\n"
  else
    printf "playground connector oracle-cdc-xstream generate-report - ⚙️ Generate and open oracle cdc xstream connector diagnostics, see https://docs.confluent.io/kafka-connectors/oracle-xstream-cdc-source/current/troubleshooting.html#connector-diagnostics-script\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector oracle-cdc-xstream generate-report\n"
  printf "  playground connector oracle-cdc-xstream generate-report --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_oracle_cdc_xstream_debug_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector oracle-cdc-xstream debug\n\n"
    printf "  🐞 Execute various SQL commands to debug xstream components\n\n"
  else
    printf "playground connector oracle-cdc-xstream debug - 🐞 Execute various SQL commands to debug xstream components\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector oracle-cdc-xstream debug\n"
  printf "  playground connector oracle-cdc-xstream debug --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_offsets_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector offsets\n\n"
    printf "  💈 Handle source and sink connectors offsets\n  \n    Note: First-class offsets (KIP-875) is only available if CP > 7.6\n\n"
  else
    printf "playground connector offsets - 💈 Handle source and sink connectors offsets\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector offsets COMMAND\n"
  printf "  playground connector offsets [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   🏹 Get current offsets for source and sink connectors\n" "$(green "get")                       "
  printf "  %s   🆕 Reset offsets for source and sink connectors\n" "$(green "reset")                     "
  printf "  %s   ⛏️ Alter offsets for source and sink connectors\n" "$(green "alter")                     "
  printf "  %s   👁️‍🗨️ Get the status of the previous offset request\n" "$(green "get-offsets-request-status")"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_offsets_get_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector offsets get\n\n"
    printf "  🏹 Get current offsets for source and sink connectors\n  \n  ⚠️ Available for ccloud source connectors (see\n  https://docs.confluent.io/cloud/current/connectors/offsets.html)\n\n"
  else
    printf "playground connector offsets get - 🏹 Get current offsets for source and sink connectors\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector offsets get [OPTIONS]\n"
  printf "  playground connector offsets get --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_offsets_reset_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector offsets reset\n\n"
    printf "  🆕 Reset offsets for source and sink connectors\n  \n  ⚠️ Available for ccloud connectors (see\n  https://docs.confluent.io/cloud/current/connectors/offsets.html)\n\n"
  else
    printf "playground connector offsets reset - 🆕 Reset offsets for source and sink connectors\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector offsets reset [OPTIONS]\n"
  printf "  playground connector offsets reset --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_offsets_alter_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector offsets alter\n\n"
    printf "  ⛏️ Alter offsets for source and sink connectors\n  \n  ⚠️ Available for ccloud connectors (see\n  https://docs.confluent.io/cloud/current/connectors/offsets.html)\n\n"
  else
    printf "playground connector offsets alter - ⛏️ Alter offsets for source and sink connectors\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector offsets alter [OPTIONS]\n"
  printf "  playground connector offsets alter --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_offsets_get_offsets_request_status_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector offsets get-offsets-request-status\n\n"
    printf "  👁️‍🗨️ Get the status of the previous offset request\n  \n  ⚠️ Available for ccloud source connectors (see\n  https://docs.confluent.io/cloud/current/connectors/offsets.html)\n\n"
  else
    printf "playground connector offsets get-offsets-request-status - 👁️‍🗨️ Get the status of the previous offset request\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector offsets get-offsets-request-status [OPTIONS]\n"
  printf "  playground connector offsets get-offsets-request-status --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_plugins_usage() {
  printf "playground connector plugins - 🎨 Show all connector plugins installed. You can also display transforms, converters and predicates using --all flag\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector plugins [OPTIONS]\n"
  printf "  playground connector plugins --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--all")"
    printf "    🌕 Show also transforms, converters, predicates available\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_pause_usage() {
  printf "playground connector pause - ⏸️  Pause connector\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector pause [OPTIONS]\n"
  printf "  playground connector pause --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_versions_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector versions\n\n"
    printf "  🧞 Get current and latest versions available on Confluent Hub for connector(s)\n  used in example\n\n"
  else
    printf "playground connector versions - 🧞 Get current and latest versions available on Confluent Hub for connector(s) used in example\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector versions\n"
  printf "  playground connector versions --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_sourcecode_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector sourcecode\n\n"
    printf "  🧑‍💻 open source code url for connector(s) used in example\n  \n  You can compare different sourcecode versions by specifying --connector-tag\n  two times, in such case it will open github in comparison mode\n\n"
  else
    printf "playground connector sourcecode - 🧑‍💻 open source code url for connector(s) used in example\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector sourcecode [OPTIONS]\n"
  printf "  playground connector sourcecode --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--only-show-url")"
    printf "    🌐 Only show url\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector-tag CONNECTOR_TAG (repeatable)")"
    printf "    🔗 Connector version to use\n    \n    By default, for each connector, the current version is used (for Confluent\n    employees, it will also get latest versions for fully managed connectors)\n    \n    🎓 Tip: set to \" \" in order to select the version dynamically\n    \n    🎓 Tip: you can compare different sourcecode versions by specifying\n    --connector-tag two times, in such case it will open github in comparison\n    mode\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  # will open current version source code\n  # if you're a confluent employee (make sure to set your aws credentials), it\n  will also work on proprietary connectors and fully managed connectors\n  playground connector sourcecode\n  \n  # will ask you to select a version\n  playground connector sourcecode  --connector-tag \" \"\n  \n  # comparison mode:\n  playground connector-plugin sourcecode --connector-plugin\n  confluentinc/kafka-connect-hdfs --connector-tag \"10.2.1\" --connector-tag\n  \"10.2.0\"\n  \n  # comparison mode (with versions selection):\n  playground connector-plugin sourcecode --connector-plugin\n  confluentinc/kafka-connect-hdfs --connector-tag \" \" --connector-tag \" \"\n"
    echo

  fi
}

# :command.usage
playground_connector_restart_usage() {
  printf "playground connector restart - ♻️  Restart connector\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector restart [OPTIONS]\n"
  printf "  playground connector restart --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--task-id, -t TASK_ID")"
    printf "    🔧 Restart specific task ID only (instead of restarting entire connector)\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_stop_usage() {
  printf "playground connector stop - 🛑 Stop connector (only available if CP > 7.5)\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector stop [OPTIONS]\n"
  printf "  playground connector stop --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_resume_usage() {
  printf "playground connector resume - ⏯️  Resume connector\n\n"
  printf "Alias: unpause\n"
  echo

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector resume [OPTIONS]\n"
  printf "  playground connector resume --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_delete_usage() {
  printf "playground connector delete - 🗑️  Delete connector\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector delete [OPTIONS]\n"
  printf "  playground connector delete --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_show_lag_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector show-lag\n\n"
    printf "  🐢 Show lag of sink connector\n  \n  It will run until all lag becomes 0 (press ctrl-c to exit)\n\n"
  else
    printf "playground connector show-lag - 🐢 Show lag of sink connector\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector show-lag [OPTIONS]\n"
  printf "  playground connector show-lag --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--interval INTERVAL")"
    printf "    Interval between lag checks (default is 20 seconds).\n"
    printf "    %s\n" "Default: 20"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--max-wait MAX_WAIT")"
    printf "    ⏳ Max time in seconds to wait for lag to become 0. If set to 0 (default), it\n    will run until all lag becomes 0.\n"
    printf "    %s\n" "Default: 0"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_show_config_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector show-config\n\n"
    printf "  🧰 Show current connector config that was applied\n  \n  use --force-rest-endpoint to get results with REST API /config endpoint\n  (https://docs.confluent.io/platform/current/connect/references/restapi.html#get--connectors-(string-name)-config)\n\n"
  else
    printf "playground connector show-config - 🧰 Show current connector config that was applied\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector show-config [OPTIONS]\n"
  printf "  playground connector show-config --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--force-rest-endpoint")"
    printf "    ☢️ Force using REST API /config endpoint\n    (https://docs.confluent.io/platform/current/connect/references/restapi.html#get--connectors-(string-name)-config)\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_show_config_parameters_usage() {
  printf "playground connector show-config-parameters - 🔩 Show all possible configuration parameters of connector\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector show-config-parameters [OPTIONS]\n"
  printf "  playground connector show-config-parameters --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--open, -o")"
    printf "    🔖 Save output to a file and open with text editor set with playground config\n    editor <editor> (default is code)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--force-refresh")"
    printf "    ☢️ Force refresh.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--only-show-json")"
    printf "    📗 Only show list of all available parameters for connector (with default\n    value when applicable)\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_select_config_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector select-config\n\n"
    printf "  🗜️ Easily select config from all possible configuration parameters of\n  connector\n  \n  🎓 Tip: use <tab> to select multiple config at once !\n\n"
  else
    printf "playground connector select-config - 🗜️ Easily select config from all possible configuration parameters of connector\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector select-config [OPTIONS]\n"
  printf "  playground connector select-config --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_snippets_usage() {
  printf "playground connector snippets - 🔌 useful snippets\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector snippets [OPTIONS]\n"
  printf "  playground connector snippets --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--converter CONVERTER")"
    printf "    🔌 Converter\n"
    printf "    %s\n" "Allowed: avro, protobuf, json-schema, json, json-schema-enabled, string, bytearray"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--dlq")"
    printf "    💀 dlq\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground connector snippets --converter avro --dlq\n"
    echo

  fi
}

# :command.usage
playground_connector_open_docs_usage() {
  printf "playground connector open-docs - 🧑‍🎓 Open connector documentation of currently running conector(s)\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector open-docs [OPTIONS]\n"
  printf "  playground connector open-docs --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--only-show-url")"
    printf "    🌐 Only show url\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_log_level_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector log-level\n\n"
    printf "  🧬 Set connect log level\n  \n  🎓 Tip: it will also set\n  io.confluent.kafka.schemaregistry.client.rest.RestService (to see schema\n  registry rest requests) and\n  org.apache.kafka.connect.runtime.TransformationChain (to see records before\n  and after SMTs)\n          it will also set org.apache.kafka.connect.runtime.WorkerSinkTask for\n  sink and org.apache.kafka.connect.runtime.WorkerSourceTask for source\n  connectors.\n\n"
  else
    printf "playground connector log-level - 🧬 Set connect log level\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector log-level [OPTIONS]\n"
  printf "  playground connector log-level --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--level, -l LEVEL (required)")"
    printf "    ❕Log level\n"
    printf "    %s\n" "Allowed: INFO, WARN, DEBUG, TRACE"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_logs_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector logs\n\n"
    printf "  🕵️  Tail and follow connect logs\n  \n  For onprem connectors, this is basically a shortcut for \"playground container\n  logs --container connect\", --connector flag is not relevant\n  \n  For Fully Managed connectors, limitations apply (see\n  https://docs.confluent.io/cloud/current/connectors/logging-cloud-connectors.html#using-ccloud-cli)\n\n"
  else
    printf "playground connector logs - 🕵️  Tail and follow connect logs\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector logs [OPTIONS]\n"
  printf "  playground connector logs --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--open, -o")"
    printf "    🔖 Save output to a file and open with text editor set with playground config\n    editor <editor> (default is code)\n"
    printf "    %s\n" "Conflicts: --wait-for-log"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--wait-for-log, -w LOG")"
    printf "    😴 Wait until log appears\n"
    printf "    %s\n" "Conflicts: --open"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_open_ccloud_connector_in_browser_usage() {
  printf "playground connector open-ccloud-connector-in-browser - 🤖 Open Fully Managed connector in browser (Confluent Cloud dashboard)\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector open-ccloud-connector-in-browser [OPTIONS]\n"
  printf "  playground connector open-ccloud-connector-in-browser --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--browser BROWSER")"
    printf "    🌎 browser name\n    \n    Default browser from your system if not set\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_connect_migration_utility_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector connect-migration-utility\n\n"
    printf "  🧩 Run Kafka Connector Migration Utility (see\n  https://github.com/confluentinc/connect-migration-utility/) on running connect\n  cluster\n  \n  The connector example should be ran with --environment flag set to <ccloud>\n  \n  See a full example at\n  https://github.com/vdesabou/kafka-docker-playground/blob/master/ccloud/connect-migration-utility/README.md\n\n"
  else
    printf "playground connector connect-migration-utility - 🧩 Run Kafka Connector Migration Utility (see https://github.com/confluentinc/connect-migration-utility/) on running connect cluster\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector connect-migration-utility COMMAND\n"
  printf "  playground connector connect-migration-utility [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   👨‍🔬 Discover connectors in the local connect cluster and export their configurations to files\n" "$(green "discovery")"
  printf "  %s   🪄 Migrate discovered connectors to fully managed connectors\n" "$(green "migrate")  "
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_connect_migration_utility_discovery_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector connect-migration-utility discovery\n\n"
    printf "  👨‍🔬 Discover connectors in the local connect cluster and export their\n  configurations to files\n    \n    see\n  https://github.com/confluentinc/connect-migration-utility/tree/master?tab=readme-ov-file#step-1-specify-the-connector-configuration\n\n"
  else
    printf "playground connector connect-migration-utility discovery - 👨‍🔬 Discover connectors in the local connect cluster and export their configurations to files\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector connect-migration-utility discovery [OPTIONS]\n"
  printf "  playground connector connect-migration-utility discovery --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_connect_migration_utility_migrate_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground connector connect-migration-utility migrate\n\n"
    printf "  🪄 Migrate discovered connectors to fully managed connectors\n  \n    see\n  https://github.com/confluentinc/connect-migration-utility/tree/master?tab=readme-ov-file#step-2-migrate-the-connector\n    ⚠️ <discovery> command should be run first\n\n"
  else
    printf "playground connector connect-migration-utility migrate - 🪄 Migrate discovered connectors to fully managed connectors\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector connect-migration-utility migrate [OPTIONS]\n"
  printf "  playground connector connect-migration-utility migrate --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--migration-mode MIGRATION-MODE")"
    printf "    - create: Create connector without any offset consideration\n    - stop_create_latest_offset: Create a connector with no data\n    loss/duplication (the python script stops the self-managed connector and\n    fetches the latest offset and creates a fully-managed connector on Confluent\n    Cloud using the fetched offset). See\n    https://github.com/confluentinc/connect-migration-utility/tree/master?tab=readme-ov-file#create-a-connector-with-no-data-lossduplication.\n    - create_latest_offset: Create a connector with no downtime (the python\n    script fetches the latest offset without stopping the connector and creates\n    a fully-managed connector on Confluent Cloud using the fetched offset. This\n    option may cause data duplication as the self-managed connector is still\n    running). See\n    https://github.com/confluentinc/connect-migration-utility/tree/master?tab=readme-ov-file#create-a-connector-with-no-downtime.\n"
    printf "    %s\n" "Allowed: stop_create_latest_offset, create, create_latest_offset"
    printf "    %s\n" "Default: create"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_connector_create_or_update_usage() {
  printf "playground connector create-or-update - 🧑‍🎨  Create or update connector\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector create-or-update [JSON] [OPTIONS]\n"
  printf "  playground connector create-or-update --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--verbose, -v")"
    printf "    🐞 Show command being ran.\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR (required)")"
    printf "    🔗 Connector name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--level, -l LEVEL")"
    printf "    ❕Log level\n    \n    ⚠️ Not available for ccloud connectors\n"
    printf "    %s\n" "Allowed: INFO, WARN, DEBUG, TRACE"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--package, -p PACKAGE")"
    printf "    Package name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--wait-for-zero-lag")"
    printf "    😴 Wait until lag becomes 0\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--validate")"
    printf "    ✅ Validate config using PUT /connector-plugins/(string:name)/config/validate\n    (https://docs.confluent.io/platform/current/connect/references/restapi.html#put--connector-plugins-(string-name)-config-validate)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--skip-automatic-connector-config")"
    printf "    🤖 If example is run (playground run) with --environment flag, automatic\n    configuration to adapt to the environment is added.\n    \n    This flag allows to skip this automatic configuration (only useful to\n    reproduce issues)\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--offsets OFFSETS")"
    printf "    📍 Create connector with offsets\n    (https://docs.confluent.io/cloud/current/connectors/offsets.html#create-connectors-with-offsets)\n    \n    ⚠️ Only available for ccloud connectors, the connector should not really\n    exists\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--initial-state INITIAL-STATE")"
    printf "    🪵 Create connector with specific status\n    (https://cwiki.apache.org/confluence/display/KAFKA/KIP-980%%3A+Allow+creating+connectors+in+a+stopped+state)\n    \n    Only available if CP > 7.7\n    \n    ⚠️ not available for ccloud connectors\n"
    printf "    %s\n" "Allowed: RUNNING, PAUSED, STOPPED"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_args
    printf "%s\n" "$(bold "== Arguments ==")"

    # :argument.usage
    printf "  %s\n" "$(blue "JSON")"
    printf "    json (reads from stdin if empty)\n"
    printf "    %s\n" "Default: -"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground connector create-or-update -c filestream-sink << EOF\n{\n    \"tasks.max\": \"1\",\n    \"connector.class\":\n\"org.apache.kafka.connect.file.FileStreamSinkConnector\",\n    \"topics\": \"filestream\",\n    \"file\": \"/tmp/output.json\",\n    \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\",\n    \"value.converter\": \"org.apache.kafka.connect.json.JsonConverter\",\n    \"value.converter.schemas.enable\": \"false\"\n}\nEOF\n  \n  playground connector create-or-update -c filestream-sink --offsets\n  '[{\"partition\":{\"kafka_topic\":\"filestream\",\"kafka_partition\":0},\"offset\":{\"kafka_offset\":8}}]'\n  << EOF\n{\n    \"tasks.max\": \"1\",\n    \"connector.class\":\n\"org.apache.kafka.connect.file.FileStreamSinkConnector\",\n    \"topics\": \"filestream\",\n    \"file\": \"/tmp/output.json\",\n    \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\",\n    \"value.converter\": \"org.apache.kafka.connect.json.JsonConverter\",\n    \"value.converter.schemas.enable\": \"false\"\n}\nEOF\n"
echo

fi
}

# :command.usage
playground_connector_update_usage() {
  printf "playground connector update - 🛠️ Update connector configuration by opening current connector config in text editor set with playground config editor <editor> (default is code). Once file is saved, the new configuration is updated.\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground connector update [OPTIONS]\n"
  printf "  playground connector update --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--connector, -c CONNECTOR")"
    printf "    🔗 Connector name\n    \n    🎓 Tip: If not specified, the command will apply to all connectors\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

    # :command.usage_examples
    printf "%s\n" "$(bold "Examples")"
    printf "  playground connector update -c filestream-sink\n"
    echo

  fi
}

# :command.usage
playground_ec2_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground ec2\n\n"
    printf "  ✨ Create and manage AWS EC2 instances (using Cloud Formation) to run\n  kafka-docker-playground\n  \n  🪄 Open EC2 instances directly in Visual Studio code using Remote Development\n  (over SSH)\n\n"
  else
    printf "playground ec2 - ✨ Create and manage AWS EC2 instances (using Cloud Formation) to run kafka-docker-playground\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ec2 COMMAND\n"
  printf "  playground ec2 [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   👷 Create kafka-docker-playground EC2 instance using AWS Cloud Formation\n" "$(green "create")           "
  printf "  %s   ❌ Delete an EC2 instance created with Cloud Formation\n" "$(green "delete")           "
  printf "  %s   👨‍💻 Open an EC2 instance using Visual Studio code\n" "$(green "open")             "
  printf "  %s   🔘 List all EC2 instance\n" "$(green "list")             "
  printf "  %s   🔴 Stop an EC2 instance\n" "$(green "stop")             "
  printf "  %s   🟢 Start an EC2 instance\n" "$(green "start")            "
  printf "  %s   ↔️ Synchronize reproduction-models folder bewteen local and ec2 instance\n" "$(green "sync-repro-folder")"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_ec2_create_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground ec2 create\n\n"
    printf "  👷 Create kafka-docker-playground EC2 instance using AWS Cloud Formation\n  \n  🔐 AWS EC2 pem file for the ec2 instance will be created and stored in root\n  folder (make sure to do backup)\n  \n  🌍 Region being used will be the one set in your environment (\`aws configure\n  get region\`) either by AWS_REGION environment variable or ~/.aws/config\n\n"
  else
    printf "playground ec2 create - 👷 Create kafka-docker-playground EC2 instance using AWS Cloud Formation\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ec2 create [OPTIONS]\n"
  printf "  playground ec2 create --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--instance-type INSTANCE-TYPE")"
    printf "    🧑‍💻 instance type. default is t3.2xlarge\n"
    printf "    %s\n" "Allowed: c1.medium, c1.xlarge, c3.2xlarge, c3.4xlarge, c3.8xlarge, c3.large, c3.xlarge, c4.2xlarge, c4.4xlarge, c4.large, c4.xlarge, m1.large, m1.medium, m1.small, m1.xlarge, m2.2xlarge, m2.4xlarge, m2.xlarge, m3.2xlarge, m3.large, m3.medium, m3.xlarge, m4.10xlarge, m4.2xlarge, m4.4xlarge, m4.large, m4.xlarge, t1.micro, t2.large, t2.medium, t2.micro, t2.nano, t2.small, t3.2xlarge"
    printf "    %s\n" "Default: t3.2xlarge"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--size SIZE")"
    printf "    💾 instance size in Gb. default is 1000 Gb\n"
    printf "    %s\n" "Default: 1000"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--suffix SUFFIX")"
    printf "    📮 suffix to add to instance name pg-${username}-${suffix} \n    \n    if not set, default is pg-${username}-${6-chars-random-string}\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_ec2_delete_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground ec2 delete\n\n"
    printf "  ❌ Delete an EC2 instance created with Cloud Formation\n  \n  WARNING:  This will delete your cloud formation and associated EC2 instance\n\n"
  else
    printf "playground ec2 delete - ❌ Delete an EC2 instance created with Cloud Formation\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ec2 delete [OPTIONS]\n"
  printf "  playground ec2 delete --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--instance, -i INSTANCE")"
    printf "    🌀 ec2 instance cloudformation (need to use completion to get all required\n    details)\n    \n    🎓 Tip: If not specified, the command will apply to all ec2 instances\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_ec2_open_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground ec2 open\n\n"
    printf "  👨‍💻 Open an EC2 instance using Visual Studio code\n  \n  🔐 Only your current ip address will be allowed to connect\n\n"
  else
    printf "playground ec2 open - 👨‍💻 Open an EC2 instance using Visual Studio code\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ec2 open [OPTIONS]\n"
  printf "  playground ec2 open --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--instance, -i INSTANCE")"
    printf "    🖥️ ec2 instance (need to use completion to get all required details)\n    \n    🎓 Tip: If not specified, the command will apply to all ec2 instances\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--enable-sync-repro-folder")"
    printf "    👉 Enable sync reproduction-models folder between local and ec2 instance\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_ec2_allow_my_ip_usage() {
  printf "playground ec2 allow-my-ip - 🛂 Allow your current ip to connect to ec2 instance via ssh\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ec2 allow-my-ip [OPTIONS]\n"
  printf "  playground ec2 allow-my-ip --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--instance, -i INSTANCE")"
    printf "    🖥️ ec2 instance (need to use completion to get all required details)\n    \n    🎓 Tip: If not specified, the command will apply to all ec2 instances\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_ec2_list_usage() {
  printf "playground ec2 list - 🔘 List all EC2 instance\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ec2 list\n"
  printf "  playground ec2 list --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_ec2_stop_usage() {
  printf "playground ec2 stop - 🔴 Stop an EC2 instance\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ec2 stop [OPTIONS]\n"
  printf "  playground ec2 stop --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--instance, -i INSTANCE")"
    printf "    🖥️ ec2 instance (need to use completion to get all required details)\n    \n    🎓 Tip: If not specified, the command will apply to all ec2 instances\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_ec2_start_usage() {
  printf "playground ec2 start - 🟢 Start an EC2 instance\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ec2 start [OPTIONS]\n"
  printf "  playground ec2 start --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--instance, -i INSTANCE")"
    printf "    🖥️ ec2 instance (need to use completion to get all required details)\n    \n    🎓 Tip: If not specified, the command will apply to all ec2 instances\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_ec2_status_usage() {
  printf "playground ec2 status - 🗺️ Show a status\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ec2 status [OPTIONS]\n"
  printf "  playground ec2 status --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--instance, -i INSTANCE (required)")"
    printf "    🖥️ EC2 instance name\n"
    echo

    # :flag.usage
    printf "  %s\n" "$(magenta "--all")"
    printf "    return all details\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_ec2_sync_repro_folder_usage() {
  if [[ -n $long_usage ]]; then
    printf "playground ec2 sync-repro-folder\n\n"
    printf "  ↔️ Synchronize reproduction-models folder bewteen local and ec2 instance\n  \n  Note: rsync needs to be installed\n\n"
  else
    printf "playground ec2 sync-repro-folder - ↔️ Synchronize reproduction-models folder bewteen local and ec2 instance\n\n"
  fi

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ec2 sync-repro-folder COMMAND\n"
  printf "  playground ec2 sync-repro-folder [COMMAND] --help | -h\n"
  echo
  # :command.usage_commands
  printf "%s\n" "$(bold "== Commands ==")"
  printf "  %s   👉 Sync local reproduction-models folder to ec2 instance\n" "$(green "local-to-ec2")"
  printf "  %s   👈 Sync ec2 instance reproduction-models folder to local\n" "$(green "ec2-to-local")"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_ec2_sync_repro_folder_local_to_ec2_usage() {
  printf "playground ec2 sync-repro-folder local-to-ec2 - 👉 Sync local reproduction-models folder to ec2 instance\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ec2 sync-repro-folder local-to-ec2 [OPTIONS]\n"
  printf "  playground ec2 sync-repro-folder local-to-ec2 --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--instance, -i INSTANCE")"
    printf "    🖥️ ec2 instance (need to use completion to get all required details)\n    \n    🎓 Tip: If not specified, the command will apply to all ec2 instances\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.usage
playground_ec2_sync_repro_folder_ec2_to_local_usage() {
  printf "playground ec2 sync-repro-folder ec2-to-local - 👈 Sync ec2 instance reproduction-models folder to local\n\n"

  printf "%s\n" "$(bold "== Usage ==")"
  printf "  playground ec2 sync-repro-folder ec2-to-local [OPTIONS]\n"
  printf "  playground ec2 sync-repro-folder ec2-to-local --help | -h\n"
  echo

  # :command.long_usage
  if [[ -n "$long_usage" ]]; then
    printf "%s\n" "$(bold "== Options ==")"

    # :command.usage_flags
    # :flag.usage
    printf "  %s\n" "$(magenta "--instance, -i INSTANCE")"
    printf "    🖥️ ec2 instance (need to use completion to get all required details)\n    \n    🎓 Tip: If not specified, the command will apply to all ec2 instances\n"
    echo

    # :command.usage_fixed_flags
    printf "  %s\n" "$(magenta "--help, -h")"
    printf "    Show this help\n"
    echo

  fi
}

# :command.normalize_input
# :command.normalize_input_function
normalize_input() {
  local arg passthru flags
  passthru=false

  while [[ $# -gt 0 ]]; do
    arg="$1"
    if [[ $passthru == true ]]; then
      input+=("$arg")
    elif [[ $arg =~ ^(--[a-zA-Z0-9_\-]+)=(.+)$ ]]; then
      input+=("${BASH_REMATCH[1]}")
      input+=("${BASH_REMATCH[2]}")
    elif [[ $arg =~ ^(-[a-zA-Z0-9])=(.+)$ ]]; then
      input+=("${BASH_REMATCH[1]}")
      input+=("${BASH_REMATCH[2]}")
    elif [[ $arg =~ ^-([a-zA-Z0-9][a-zA-Z0-9]+)$ ]]; then
      flags="${BASH_REMATCH[1]}"
      for ((i = 0; i < ${#flags}; i++)); do
        input+=("-${flags:i:1}")
      done
    elif [[ "$arg" == "--" ]]; then
      passthru=true
      input+=("$arg")
    else
      input+=("$arg")
    fi

    shift
  done
}

# :command.inspect_args
inspect_args() {
  if ((${#args[@]})); then
    readarray -t sorted_keys < <(printf '%s\n' "${!args[@]}" | sort)
    echo args:
    for k in "${sorted_keys[@]}"; do
      echo "- \${args[$k]} = ${args[$k]}"
    done
  else
    echo args: none
  fi

  if ((${#other_args[@]})); then
    echo
    echo other_args:
    echo "- \${other_args[*]} = ${other_args[*]}"
    for i in "${!other_args[@]}"; do
      echo "- \${other_args[$i]} = ${other_args[$i]}"
    done
  fi

  if ((${#deps[@]})); then
    readarray -t sorted_keys < <(printf '%s\n' "${!deps[@]}" | sort)
    echo
    echo deps:
    for k in "${sorted_keys[@]}"; do
      echo "- \${deps[$k]} = ${deps[$k]}"
    done
  fi

  if ((${#env_var_names[@]})); then
    readarray -t sorted_names < <(printf '%s\n' "${env_var_names[@]}" | sort)
    echo
    echo "environment variables:"
    for k in "${sorted_names[@]}"; do
      echo "- \$$k = ${!k:-}"
    done
  fi
}

# :command.user_lib
# src/lib/cli_function.sh
function get_environment_used() {
  environment=$(playground state get run.environment)
}

function is_container_running() {
  container_name=$1
  docker inspect -f '{{.State.Running}}' "$container_name" 2>/dev/null | grep -q "true"
}

function get_connect_container() {
  for worker in connect connect2 connect3 connect-us connect-europe
  do
    if is_container_running $worker
    then
      connect_container=$worker
      break
    fi
  done
}

function get_connect_url_and_security() {
  get_environment_used

  connect_port="8083"

  if ! is_container_running "connect" && ! is_container_running "connect-us"
  then
    if is_container_running "connect2" || is_container_running "connect-europe"
    then
      connect_port="8283"
      # log "💫 using connect rest api for connect2 as connect rest api on port 8083 is not available"
    elif is_container_running "connect3"
    then
      connect_port="8383"
      # log "💫 using connect rest api for connect3 as connect rest api on port 8083 and connect2 rest api on port 8283 are not available"
    else
      logerror "❌ No available port found for connect rest api, none of containers connect, connect2 or connect3 are running!"
      exit 1
    fi
  fi

  connect_url="http://localhost:$connect_port"

  security=""
  if [[ "$environment" == "sasl-ssl" ]] || [[ "$environment" == "2way-ssl" ]]
  then
      connect_url="https://localhost:$connect_port"
      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

      security="--cert $DIR_CLI/../../environment/$environment/security/connect.certificate.pem --key $DIR_CLI/../../environment/$environment/security/connect.key --tlsv1.2 --cacert $DIR_CLI/../../environment/$environment/security/snakeoil-ca-1.crt"
  elif [[ "$environment" == "rbac-sasl-plain" ]]
  then
      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

      security="-u connectorSubmitter:connectorSubmitter"
  fi
}

function generate_get_examples_add_emoji () {
  repro=""
  if [[ $file_path == *"reproduction-models"* ]]
  then
    repro="🛠"
  fi

  if [[ $file_path == *"ccloud"* ]]
  then
    if [[ $file_path == *"fm-"* ]]
    then
      echo "${repro}🌤️🤖 $file_path" >> $output_file
    elif [[ $file_path == *"custom-connector"* ]]
    then
      echo "${repro}🌤️🛃 $file_path" >> $output_file
    elif [[ $file_path == *"environment"* ]]
    then
      echo "${repro}🌤️🔐 $file_path" >> $output_file
    else
      echo "${repro}🌤️ $file_path" >> $output_file
    fi
  elif [[ $file_path == *"connect"* ]]
  then
    if [[ $file_path == *"sink"* ]]
    then
      echo "${repro}🔗🌎🔹 $file_path" >> $output_file
    elif [[ $file_path == *"source"* ]]
    then
      echo "${repro}🔗🌎🔻 $file_path" >> $output_file
    else
      echo "${repro}🔗🌎 $file_path" >> $output_file
    fi
  elif [[ $file_path == *"ksql"* ]]
  then
    echo "${repro}🎏 $file_path" >> $output_file
  elif [[ $file_path == *"schema-registry"* ]]
  then
    echo "${repro}🔰 $file_path" >> $output_file
  elif [[ $file_path == *"rest-proxy"* ]]
  then
    echo "${repro}😴 $file_path" >> $output_file
  elif [[ $file_path == *"environment"* ]]
  then
    echo "${repro}🔐 $file_path" >> $output_file
  else
    echo "${repro}👾 $file_path" >> $output_file
  fi
}

function generate_fzf_find_files() {
  generate_get_examples_list_with_fzf_without_repro_sink_only
  generate_get_examples_list_with_fzf_without_repro
  generate_get_examples_list_with_fzf_ccloud_only
  generate_get_examples_list_with_fzf

  generate_get_examples_list_with_fzf_connector_only
  generate_get_examples_list_with_fzf_repro_only
  generate_get_examples_list_with_fzf_environemnt_only
  generate_get_examples_list_with_fzf_ksql_only
  generate_get_examples_list_with_fzf_fully_managed_connector_only
  generate_get_examples_list_with_fzf_schema_registry_only
  generate_get_examples_list_with_fzf_rest_proxy_only
  generate_get_examples_list_with_fzf_academy_only
  generate_get_examples_list_with_fzf_other_playgrounds_only
}

function generate_get_examples_list_with_fzf_connector_only () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_connector_only"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'stop.sh' -path '*/connect/connect-*/*' ! -path '*/scripts/*' ! -path '*/security/*' ! -path '*/reproduction-models/*' ! -path '*/ccloud/*'  | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  sort -o $output_file $output_file
}

function generate_get_examples_list_with_fzf_repro_only () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_repro_only"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'stop.sh' ! -path '*/scripts/*'  ! -path '*/security/*' -path '*/reproduction-models/*' | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  if [ -s "$output_file" ]; then
    sort -o $output_file $output_file
  fi
}

function generate_get_examples_list_with_fzf_environemnt_only () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_environment_only"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'update_run.sh' ! -name 'stop.sh' ! -path '*/scripts/*' ! -path '*/security/*' -path '*/environment/*' | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  if [ -s "$output_file" ]; then
    sort -o $output_file $output_file
  fi
}

function generate_get_examples_list_with_fzf_ksql_only () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_ksql_only"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'stop.sh' -path '*/ksqldb/*' ! -path '*/scripts/*' ! -path '*/security/*' ! -path '*/reproduction-models/*'  ! -path '*/ccloud/*' | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  if [ -s "$output_file" ]; then
    sort -o $output_file $output_file
  fi
}

function generate_get_examples_list_with_fzf_fully_managed_connector_only () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_fully_managed_connector_only"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'stop.sh' -path '*/fm-*/*' ! -path '*/scripts/*' ! -path '*/security/*' ! -path '*/reproduction-models/*' -path '*/ccloud/*' | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  if [ -s "$output_file" ]; then
    sort -o $output_file $output_file
  fi
}

function generate_get_examples_list_with_fzf_schema_registry_only () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_schema_registry_only"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'stop.sh' -path '*/schema-registry/*' ! -path '*/scripts/*' ! -path '*/security/*' ! -path '*/reproduction-models/*' ! -path '*/ccloud/*' | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  if [ -s "$output_file" ]; then
    sort -o $output_file $output_file
  fi
}

function generate_get_examples_list_with_fzf_rest_proxy_only () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_rest_proxy_only"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'stop.sh' -path '*/rest-proxy/*' ! -path '*/scripts/*' ! -path '*/security/*' ! -path '*/reproduction-models/*'  ! -path '*/ccloud/*' | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  if [ -s "$output_file" ]; then
    sort -o $output_file $output_file
  fi
}

function generate_get_examples_list_with_fzf_academy_only () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_academy_only"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'stop.sh' -path '*/academy/*' ! -path '*/scripts/*' ! -path '*/security/*' ! -path '*/reproduction-models/*'  ! -path '*/ccloud/*' | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  if [ -s "$output_file" ]; then
    sort -o $output_file $output_file
  fi
}

function generate_get_examples_list_with_fzf_other_playgrounds_only () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_other_playgrounds_only"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'stop.sh' ! -path '*/scripts/*'  ! -path '*/security/*' ! -path '*/reproduction-models/*'  ! -path '*/ccloud/*' ! -path '*/reproduction-models/*' ! -path '*/connect/*' ! -path '*/ksqldb/*' ! -path '*/schema-registry/*'  | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  if [ -s "$output_file" ]; then
    sort -o $output_file $output_file
  fi
}

function generate_get_examples_list_with_fzf_without_repro_sink_only () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_without_repro_sink_only"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'stop.sh' -path '*/connect-*-sink/*' ! -path '*/scripts/*'  ! -path '*/other/*' ! -path '*/ccloud/*'  ! -path '*/academy/*' ! -path '*/security/*' ! -path '*/reproduction-models/*' | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  if [ -s "$output_file" ]; then
    sort -o $output_file $output_file
  fi
}

function generate_get_examples_list_with_fzf_without_repro () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_without_repro"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'stop.sh' ! -path '*/scripts/*'  ! -path '*/security/*' ! -path '*/reproduction-models/*' | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  if [ -s "$output_file" ]; then
    sort -o $output_file $output_file
  fi
}

function generate_get_examples_list_with_fzf_ccloud_only () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_ccloud_only"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'stop.sh' -path '*/ccloud*' ! -path '*/security/*' | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  if [ -s "$output_file" ]; then
    sort -o $output_file $output_file
  fi
}

function generate_get_examples_list_with_fzf () {
  output_file="$root_folder/scripts/cli/get_examples_list_with_fzf_all"
  rm -f $output_file
  find $root_folder -name \*.sh ! -name 'stop.sh' ! -path '*/scripts/*' ! -path '*/security/*' | while read file_path
  do
    if grep -q "scripts/utils.sh" "$file_path"; then
      generate_get_examples_add_emoji
    fi
  done
  if [ -s "$output_file" ]; then
    sort -o $output_file $output_file
  fi
}

function get_ccloud_connect() {
  get_kafka_docker_playground_dir

  if [ ! -f $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta ]
  then
      logerror "❌ $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta has not been generated"
      exit 1
  fi

  environment=$(grep "ENVIRONMENT ID" $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta | cut -d " " -f 4)
  cluster=$(grep "KAFKA CLUSTER ID" $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta | cut -d " " -f 5)

  if [ -z $CLOUD_API_KEY ]
  then
    logerror "❌ environment variable CLOUD_API_KEY should be set to use $CONNECTOR_TYPE_FULLY_MANAGED or $CONNECTOR_TYPE_CUSTOM connector"
    logerror "Set it with Cloud API key, see https://docs.confluent.io/cloud/current/access-management/authenticate/api-keys/api-keys.html#cloud-cloud-api-keys"
    exit 1
  fi

  if [ -z $CLOUD_API_SECRET ]
  then
    logerror "❌ environment variable CLOUD_API_SECRET should be set to use $CONNECTOR_TYPE_FULLY_MANAGED or $CONNECTOR_TYPE_CUSTOM connector"
    logerror "Set it with Cloud API secret, see https://docs.confluent.io/cloud/current/access-management/authenticate/api-keys/api-keys.html#cloud-cloud-api-keys"
    exit 1
  fi

  authorization=$(echo -n "$CLOUD_API_KEY:$CLOUD_API_SECRET" | base64)
}

function get_sr_url_and_security() {
  get_environment_used

  sr_url="http://localhost:8081"
  sr_security=""

  if [[ "$environment" == "sasl-ssl" ]] || [[ "$environment" == "2way-ssl" ]]
  then
      sr_url="https://localhost:8081"
      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

      sr_security="--cert $DIR_CLI/../../environment/$environment/security/schema-registry.certificate.pem --key $DIR_CLI/../../environment/$environment/security/schema-registry.key --tlsv1.2 --cacert $DIR_CLI/../../environment/$environment/security/snakeoil-ca-1.crt"
  elif [[ "$environment" == "rbac-sasl-plain" ]]
  then
      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

      sr_security="-u superUser:superUser"
  elif [[ "$environment" == "ccloud" ]]
  then
    if [[ ! -n "$root_folder" ]]
    then
      # can happen in filter function where before hook is not called
      DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
      dir1=$(echo ${DIR_CLI%/*})
      root_folder=$(echo ${dir1%/*})
    fi
    if [ -f $root_folder/.ccloud/env.delta ]
    then
        source $root_folder/.ccloud/env.delta
    else
        logerror "❌ $root_folder/.ccloud/env.delta has not been generated"
        exit 1
    fi
    sr_url=$SCHEMA_REGISTRY_URL
    sr_security="-u $SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO"
  fi
}

function get_broker_container() {
  for broker in broker broker2 broker3 broker-us broker-europe
  do
    if is_container_running $broker
    then
      broker_container=$broker
      break
    fi
  done
}

function get_security_broker() {
  config_file_name="$1"
  get_environment_used

  get_broker_container
  container="$broker_container"
  bootstrap_server="$broker_container:9092"

  security=""
  if [[ "$environment" == "kerberos" ]] || [[ "$environment" == "ssl_kerberos" ]]
  then
      container="client"
      security="$config_file_name /etc/kafka/consumer.properties"

      docker exec -i client kinit -k -t /var/lib/secret/kafka-connect.key connect
  elif [ "$environment" == "ldap-authorizer-sasl-plain" ]
  then
      security="$config_file_name /service/kafka/users/kafka.properties"
  elif [ "$environment" == "ldap-sasl-plain" ] || [ "$environment" == "sasl-plain" ] || [ "$environment" == "sasl-scram" ]
  then
      security="$config_file_name /tmp/client.properties"
  elif [[ "$environment" != *plaintext ]]
  then
      security="$config_file_name /etc/kafka/secrets/client_without_interceptors.config"
  fi
}

function get_fzf_version() {
    version=$(fzf --version | grep -oE "[0-9]+\.[0-9]+\.[0-9]+" | cut -d " " -f 1)
    echo "$version"
}

function get_examples_list_with_fzf() {
  cur="$1"
  file="$2"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  terminal_columns=$(tput cols)
  if [[ $terminal_columns -gt 180 ]]
  then
    if [[ $(type -f bat 2>&1) =~ "not found" ]]
    then
        res=$(cat $file | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🚀" --header="select example" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "1,-3,-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'cat /{2..}');echo "$cur@$(echo $res | cut -d ' ' -f 2)"
    else
      res=$(cat $file | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🚀" --header="select example" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "1,-3,-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'bat --style=plain --color=always --line-range :500 /{2..}');echo "$cur@$(echo $res | cut -d ' ' -f 2)"
    fi
  else
    res=$(cat $file | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🚀" --header="select example" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "1,-3,-2,-1" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$(echo $res | cut -d ' ' -f 2)"
  fi
}

function get_zip_or_jar_with_fzf() {
  cur="$1"
  type="$2"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  folder_zip_or_jar=$(playground config get folder_zip_or_jar)
  if [ "$folder_zip_or_jar" == "" ]
  then
    logerror "Could not find config value <folder_zip_or_jar> !"
    exit 1
  fi

  folder_zip_or_jar=${folder_zip_or_jar//\~/$HOME}
  folder_zip_or_jar=${folder_zip_or_jar//,/ }

  fzf_output=$(find $folder_zip_or_jar $PWD -name \*.$type ! -path '*/\.*' | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🤐" --header="select zip or jar file (use option+enter to use the value you typed manually)" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer --print-query --bind "alt-enter:print-query")

  # Parse fzf output: first line is query, second line is selection (or query again if alt-enter was used)
  query_line=$(echo "$fzf_output" | head -n1)
  selected_line=$(echo "$fzf_output" | tail -n1)

  # If both lines are the same, user pressed alt-enter (use typed value)
  if [ "$query_line" = "$selected_line" ]; then
    res="$query_line"
  else
    res="$selected_line"
  fi

  echo "$cur@$res"
}

function get_specific_file_extension() {
  cur="$1"
  extension="$2"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  fzf_output=$(find $PWD -name \*.$extension ! -path '*/\.*' | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🔖" --header="select $extension file (use option+enter to use the value you typed manually)" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer --print-query --bind "alt-enter:print-query")

  # Parse fzf output: first line is query, second line is selection (or query again if alt-enter was used)
  query_line=$(echo "$fzf_output" | head -n1)
  selected_line=$(echo "$fzf_output" | tail -n1)

  # If both lines are the same, user pressed alt-enter (use typed value)
  if [ "$query_line" = "$selected_line" ]; then
    res="$query_line"
  else
    res="$selected_line"
  fi

  echo "$cur@$res"
}

function get_playground_repro_export_with_fzf() {
  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  folder_zip_or_jar=$(playground config get folder_zip_or_jar)
  if [ "$folder_zip_or_jar" == "" ]
  then
    logerror "Could not find config value <folder_zip_or_jar> !"
    exit 1
  fi

  folder_zip_or_jar=${folder_zip_or_jar//\~/$HOME}
  folder_zip_or_jar=${folder_zip_or_jar//,/ }

  fzf_output=$(cat /tmp/get_any_files_with_fzf | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="📃" --header="select file" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer --print-query --bind "alt-enter:print-query")

  # Parse fzf output: first line is query, second line is selection (or query again if alt-enter was used)
  query_line=$(echo "$fzf_output" | head -n1)
  selected_line=$(echo "$fzf_output" | tail -n1)

  # If both lines are the same, user pressed alt-enter (use typed value)
  if [ "$query_line" = "$selected_line" ]; then
    res="$query_line"
  else
    res="$selected_line"
  fi

  echo "$cur@$res"
}

function get_ccloud_environment_list_with_fzf() {
  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  res=$(confluent environment list | awk -F'|' '{print $2"/"$3}' | sed 's/[[:blank:]]//g' | grep -v "ID" | grep -v "\-\-\-" | grep -v '^/' | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🌐" --header="select ccloud environment" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
}

function get_ccloud_cluster_list_with_fzf() {
  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  res=$(confluent kafka cluster list | awk -F'|' '{print $2"/"$3}' | sed 's/[[:blank:]]//g' | grep -v "ID" | grep -v "\-\-\-" | grep -v '^/' | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🌐" --header="select ccloud cluster" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
}

function get_confluent_kafka_region_list_with_fzf() {
  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  res=$(cat $root_folder/scripts/cli/confluent-kafka-region-list.txt | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🌍" --header="select region" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
}

function ec2_instance_list() {
  username=$(whoami)
  name="pg-${username}"

  for row in $(aws ec2 describe-instances --filters "Name=tag:Name,Values=$name-*" | jq '[.Reservations | .[] | .Instances | .[] | select(.State.Name!="terminated") | {PublicDnsName: .PublicDnsName, InstanceId: .InstanceId,State: .State.Name, Name: (.Tags[]|select(.Key=="Name")|.Value)}]' | jq -r '.[] | @base64'); do
      _jq() {
      echo ${row} | base64 -d | jq -r ${1}
      }

      Name=$(echo $(_jq '.Name'))
      if [[ $Name != $name* ]]
      then
          continue
      fi
      PublicDnsName=$(echo $(_jq '.PublicDnsName'))
      InstanceId=$(echo $(_jq '.InstanceId'))
      State=$(echo $(_jq '.State'))

      if [ "$State" = "stopped" ]
      then
          echo "$Name/$EC2_INSTANCE_STATE_STOPPED/$PublicDnsName/$InstanceId"
      elif [ "$State" = "stopping" ]
      then
          echo "$Name/$EC2_INSTANCE_STATE_STOPPING"
      elif [ "$State" = "pending" ]
      then
          echo "$Name/$EC2_INSTANCE_STATE_PENDING"
      else
          echo "$Name/$EC2_INSTANCE_STATE_RUNNING/$PublicDnsName/$InstanceId"
      fi
  done
}

function get_ec2_instance_list_with_fzf() {
  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  res=$(ec2_instance_list | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🖥️" --header="select ec2 instance (wait for it)" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
}

function ec2_cloudformation_list() {
  username=$(whoami)
  name="pg-${username}"

  for row in $(aws cloudformation list-stacks --stack-status-filter CREATE_COMPLETE ROLLBACK_COMPLETE | jq '[.StackSummaries | .[] | {StackName: .StackName,StackStatus: .StackStatus }]' | jq -r '.[] | @base64'); do
      _jq() {
      echo ${row} | base64 -d | jq -r ${1}
      }

      StackName=$(echo $(_jq '.StackName'))
      StackStatus=$(echo $(_jq '.StackStatus'))

      if [[ $StackName != $name* ]]
      then
          continue
      fi

      echo "$StackName/$StackStatus"
  done
}

function get_ec2_cloudformation_list_with_fzf() {
  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  res=$(ec2_cloudformation_list | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🌀" --header="select ec2 cloudformation (wait for it)" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
}

function get_tag_list_with_fzf() {
  cur="$1"
  connect_only="$2"

  if [[ "$connect_only" == "1" ]]
  then
    txt_file="connect-tag-list.txt"
  else
    txt_file="tag-list.txt"
  fi

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  res=$(cat $root_folder/scripts/cli/$txt_file | sed '1!G;h;$!d' | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🎯" --header="select cp version" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
}

function get_any_files_with_fzf() {
  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  res=$(cat /tmp/get_any_files_with_fzf | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="📃" --header="select file" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer --print-query --bind "alt-enter:print-query");echo "$cur@$res"
}

function get_predefined_schemas_with_fzf() {
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  dir2=$(echo ${dir1%/*})
  predefined_folder=$dir2/scripts/cli/predefined-schemas

  cur="$1"

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=70%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  if [[ $(type -f bat 2>&1) =~ "not found" ]]
  then
    res=$(find $predefined_folder -maxdepth 3 \( -name "*.json" -o -name "*.avsc" -o -name "*.proto" -o -name "*.proto5" -o -name "*.sql" \) | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🔰" --header="select a predefined schema" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'cat {}');echo "$cur@$res"
  else
    res=$(find $predefined_folder -maxdepth 3 \( -name "*.json" -o -name "*.avsc" -o -name "*.proto" -o -name "*.proto5" -o -name "*.sql" \) | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🔰" --header="select a predefined schema" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter / --with-nth "-2,-1" $fzf_option_wrap $fzf_option_pointer --preview 'bat --style=plain --color=always --line-range :500 {}');echo "$cur@$res"
  fi
}

function get_plugin_list() {
  cur="$1"
  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

    if [ ! -f $root_folder/scripts/cli/confluent-hub-plugin-list.txt ]
    then
        playground generate-connector-plugin-list
    fi

    if [ ! -f $root_folder/scripts/cli/confluent-hub-plugin-list.txt ]
    then
        logerror "file $root_folder/scripts/cli/confluent-hub-plugin-list.txt could not be generated"
        exit 1
    fi

  res=$(cat $root_folder/scripts/cli/confluent-hub-plugin-list.txt | grep -v "CONFLUENT EMPLOYEE VERSION" |cut -d "|" -f 1 | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🔌" --header="select connector plugin" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer);echo "$cur@$res"
}

function choose_connector_tag() {
  connector_plugin="$1"

  owner=$(echo "$connector_plugin" | cut -d "/" -f 1)
  name=$(echo "$connector_plugin" | cut -d "/" -f 2)

  filename="/tmp/version_$owner_$name"

  if [ ! -f $filename ]
  then
    playground connector-plugin versions --connector-plugin $owner/$name > /dev/null 2>&1
  fi

  if [ ! -f $filename ]
  then
      logerror "❌ could not get versions for connector plugin $connector_plugin"
      exit 1
  fi

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
    fzf_option_wrap="--preview-window=40%,wrap"
    fzf_option_pointer="--pointer=👉"
    fzf_option_rounded="--border=rounded"
  else
    fzf_option_wrap=""
    fzf_option_pointer=""
    fzf_option_rounded=""
  fi

  cat $filename | grep -v "documentation"| sed '1!G;h;$!d' | fzf -i --query "$cur" --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🔢" --header="select connector version for $owner/$name" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer
}

function filter_not_mdc_environment() {
  get_environment_used

  if [[ "$environment" == "mdc"* ]]
  then
    logerror "$environment is not supported with this command !"
  fi
}

function filter_ccloud_environment() {
  get_environment_used

  if [[ "$environment" != "ccloud" ]]
  then
    logerror "environment should be ccloud with this command (it is $environment)!"
  fi
}

function filter_plaintext_or_ccloud_environment() {
  get_environment_used

  if [[ "$environment" != "ccloud" ]] && [[ "$environment" != "plaintext" ]]
  then
    logerror "environment should be plaintext or ccloud with this command (it is $environment)!"
  fi
}

function filter_schema_registry_running() {
  get_sr_url_and_security

  for i in {1..30}; do
    curl $sr_security -s "${sr_url}/config" > /dev/null 2>&1
    if [ $? == 0 ]; then
      break
    fi
    sleep 1
  done

  if [ $? != 0 ]; then
    logerror "schema registry rest api should be running to run this command"
  fi
}

function filter_oracle_running() {
  docker ps --filter "name=oracle" --filter "status=running" --format "{{.Names}}" | grep -q "oracle"
  if [ $? != 0 ]; then
    logerror "oracle docker container should be running to run this command"
  fi
}

function filter_connect_running() {
  get_connect_url_and_security

  curl $security -s "${connect_url}" > /dev/null 2>&1
  if [ $? != 0 ]
  then
    logerror "connect rest api should be running to run this command"
  fi
}

function filter_docker_running() {
  docker info >/dev/null 2>&1 || logerror "docker must be running"
}

function filter_aws_ec2_permissions() {
  aws ec2 describe-instances --dry-run > /tmp/output_ec2_describe_instance.log 2>&1
  if ! grep -q "DryRunOperation" /tmp/output_ec2_describe_instance.log
  then
    logerror "aws ec2 describe-instances command got an error"
    logerror "please make sure to have AdministratorAccess in aws"
    cat /tmp/output_ec2_describe_instance.log
  fi
}

function increment_cli_metric() {
  metric_name="$1"
  metric=$(playground state get "metrics.$metric_name")
  if [ "$metric" == "" ]
  then
    # initialize
    playground state set "metrics.$metric_name" 1
  else
    playground state set "metrics.$metric_name" $((metric+1))
  fi
}

function get_cli_metric() {
  metric_name="$1"
  playground state get "metrics.$metric_name"
}

function set_cli_metric() {
  metric_name="$1"
  metric_value="$2"
  playground state set "metrics.$metric_name" "$metric_value"
}

function add_connector_config_based_on_environment () {
  environment="$1"
  json_content="$2"

  echo "$json_content" > $tmp_dir/1.json

  if [ -n "$AWS_SHORT_LIVE_CREDENTIALS_USED" ]
  then
    log "💫 removing aws.access.key.id and aws.secret.access.key from config"
    echo "$json_content" > $tmp_dir/input.json
    jq 'del(.["aws.access.key.id"], .["aws.secret.access.key"])' $tmp_dir/input.json > $tmp_dir/output.json
    json_content=$(cat $tmp_dir/output.json)
  fi

  case "${environment}" in
    plaintext)
      # nothing to do
      return
    ;;
    ccloud)
      if [ -f $root_folder/.ccloud/env.delta ]
      then
          source $root_folder/.ccloud/env.delta
      else
          logerror "❌ $root_folder/.ccloud/env.delta has not been generated"
          exit 1
      fi

      echo "$json_content" > $tmp_dir/input.json
      jq ".[\"topic.creation.default.replication.factor\"] = \"-1\" | .[\"topic.creation.default.partitions\"] = \"-1\"" $tmp_dir/input.json > $tmp_dir/output.json
      json_content=$(cat $tmp_dir/output.json)

      for prefix in {"confluent.topic","redo.log.consumer"}
      do
        if echo "$json_content" | jq ". | has(\"$prefix.bootstrap.servers\")" 2> /dev/null | grep -q true

        then
          # log "replacing $prefix config for environment $environment"

          echo "$json_content" > $tmp_dir/input.json
          jq ".[\"$prefix.bootstrap.servers\"] = \"\${file:/datacloud:bootstrap.servers}\" | .[\"$prefix.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"\${file:/datacloud:sasl.username}\\\" password=\\\"\${file:/datacloud:sasl.password}\\\";\" | .[\"$prefix.security.protocol\"] = \"SASL_SSL\" | .[\"$prefix.sasl.mechanism\"] = \"PLAIN\"" $tmp_dir/input.json > $tmp_dir/output.json
          json_content=$(cat $tmp_dir/output.json)

          if [ "$prefix" == "confluent.topic" ]
          then
            echo "$json_content" > $tmp_dir/input.json
            jq ".[\"confluent.topic.replication.factor\"] = \"3\"" $tmp_dir/input.json > $tmp_dir/output.json
            json_content=$(cat $tmp_dir/output.json)
          fi
        fi
      done

      for prefix in {"key","value"}
      do
        if echo "$json_content" | jq ". | has(\"$prefix.converter.schema.registry.url\")" 2> /dev/null | grep -q true

        then
          # log "replacing $prefix.converter.schema.registry.url config for environment $environment"

          echo "$json_content" > $tmp_dir/input.json
          jq ".[\"$prefix.converter.schema.registry.url\"] = \"$SCHEMA_REGISTRY_URL\" | .[\"$prefix.converter.basic.auth.user.info\"] = \"\${file:/datacloud:schema.registry.basic.auth.user.info}\" | .[\"$prefix.converter.basic.auth.credentials.source\"] = \"USER_INFO\"" $tmp_dir/input.json > $tmp_dir/output.json
          json_content=$(cat $tmp_dir/output.json)
        fi
      done

      if echo "$json_content" | jq ". | has(\"database.history.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing database.history.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"database.history.kafka.bootstrap.servers\"] = \"\${file:/datacloud:bootstrap.servers}\" | .[\"database.history.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"\${file:/datacloud:sasl.username}\\\" password=\\\"\${file:/datacloud:sasl.password}\\\";\" | .[\"database.history.producer.security.protocol\"] = \"SASL_SSL\" | .[\"database.history.producer.sasl.mechanism\"] = \"PLAIN\" | .[\"database.history.consumer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"\${file:/datacloud:sasl.username}\\\" password=\\\"\${file:/datacloud:sasl.password}\\\";\" | .[\"database.history.consumer.security.protocol\"] = \"SASL_SSL\" | .[\"database.history.consumer.sasl.mechanism\"] = \"PLAIN\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"schema.history.internal.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing schema.history.internal.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"schema.history.internal.kafka.bootstrap.servers\"] = \"\${file:/datacloud:bootstrap.servers}\" | .[\"schema.history.internal.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"\${file:/datacloud:sasl.username}\\\" password=\\\"\${file:/datacloud:sasl.password}\\\";\" | .[\"schema.history.internal.producer.security.protocol\"] = \"SASL_SSL\" | .[\"schema.history.internal.producer.sasl.mechanism\"] = \"PLAIN\" | .[\"schema.history.internal.consumer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"\${file:/datacloud:sasl.username}\\\" password=\\\"\${file:/datacloud:sasl.password}\\\";\" | .[\"schema.history.internal.consumer.security.protocol\"] = \"SASL_SSL\" | .[\"schema.history.internal.consumer.sasl.mechanism\"] = \"PLAIN\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"reporter.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing reporter.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"reporter.bootstrap.servers\"] = \"\${file:/datacloud:bootstrap.servers}\" | .[\"reporter.result.topic.replication.factor\"] = \"3\" | .[\"reporter.error.topic.replication.factor\"] = \"3\" | .[\"reporter.admin.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"\${file:/datacloud:sasl.username}\\\" password=\\\"\${file:/datacloud:sasl.password}\\\";\" | .[\"reporter.admin.security.protocol\"] = \"SASL_SSL\" | .[\"reporter.admin.sasl.mechanism\"] = \"PLAIN\" | .[\"reporter.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"\${file:/datacloud:sasl.username}\\\" password=\\\"\${file:/datacloud:sasl.password}\\\";\" | .[\"reporter.producer.security.protocol\"] = \"SASL_SSL\" | .[\"reporter.producer.sasl.mechanism\"] = \"PLAIN\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi
    ;;

    sasl-plain|ldap-authorizer-sasl-plain|ldap-sasl-plain)

      for prefix in {"confluent.topic","redo.log.consumer"}
      do
        if echo "$json_content" | jq ". | has(\"$prefix.bootstrap.servers\")" 2> /dev/null | grep -q true

        then
          # log "replacing $prefix config for environment $environment"

          echo "$json_content" > $tmp_dir/input.json
          jq ".[\"$prefix.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"$prefix.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"$prefix.sasl.mechanism\"] = \"PLAIN\"" $tmp_dir/input.json > $tmp_dir/output.json
          json_content=$(cat $tmp_dir/output.json)
        fi
      done

      if echo "$json_content" | jq ". | has(\"database.history.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing database.history.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"database.history.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"database.history.producer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"database.history.producer.sasl.mechanism\"] = \"PLAIN\" | .[\"database.history.consumer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"database.history.consumer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"database.history.consumer.sasl.mechanism\"] = \"PLAIN\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"schema.history.internal.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing schema.history.internal.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"schema.history.internal.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"schema.history.internal.producer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"schema.history.internal.producer.sasl.mechanism\"] = \"PLAIN\" | .[\"schema.history.internal.consumer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"schema.history.internal.consumer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"schema.history.internal.consumer.sasl.mechanism\"] = \"PLAIN\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"reporter.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing reporter.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"reporter.admin.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"reporter.admin.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"reporter.admin.sasl.mechanism\"] = \"PLAIN\" | .[\"reporter.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"reporter.producer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"reporter.producer.sasl.mechanism\"] = \"PLAIN\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi
    ;;

    sasl-ssl)
      get_broker_container
      for prefix in {"confluent.topic","redo.log.consumer"}
      do
        if echo "$json_content" | jq ". | has(\"$prefix.bootstrap.servers\")" 2> /dev/null | grep -q true

        then
          # log "replacing $prefix config for environment $environment"

          echo "$json_content" > $tmp_dir/input.json
          jq ".[\"$prefix.bootstrap.servers\"] = \"$broker_container:9092\" | .[\"$prefix.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"$prefix.security.protocol\"] = \"SASL_SSL\" | .[\"$prefix.sasl.mechanism\"] = \"PLAIN\" | .[\"$prefix.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"$prefix.ssl.truststore.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
          json_content=$(cat $tmp_dir/output.json)
        fi
      done

      for prefix in {"key","value"}
      do
        if echo "$json_content" | jq ". | has(\"$prefix.converter.schema.registry.url\")" 2> /dev/null | grep -q true

        then
          # log "replacing $prefix.converter.schema.registry.url config for environment $environment"

          echo "$json_content" > $tmp_dir/input.json
          jq ".[\"$prefix.converter.schema.registry.url\"] = \"https://schema-registry:8081\" | .[\"$prefix.converter.schema.registry.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"$prefix.converter.schema.registry.ssl.truststore.password\"] = \"confluent\" | .[\"$prefix.converter.schema.registry.ssl.keystore.location\"] = \"/etc/kafka/secrets/kafka.connect.keystore.jks\" | .[\"$prefix.converter.schema.registry.ssl.keystore.password\"] = \"confluent\" | .[\"$prefix.converter.schema.registry.ssl.key.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
          json_content=$(cat $tmp_dir/output.json)
        fi
      done

      if echo "$json_content" | jq ". | has(\"database.history.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing database.history.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"database.history.kafka.bootstrap.servers\"] = \"$broker_container:9092\" | .[\"database.history.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"database.history.producer.security.protocol\"] = \"SASL_SSL\" | .[\"database.history.producer.sasl.mechanism\"] = \"PLAIN\" | .[\"database.history.consumer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"database.history.consumer.security.protocol\"] = \"SASL_SSL\" | .[\"database.history.consumer.sasl.mechanism\"] = \"PLAIN\" | .[\"database.history.producer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"database.history.producer.ssl.truststore.password\"] = \"confluent\" | .[\"database.history.consumer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"database.history.consumer.ssl.truststore.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"schema.history.internal.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing schema.history.internal.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"schema.history.internal.kafka.bootstrap.servers\"] = \"$broker_container:9092\" | .[\"schema.history.internal.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"schema.history.internal.producer.security.protocol\"] = \"SASL_SSL\" | .[\"schema.history.internal.producer.sasl.mechanism\"] = \"PLAIN\" | .[\"schema.history.internal.consumer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"schema.history.internal.consumer.security.protocol\"] = \"SASL_SSL\" | .[\"schema.history.internal.consumer.sasl.mechanism\"] = \"PLAIN\" | .[\"schema.history.internal.producer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"schema.history.internal.producer.ssl.truststore.password\"] = \"confluent\" | .[\"schema.history.internal.consumer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"schema.history.internal.consumer.ssl.truststore.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"reporter.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing reporter.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"reporter.admin.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"reporter.admin.security.protocol\"] = \"SASL_SSL\" | .[\"reporter.admin.sasl.mechanism\"] = \"PLAIN\" | .[\"reporter.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"reporter.producer.security.protocol\"] = \"SASL_SSL\" | .[\"reporter.producer.sasl.mechanism\"] = \"PLAIN\" | .[\"reporter.admin.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"reporter.admin.ssl.truststore.password\"] = \"confluent\" | .[\"reporter.producer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"reporter.producer.ssl.truststore.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi
    ;;

    2way-ssl)
      get_broker_container
      for prefix in {"confluent.topic","redo.log.consumer"}
      do
        if echo "$json_content" | jq ". | has(\"$prefix.bootstrap.servers\")" 2> /dev/null | grep -q true

        then
          # log "replacing $prefix config for environment $environment"

          echo "$json_content" > $tmp_dir/input.json
          jq ".[\"$prefix.bootstrap.servers\"] = \"$broker_container:9092\" | .[\"$prefix.security.protocol\"] = \"SSL\" | .[\"$prefix.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"$prefix.ssl.truststore.password\"] = \"confluent\" | .[\"$prefix.ssl.keystore.location\"] = \"/etc/kafka/secrets/kafka.connect.keystore.jks\" | .[\"$prefix.ssl.keystore.password\"] = \"confluent\" | .[\"$prefix.ssl.key.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
          json_content=$(cat $tmp_dir/output.json)
        fi
      done

      for prefix in {"key","value"}
      do
        if echo "$json_content" | jq ". | has(\"$prefix.converter.schema.registry.url\")" 2> /dev/null | grep -q true

        then
          # log "replacing $prefix.converter.schema.registry.url config for environment $environment"

          echo "$json_content" > $tmp_dir/input.json
          jq ".[\"$prefix.converter.schema.registry.url\"] = \"https://schema-registry:8081\" | .[\"$prefix.converter.schema.registry.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"$prefix.converter.schema.registry.ssl.truststore.password\"] = \"confluent\" | .[\"$prefix.converter.schema.registry.ssl.keystore.location\"] = \"/etc/kafka/secrets/kafka.connect.keystore.jks\" | .[\"$prefix.converter.schema.registry.ssl.keystore.password\"] = \"confluent\" | .[\"$prefix.converter.schema.registry.ssl.key.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
          json_content=$(cat $tmp_dir/output.json)
        fi
      done

      if echo "$json_content" | jq ". | has(\"database.history.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing database.history.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"database.history.kafka.bootstrap.servers\"] = \"$broker_container:9092\" | .[\"database.history.producer.security.protocol\"] = \"SSL\" | .[\"database.history.consumer.security.protocol\"] = \"SSL\" | .[\"database.history.producer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"database.history.producer.ssl.truststore.password\"] = \"confluent\" | .[\"database.history.producer.ssl.keystore.location\"] = \"/etc/kafka/secrets/kafka.connect.keystore.jks\" | .[\"database.history.producer.ssl.keystore.password\"] = \"confluent\" | .[\"database.history.producer.ssl.keystore.password\"] = \"confluent\" | .[\"database.history.consumer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"database.history.consumer.ssl.truststore.password\"] = \"confluent\" | .[\"database.history.consumer.ssl.keystore.location\"] = \"/etc/kafka/secrets/kafka.connect.keystore.jks\" | .[\"database.history.consumer.ssl.keystore.password\"] = \"confluent\" | .[\"database.history.consumer.ssl.keystore.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"schema.history.internal.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing schema.history.internal.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"schema.history.internal.kafka.bootstrap.servers\"] = \"$broker_container:9092\" | .[\"schema.history.internal.producer.security.protocol\"] = \"SSL\" | .[\"schema.history.internal.consumer.security.protocol\"] = \"SSL\" | .[\"schema.history.internal.producer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"schema.history.internal.producer.ssl.truststore.password\"] = \"confluent\" | .[\"schema.history.internal.producer.ssl.keystore.location\"] = \"/etc/kafka/secrets/kafka.connect.keystore.jks\" | .[\"schema.history.internal.producer.ssl.keystore.password\"] = \"confluent\" | .[\"schema.history.internal.producer.ssl.keystore.password\"] = \"confluent\" | .[\"schema.history.internal.consumer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"schema.history.internal.consumer.ssl.truststore.password\"] = \"confluent\" | .[\"schema.history.internal.consumer.ssl.keystore.location\"] = \"/etc/kafka/secrets/kafka.connect.keystore.jks\" | .[\"schema.history.internal.consumer.ssl.keystore.password\"] = \"confluent\" | .[\"schema.history.internal.consumer.ssl.keystore.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"reporter.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing reporter.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"reporter.admin.security.protocol\"] = \"SSL\" | .[\"reporter.admin.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"reporter.admin.ssl.truststore.password\"] = \"confluent\" | .[\"reporter.admin.ssl.keystore.location\"] = \"/etc/kafka/secrets/kafka.connect.keystore.jks\" | .[\"reporter.admin.ssl.keystore.password\"] = \"confluent\" | .[\"reporter.admin.ssl.keystore.password\"] = \"confluent\" | .[\"reporter.producer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"reporter.producer.ssl.truststore.password\"] = \"confluent\" | .[\"reporter.producer.security.protocol\"] = \"SSL\" | .[\"reporter.producer.ssl.keystore.location\"] = \"/etc/kafka/secrets/kafka.connect.keystore.jks\" | .[\"reporter.producer.ssl.keystore.password\"] = \"confluent\" | .[\"reporter.producer.ssl.keystore.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi
    ;;

    sasl-scram)

      for prefix in {"confluent.topic","redo.log.consumer"}
      do
        if echo "$json_content" | jq ". | has(\"$prefix.bootstrap.servers\")" 2> /dev/null | grep -q true

        then
          # log "replacing $prefix config for environment $environment"

          echo "$json_content" > $tmp_dir/input.json
          jq ".[\"$prefix.sasl.jaas.config\"] = \"org.apache.kafka.common.security.scram.ScramLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"$prefix.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"$prefix.sasl.mechanism\"] = \"SCRAM-SHA-256\"" $tmp_dir/input.json > $tmp_dir/output.json
          json_content=$(cat $tmp_dir/output.json)
        fi
      done

      if echo "$json_content" | jq ". | has(\"database.history.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing database.history.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"database.history.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.scram.ScramLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"database.history.producer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"database.history.producer.sasl.mechanism\"] = \"SCRAM-SHA-256\" | .[\"database.history.consumer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.scram.ScramLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"database.history.consumer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"database.history.consumer.sasl.mechanism\"] = \"SCRAM-SHA-256\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"schema.history.internal.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing schema.history.internal.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"schema.history.internal.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.scram.ScramLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"schema.history.internal.producer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"schema.history.internal.producer.sasl.mechanism\"] = \"SCRAM-SHA-256\" | .[\"schema.history.internal.consumer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.scram.ScramLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"schema.history.internal.consumer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"schema.history.internal.consumer.sasl.mechanism\"] = \"SCRAM-SHA-256\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"reporter.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing reporter.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"reporter.admin.sasl.jaas.config\"] = \"org.apache.kafka.common.security.scram.ScramLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"reporter.admin.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"reporter.admin.sasl.mechanism\"] = \"SCRAM-SHA-256\" | .[\"reporter.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.scram.ScramLoginModule required username=\\\"client\\\" password=\\\"client-secret\\\";\" | .[\"reporter.producer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"reporter.producer.sasl.mechanism\"] = \"SCRAM-SHA-256\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi
    ;;

    kerberos)

      for prefix in {"confluent.topic","redo.log.consumer"}
      do
        if echo "$json_content" | jq ". | has(\"$prefix.bootstrap.servers\")" 2> /dev/null | grep -q true

        then
          # log "replacing $prefix config for environment $environment"

          echo "$json_content" > $tmp_dir/input.json
          jq ".[\"$prefix.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"$prefix.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"$prefix.sasl.mechanism\"] = \"GSSAPI\" | .[\"$prefix.sasl.kerberos.service.name\"] = \"kafka\"" $tmp_dir/input.json > $tmp_dir/output.json
          json_content=$(cat $tmp_dir/output.json)
        fi
      done

      if echo "$json_content" | jq ". | has(\"database.history.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing database.history.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"database.history.producer.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"database.history.producer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"database.history.producer.sasl.mechanism\"] = \"GSSAPI\" | .[\"database.history.producer.sasl.kerberos.service.name\"] = \"kafka\" | .[\"database.history.consumer.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"database.history.consumer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"database.history.consumer.sasl.mechanism\"] = \"GSSAPI\" | .[\"database.history.consumer.sasl.kerberos.service.name\"] = \"kafka\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"schema.history.internal.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing schema.history.internal.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"schema.history.internal.producer.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"schema.history.internal.producer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"schema.history.internal.producer.sasl.mechanism\"] = \"GSSAPI\" | .[\"schema.history.internal.producer.sasl.kerberos.service.name\"] = \"kafka\" | .[\"schema.history.internal.consumer.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"schema.history.internal.consumer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"schema.history.internal.consumer.sasl.mechanism\"] = \"GSSAPI\" | .[\"schema.history.internal.consumer.sasl.kerberos.service.name\"] = \"kafka\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"reporter.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing reporter.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"reporter.admin.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"reporter.admin.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"reporter.admin.sasl.mechanism\"] = \"GSSAPI\" | .[\"reporter.admin.sasl.kerberos.service.name\"] = \"kafka\" | .[\"reporter.producer.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"reporter.producer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"reporter.producer.sasl.mechanism\"] = \"GSSAPI\" | .[\"reporter.producer.sasl.kerberos.service.name\"] = \"kafka\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi
    ;;

    ssl_kerberos)

      for prefix in {"confluent.topic","redo.log.consumer"}
      do
        if echo "$json_content" | jq ". | has(\"$prefix.bootstrap.servers\")" 2> /dev/null | grep -q true

        then
          # log "replacing $prefix config for environment $environment"

          echo "$json_content" > $tmp_dir/input.json
          jq ".[\"$prefix.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"$prefix.security.protocol\"] = \"SASL_SSL\" | .[\"$prefix.sasl.mechanism\"] = \"GSSAPI\" | .[\"$prefix.sasl.kerberos.service.name\"] = \"kafka\" | .[\"$prefix.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"$prefix.ssl.truststore.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
          json_content=$(cat $tmp_dir/output.json)
        fi
      done

      if echo "$json_content" | jq ". | has(\"database.history.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing database.history.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"database.history.producer.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"database.history.producer.security.protocol\"] = \"SASL_SSL\" | .[\"database.history.producer.sasl.mechanism\"] = \"GSSAPI\" | .[\"database.history.producer.sasl.kerberos.service.name\"] = \"kafka\" | .[\"database.history.producer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"database.history.producer.ssl.truststore.password\"] = \"confluent\" | .[\"database.history.consumer.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"database.history.consumer.security.protocol\"] = \"SASL_SSL\" | .[\"database.history.consumer.sasl.mechanism\"] = \"GSSAPI\" | .[\"database.history.consumer.sasl.kerberos.service.name\"] = \"kafka\" | .[\"database.history.consumer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"database.history.consumer.ssl.truststore.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"schema.history.internal.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing schema.history.internal.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"schema.history.internal.producer.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"schema.history.internal.producer.security.protocol\"] = \"SASL_SSL\" | .[\"schema.history.internal.producer.sasl.mechanism\"] = \"GSSAPI\" | .[\"schema.history.internal.producer.sasl.kerberos.service.name\"] = \"kafka\" | .[\"schema.history.internal.producer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"schema.history.internal.producer.ssl.truststore.password\"] = \"confluent\" | .[\"schema.history.internal.consumer.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"schema.history.internal.consumer.security.protocol\"] = \"SASL_SSL\" | .[\"schema.history.internal.consumer.sasl.mechanism\"] = \"GSSAPI\" | .[\"schema.history.internal.consumer.sasl.kerberos.service.name\"] = \"kafka\" | .[\"schema.history.internal.consumer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"schema.history.internal.consumer.ssl.truststore.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"reporter.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing reporter.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"reporter.admin.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"reporter.admin.security.protocol\"] = \"SASL_SSL\" | .[\"reporter.admin.sasl.mechanism\"] = \"GSSAPI\" | .[\"reporter.admin.sasl.kerberos.service.name\"] = \"kafka\" | .[\"reporter.admin.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"reporter.admin.ssl.truststore.password\"] = \"confluent\" | .[\"reporter.producer.sasl.jaas.config\"] = \"com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true storeKey=true keyTab=\\\"/var/lib/secret/kafka-connect.key\\\" principal=\\\"connect@TEST.CONFLUENT.IO\\\";\" | .[\"reporter.producer.security.protocol\"] = \"SASL_SSL\" | .[\"reporter.producer.sasl.mechanism\"] = \"GSSAPI\" | .[\"reporter.producer.sasl.kerberos.service.name\"] = \"kafka\" | .[\"reporter.producer.ssl.truststore.location\"] = \"/etc/kafka/secrets/kafka.connect.truststore.jks\" | .[\"reporter.producer.ssl.truststore.password\"] = \"confluent\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi
    ;;

    rbac-sasl-plain)

      echo "$json_content" > $tmp_dir/input.json
      jq ".[\"principal.service.name\"] = \"connectorSA\" | .[\"principal.service.password\"] = \"connectorSA\"" $tmp_dir/input.json > $tmp_dir/output.json
      json_content=$(cat $tmp_dir/output.json)

      for prefix in {"confluent.topic","redo.log.consumer"}
      do
        if echo "$json_content" | jq ". | has(\"$prefix.bootstrap.servers\")" 2> /dev/null | grep -q true

        then
          # log "replacing $prefix config for environment $environment"

          echo "$json_content" > $tmp_dir/input.json
          jq ".[\"$prefix.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"admin\\\" password=\\\"admin-secret\\\";\" | .[\"$prefix.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"$prefix.sasl.mechanism\"] = \"PLAIN\"" $tmp_dir/input.json > $tmp_dir/output.json
          json_content=$(cat $tmp_dir/output.json)
        fi
      done

      if echo "$json_content" | jq ". | has(\"database.history.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing database.history.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"database.history.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"admin\\\" password=\\\"admin-secret\\\";\" | .[\"database.history.producer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"database.history.producer.sasl.mechanism\"] = \"PLAIN\" | .[\"database.history.consumer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"admin\\\" password=\\\"admin-secret\\\";\" | .[\"database.history.consumer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"database.history.consumer.sasl.mechanism\"] = \"PLAIN\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"schema.history.internal.kafka.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing schema.history.internal.kafka.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"schema.history.internal.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"admin\\\" password=\\\"admin-secret\\\";\" | .[\"schema.history.internal.producer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"schema.history.internal.producer.sasl.mechanism\"] = \"PLAIN\" | .[\"schema.history.internal.consumer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"admin\\\" password=\\\"admin-secret\\\";\" | .[\"schema.history.internal.consumer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"schema.history.internal.consumer.sasl.mechanism\"] = \"PLAIN\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi

      if echo "$json_content" | jq ". | has(\"reporter.bootstrap.servers\")" 2> /dev/null | grep -q true

      then
        # log "replacing reporter.bootstrap.servers config for environment $environment"

        echo "$json_content" > $tmp_dir/input.json
        jq ".[\"reporter.admin.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"admin\\\" password=\\\"admin-secret\\\";\" | .[\"reporter.admin.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"reporter.admin.sasl.mechanism\"] = \"PLAIN\" | .[\"reporter.producer.sasl.jaas.config\"] = \"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"admin\\\" password=\\\"admin-secret\\\";\" | .[\"reporter.producer.security.protocol\"] = \"SASL_PLAINTEXT\" | .[\"reporter.producer.sasl.mechanism\"] = \"PLAIN\"" $tmp_dir/input.json > $tmp_dir/output.json
        json_content=$(cat $tmp_dir/output.json)
      fi
    ;;

    *)
      return
    ;;
  esac

  echo "$json_content" > $tmp_dir/2.json
  log "✨ Following config was added to handle environment $environment:"
  set +e
  diff <(jq --sort-keys . $tmp_dir/1.json) <(jq --sort-keys . $tmp_dir/2.json)
  set -e
}

function maybe_remove_flag () {
  flag="$1"
  for ((i=0; i<${#array_flag_list[@]}; i++))
  do
    if [[ ${array_flag_list[i]} == ${flag}=* ]]
    then
        unset "array_flag_list[i]"
    fi
  done
}

function display_interactive_menu_categories () {
  repro=$1

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
      fzf_option_wrap="--preview-window=40%,wrap"
      fzf_option_pointer="--pointer=👉"
      fzf_option_rounded="--border=rounded"
  else
      fzf_option_pointer=""
      fzf_option_rounded=""
  fi

  if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_fully_managed_connector_only ]
  then
    playground generate-fzf-find-files
  fi

  terminal_columns=$(tput cols)
  if [[ $terminal_columns -gt 180 ]]
  then
    MAX_LENGTH=$((${terminal_columns}-120))
  else
    MAX_LENGTH=$((${terminal_columns}-65))
  fi

  if [ -f $root_folder/scripts/cli/get_examples_list_with_fzf_repro_only ]
  then
    nb_repro=$(wc -l $root_folder/scripts/cli/get_examples_list_with_fzf_repro_only | awk '{print $1}')
  else
    nb_repro=0
  fi

  MENU_CONNECTOR="🔗 Connectors $(printf '%*s' $((${MAX_LENGTH}-13-${#MENU_CONNECTOR})) ' ') $(wc -l $root_folder/scripts/cli/get_examples_list_with_fzf_connector_only | awk '{print $1}') examples"
  MENU_CCLOUD="🌤️  Confluent cloud $(printf '%*s' $((${MAX_LENGTH}-18-${#MENU_CCLOUD})) ' ') $(wc -l $root_folder/scripts/cli/get_examples_list_with_fzf_ccloud_only | awk '{print $1}') examples"
  MENU_FULLY_MANAGED_CONNECTOR="🤖 Fully-Managed connectors $(printf '%*s' $((${MAX_LENGTH}-27-${#MENU_FULLY_MANAGED_CONNECTOR})) ' ') $(wc -l $root_folder/scripts/cli/get_examples_list_with_fzf_fully_managed_connector_only | awk '{print $1}') examples"
  MENU_REPRO="🛠  Reproduction models $(printf '%*s' $((${MAX_LENGTH}-22-${#MENU_REPRO})) ' ') $nb_repro examples"
  MENU_OTHER="👾 Other playgrounds $(printf '%*s' $((${MAX_LENGTH}-20-${#MENU_OTHER})) ' ') $(wc -l $root_folder/scripts/cli/get_examples_list_with_fzf_other_playgrounds_only | awk '{print $1}') examples"
  MENU_ENVIRONMENTS="🔐 Environments $(printf '%*s' $((${MAX_LENGTH}-15-${#MENU_ENVIRONMENTS})) ' ') $(wc -l $root_folder/scripts/cli/get_examples_list_with_fzf_environment_only | awk '{print $1}') examples"
  MENU_ALL="🎲 All $(printf '%*s' $((${MAX_LENGTH}-6-${#MENU_ALL})) ' ') $(wc -l $root_folder/scripts/cli/get_examples_list_with_fzf_all | awk '{print $1}') examples"
  MENU_KSQL="🎏 ksqlDB $(printf '%*s' $((${MAX_LENGTH}-9-${#MENU_KSQL})) ' ') $(wc -l $root_folder/scripts/cli/get_examples_list_with_fzf_ksql_only | awk '{print $1}') examples"
  MENU_SR="🔰 Schema registry $(printf '%*s' $((${MAX_LENGTH}-18-${#MENU_SR})) ' ') $(wc -l $root_folder/scripts/cli/get_examples_list_with_fzf_schema_registry_only | awk '{print $1}') examples"
  MENU_RP="🧲 Rest proxy $(printf '%*s' $((${MAX_LENGTH}-13-${#MENU_RP})) ' ') $(wc -l $root_folder/scripts/cli/get_examples_list_with_fzf_rest_proxy_only | awk '{print $1}') examples"
  MENU_ACADEMY="🧑‍🎓 Academy $(printf '%*s' $((${MAX_LENGTH}-10-${#MENU_ACADEMY})) ' ') $(wc -l $root_folder/scripts/cli/get_examples_list_with_fzf_academy_only | awk '{print $1}') examples"

  if [ "$repro" == 1 ]
  then
    propose_current_example=0
    set +e
    current_file=$(playground state get run.test_file)
    if [ $? -ne 0 ]
    then
      propose_current_example=0
    fi
    set -e
    if [ -f "$current_file" ]
    then
      last_two_folders=$(basename $(dirname $(dirname $current_file)))/$(basename $(dirname $current_file))
      filename=$(basename $current_file)
      current_file="$last_two_folders/$filename"

      if [[ $current_file != *"reproduction-models"* ]]
      then
        propose_current_example=1
      fi
    fi

    if [ $propose_current_example -eq 1 ]
    then
      MENU_CURRENT_EXAMPLE="🕹️  Current example $(printf '%*s' $((${MAX_LENGTH}-18-${#MENU_CURRENT_EXAMPLE})) ' ') $current_file"
      options=("$MENU_CURRENT_EXAMPLE" "$MENU_CONNECTOR" "$MENU_CCLOUD" "$MENU_FULLY_MANAGED_CONNECTOR" "$MENU_OTHER" "$MENU_ENVIRONMENTS" "$MENU_ALL" "$MENU_KSQL" "$MENU_SR" "$MENU_RP" "$MENU_ACADEMY")
    else
      options=("$MENU_CONNECTOR" "$MENU_CCLOUD" "$MENU_FULLY_MANAGED_CONNECTOR" "$MENU_OTHER" "$MENU_ENVIRONMENTS" "$MENU_ALL" "$MENU_KSQL" "$MENU_SR" "$MENU_RP" "$MENU_ACADEMY")
    fi
  else
    options=("$MENU_CONNECTOR" "$MENU_CCLOUD" "$MENU_FULLY_MANAGED_CONNECTOR" "$MENU_REPRO" "$MENU_OTHER" "$MENU_ENVIRONMENTS" "$MENU_ALL" "$MENU_KSQL" "$MENU_SR" "$MENU_RP" "$MENU_ACADEMY")
  fi

  res=$(printf '%s\n' "${options[@]}" | fzf --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🚀" --header="select a category (ctrl-c or esc to quit)" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_pointer)

  case "${res}" in
    "$MENU_CURRENT_EXAMPLE")
      test_file=$(playground state get run.test_file)
      if [ ! -f $test_file ]
      then
          logerror "❌ file $test_file retrieved from $root_folder/playground.ini does not exist!"
          exit 1
      fi
    ;;
    "$MENU_CONNECTOR")
      test_file=$(playground get-examples-list-with-fzf --connector-only)
    ;;
    "$MENU_CCLOUD")
      test_file=$(playground get-examples-list-with-fzf --ccloud-only)
    ;;
    "$MENU_FULLY_MANAGED_CONNECTOR")
      test_file=$(playground get-examples-list-with-fzf --fully-managed-connector-only)
    ;;
    "$MENU_REPRO")
      test_file=$(playground get-examples-list-with-fzf --repro-only)
    ;;
    "$MENU_ENVIRONMENTS")
      test_file=$(playground get-examples-list-with-fzf --environment-only)
    ;;
    "$MENU_KSQL")
      test_file=$(playground get-examples-list-with-fzf --ksql-only)
    ;;
    "$MENU_SR")
      test_file=$(playground get-examples-list-with-fzf --schema-registry-only)
    ;;
    "$MENU_RP")
      test_file=$(playground get-examples-list-with-fzf --rest-proxy-only)
    ;;
    "$MENU_ACADEMY")
      test_file=$(playground get-examples-list-with-fzf --academy-only)
    ;;
    "$MENU_OTHER")
      test_file=$(playground get-examples-list-with-fzf --other-playgrounds-only)
    ;;
    "$MENU_ALL")
      test_file=$(playground get-examples-list-with-fzf)
    ;;
    *)
      logerror "❌ wrong choice: $res"
      exit 1
    ;;
  esac
}

function cleanup_confluent_cloud_resources () {
  bootstrap_ccloud_environment

  log "🧹 cleanup resources for confluent cloud cluster $CLUSTER_NAME"

  # for row in $(confluent api-key list --output json | jq -r '.[] | @base64'); do
  #     _jq() {
  #     echo ${row} | base64 -d | jq -r ${1}
  #     }

  #     key=$(echo $(_jq '.key'))
  #     resource_type=$(echo $(_jq '.resource_type'))

  #     if [[ $resource_type = cloud ]] && [[ "$key" != "$CLOUD_API_KEY" ]]
  #     then
  #       log "deleting cloud api key $key"
  #       confluent api-key delete $key --force
  #     fi
  # done

  for row in $(confluent connect cluster list --output json | jq -r '.[] | @base64'); do
      _jq() {
      echo ${row} | base64 -d | jq -r ${1}
      }

      id=$(echo $(_jq '.id'))
      name=$(echo $(_jq '.name'))

      if [[ $name = *_${user}* ]]
      then
          log "deleting connector $id ($name)"
          check_if_skip "confluent connect cluster delete $id --force"
      fi
  done

  for row in $(confluent environment list --output json | jq -r '.[] | @base64'); do
      _jq() {
      echo ${row} | base64 -d | jq -r ${1}
      }

      id=$(echo $(_jq '.id'))
      name=$(echo $(_jq '.name'))

      if [[ $name = pg-${user}-sa-* ]]
      then
          log "deleting environment $id ($name)"
          check_if_skip "confluent environment delete $id --force"
      fi
  done

  for topic in $(confluent kafka topic list | awk '{if(NR>2) print $1}')
  do
      log "delete topic $topic"
      check_if_skip "confluent kafka topic delete \"$topic\" --force"
  done

  if [ ! -z "$GITHUB_RUN_NUMBER" ]
  then
    for subject in $(curl -u "$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" "$SCHEMA_REGISTRY_URL/subjects" | jq -r '.[]')
    do
        log "permanently delete subject $subject"
        check_if_skip "curl --request DELETE -u \"$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO\" \"$SCHEMA_REGISTRY_URL/subjects/$subject\" && curl --request DELETE -u \"$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO\" \"$SCHEMA_REGISTRY_URL/subjects/$subject?permanent=true\""
    done

    for row in $(confluent iam service-account list --output json | jq -r '.[] | @base64'); do
        _jq() {
        echo ${row} | base64 -d | jq -r ${1}
        }

        description=$(echo $(_jq '.description'))
        id=$(echo $(_jq '.id'))
        name=$(echo $(_jq '.name'))

        log "deleting service-account $id ($description)"
        check_if_skip "confluent iam service-account delete $id --force"
    done
  fi
}

function get_zazkia_id_list () {
  handle_onprem_connect_rest_api "curl -s -X GET -H \"Content-Type: application/json\" \"http://localhost:9191/links/\""
  if [[ $(echo "$curl_output" | jq -r '.[].links[]') != "" ]]
  then
    echo "$curl_output" | jq -r '.[].links[] | select(.serviceReceiveError != "EOF") | .id' | tr '\n' ' ' | sed -e 's/[[:space:]]*$//'
  else
    echo ""
  fi
}

function wait_for_ec2_instance_to_be_running () {
  instance="$1"
  max_wait=${2:-300}
  cur_wait=0
  log "⌛ waiting up to $max_wait seconds for ec2 instance $instance to be running"
  playground ec2 status --instance "$instance" > /tmp/out.txt 2>&1
  while ! grep "running" /tmp/out.txt > /dev/null;
  do
    sleep 10
    playground ec2 status --instance "$instance" > /tmp/out.txt 2>&1
    status=$(cat /tmp/out.txt)
    log "⌛ current status: $status"
    cur_wait=$(( cur_wait+10 ))
    if [[ "$cur_wait" -gt "$max_wait" ]]
    then
      logerror "❌ ec2 instance $instance is still not running after $max_wait seconds"
      return 1
    fi
  done
  log "🟢 ec2 instance $instance is running"
}

function wait_for_ec2_cloudformation_to_be_completed () {
  stack_name="$1"
  max_wait=${2:-900}
  cur_wait=0
  log "⌛ waiting up to $max_wait seconds for ec2 cloudformation stack $stack_name to be in status CREATE_COMPLETE"
  log "⌛ you can check progress by checking log file output.log in root folder of ec2 instance"

  aws cloudformation describe-stacks --output text --query "Stacks[?StackName==\`$stack_name\`].StackStatus" > /tmp/out.txt 2>&1
  while ! grep "CREATE_COMPLETE" /tmp/out.txt > /dev/null;
  do
    sleep 10
    aws cloudformation describe-stacks --output text --query "Stacks[?StackName==\`$stack_name\`].StackStatus" > /tmp/out.txt 2>&1
    status=$(cat /tmp/out.txt)
    log "⌛ current status: $status"

    if grep "CREATE_FAILED" /tmp/out.txt > /dev/null;
    then
      logerror "❌ ec2 cloudformation stack $stack_name is in state $status"
      logerror "❌ check log file output.log in root folder of ec2 instance for troubleshooting the issue"
      return 1
    fi

    if grep "ROLLBACK_" /tmp/out.txt > /dev/null;
    then
      logerror "❌ ec2 cloudformation stack $stack_name is in state $status"
      logerror "❌ check log file output.log in root folder of ec2 instance for troubleshooting the issue"
      return 1
    fi

    cur_wait=$(( cur_wait+10 ))
    if [[ "$cur_wait" -gt "$max_wait" ]]
    then
      logerror "❌ ec2 cloudformation $stack_name is still not in status CREATE_COMPLETE after $max_wait seconds"
      logerror "❌ check log file output.log in root folder of ec2 instance for troubleshooting the issue"
      return 1
    fi
  done
  log "🟢 ec2 cloudformation $stack_name is in status CREATE_COMPLETE"
}

function add_ec2_instance_to_running_list() {
  instance="$1"
  current_list=$(playground state get "ec2.running_list")
  # list can be separated with |
  if [[ "$current_list" == "" ]]
  then
    playground state set "ec2.running_list" "$instance"
  else
    # make sure insance is not already in the list
    if [[ "$current_list" != *"$instance"* ]]
    then
      playground state set "ec2.running_list" "$current_list|$instance"
    fi
  fi
}

function remove_ec2_instance_from_running_list() {
  instance="$1"
  current_list=$(playground state get "ec2.running_list")
  # list can be separated with |
  if [[ "$current_list" != "" ]]
  then
    # make sure insance is not already in the list
    if [[ "$current_list" == *"$instance"* ]]
    then
      new_list=$(echo "$current_list" | sed -e "s/$instance//g" | sed -e 's/||/|/g' | sed -e 's/|$//')
      playground state set "ec2.running_list" "$new_list"
    fi
  fi
}

function check_for_ec2_instance_running() {
  # echo the name of ec2 instance running
  current_list=$(playground state get "ec2.running_list")
  if [[ "$current_list" != "" ]]
  then
    # loop through the list
    for instance in $(echo $current_list | tr "|" "\n")
    do
      echo ""
      echo ""
      log "💸💸💸💸💸💸💸💸💸💸💸💸💸💸💸💸💸💸💸💸💸💸💸"
      log "🤑 you have an ec2 instance $instance running !"
      log "💸💸💸💸💸💸💸💸💸💸💸💸💸💸💸💸💸💸💸💸💸💸💸"
    done
  fi
}

function open_file_with_editor() {
  filename="$1"
  wait="$2"

	if [ ! -z "$GITHUB_RUN_NUMBER" ]
	then
		# running with CI
		return
	fi
  editor=$(playground config get editor)
  if [ "$editor" != "" ] && command -v "$editor" > /dev/null
  then
    log "📖 opening ${filename} using configured editor \"$editor\" (you can change editor by using \"playground config set editor <editor>\")"
    if [ "$editor" = "code" ] && [ "$wait" != "" ]
    then
      code --wait ${filename}
    else
      $editor ${filename}
    fi
  else
    logerror "❌ editor \"$editor\" is not installed - you can change editor by using \"playground config set editor <editor>\""
    exit 1
  fi
}

function arm64_support() {

  test_file=$(playground state get run.test_file)

  if [ ! -f $test_file ]
  then

    return
  fi

  set +e
  if [ "$(uname -m)" = "arm64" ]
  then
    base_folder=$(basename $(dirname $(dirname $test_file)))
    base_test=$(basename $(dirname $test_file))
    if [ "$base_folder" == "reproduction-models" ]
    then
      base_test=${base_test#*-}
    fi

    grep "${base_test}" ${root_folder}/scripts/arm64-support-none.txt > /dev/null
    if [ $? = 0 ]
    then
      echo "❌🖥️ this example is not working with ARM64 !"
      echo "❌🖥️ it is highly recommended to use 'playground ec2 command' to run the example on ubuntu ec2 instance"
      echo "❌🖥️ you can also use gitpod"
      return
    fi

    grep "${base_test}" ${root_folder}/scripts/arm64-support-with-emulation.txt > /dev/null
    if [ $? = 0 ]
    then
        echo "☑️🖥️ this example is working with ARM64 but requires emulation"
        return
    fi

    echo "✅🖥️ this example should work natively with ARM64"
  fi
  set -e
}

# src/lib/colors.sh
print_in_color() {
  local color="$1"
  shift
  if [[ -z ${NO_COLOR+x} ]]; then
    printf "$color%b\e[0m\n" "$*"
  else
    printf "%b\n" "$*"
  fi
}

red() { print_in_color "\e[31m" "$*"; }
green() { print_in_color "\e[32m" "$*"; }
yellow() { print_in_color "\e[33m" "$*"; }
blue() { print_in_color "\e[34m" "$*"; }
magenta() { print_in_color "\e[35m" "$*"; }
cyan() { print_in_color "\e[36m" "$*"; }
bold() { print_in_color "\e[1m" "$*"; }
underlined() { print_in_color "\e[4m" "$*"; }
red_bold() { print_in_color "\e[1;31m" "$*"; }
green_bold() { print_in_color "\e[1;32m" "$*"; }
yellow_bold() { print_in_color "\e[1;33m" "$*"; }
blue_bold() { print_in_color "\e[1;34m" "$*"; }
magenta_bold() { print_in_color "\e[1;35m" "$*"; }
cyan_bold() { print_in_color "\e[1;36m" "$*"; }
red_underlined() { print_in_color "\e[4;31m" "$*"; }
green_underlined() { print_in_color "\e[4;32m" "$*"; }
yellow_underlined() { print_in_color "\e[4;33m" "$*"; }
blue_underlined() { print_in_color "\e[4;34m" "$*"; }
magenta_underlined() { print_in_color "\e[4;35m" "$*"; }
cyan_underlined() { print_in_color "\e[4;36m" "$*"; }

# src/lib/ini.sh
ini_load() {
  declare -gA ini

  local ini_file="$1"

  local section=""
  local key=""
  local value=""
  local section_regex="^\[(.+)\]"
  local key_regex="^([^ =]+) *= *(.*) *$"
  local comment_regex="^;"

  while IFS= read -r line; do
    if [[ $line =~ $comment_regex ]]; then
      continue
    elif [[ $line =~ $section_regex ]]; then
      section="${BASH_REMATCH[1]}."
    elif [[ $line =~ $key_regex ]]; then
      key="${BASH_REMATCH[1]}"
      value="${BASH_REMATCH[2]}"
      [[ $value == *\$* ]] && eval "value=\"$value\""
      ini["${section}${key}"]="$value"
    fi
  done <"$ini_file"
}

ini_save() {
  declare -gA ini

  local ini_file="$1"

  local current_section=""
  local has_free_keys=false

  rm -f "$ini_file"

  for key in $(ini_keys); do
    [[ $key == *.* ]] && continue
    has_free_keys=true
    value="${ini[$key]}"
    echo "$key = $value" >>"$ini_file"
  done

  [[ "${has_free_keys}" == "true" ]] && echo >>"$ini_file"

  for key in $(ini_keys); do
    [[ $key == *.* ]] || continue
    value="${ini[$key]}"
    IFS="." read -r section_name key_name <<<"$key"

    if [[ "$current_section" != "$section_name" ]]; then
      [[ $current_section ]] && echo >>"$ini_file"
      echo "[$section_name]" >>"$ini_file"
      current_section="$section_name"
    fi

    echo "$key_name = $value" >>"$ini_file"
  done
}

ini_show() {
  declare -gA ini

  for key in $(ini_keys); do
    echo "$key = ${ini[$key]}"
  done
}

ini_keys() {
  declare -gA ini

  local keys=("${!ini[@]}")
  for a in "${keys[@]}"; do echo "$a"; done | sort
}

# src/lib/send_completions.sh
send_completions() {
  echo $'# playground completion                                    -*- shell-script -*-'
  echo $''
  echo $'# This bash completions script was generated by'
  echo $'# completely (https://github.com/dannyben/completely)'
  echo $'# Modifying it manually is not recommended'
  echo $''
  echo $'_playground_completions_filter() {'
  echo $'  local words="$1"'
  echo $'  local cur=${COMP_WORDS[COMP_CWORD]}'
  echo $'  local result=()'
  echo $''
  echo $'  if [[ "${cur:0:1}" == "-" ]]; then'
  echo $'    echo "$words"'
  echo $'  '
  echo $'  else'
  echo $'    for word in $words; do'
  echo $'      [[ "${word:0:1}" != "-" ]] && result+=("$word")'
  echo $'    done'
  echo $''
  echo $'    echo "${result[*]}"'
  echo $''
  echo $'  fi'
  echo $'}'
  echo $''
  echo $'_playground_completions() {'
  echo $'  local cur=${COMP_WORDS[COMP_CWORD]}'
  echo $'  local compwords=("${COMP_WORDS[@]:1:$COMP_CWORD-1}")'
  echo $'  local compline="${compwords[*]}"'
  echo $''
  echo $'  case "$compline" in'
  echo $'    \'recreate-container\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'get-properties\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h broker.* connect.* schema-registry.* zookeeper.*")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'completions\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'properties\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h broker.* connect.* schema-registry.* zookeeper.*")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'bootstrap\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -A file -W "$(_playground_completions_filter "--help -h avro avro-with-key json-schema json-schema-with-key none protobuf protobuf-with-key")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'recreate\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'boot\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -A file -W "$(_playground_completions_filter "--help -h avro avro-with-key json-schema json-schema-with-key none protobuf protobuf-with-key")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'get\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h broker.* connect.* schema-registry.* zookeeper.*")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'b\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -A file -W "$(_playground_completions_filter "--help -h avro avro-with-key json-schema json-schema-with-key none protobuf protobuf-with-key")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'g\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h broker.* connect.* schema-registry.* zookeeper.*")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    \'r\'*)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help -h")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'    *)'
  echo $'      while read -r; do COMPREPLY+=( "$REPLY" ); done < <( compgen -W "$(_playground_completions_filter "--help --version -h -v b boot bootstrap completions g get get-properties properties r recreate recreate-container")" -- "$cur" )'
  echo $'      ;;'
  echo $''
  echo $'  esac'
  echo $'} &&'
  echo $'complete -F _playground_completions playground'
  echo $''
  echo $'# ex: filetype=sh'
}

# src/lib/utils_function.sh
function verbose_begin () {
  # Check if set -x is currently active
  if [[ $- = *x* ]]
  then
    # Disable set -x
    set +x
    was_x_set=1
  else
    was_x_set=0
  fi
}

function verbose_end () {
  return_code="$?"
  # If set -x was initially active, re-enable it
  if [[ $was_x_set -eq 1 ]]
  then
    set -x
  fi
  return $return_code
}

function log() {
  if [ ! -z $PG_LOG_LEVEL ]
  then
    case "${PG_LOG_LEVEL}" in
      WARN|ERROR)
        return
      ;;
    esac
  fi

  verbose_begin
  YELLOW='\033[0;33m'
  NC='\033[0m' # No Color
  echo -e "$YELLOW$(date +"%H:%M:%S") ℹ️ $@$NC"
  verbose_end
}

function logerror() {
  verbose_begin
  RED='\033[0;31m'
  NC='\033[0m' # No Color
  echo -e "$RED$(date +"%H:%M:%S") 🔥 $@$NC"
  verbose_end
}

function logwarn() {
  if [ ! -z $PG_LOG_LEVEL ]
  then
    case "${PG_LOG_LEVEL}" in
      INFO)
        return
      ;;
    esac
  fi
  verbose_begin
  PURPLE='\033[0;35m'
  NC='\033[0m' # No Color
  echo -e "$PURPLE`date +"%H:%M:%S"` ❗ $@$NC"
  verbose_end
}

function urlencode() {
  # https://gist.github.com/cdown/1163649
  # urlencode <string>

  old_lc_collate=$LC_COLLATE
  LC_COLLATE=C

  local length="${#1}"
  for (( i = 0; i < length; i++ )); do
      local c="${1:$i:1}"
      case $c in
          [a-zA-Z0-9.~_-]) printf '%s' "$c" ;;
          *) printf '%%%02X' "'$c" ;;
      esac
  done

  LC_COLLATE=$old_lc_collate
}

function base64() {
  docker run -i --rm ddev/ddev-utilities:latest base64 -w 0 "$@"
}

function jq() {
  verbose_begin
  if [[ $(type -f jq 2>&1) =~ "not found" ]]
  then
    docker run --quiet --rm -i imega/jq "$@"
  else
    $(type -f jq | awk '{print $3}') "$@"
  fi
  verbose_end
}

function yq() {
  verbose_begin
  if [[ $(type -f yq 2>&1) =~ "not found" ]]
  then
    docker run --quiet  -u0 -v /tmp:/tmp --rm -i mikefarah/yq "$@"
  else
    $(type -f yq | awk '{print $3}') "$@"
  fi
  verbose_end
}

# https://stackoverflow.com/a/24067243
function version_gt() {
  test "$(printf '%s\n' "$@" | sort -V | head -n 1)" != "$1";
}

function set_kafka_client_tag()
{
    if [[ $TAG_BASE = 8.1.* ]]
    then
      export KAFKA_CLIENT_TAG="4.1.0"
    fi

    if [[ $TAG_BASE = 8.0.* ]]
    then
      export KAFKA_CLIENT_TAG="4.0.0"
    fi

    if [[ $TAG_BASE = 7.9.* ]]
    then
      export KAFKA_CLIENT_TAG="3.9.0"
    fi

    if [[ $TAG_BASE = 7.8.* ]]
    then
      export KAFKA_CLIENT_TAG="3.8.0"
    fi

    if [[ $TAG_BASE = 7.7.* ]]
    then
      export KAFKA_CLIENT_TAG="3.7.0"
    fi

    if [[ $TAG_BASE = 7.6.* ]]
    then
      export KAFKA_CLIENT_TAG="3.6.0"
    fi

    if [[ $TAG_BASE = 7.5.* ]]
    then
      export KAFKA_CLIENT_TAG="3.5.0"
    fi

    if [[ $TAG_BASE = 7.4.* ]]
    then
      export KAFKA_CLIENT_TAG="3.4.0"
    fi

    if [[ $TAG_BASE = 7.3.* ]]
    then
      export KAFKA_CLIENT_TAG="3.3.0"
    fi

    if [[ $TAG_BASE = 7.2.* ]]
    then
      export KAFKA_CLIENT_TAG="3.2.0"
    fi

    if [[ $TAG_BASE = 7.1.* ]]
    then
      export KAFKA_CLIENT_TAG="3.1.0"
    fi

    if [[ $TAG_BASE = 7.0.* ]]
    then
      export KAFKA_CLIENT_TAG="3.0.0"
    fi

    if [[ $TAG_BASE = 6.2.* ]]
    then
      export KAFKA_CLIENT_TAG="2.8.0"
    fi

    if [[ $TAG_BASE = 6.1.* ]]
    then
      export KAFKA_CLIENT_TAG="2.7.0"
    fi

    if [[ $TAG_BASE = 6.0.* ]]
    then
      export KAFKA_CLIENT_TAG="2.6.0"
    fi

    if [[ $TAG_BASE = 5.5.* ]]
    then
      export KAFKA_CLIENT_TAG="2.5.0"
    fi

    if [[ $TAG_BASE = 5.4.* ]]
    then
      export KAFKA_CLIENT_TAG="2.4.0"
    fi

    if [[ $TAG_BASE = 5.3.* ]]
    then
      export KAFKA_CLIENT_TAG="2.3.0"
    fi

    if [[ $TAG_BASE = 5.2.* ]]
    then
      export KAFKA_CLIENT_TAG="2.2.0"
    fi

    if [[ $TAG_BASE = 5.1.* ]]
    then
      export KAFKA_CLIENT_TAG="2.1.0"
    fi

    if [[ $TAG_BASE = 5.0.* ]]
    then
      export KAFKA_CLIENT_TAG="2.0.0"
    fi
}

function displaytime {
  local T=$1
  local D=$((T/60/60/24))
  local H=$((T/60/60%24))
  local M=$((T/60%60))
  local S=$((T%60))
  (( $D > 0 )) && printf '%d days ' $D
  (( $H > 0 )) && printf '%d hours ' $H
  (( $M > 0 )) && printf '%d minutes ' $M
  (( $D > 0 || $H > 0 || $M > 0 )) && printf 'and '
  printf '%d seconds\n' $S
}

function choosejar()
{
  log "☕ Select the jar to replace:"
  select jar
  do
    # Check the selected menu jar number
    if [ 1 -le "$REPLY" ] && [ "$REPLY" -le $# ];
    then
      break;
    else
      logwarn "Wrong selection: select any number from 1-$#"
    fi
  done
}

function verify_installed()
{
  local cmd="$1"
  if [[ $(type $cmd 2>&1) =~ "not found" ]]; then
    logerror "❌ the script requires $cmd. Please install $cmd and run again"
    exit 1
  fi
}

function maybe_create_image()
{
  if [ ! -z "$DOCKER_COMPOSE_FILE_UPDATE_VERSION" ]
  then
    return
  fi
  set +e
  log "🧰 Checking if Docker image ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} contains additional tools"
  log "⏳ it can take a while if image is downloaded for the first time"
  docker run --quiet --rm ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} type unzip > /dev/null 2>&1
  if [ $? != 0 ]
  then
    if [[ "$TAG" == *ubi8 ]] || version_gt $TAG_BASE "5.9.0"
    then
      export CONNECT_USER="appuser"
      if [ "$(uname -m)" = "arm64" ]
      then
        if version_gt $TAG_BASE "7.9.9"
        then
          CONNECT_3RDPARTY_INSTALL="if [ ! -f /tmp/done ]; then yum -y install bind-utils openssl unzip findutils net-tools nc jq which iptables libmnl krb5-workstation krb5-libs vim && yum clean all && rm -rf /var/cache/yum && rpm -i --nosignature https://yum.oracle.com/repo/OracleLinux/OL9/appstream/aarch64/getPackage/tcpdump-4.99.0-9.el9.aarch64.rpm && touch /tmp/done; fi"
        else
          CONNECT_3RDPARTY_INSTALL="if [ ! -f /tmp/done ]; then yum -y install --disablerepo='Confluent*' bind-utils openssl unzip findutils net-tools nc jq which iptables libmnl krb5-workstation krb5-libs vim && yum clean all && rm -rf /var/cache/yum && rpm -i --nosignature https://yum.oracle.com/repo/OracleLinux/OL8/appstream/aarch64/getPackage/tcpdump-4.9.3-3.el8.aarch64.rpm && touch /tmp/done; fi"
        fi
      else
        if version_gt $TAG_BASE "7.9.9"
        then
          CONNECT_3RDPARTY_INSTALL="if [ ! -f /tmp/done ]; then yum -y install bind-utils openssl unzip findutils net-tools nc jq which iptables libmnl krb5-workstation krb5-libs vim && yum clean all && rm -rf /var/cache/yum && rpm -i --nosignature https://yum.oracle.com/repo/OracleLinux/OL9/appstream/x86_64/getPackage/tcpdump-4.99.0-9.el9.x86_64.rpm && touch /tmp/done; fi"
        else
          CONNECT_3RDPARTY_INSTALL="if [ ! -f /tmp/done ]; then curl https://download.rockylinux.org/pub/rocky/8/AppStream/x86_64/kickstart/Packages/t/tcpdump-4.9.3-5.el8.x86_64.rpm -o tcpdump-4.9.3-1.el8.x86_64.rpm && rpm -Uvh tcpdump-4.9.3-1.el8.x86_64.rpm && yum -y install --disablerepo='Confluent*' bind-utils openssl unzip findutils net-tools nc jq which iptables libmnl krb5-workstation krb5-libs vim && yum clean all && rm -rf /var/cache/yum && touch /tmp/done; fi"
        fi
      fi
    else
      export CONNECT_USER="root"
      CONNECT_3RDPARTY_INSTALL="if [ ! -f /tmp/done ]; then apt-get update && echo bind-utils openssl unzip findutils net-tools nc jq which iptables tree | xargs -n 1 apt-get install --force-yes -y && rm -rf /var/lib/apt/lists/* && touch /tmp/done; fi"
    fi

    tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
    if [ -z "$PG_VERBOSE_MODE" ]
then
    trap 'rm -rf $tmp_dir' EXIT
else
    log "🐛📂 not deleting tmp dir $tmp_dir"
fi
cat << EOF > $tmp_dir/Dockerfile
FROM ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG}
USER root
# https://github.com/confluentinc/common-docker/pull/743 and https://github.com/adoptium/adoptium-support/issues/1285
RUN if [ -f /etc/yum.repos.d/adoptium.repo ]; then sed -i "s/packages\.adoptium\.net/adoptium\.jfrog\.io/g" /etc/yum.repos.d/adoptium.repo; fi
RUN ${CONNECT_3RDPARTY_INSTALL}
USER ${CONNECT_USER}
EOF
    log "👷📦 Re-building Docker image ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} to include additional tools"
    docker build -t ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} $tmp_dir
    rm -rf $tmp_dir
  fi
  set -e
}

function verify_docker_and_memory()
{
  set +e
  docker info > /dev/null 2>&1
  if [[ $? -ne 0 ]]
  then
    logerror "Cannot connect to the Docker daemon. Is the docker daemon running?"
    exit 1
  fi
  set -e
  # Check only with Mac OS
  # if [[ "$OSTYPE" == "darwin"* ]]
  # then
  #   # Verify Docker memory is increased to at least 8GB
  #   DOCKER_MEMORY=$(docker system info | grep Memory | grep -o "[0-9\.]\+")
  #   if (( $(echo "$DOCKER_MEMORY 7.0" | awk '{print ($1 < $2)}') )); then
  #       logerror "WARNING: Did you remember to increase the memory available to Docker to at least 8GB (default is 2GB)? Demo may otherwise not work properly"
  #       exit 1
  #   fi
  # fi
  return 0
}

function verify_confluent_login()
{
  local cmd="$1"
  set +e
  output=$($cmd 2>&1)
  set -e
  if [ "${output}" = "Error: You must login to run that command." ] || [ "${output}" = "Error: Your session has expired. Please login again." ]; then
    logerror "This script requires confluent CLI to be logged in. Please execute 'confluent login' and run again."
    exit 1
  fi
}

function verify_confluent_details()
{
    if [ "$(confluent prompt -f "%E")" = "(none)" ]
    then
        logerror "confluent command is badly configured: environment is not set"
        logerror "Example: confluent kafka environment list"
        logerror "then: confluent kafka environment use <environment id>"
        exit 1
    fi

    if [ "$(confluent prompt -f "%K")" = "(none)" ]
    then
        logerror "confluent command is badly configured: cluster is not set"
        logerror "Example: confluent kafka cluster list"
        logerror "then: confluent kafka cluster use <cluster id>"
        exit 1
    fi

    if [ "$(confluent prompt -f "%a")" = "(none)" ]
    then
        logerror "confluent command is badly configured: api key is not set"
        logerror "Example: confluent api-key store <api key> <password>"
        logerror "then: confluent api-key use <api key>"
        exit 1
    fi

    CCLOUD_PROMPT_FMT='You will be using Confluent Cloud cluster with user={{fgcolor "green" "%u"}}, environment={{fgcolor "red" "%E"}}, cluster={{fgcolor "cyan" "%K"}}, api key={{fgcolor "yellow" "%a"}}'
    confluent prompt -f "$CCLOUD_PROMPT_FMT"
}

function check_if_continue()
{
  if [ ! -z "$GITHUB_RUN_NUMBER" ]
  then
      # running with github actions, continue
      return
  fi
  read -p "Continue (y/n)?" choice
  case "$choice" in
  y|Y ) ;;
  n|N ) exit 1;;
  * ) logwarn "invalid response <$choice>! Please enter y or n."; check_if_continue;;
  esac
}

function check_if_skip() {

  if [[ -n "$force" ]] || [ ! -z "$GITHUB_RUN_NUMBER" ]
  then
    eval "$1"
  else
    read -p "Do you want to skip this command? (y/n) " reply

    case "$reply" in
    y|Y ) log "Skipping command...";;
    n|N ) eval "$1";;
    * ) logwarn "invalid response <$reply>! Please enter y or n."; check_if_skip;;
    esac
  fi
}

function create_topic()
{
  local topic="$1"
  # log "Check if topic $topic exists"
  confluent kafka topic create "$topic" --partitions 1 --dry-run > /dev/null 2>/dev/null
  if [[ $? == 0 ]]; then
    log "Create topic $topic"
    log "confluent kafka topic create $topic --partitions 1"
    confluent kafka topic create "$topic" --partitions 1 || true
  else
    log "Topic $topic already exists"
  fi
}

function delete_topic()
{
  local topic="$1"
  # log "Check if topic $topic exists"
  confluent kafka topic create "$topic" --partitions 1 --dry-run > /dev/null 2>/dev/null
  if [[ $? != 0 ]]; then
    log "Delete topic $topic"
    log "confluent kafka topic delete $topic --force"
    confluent kafka topic delete "$topic" --force || true
  else
    log "Topic $topic does not exist"
  fi
}

function version_gt() {
  test "$(printf '%s\n' "$@" | sort -V | head -n 1)" != "$1";
}

function get_docker_compose_version() {
  docker compose version | grep "^Docker Compose version" | cut -d' ' -f3 | cut -d',' -f1
}

function check_docker_compose_version() {
  REQUIRED_DOCKER_COMPOSE_VER=${1:-"1.28.0"}
  DOCKER_COMPOSE_VER=$(get_docker_compose_version)

  if version_gt $REQUIRED_DOCKER_COMPOSE_VER $DOCKER_COMPOSE_VER; then
    logerror "docker compose version ${REQUIRED_DOCKER_COMPOSE_VER} or greater is required. Current reported version: ${DOCKER_COMPOSE_VER}"
    exit 1
  fi
}

function get_bash_version() {
  bash_major_version=$(bash --version | head -n1 | awk '{print $4}')
  major_version="${bash_major_version%%.*}"
  echo "$major_version"
}

function check_bash_version() {
  REQUIRED_BASH_VER=${1:-"4"}
  BASH_VER=$(get_bash_version)

  if version_gt $REQUIRED_BASH_VER $BASH_VER; then
    logerror "bash version ${REQUIRED_BASH_VER} or greater is required. Current reported version: ${BASH_VER}"
    exit 1
  fi
}

function check_and_update_playground_version() {
  check_repo_version=$(playground config get check-and-update-repo-version)
  if [ "$check_repo_version" == "" ]
  then
      playground config set check-and-update-repo-version true
  fi

  if [ "$check_repo_version" == "true" ] || [ "$check_repo_version" == "" ]
  then
    set +e
    X=3
    git fetch
    latest_commit_date=$(git log -1 --format=%cd --date=short)
    remote_commit_date=$(git log -1 --format=%cd --date=short origin/master)

    if [[ "$OSTYPE" == "darwin"* ]]
    then
      latest_commit_date_seconds=$(date -j -f "%Y-%m-%d" "$latest_commit_date" +%s)
      remote_commit_date_seconds=$(date -j -f "%Y-%m-%d" "$remote_commit_date" +%s)
    else
      latest_commit_date_seconds=$(date -d "$latest_commit_date" +%s)
      remote_commit_date_seconds=$(date -d "$remote_commit_date" +%s)
    fi

    difference=$(( (remote_commit_date_seconds - latest_commit_date_seconds) / (60*60*24) ))

    if [ $difference -gt $X ]
    then
        logwarn "🥶 The current repo version is older than $X days ($difference days), now trying to refresh your version using git pull (disable with 'playground config check-and-update-repo-version false')"
        set +e
        git pull
        if [ $? -ne 0 ]
        then
          logerror "❌ Error while pulling the latest version of the repo. Please check your git configuration/error message, do you still want to continue using outdated version ?"
          check_if_continue
        else
          log "🔄 The repo version is now up to date, calling <playground re-run> to restart your example now."
          playground re-run
        fi
    fi
    set -e
  fi
}

function get_ccs_or_ce_specifics() {
  if [[ $CP_CONNECT_IMAGE == *"cp-kafka-"* ]]
  then
    log "Ⓜ️ detected connect community image used, disabling Monitoring Interceptors"
    export CONNECT_CONSUMER_INTERCEPTOR_CLASSES=""
    export CONNECT_PRODUCER_INTERCEPTOR_CLASSES=""
  elif version_gt $TAG_BASE "7.9.9"
  then
    log "Ⓜ️ disabling Monitoring Interceptors as CP image is > 8"
    export CONNECT_CONSUMER_INTERCEPTOR_CLASSES=""
    export CONNECT_PRODUCER_INTERCEPTOR_CLASSES=""
  else
    export CONNECT_CONSUMER_INTERCEPTOR_CLASSES="io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
    export CONNECT_PRODUCER_INTERCEPTOR_CLASSES="io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
  fi

  if [[ $CP_KAFKA_IMAGE == *"cp-kafka" ]]
  then
    log "Ⓜ️ detected kafka community image used, disabling Metrics Reporter"
    export KAFKA_METRIC_REPORTERS=""
  else
    export KAFKA_METRIC_REPORTERS="io.confluent.metrics.reporter.ConfluentMetricsReporter"
  fi
}

function determine_kraft_mode() {
  TAG_BASE=$(echo $TAG | cut -d "-" -f1)
  first_version=${TAG_BASE}
  if [[ -n $ENABLE_KRAFT ]] || version_gt $first_version "7.9.99"
  then
    if [[ -n $ENABLE_KRAFT ]]
    then
      log "🛰️ Starting up Confluent Platform in Kraft mode as ENABLE_KRAFT environment variable is set"
      if ! version_gt $TAG_BASE "7.3.99"
      then
        logerror "❌ Kraft mode is not supported with playground for CP version < 7.4, please use Zookeeper mode"
        exit 1
      fi
    else
      log "🛰️ Starting up Confluent Platform in Kraft mode as CP version is > 8"
    fi
    export ENABLE_KRAFT="true"
    export KRAFT_DOCKER_COMPOSE_FILE_OVERRIDE="-f ${DIR_UTILS}/../environment/plaintext/docker-compose-kraft.yml"
    export MDC_KRAFT_DOCKER_COMPOSE_FILE_OVERRIDE="-f ${DIR_UTILS}/../environment/mdc-plaintext/docker-compose-kraft.yml"
    export CONTROLLER_SECURITY_PROTOCOL_MAP=",CONTROLLER:PLAINTEXT"
    export KAFKA_AUTHORIZER_CLASS_NAME="org.apache.kafka.metadata.authorizer.StandardAuthorizer"
  else
    log "👨‍🦳 Starting up Confluent Platform in Zookeeper mode"
    export ENABLE_ZOOKEEPER="true"
    export KRAFT_DOCKER_COMPOSE_FILE_OVERRIDE=""
    export MDC_KRAFT_DOCKER_COMPOSE_FILE_OVERRIDE=""
    export CONTROLLER_SECURITY_PROTOCOL_MAP=""

    # Migrate SimpleAclAuthorizer to AclAuthorizer #1276
    if version_gt $TAG "5.3.99"
    then
      export KAFKA_AUTHORIZER_CLASS_NAME="kafka.security.authorizer.AclAuthorizer"
    else
      export KAFKA_AUTHORIZER_CLASS_NAME="kafka.security.auth.SimpleAclAuthorizer"
    fi
  fi
}

function set_profiles() {
  # https://docs.docker.com/compose/profiles/
  profile_zookeeper_command=""
  if [ -z "$ENABLE_ZOOKEEPER" ]
  then
    log "🛑 zookeeper is disabled"
    playground state del flags.ENABLE_ZOOKEEPER
  else
    log "👨‍⚕️ zookeeper is enabled"
    profile_zookeeper_command="--profile zookeeper"
    playground state set flags.ENABLE_ZOOKEEPER 1
  fi

  # profile_kraft_command=""
  # if [ -z "$ENABLE_KRAFT" ]
  # then
  #   log "🛑 kraft is disabled"
  #   playground state del flags.ENABLE_KRAFT
  # else
  #   log "🛰️ kraft is enabled"
  #   profile_kraft_command="--profile kraft"
  #   playground state set flags.ENABLE_KRAFT 1
  # fi

  profile_control_center_command=""
  if [ -z "$ENABLE_CONTROL_CENTER" ]
  then
    log "🛑 control-center is disabled"
    playground state del flags.ENABLE_CONTROL_CENTER
  else
    log "💠 control-center is enabled"
    log "Use http://localhost:9021 to login"
    profile_control_center_command="--profile control-center"
    playground state set flags.ENABLE_CONTROL_CENTER 1
  fi

  # Check if ENABLE_FLINK is set to true
  profile_flink=""
  if [ -z "$ENABLE_FLINK" ]

  then
    log "🛑 Starting services without Flink"
    playground state del flags.ENABLE_FLINK
    export flink_connectors=""
  else
    log "🐿️ Starting services with Flink"
    profile_flink="--profile flink"
    playground state set flags.ENABLE_FLINK 1
    source ${DIR}/../../scripts/flink_download_connectors.sh
  fi

  profile_ksqldb_command=""
  if [ -z "$ENABLE_KSQLDB" ]
  then
    log "🛑 ksqldb is disabled"
    playground state del flags.ENABLE_KSQLDB
  else
    log "🚀 ksqldb is enabled"
    log "🔧 You can use ksqlDB with CLI using:"
    log "docker exec -i ksqldb-cli ksql http://ksqldb-server:8088"
    profile_ksqldb_command="--profile ksqldb"
    playground state set flags.ENABLE_KSQLDB 1
  fi

  profile_rest_proxy_command=""
  if [ -z "$ENABLE_RESTPROXY" ]
  then
    log "🛑 REST Proxy is disabled"
    playground state del flags.ENABLE_RESTPROXY
  else
    log "📲 REST Proxy is enabled"
    profile_rest_proxy_command="--profile rest-proxy"
    playground state set flags.ENABLE_RESTPROXY 1
  fi

  # defined grafana variable and when profile is included/excluded
  profile_grafana_command=""
  if [ -z "$ENABLE_JMX_GRAFANA" ]
  then
    log "🛑 Grafana is disabled"
    playground state del flags.ENABLE_JMX_GRAFANA
  else
    log "📊 Grafana is enabled"
    profile_grafana_command="--profile grafana"
    playground state set flags.ENABLE_JMX_GRAFANA 1
  fi
  profile_kcat_command=""
  if [ -z "$ENABLE_KCAT" ]
  then
    log "🛑 kcat is disabled"
    playground state del flags.ENABLE_KCAT
  else
    log "🧰 kcat is enabled"
    profile_kcat_command="--profile kcat"
    playground state set flags.ENABLE_KCAT 1
  fi
  profile_conduktor_command=""
  if [ -z "$ENABLE_CONDUKTOR" ]
  then
    log "🛑 conduktor is disabled"
    playground state del flags.ENABLE_CONDUKTOR
  else
    log "🐺 conduktor is enabled"
    log "Use http://localhost:8080/console to login"
    profile_conduktor_command="--profile conduktor"
    playground state set flags.ENABLE_CONDUKTOR 1
  fi
  profile_sql_datagen_command=""
  if [ ! -z "$SQL_DATAGEN" ]
  then
    profile_sql_datagen_command="--profile sql_datagen"
    playground state set flags.SQL_DATAGEN 1
  else
    playground state del flags.SQL_DATAGEN
  fi

  #define kafka_nodes variable and when profile is included/excluded
  profile_kafka_nodes_command=""
  if [ -z "$ENABLE_KAFKA_NODES" ]
  then
    profile_kafka_nodes_command=""
    playground state del flags.ENABLE_KAFKA_NODES
  else
    log "3️⃣  Multi broker nodes enabled"
    profile_kafka_nodes_command="--profile kafka_nodes"
    playground state set flags.ENABLE_KAFKA_NODES 1
  fi

  # defined 3 Connect variable and when profile is included/excluded
  profile_connect_nodes_command=""
  if [ -z "$ENABLE_CONNECT_NODES" ]
  then
    playground state del flags.ENABLE_CONNECT_NODES
  elif [ ${nb_connect_services} -gt 1 ]
  then
    log "🥉 Multiple Connect nodes mode is enabled, connect2 and connect 3 containers will be started"
    profile_connect_nodes_command="--profile connect_nodes"
    export CONNECT_NODES_PROFILES="connect_nodes"
    playground state set flags.ENABLE_CONNECT_NODES 1
  else
    if [ ! -f "${DOCKER_COMPOSE_FILE_OVERRIDE}" ]
    then
      log "🥉 Multiple connect nodes mode is enabled, connect2 and connect 3 containers will be started"
      profile_connect_nodes_command="--profile connect_nodes"
      playground state set flags.ENABLE_CONNECT_NODES 1
    else
      logerror "🛑 Could not find connect2 and connect3 in ${DOCKER_COMPOSE_FILE_OVERRIDE}. Update the yaml files to contain the connect2 && connect3 in ${DOCKER_COMPOSE_FILE_OVERRIDE}"
      exit 1
    fi
  fi
}

function get_confluent_version() {
  confluent version | grep "^Version:" | cut -d':' -f2 | cut -d'v' -f2
}

function get_ansible_version() {
  ansible --version | grep "core" | cut -d'[' -f2 | cut -d']' -f1 | cut -d' ' -f 2
}

function check_confluent_version() {
  REQUIRED_CONFLUENT_VER=${1:-"4.0.0"}
  CONFLUENT_VER=$(get_confluent_version)

  if version_gt $REQUIRED_CONFLUENT_VER $CONFLUENT_VER; then
    log "confluent version ${REQUIRED_CONFLUENT_VER} or greater is required.  Current reported version: ${CONFLUENT_VER}"
    echo 'To update run: confluent update'
    exit 1
  fi
}

function container_to_ip() {
    name=$1
    echo $(docker exec $name hostname -I)
}

function block_host() {
    name=$1
    shift 1

    # https://serverfault.com/a/906499
    docker exec --privileged -t $name bash -c "tc qdisc add dev eth0 root handle 1: prio" 2>&1

    for ip in $@; do
        docker exec --privileged -t $name bash -c "tc filter add dev eth0 protocol ip parent 1: prio 1 u32 match ip dst $ip flowid 1:1" 2>&1
    done

    docker exec --privileged -t $name bash -c "tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip dst 0.0.0.0/0 flowid 1:2" 2>&1
    docker exec --privileged -t $name bash -c "tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip protocol 1 0xff flowid 1:2" 2>&1
    docker exec --privileged -t $name bash -c "tc qdisc add dev eth0 parent 1:1 handle 10: netem loss 100%" 2>&1
    docker exec --privileged -t $name bash -c "tc qdisc add dev eth0 parent 1:2 handle 20: sfq" 2>&1
}

function remove_partition() {
    for name in $@; do
        docker exec --privileged -t $name bash -c "tc qdisc del dev eth0 root"
    done
}

function aws() {
    if [ ! -z "$AWS_REGION" ]
    then
      if [ ! -f $HOME/.aws/config ]
      then
        aws_tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
        if [ -z "$PG_VERBOSE_MODE" ]
        then
            trap 'rm -rf $aws_tmp_dir' EXIT
        else
            log "🐛📂 not deleting aws tmp dir $aws_tmp_dir"
        fi
cat << EOF > $aws_tmp_dir/config
[default]
region = $AWS_REGION
EOF
      fi
    fi

    if [ ! -z "$AWS_ACCESS_KEY_ID" ] && [ ! -z "$AWS_SECRET_ACCESS_KEY" ]
    then
      AWS_ACCESS_KEY_ID=$(echo "$AWS_ACCESS_KEY_ID"| sed 's/[[:blank:]]//g')
      AWS_SECRET_ACCESS_KEY=$(echo "$AWS_SECRET_ACCESS_KEY"| sed 's/[[:blank:]]//g')
      AWS_SESSION_TOKEN=$(echo "$AWS_SESSION_TOKEN"| sed 's/[[:blank:]]//g')
      # log "💭 Using environment variables AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY"
      if [ -f $aws_tmp_dir/config ]
      then
        docker run --quiet --rm -iv $aws_tmp_dir/config:/root/.aws/config -e AWS_ACCESS_KEY_ID="$AWS_ACCESS_KEY_ID" -e AWS_SECRET_ACCESS_KEY="$AWS_SECRET_ACCESS_KEY" -e AWS_SESSION_TOKEN="$AWS_SESSION_TOKEN" -v $(pwd):/aws -v /tmp:/tmp amazon/aws-cli "$@"
      else
        docker run --quiet --rm -iv $HOME/.aws/config:/root/.aws/config -e AWS_ACCESS_KEY_ID="$AWS_ACCESS_KEY_ID" -e AWS_SECRET_ACCESS_KEY="$AWS_SECRET_ACCESS_KEY" -e AWS_SESSION_TOKEN="$AWS_SESSION_TOKEN" -v $(pwd):/aws -v /tmp:/tmp amazon/aws-cli "$@"
      fi
    else
      if [ ! -f $HOME/.aws/credentials ]
      then
        logerror "❌ $HOME/.aws/credentials does not exist"
      else
        # log "💭 AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY are set based on $HOME/.aws/credentials"
        docker run --quiet --rm -iv $HOME/.aws:/root/.aws -v $(pwd):/aws -v /tmp:/tmp amazon/aws-cli "$@"
      fi
    fi
}

function timeout() {
  verbose_begin
  if [[ $(type -f timeout 2>&1) =~ "not found" ]]; then
    # ignore
    shift
    eval "$@"
  else
    $(type -f timeout | awk '{print $3}') "$@"
  fi
  verbose_end
}

function get_connect_image() {
  set +e
  CP_CONNECT_TAG=$(docker inspect -f '{{.Config.Image}}' connect 2> /dev/null | cut -d ":" -f 2)
  set -e
  if [ "$CP_CONNECT_TAG" == "" ]
  then
    if [ -z "$TAG" ]
    then
      CP_CONNECT_TAG=$(grep "export TAG" $root_folder/scripts/utils.sh | head -1 | cut -d "=" -f 2 | cut -d " " -f 1)
    else
      CP_CONNECT_TAG=$TAG
    fi

    if [ "$CP_CONNECT_TAG" == "" ]
    then
      logerror "Error while getting default TAG in get_connect_image()"
      exit 1
    fi
  fi

  if [ -z "$CP_CONNECT_IMAGE" ]
  then
    if version_gt $CP_CONNECT_TAG 5.2.99
    then
      CP_CONNECT_IMAGE=confluentinc/cp-server-connect-base
    else
      CP_CONNECT_IMAGE=confluentinc/cp-kafka-connect-base
    fi
  fi
}

function az() {
  docker run --quiet --rm -v /tmp:/tmp -v $HOME/.azure:/home/az/.azure -e HOME=/home/az --rm -i mcr.microsoft.com/azure-cli:azurelinux3.0 az "$@"
}

function display_docker_container_error_log() {
  set +e
  logerror "####################################################"
  logerror "🐳 docker ps"
  docker ps
  logerror "####################################################"
  while IFS= read -r container
  do
    logerror "####################################################"
    logerror "$container logs"
    if [[ "$container" == "connect" ]] || [[ "$container" == "sap" ]]
    then
        # always show all logs for connect
        docker container logs --tail=250 $container 2>&1 | grep -v "was supplied but isn't a known config"
    else
        docker container logs $container 2>&1 | grep -E "ERROR|FATAL"
    fi
    logwarn "####################################################"
  done < <(docker ps --format="{{.Names}}")
}

function retry() {
  local n=1
  local max_retriable=3
  local max_default_retry=1
  while true; do
    "$@"
    ret=$?
    if [ $ret -eq 0 ]
    then
      return 0
    elif [ $ret -eq 111 ] # skipped
    then
      return 111
    elif [ $ret -eq 107 ] # known issue https://github.com/vdesabou/kafka-docker-playground/issues/907
    then
      return 107
    else
      test_file=$(echo "$@" | awk '{ print $4}')
      script=$(basename $test_file)
      # check for retriable scripts in scripts/tests-retriable.txt
      grep "$script" ${DIR}/tests-retriable.txt > /dev/null
      if [ $? = 0 ]
      then
        if [[ $n -lt $max_retriable ]]; then
          ((n++))
          logwarn "####################################################"
          logwarn "🧟‍♂️ The test $script (retriable) has failed. Retrying (attempt $n/$max_retriable)"
          logwarn "####################################################"
          display_docker_container_error_log
        else
          logerror "💀 The test $script (retriable) has failed after $n attempts."
          display_docker_container_error_log
          return 1
        fi
      else
        if [[ $n -lt $max_default_retry ]]; then
          ((n++))
          logwarn "####################################################"
          logwarn "🎰 The test $script (default_retry) has failed. Retrying (attempt $n/$max_default_retry)"
          logwarn "####################################################"
          display_docker_container_error_log
        else
          logerror "💀 The test $script (default_retry) has failed after $n attempts."
          display_docker_container_error_log
          return 1
        fi
      fi
    fi
  done
}

retrycmd() {
    local -r -i max_attempts="$1"; shift
    local -r -i sleep_interval="$1"; shift
    local -r cmd="$@"
    local -i attempt_num=1

    until $cmd
    do
        if (( attempt_num == max_attempts ))
        then
            display_docker_container_error_log
            logerror "Failed after $attempt_num attempts. Please troubleshoot and run again."
            return 1
        else
            printf "."
            ((attempt_num++))
            sleep $sleep_interval
        fi
    done
    printf "\n"
}

# for RBAC, taken from cp-demo
function host_check_kafka_cluster_registered() {
  KAFKA_CLUSTER_ID=$(docker container exec zookeeper zookeeper-shell zookeeper:2181 get /cluster/id 2> /dev/null | grep \"version\" | jq -r .id)
  if [ -z "$KAFKA_CLUSTER_ID" ]; then
    return 1
  fi
  echo $KAFKA_CLUSTER_ID
  return 0
}

# for RBAC, taken from cp-demo
function host_check_mds_up() {
  docker container logs broker > /tmp/out.txt 2>&1
  FOUND=$(cat /tmp/out.txt | grep "Started NetworkTrafficServerConnector")
  if [ -z "$FOUND" ]; then
    return 1
  fi
  return 0
}

# for RBAC, taken from cp-demo
function mds_login() {
  MDS_URL=$1
  SUPER_USER=$2
  SUPER_USER_PASSWORD=$3

  # Log into MDS
  if [[ $(type expect 2>&1) =~ "not found" ]]; then
    echo "'expect' is not found. Install 'expect' and try again"
    exit 1
  fi
  echo -e "\n# Login"
  OUTPUT=$(
  expect <<END
    log_user 1
    spawn confluent login --url $MDS_URL
    expect "Username: "
    send "${SUPER_USER}\r";
    expect "Password: "
    send "${SUPER_USER_PASSWORD}\r";
    expect "Logged in as "
    set result $expect_out(buffer)
END
  )
  echo "$OUTPUT"
  if [[ ! "$OUTPUT" =~ "Logged in as" ]]; then
    echo "Failed to log into MDS.  Please check all parameters and run again"
    exit 1
  fi
}

# https://raw.githubusercontent.com/zlabjp/kubernetes-scripts/master/wait-until-pods-ready

function __is_pod_ready() {
  [[ "$(kubectl get po "$1" -n $namespace -o 'jsonpath={.status.conditions[?(@.type=="Ready")].status}')" == 'True' ]]
}

function __pods_ready() {
  local pod

  [[ "$#" == 0 ]] && return 0

  for pod in $pods; do
    __is_pod_ready "$pod" || return 1
  done

  return 0
}

function wait-until-pods-ready() {
  local period interval i pods

  if [[ $# != 3 ]]; then
    echo "Usage: wait-until-pods-ready PERIOD INTERVAL NAMESPACE" >&2
    echo "" >&2
    echo "This script waits for all pods to be ready in the current namespace." >&2

    return 1
  fi

  period="$1"
  interval="$2"
  namespace="$3"

  sleep 10

  for ((i=0; i<$period; i+=$interval)); do
    pods="$(kubectl get po -n $namespace -o 'jsonpath={.items[*].metadata.name}')"
    if __pods_ready $pods; then
      return 0
    fi

    echo "Waiting for pods to be ready..."
    sleep "$interval"
  done

  echo "Waited for $period seconds, but all pods are not ready yet."
  return 1
}

function wait_for_datagen_connector_to_inject_data () {
  sleep 3
  connector_name="$1"
  datagen_tasks="$2"
  prefix_cmd="$3"
  set +e
  # wait for all tasks to be FAILED with org.apache.kafka.connect.errors.ConnectException: Stopping connector: generated the configured xxx number of messages
  MAX_WAIT=3600
  CUR_WAIT=0
  log "⌛ Waiting up to $MAX_WAIT seconds for connector $connector_name to finish injecting requested load"
  $prefix_cmd curl -s -X GET http://localhost:8083/connectors/datagen-${connector_name}/status | jq .tasks[].trace | grep "generated the configured" | wc -l > /tmp/out.txt 2>&1
  while [[ ! $(cat /tmp/out.txt) =~ "${datagen_tasks}" ]]; do
    sleep 5
    $prefix_cmd curl -s -X GET http://localhost:8083/connectors/datagen-${connector_name}/status | jq .tasks[].trace | grep "generated the configured" | wc -l > /tmp/out.txt 2>&1
    CUR_WAIT=$(( CUR_WAIT+10 ))
    if [[ "$CUR_WAIT" -gt "$MAX_WAIT" ]]; then
      echo -e "\nERROR: Please troubleshoot'.\n"
      $prefix_cmd curl -s -X GET http://localhost:8083/connectors/datagen-${connector_name}/status | jq
      exit 1
    fi
  done
  log "Connector $connector_name has finish injecting requested load"
  set -e
}

# https://gist.github.com/Fuxy22/da4b7ca3bcb0bfea2c582964eafeb4ed
# remove specified host from /etc/hosts
function removehost() {
    if [ ! -z "$1" ]
    then
        HOSTNAME=$1

        if [ -n "$(grep $HOSTNAME /etc/hosts)" ]
        then
            echo "$HOSTNAME Found in your /etc/hosts, Removing now...";
            sudo sed -i".bak" "/$HOSTNAME/d" /etc/hosts
        else
            echo "$HOSTNAME was not found in your /etc/hosts";
        fi
    else
        echo "Error: missing required parameters."
        echo "Usage: "
        echo "  removehost domain"
    fi
}

# https://gist.github.com/Fuxy22/da4b7ca3bcb0bfea2c582964eafeb4ed
#add new ip host pair to /etc/hosts
function addhost() {
    if [ $# -eq 2 ]
    then
        IP=$1
        HOSTNAME=$2

        if [ -n "$(grep $HOSTNAME /etc/hosts)" ]
            then
                echo "$HOSTNAME already exists:";
                echo $(grep $HOSTNAME /etc/hosts);
            else
                echo "Adding $HOSTNAME to your /etc/hosts";
                printf "%s\t%s\n" "$IP" "$HOSTNAME" | sudo tee -a /etc/hosts > /dev/null;

                if [ -n "$(grep $HOSTNAME /etc/hosts)" ]
                    then
                        echo "$HOSTNAME was added succesfully:";
                        echo $(grep $HOSTNAME /etc/hosts);
                    else
                        echo "Failed to Add $HOSTNAME, Try again!";
                fi
        fi
    else
        echo "Error: missing required parameters."
        echo "Usage: "
        echo "  addhost ip domain"
    fi
}

function stop_all() {
  playground stop
}

function wait_container_ready() {

  CONNECT_CONTAINER=${1:-"connect"}
  CONTROL_CENTER_CONTAINER=${1:-"control-center"}
  MAX_WAIT=300

  if [ ! -z $WAIT_FOR_CONTROL_CENTER ]
  then
    log "⌛ Waiting up to $MAX_WAIT seconds for ${CONTROL_CENTER_CONTAINER} to start"
    playground --output-level WARN container logs --container $CONTROL_CENTER_CONTAINER --wait-for-log "Started NetworkTrafficServerConnector" --max-wait $MAX_WAIT
  elif [[ $CONNECT_CONTAINER == connect* ]]
  then
    log "⌛ Waiting up to $MAX_WAIT seconds for ${CONNECT_CONTAINER} to start"
    playground container wait-for-connect-rest-api-ready --max-wait $MAX_WAIT
  else
    log "⌛ Waiting up to $MAX_WAIT seconds for ${CONNECT_CONTAINER} to start"
    playground container logs --container $CONNECT_CONTAINER --wait-for-log "Finished starting connectors and tasks" --max-wait $MAX_WAIT
  fi
  # Verify Docker containers started
  if [[ $(docker container ps) =~ "Exit 137" ]]
  then
    logerror "at least one Docker container did not start properly, see <docker container ps>"
    exit 1
  fi

  log "🚦 containers have started!"
}

function display_jmx_info() {
  if [ -z "$ENABLE_JMX_GRAFANA" ]
  then
    log "📊 JMX metrics are available locally on those ports:"
  else
    log "🛡️ Prometheus is reachable at http://127.0.0.1:9090"
    log "📛 Pyroscope is reachable at http://127.0.0.1:4040"
    log "📊 Grafana is reachable at http://127.0.0.1:3000 (login/password is admin/password) or JMX metrics are available locally on those ports:"
  fi
  if [ ! -z $ENABLE_KRAFT ]
  then
    log "    - kraft-controller : 10005"
  else
    log "    - zookeeper       : 9999"
  fi
  log "    - zookeeper       : 9999"
  log "    - broker          : 10000"
  log "    - schema-registry : 10001"
  log "    - connect         : 10002"

  if [ ! -z "$ENABLE_KSQLDB" ]
  then
    log "    - ksqldb-server   : 10003"
  fi
}
function get_jmx_metrics() {
  JMXTERM_VERSION="1.0.2"
  JMXTERM_UBER_JAR="/tmp/jmxterm-$JMXTERM_VERSION-uber.jar"
  if [ ! -f $JMXTERM_UBER_JAR ]
  then
    curl -L https://github.com/jiaqi/jmxterm/releases/download/v$JMXTERM_VERSION/jmxterm-$JMXTERM_VERSION-uber.jar -o $JMXTERM_UBER_JAR -s
  fi

  rm -f /tmp/commands
  rm -f /tmp/jmx_metrics.log

  container="$1"
  domains="$2"
  open="$3"
  if [ "$domains" = "" ]
  then
    # non existing domain: all domains will be in output !
    logwarn "You did not specify a list of domains, all domains will be exported!"
    domains="ALL"
  fi

  case "$container" in
  zookeeper )
    port=9999
  ;;
  controller )
    port=10005
  ;;
  broker )
    port=10000
  ;;
  schema-registry )
    port=10001
  ;;
  connect )
    port=10002
  ;;
  connect2 )
    port=10022
  ;;
  connect3 )
    port=10032
  ;;
  n|N ) ;;
  * ) logerror "invalid container $container! it should be one of zookeeper, broker, schema-registry, connect, connect2 or connect3";exit 1;;
  esac

  docker cp $JMXTERM_UBER_JAR $container:$JMXTERM_UBER_JAR
  if [ "$domains" = "ALL" ]
  then

log "This is the list of domains for container $container"
docker exec -i $container java -jar $JMXTERM_UBER_JAR  -l localhost:$port -n -v silent << EOF
domains
exit
EOF
  fi

for domain in `echo $domains`
do
docker exec -i $container java -jar $JMXTERM_UBER_JAR  -l localhost:$port -n -v silent > /tmp/beans.log << EOF
domain $domain
beans
exit
EOF
  while read line; do echo "get *"  -b $line; done < /tmp/beans.log >> /tmp/commands

  if [[ -n "$open" ]]
  then
    echo "####### domain $domain ########" >> /tmp/jmx_metrics.log
    docker exec -i $container java -jar $JMXTERM_UBER_JAR  -l localhost:$port -n < /tmp/commands >> /tmp/jmx_metrics.log 2>&1
  else
    echo "####### domain $domain ########"
    docker exec -i $container java -jar $JMXTERM_UBER_JAR  -l localhost:$port -n < /tmp/commands 2>&1
  fi
done

  if [[ -n "$open" ]]
  then
    playground open --file "/tmp/jmx_metrics.log"
  fi
}

# https://www.linuxjournal.com/content/validating-ip-address-bash-script
function valid_ip()
{
    local  ip=$1
    local  stat=1

    if [[ $ip =~ ^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$ ]]; then
        OIFS=$IFS
        IFS='.'
        ip=($ip)
        IFS=$OIFS
        [[ ${ip[0]} -le 255 && ${ip[1]} -le 255 \
            && ${ip[2]} -le 255 && ${ip[3]} -le 255 ]]
        stat=$?
    fi
    return $stat
}

function container_to_name() {
    container=$1
    echo "${PWD##*/}_${container}_1"
}

function container_to_ip() {
    if [ $# -lt 1 ]; then
        echo "Usage: container_to_ip container"
    fi
    echo $(docker inspect $1 -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}')
}

function clear_traffic_control() {
    if [ $# -lt 1 ]; then
        echo "Usage: clear_traffic_control src_container"
    fi

    src_container=$1

    echo "Removing all traffic control settings on $src_container"

    # Delete the entry from the tc table so the changes made to tc do not persist
    docker exec --privileged -u0 -t $src_container tc qdisc del dev eth0 root
}

function get_latency() {
    if [ $# -lt 2 ]; then
        echo "Usage: get_latency src_container dst_container"
    fi
    src_container=$1
    dst_container=$2
    docker exec --privileged -u0 -t $src_container ping $dst_container -c 4 -W 80 | tail -1 | awk -F '/' '{print $5}'
}

# https://serverfault.com/a/906499
function add_latency() {
    if [ $# -lt 3 ]; then
        echo "Usage: add_latency src_container dst_container (or ip address) latency"
        echo "Example: add_latency container-1 container-2 100ms"
    fi

    src_container=$1
    if valid_ip $2
    then
      dst_ip=$2
    else
      dst_ip=$(container_to_ip $2)
    fi
    latency=$3

    set +e
    clear_traffic_control $src_container
    set -e

    echo "Adding $latency latency from $src_container to $2"

    # Add a classful priority queue which lets us differentiate messages.
    # This queue is named 1:.
    # Three children classes, 1:1, 1:2 and 1:3, are automatically created.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 root handle 1: prio

    # Add a filter to the parent queue 1: (also called 1:0). The filter has priority 1 (if we had more filters this would make a difference).
    # For all messages with the ip of dst_ip as their destination, it routes them to class 1:1, which
    # subsequently sends them to its only child, queue 10: (All messages need to  "end up" in a queue).
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol ip parent 1: prio 1 u32 match ip dst $dst_ip flowid 1:1

    # Route the rest of the of the packets without any control.
    # Add a filter to the parent queue 1:. The filter has priority 2.
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip dst 0.0.0.0/0 flowid 1:2
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip protocol 1 0xff flowid 1:2

    # Add a child queue named 10: under class 1:1. All outgoing packets that will be routed to 10: will have delay applied them.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:1 handle 10: netem delay $latency

    # Add a child queue named 20: under class 1:2
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:2 handle 20: sfq
}

function add_packet_corruption() {
    if [ $# -lt 3 ]; then
        echo "Usage: add_packet_corruption src_container dst_container (or ip address) corrupt"
        echo "Exemple: add_packet_corruption container-1 container-2 1%"
    fi

    src_container=$1
    if valid_ip $2
    then
      dst_ip=$2
    else
      dst_ip=$(container_to_ip $2)
    fi
    corruption=$3

    set +e
    clear_traffic_control $src_container
    set -e

    echo "Adding $corruption corruption from $src_container to $2"

    # Add a classful priority queue which lets us differentiate messages.
    # This queue is named 1:.
    # Three children classes, 1:1, 1:2 and 1:3, are automatically created.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 root handle 1: prio

    # Add a filter to the parent queue 1: (also called 1:0). The filter has priority 1 (if we had more filters this would make a difference).
    # For all messages with the ip of dst_ip as their destination, it routes them to class 1:1, which
    # subsequently sends them to its only child, queue 10: (All messages need to  "end up" in a queue).
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol ip parent 1: prio 1 u32 match ip dst $dst_ip flowid 1:1

    # Route the rest of the of the packets without any control.
    # Add a filter to the parent queue 1:. The filter has priority 2.
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip dst 0.0.0.0/0 flowid 1:2
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip protocol 1 0xff flowid 1:2

    # Add a child queue named 10: under class 1:1. All outgoing packets that will be routed to 10: will have corrupt applied them.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:1 handle 10: netem corrupt $corruption

    # Add a child queue named 20: under class 1:2
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:2 handle 20: sfq
}

function add_packet_loss() {
    if [ $# -lt 3 ]; then
        echo "Usage: add_packet_loss src_container dst_container (or ip address) corrupt"
        echo "Exemple: add_packet_loss container-1 container-2 1%"
    fi

    src_container=$1
    if valid_ip $2
    then
      dst_ip=$2
    else
      dst_ip=$(container_to_ip $2)
    fi
    loss=$3

    set +e
    clear_traffic_control $src_container
    set -e

    echo "Adding $loss loss from $src_container to $2"

    # Add a classful priority queue which lets us differentiate messages.
    # This queue is named 1:.
    # Three children classes, 1:1, 1:2 and 1:3, are automatically created.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 root handle 1: prio

    # Add a filter to the parent queue 1: (also called 1:0). The filter has priority 1 (if we had more filters this would make a difference).
    # For all messages with the ip of dst_ip as their destination, it routes them to class 1:1, which
    # subsequently sends them to its only child, queue 10: (All messages need to  "end up" in a queue).
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol ip parent 1: prio 1 u32 match ip dst $dst_ip flowid 1:1

    # Route the rest of the of the packets without any control.
    # Add a filter to the parent queue 1:. The filter has priority 2.
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip dst 0.0.0.0/0 flowid 1:2
    docker exec --privileged -u0 -t $src_container tc filter add dev eth0 protocol all parent 1: prio 2 u32 match ip protocol 1 0xff flowid 1:2

    # Add a child queue named 10: under class 1:1. All outgoing packets that will be routed to 10: will have loss applied them.
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:1 handle 10: netem loss $loss

    # Add a child queue named 20: under class 1:2
    docker exec --privileged -u0 -t $src_container tc qdisc add dev eth0 parent 1:2 handle 20: sfq
}

function get_3rdparty_file () {
  file="$1"

  if [ -f $file ]
  then
    log "$file already present, skipping"
    return
  fi

  folder="3rdparty"
  if [[ "$file" == *repro* ]]
  then
    folder="repro-files"
  fi
  set +e
  log "attempting to get the file $file from Confluent S3 bucket (only works for Confluent employees when aws creds are set)..."
  log "command is <aws s3 ls s3://kafka-docker-playground/$folder/$file"
  handle_aws_credentials
  aws s3 ls s3://kafka-docker-playground/$folder/$file > /dev/null 2>&1
  if [ $? -eq 0 ]
  then
      log "Downloading <s3://kafka-docker-playground/$folder/$file> from S3 bucket"
      if [ ! -z "$GITHUB_RUN_NUMBER" ]
      then
        aws s3 cp --only-show-errors "s3://kafka-docker-playground/$folder/$file" .
      else
        aws s3 cp "s3://kafka-docker-playground/$folder/$file" .
      fi
      if [ $? -eq 0 ]; then
        log "📄 <s3://kafka-docker-playground/$folder/$file> was downloaded from S3 bucket"
      fi
      if [[ "$OSTYPE" == "darwin"* ]]
      then
          # workaround for issue on linux, see https://github.com/vdesabou/kafka-docker-playground/issues/851#issuecomment-821151962
          chmod a+rw $file
      else
          # on CI, docker is run as runneradmin user, need to use sudo
          sudo chmod a+rw $file
      fi
  fi
  set -e
}

function remove_cdb_oracle_image() {
  ZIP_FILE="$1"
  SETUP_FOLDER="$2"

  if [ "$ZIP_FILE" == "linuxx64_12201_database.zip" ]
  then
      ORACLE_VERSION="12.2.0.1-ee"
  elif [ "$ZIP_FILE" == "LINUX.X64_180000_db_home.zip" ]
  then
      ORACLE_VERSION="18.3.0-ee"
  elif [ "$ZIP_FILE" == "LINUX.X64_213000_db_home.zip" ]
  then
      ORACLE_VERSION="21.3.0-ee"
  else
      ORACLE_VERSION="19.3.0-ee"
  fi

  SETUP_FILE=${SETUP_FOLDER}/01_user-setup.sh
  SETUP_FILE_CKSUM=$(cksum $SETUP_FILE | awk '{ print $1 }')
  if [ "$(uname -m)" = "arm64" ]
  then
      export ORACLE_IMAGE="db-prebuilt-arm64-$SETUP_FILE_CKSUM:$ORACLE_VERSION"
  else
      export ORACLE_IMAGE="db-prebuilt-$SETUP_FILE_CKSUM:$ORACLE_VERSION"
  fi

  if ! test -z "$(docker images -q $ORACLE_IMAGE)"
  then
    log "🧹 Removing Oracle image $ORACLE_IMAGE"
    docker image rm $ORACLE_IMAGE
  fi
}

function create_or_get_oracle_image() {
  local ZIP_FILE="$1"
  local SETUP_FOLDER="$2"

  if [ "$ZIP_FILE" == "linuxx64_12201_database.zip" ]
  then
      ORACLE_VERSION="12.2.0.1-ee"
  elif [ "$ZIP_FILE" == "LINUX.X64_180000_db_home.zip" ]
  then
      ORACLE_VERSION="18.3.0-ee"
  elif [ "$ZIP_FILE" == "LINUX.X64_213000_db_home.zip" ]
  then
      ORACLE_VERSION="21.3.0-ee"
  else
      if [ "$(uname -m)" = "arm64" ]
      then
          ZIP_FILE="LINUX.ARM64_1919000_db_home.zip"
      else
          ZIP_FILE="LINUX.X64_193000_db_home.zip"
      fi
      ORACLE_VERSION="19.3.0-ee"
  fi
  # used for docker-images repo
  DOCKERFILE_VERSION=$(echo "$ORACLE_VERSION" | cut -d "-" -f 1)

  # https://github.com/oracle/docker-images/tree/main/OracleDatabase/SingleInstance/samples/prebuiltdb
  SETUP_FILE=${SETUP_FOLDER}/01_user-setup.sh
  SETUP_FILE_CKSUM=$(cksum $SETUP_FILE | awk '{ print $1 }')

  if [ "$(uname -m)" = "arm64" ]
  then
      export ORACLE_IMAGE="db-prebuilt-arm64-$SETUP_FILE_CKSUM:$ORACLE_VERSION"
  else
      export ORACLE_IMAGE="db-prebuilt-$SETUP_FILE_CKSUM:$ORACLE_VERSION"
  fi
  TEMP_CONTAINER="oracle-build-$ORACLE_VERSION-$(basename $SETUP_FOLDER)"

  if test -z "$(docker images -q $ORACLE_IMAGE)"
  then
    set +e
    log "attempting to get the Oracle prebuilt docker image from Confluent S3 bucket (only works for Confluent employees)..."
    log "command is <aws s3 ls s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar>"
    handle_aws_credentials
    aws s3 ls s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar
    if [ $? -eq 0 ]
    then
        log "Downloading prebuilt image <s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar> from S3 bucket"
        if [ ! -z "$GITHUB_RUN_NUMBER" ]
        then
          aws s3 cp --only-show-errors "s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar" .
        else
          aws s3 cp "s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar" .
        fi
        if [ $? -eq 0 ]
        then
          log "📄 <s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar> was downloaded from S3 bucket"
          docker load -i $ORACLE_IMAGE.tar
          if [ $? -eq 0 ]
          then
            log "📄 image $ORACLE_IMAGE has been installed locally"
          fi

          if [[ "$OSTYPE" == "darwin"* ]]
          then
            log "🧹 Removing prebuilt image $ORACLE_IMAGE.tar"
            rm -f $ORACLE_IMAGE.tar
          else
            log "🧹 Removing prebuilt image $ORACLE_IMAGE.tar with sudo"
            sudo rm -f $ORACLE_IMAGE.tar
          fi
        fi
    else
      logwarn "If you're a Confluent employee, please check this link https://confluent.slack.com/archives/C0116NM415F/p1636391410032900 and also here https://confluent.slack.com/archives/C0116NM415F/p1636389483030900"
      logwarn "re-run with <playground -v (or --vvv) run> to troubleshoot"
    fi
    set -e
  fi

  if ! test -z "$(docker images -q $ORACLE_IMAGE)"
  then
    log "✨ Using Oracle prebuilt image $ORACLE_IMAGE (oracle version 🔢 $ORACLE_VERSION and 📂 setup folder $SETUP_FOLDER)"
    return
  fi

  BASE_ORACLE_IMAGE="oracle/database:$ORACLE_VERSION"

  if test -z "$(docker images -q $BASE_ORACLE_IMAGE)"
  then
    set +e
    handle_aws_credentials
    aws s3 ls s3://kafka-docker-playground/3rdparty/oracle_database_$ORACLE_VERSION.tar > /dev/null 2>&1
    if [ $? -eq 0 ]
    then
        log "Downloading <s3://kafka-docker-playground/3rdparty/oracle_database_$ORACLE_VERSION.tar> from S3 bucket"
        if [ ! -z "$GITHUB_RUN_NUMBER" ]
        then
          aws s3 cp --only-show-errors "s3://kafka-docker-playground/3rdparty/oracle_database_$ORACLE_VERSION.tar" .
        else
          aws s3 cp "s3://kafka-docker-playground/3rdparty/oracle_database_$ORACLE_VERSION.tar" .
        fi
        if [ $? -eq 0 ]
        then
          log "📄 <s3://kafka-docker-playground/3rdparty/oracle_database_$ORACLE_VERSION.tar> was downloaded from S3 bucket"
          docker load -i oracle_database_$ORACLE_VERSION.tar
          if [ $? -eq 0 ]
          then
            log "📄 image $BASE_ORACLE_IMAGE has been installed locally"
          fi

          if [[ "$OSTYPE" == "darwin"* ]]
          then
            log "🧹 Removing $ORACLE_IMAGE.tar"
            rm -f oracle_database_$ORACLE_VERSION.tar
          else
            log "🧹 Removing $ORACLE_IMAGE.tar with sudo"
            sudo rm -f oracle_database_$ORACLE_VERSION.tar
          fi
        fi
    fi
    set -e
  fi

  if test -z "$(docker images -q $BASE_ORACLE_IMAGE)"
  then
      if [ ! -f ${ZIP_FILE} ]
      then
          set +e
          handle_aws_credentials
          aws s3 ls s3://kafka-docker-playground/3rdparty/${ZIP_FILE} > /dev/null 2>&1
          if [ $? -eq 0 ]
          then
              log "Downloading <s3://kafka-docker-playground/3rdparty/${ZIP_FILE}> from S3 bucket"

              if [ ! -z "$GITHUB_RUN_NUMBER" ]
              then
                aws s3 cp --only-show-errors "s3://kafka-docker-playground/3rdparty/${ZIP_FILE}" .
              else
                aws s3 cp "s3://kafka-docker-playground/3rdparty/${ZIP_FILE}" .
              fi
              if [ $? -eq 0 ]
              then
                log "📄 <s3://kafka-docker-playground/3rdparty/${ZIP_FILE}> was downloaded from S3 bucket"
              fi
          fi
          set -e
      fi
      if [ ! -f ${ZIP_FILE} ]
      then
          logerror "❌ ${ZIP_FILE} is missing. It must be downloaded manually in order to acknowledge user agreement"
          exit 1
      fi
      log "👷 Building $BASE_ORACLE_IMAGE docker image..it can take a while...(more than 15 minutes!)"
      OLDDIR=$PWD
      rm -rf docker-images
      git clone https://github.com/oracle/docker-images.git

      mv ${ZIP_FILE} docker-images/OracleDatabase/SingleInstance/dockerfiles/$DOCKERFILE_VERSION/${ZIP_FILE}
      cd docker-images/OracleDatabase/SingleInstance/dockerfiles
      ./buildContainerImage.sh -v $DOCKERFILE_VERSION -e
      rm -rf docker-images
      cd ${OLDDIR}
  fi

  if test -z "$(docker images -q $ORACLE_IMAGE)"
  then
      log "🏭 Prebuilt $ORACLE_IMAGE docker image does not exist, building it now..it can take a while..."
      log "🚦 Startup a container ${TEMP_CONTAINER} with setup folder $SETUP_FOLDER and create the database"
      cd $SETUP_FOLDER
      docker run -d -e ORACLE_PWD=Admin123 -v $PWD:/opt/oracle/scripts/setup --name ${TEMP_CONTAINER} ${BASE_ORACLE_IMAGE}
      cd -

      MAX_WAIT=2500
      CUR_WAIT=0
      log "⌛ Waiting up to $MAX_WAIT seconds for ${TEMP_CONTAINER} to start"
      docker container logs ${TEMP_CONTAINER} > /tmp/out.txt 2>&1
      while [[ ! $(cat /tmp/out.txt) =~ "DATABASE IS READY TO USE" ]]; do
      sleep 10
      docker container logs ${TEMP_CONTAINER} > /tmp/out.txt 2>&1
      CUR_WAIT=$(( CUR_WAIT+10 ))
      if [[ "$CUR_WAIT" -gt "$MAX_WAIT" ]]; then
            logerror "❌ The logs in ${TEMP_CONTAINER} container do not show 'DATABASE IS READY TO USE' after $MAX_WAIT seconds. Please troubleshoot with 'docker container ps' and 'playground container logs --open --container <container>'.\n"
            exit 1
      fi
      done
      log "${TEMP_CONTAINER} has started! Check logs in /tmp/${TEMP_CONTAINER}.log"
      docker container logs ${TEMP_CONTAINER} > /tmp/${TEMP_CONTAINER}.log 2>&1
      log "🛑 Stop the running container"
      docker stop -t 600 ${TEMP_CONTAINER}
      log "🛠 Create the image with the prebuilt database"
      docker commit -m "Image with prebuilt database" ${TEMP_CONTAINER} ${ORACLE_IMAGE}
      log "🧹 Clean up ${TEMP_CONTAINER}"
      docker rm ${TEMP_CONTAINER}

      if [ ! -z "$GITHUB_RUN_NUMBER" ]
      then
          set +e
          aws s3 ls s3://kafka-docker-playground/3rdparty/$ORACLE_IMAGE.tar > /dev/null 2>&1
          if [ $? -ne 0 ]
          then
              log "📄 Uploading </tmp/$ORACLE_IMAGE.tar> to S3 bucket"
              docker save -o /tmp/$ORACLE_IMAGE.tar $ORACLE_IMAGE
              aws s3 cp --only-show-errors "/tmp/$ORACLE_IMAGE.tar" "s3://kafka-docker-playground/3rdparty/"
              if [ $? -eq 0 ]; then
                    log "📄 </tmp/$ORACLE_IMAGE.tar> was uploaded to S3 bucket"
              fi
          fi
          set -e
      fi
  fi

  log "✨ Using Oracle prebuilt image $ORACLE_IMAGE (oracle version 🔢 $ORACLE_VERSION and 📂 setup folder $SETUP_FOLDER)"
}

function print_code_pass() {
  local MESSAGE=""
	local CODE=""
  OPTIND=1
  while getopts ":c:m:" opt; do
    case ${opt} in
			c ) CODE=${OPTARG};;
      m ) MESSAGE=${OPTARG};;
		esac
	done
  shift $((OPTIND-1))
	printf "${PRETTY_PASS}${PRETTY_CODE}%s\e[0m\n" "${CODE}"
	[[ -z "$MESSAGE" ]] || printf "\t$MESSAGE\n"
}
function print_code_error() {
  local MESSAGE=""
	local CODE=""
  OPTIND=1
  while getopts ":c:m:" opt; do
    case ${opt} in
			c ) CODE=${OPTARG};;
      m ) MESSAGE=${OPTARG};;
		esac
	done
  shift $((OPTIND-1))
	printf "${PRETTY_ERROR}${PRETTY_CODE}%s\e[0m\n" "${CODE}"
	[[ -z "$MESSAGE" ]] || printf "\t$MESSAGE\n"
}

function exit_with_error()
{
  local USAGE="\nUsage: exit_with_error -c code -n name -m message -l line_number\n"
  local NAME=""
  local MESSAGE=""
  local CODE=$UNSPECIFIED_ERROR
  local LINE=
  OPTIND=1
  while getopts ":n:m:c:l:" opt; do
    case ${opt} in
      n ) NAME=${OPTARG};;
      m ) MESSAGE=${OPTARG};;
      c ) CODE=${OPTARG};;
      l ) LINE=${OPTARG};;
      ? ) printf $USAGE;return 1;;
    esac
  done
  shift $((OPTIND-1))
  print_error "error ${CODE} occurred in ${NAME} at line $LINE"
	printf "\t${MESSAGE}\n"
  exit $CODE
}

function get_kafka_docker_playground_dir () {
  DIR_UTILS="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  KAFKA_DOCKER_PLAYGROUND_DIR="$(echo $DIR_UTILS | sed 's|\(.*kafka-docker-playground\).*|\1|')"
}

function maybe_delete_ccloud_environment () {
  get_kafka_docker_playground_dir
  DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

  if [ -f $DELTA_CONFIGS_ENV ]
  then
    source $DELTA_CONFIGS_ENV
  else
    logerror "❌ $DELTA_CONFIGS_ENV has not been generated"
    exit 1
  fi

  if [ -z "$CLUSTER_NAME" ]
  then
    #
    # CLUSTER_NAME is not set
    #
    log "🧹❌ Confluent Cloud cluster will be deleted..."
    verify_installed "confluent"
    check_confluent_version 4.32.0 || exit 1
    verify_confluent_login  "confluent kafka cluster list"

    export QUIET=true

    if [ ! -z "$ENVIRONMENT" ]
    then
      log "🌐 ENVIRONMENT $ENVIRONMENT is set, it will not be deleted"
      export PRESERVE_ENVIRONMENT=true
    else
      export PRESERVE_ENVIRONMENT=false
    fi
    SERVICE_ACCOUNT_ID=$(ccloud:get_service_account_from_current_cluster_name)
    set +e
    ccloud::destroy_ccloud_stack $SERVICE_ACCOUNT_ID
    set -e
  fi
}

function check_expected_ccloud_details () {
  local expected_cloud="$1"
  local expected_region="$2"

  if [ -n "$expected_cloud" ] && [ -n "$expected_region" ]
  then
    expected_failed=0
    if [ "$expected_cloud" != "$CLUSTER_CLOUD" ]
    then
      logerror "❌🌤 expected ccloud cloud provider for the example is $expected_cloud but you're using $CLUSTER_CLOUD"
      expected_failed=1
    fi

    if [ "$expected_region" != "$CLUSTER_REGION" ]
    then
      logerror "❌🗺 expected ccloud region for the example is $expected_region but you're using $CLUSTER_REGION"
      expected_failed=1
    fi

    if [ $expected_failed == 1 ]
    then
      exit 1
    fi
  fi
}

function bootstrap_ccloud_environment () {

  local expected_cloud="$1"
  local expected_region="$2"
  local connect_migration_utility="$3"

  DIR_UTILS="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  get_kafka_docker_playground_dir
  DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

  if [ -z "$GITHUB_RUN_NUMBER" ] && [ -z "$CLOUDFORMATION" ]
  then
    # not running with CI
    verify_installed "confluent"
    check_confluent_version 4.32.0 || exit 1
    verify_confluent_login  "confluent kafka cluster list"
  else
    if [ ! -f /usr/local/bin/confluent ]
    then
      log "🚚 installing confluent CLI"
      curl -L --http1.1 https://cnfl.io/cli | sudo sh -s -- -b /usr/local/bin
    fi
    export PATH=$PATH:/usr/local/bin
    log "⛺ log in to Confluent Cloud"
    confluent login --save
  fi

  playground ccloud-costs-history > /tmp/ccloud-costs-history.txt &

  suggest_use_previous_example_ccloud=1
  test_file=$(playground state get run.test_file)

  if [ -f "$test_file" ]
  then
    if [[ $test_file == *"fm-databricks-delta-lake-sink"* ]] || ( [[ -n "$connect_migration_utility" ]] && [[ $test_file == *"connect-databricks"* ]] )
    then
      if [ ! -z "$AWS_DATABRICKS_CLUSTER_NAME" ]
      then
        log "AWS_DATABRICKS_CLUSTER_NAME environment variable is set, forcing the cluster $AWS_DATABRICKS_CLUSTER_NAME to be used !"
        suggest_use_previous_example_ccloud=0
        export CLUSTER_NAME=$AWS_DATABRICKS_CLUSTER_NAME
        export CLUSTER_REGION=$AWS_DATABRICKS_CLUSTER_REGION
        export CLUSTER_CLOUD=$AWS_DATABRICKS_CLUSTER_CLOUD
        export CLUSTER_CREDS=$AWS_DATABRICKS_CLUSTER_CREDS
      fi
    fi

    if [[ $test_file == *"fm-aws"* ]] || ( [[ -n "$connect_migration_utility" ]] && [[ $test_file == *"connect-aws"* ]] )
    then
      if [ ! -z "$AWS_CLUSTER_NAME" ]
      then
        log "🤖 AWS Fully managed example and AWS_CLUSTER_NAME environment variable is set, forcing the cluster $AWS_CLUSTER_NAME to be used !"
        suggest_use_previous_example_ccloud=0
        export CLUSTER_NAME=$AWS_CLUSTER_NAME
        export CLUSTER_REGION=$AWS_CLUSTER_REGION
        export CLUSTER_CLOUD=$AWS_CLUSTER_CLOUD
        export CLUSTER_CREDS=$AWS_CLUSTER_CREDS
      fi
    fi

    if [[ $test_file == *"fm-gcp"* ]] || ( [[ -n "$connect_migration_utility" ]] && [[ $test_file == *"connect-gcp"* ]] )
    then
      if [ ! -z "$GCP_CLUSTER_NAME" ]
      then
        log "🤖 GCP Fully managed example and GCP_CLUSTER_NAME environment variable is set, forcing the cluster $GCP_CLUSTER_NAME to be used !"
        suggest_use_previous_example_ccloud=0
        export CLUSTER_NAME=$GCP_CLUSTER_NAME
        export CLUSTER_REGION=$GCP_CLUSTER_REGION
        export CLUSTER_CLOUD=$GCP_CLUSTER_CLOUD
        export CLUSTER_CREDS=$GCP_CLUSTER_CREDS
      fi
    fi

    if [[ $test_file == *"fm-azure"* ]] || ( [[ -n "$connect_migration_utility" ]] && [[ $test_file == *"connect-azure"* ]] )
    then
      if [ ! -z "$AZURE_CLUSTER_NAME" ]
      then
        log "🤖 Azure Fully managed example and AZURE_CLUSTER_NAME environment variable is set, forcing the cluster $AZURE_CLUSTER_NAME to be used !"
        suggest_use_previous_example_ccloud=0
        export CLUSTER_NAME=$AZURE_CLUSTER_NAME
        export CLUSTER_REGION=$AZURE_CLUSTER_REGION
        export CLUSTER_CLOUD=$AZURE_CLUSTER_CLOUD
        export CLUSTER_CREDS=$AZURE_CLUSTER_CREDS
      fi
    fi
  fi

  for item in {ENVIRONMENT,CLUSTER_NAME,CLUSTER_CLOUD,CLUSTER_REGION,CLUSTER_CREDS}
  do
      i=$(playground state get "ccloud.${item}")
      if [ "$i" == "" ]
      then
        # at least one mandatory field is missing
        suggest_use_previous_example_ccloud=0
        break
      fi
  done

  if [ ! -z "$CLUSTER_NAME" ]
  then
    if [ "$(playground state get "ccloud.CLUSTER_NAME")" == "$CLUSTER_NAME" ]
    then
      suggest_use_previous_example_ccloud=0
    fi
  fi

  if [ "$(playground state get "ccloud.suggest_use_previous_example_ccloud")" == "0" ]
  then
    suggest_use_previous_example_ccloud=0
  fi

  if [ $suggest_use_previous_example_ccloud -eq 1 ] && [ -z "$GITHUB_RUN_NUMBER" ]
  then
    log "🙋 Use previously used ccloud cluster:"
    log "  🌐 ENVIRONMENT=$(playground state get ccloud.ENVIRONMENT)"
    log "  🎰 CLUSTER_NAME=$(playground state get ccloud.CLUSTER_NAME)"
    log "  🌤  CLUSTER_CLOUD=$(playground state get ccloud.CLUSTER_CLOUD)"
    log "  🗺  CLUSTER_REGION=$(playground state get ccloud.CLUSTER_REGION)"

    read -p "Continue (y/n)?" choice
    case "$choice" in
    y|Y )

      ENVIRONMENT=$(playground state get ccloud.ENVIRONMENT)
      CLUSTER_NAME=$(playground state get ccloud.CLUSTER_NAME)
      CLUSTER_CLOUD=$(playground state get ccloud.CLUSTER_CLOUD)
      CLUSTER_REGION=$(playground state get ccloud.CLUSTER_REGION)
      CLUSTER_CREDS=$(playground state get ccloud.CLUSTER_CREDS)
      SCHEMA_REGISTRY_CREDS=$(playground state get ccloud.SCHEMA_REGISTRY_CREDS)
      ;;
    n|N )

      playground state del ccloud.ENVIRONMENT
      playground state del ccloud.CLUSTER_NAME
      playground state del ccloud.CLUSTER_CLOUD
      playground state del ccloud.CLUSTER_REGION
      playground state del ccloud.CLUSTER_CREDS
      playground state del ccloud.SCHEMA_REGISTRY_CREDS
      ;;
    * )

      logerror "invalid response!";
      exit 1
      ;;
    esac
  fi

  if [ -z "$CLUSTER_NAME" ]
  then
    #
    # CLUSTER_NAME is not set
    #
    log "🛠👷‍♀️ CLUSTER_NAME is not set, a new Confluent Cloud cluster will be created..."
    log "🎓 If you wanted to use an existing cluster, set CLUSTER_NAME, ENVIRONMENT, CLUSTER_CLOUD, CLUSTER_REGION and CLUSTER_CREDS (also optionnaly SCHEMA_REGISTRY_CREDS)"

    if [ -z "$CLUSTER_CLOUD" ] || [ -z "$CLUSTER_REGION" ]
    then
      logwarn "CLUSTER_CLOUD and/or CLUSTER_REGION are not set, the cluster will be created 🌤 AWS provider and 🗺 eu-west-2 region"
      export CLUSTER_CLOUD=aws
      export CLUSTER_REGION=eu-west-2
      if [ -z "$CLUSTER_TYPE" ]
      then
        export CLUSTER_TYPE=basic
      fi
    fi

    if [ ! -z "$CLUSTER_CREDS" ]
    then
      # make sure it is unset
      unset CLUSTER_CREDS
    fi

    if [ ! -z $ENVIRONMENT ]
    then
      log "🌐 ENVIRONMENT is set with $ENVIRONMENT and will be used"
    else
      if [ ! -z "$SCHEMA_REGISTRY_CREDS" ]
      then
        # make sure it is unset
        unset SCHEMA_REGISTRY_CREDS
      fi
    fi
    log "🔋 CLUSTER_TYPE is set with $CLUSTER_TYPE"
    log "🌤  CLUSTER_CLOUD is set with $CLUSTER_CLOUD"
    log "🗺  CLUSTER_REGION is set with $CLUSTER_REGION"

    export EXAMPLE=$(basename $PWD)
    export WARMUP_TIME=15
    export QUIET=true

    log "💡 if you notice that the playground is using unexpected ccloud details, use <playground cleanup-cloud-details> to remove all caching and re-launch the example"
    check_if_continue
  else
    #
    # CLUSTER_NAME is set
    #
    log "🌱 CLUSTER_NAME is set, your existing Confluent Cloud cluster will be used..."
    if [ -z $ENVIRONMENT ] || [ -z $CLUSTER_CLOUD ] || [ -z $CLUSTER_CLOUD ] || [ -z $CLUSTER_REGION ] || [ -z $CLUSTER_CREDS ]
    then
      logerror "One mandatory environment variable to use your cluster is missing:"
      logerror "ENVIRONMENT=$ENVIRONMENT"
      logerror "CLUSTER_NAME=$CLUSTER_NAME"
      logerror "CLUSTER_CLOUD=$CLUSTER_CLOUD"
      logerror "CLUSTER_REGION=$CLUSTER_REGION"
      logerror "CLUSTER_CREDS=$CLUSTER_CREDS"
      exit 1
    fi

    log "🌐 ENVIRONMENT is set with $ENVIRONMENT"
    log "🎰 CLUSTER_NAME is set with $CLUSTER_NAME"
    log "🌤  CLUSTER_CLOUD is set with $CLUSTER_CLOUD"
    log "🗺  CLUSTER_REGION is set with $CLUSTER_REGION"

    check_expected_ccloud_details "$expected_cloud" "$expected_region"

    log "💡 if you notice that the playground is using unexpected ccloud details, use <playground cleanup-cloud-details> to remove all caching and re-launch the example"

    for row in $(confluent kafka cluster list --output json | jq -r '.[] | @base64'); do
        _jq() {
        echo ${row} | base64 -d | jq -r ${1}
        }

        is_current=$(echo $(_jq '.is_current'))
        name=$(echo $(_jq '.name'))

        if [ "$is_current" == "true" ] && [ "$name" == "$CLUSTER_NAME" ]
        then
          if [ -f $DELTA_CONFIGS_ENV ]
          then
            source $DELTA_CONFIGS_ENV
            log "🌱 cluster $CLUSTER_NAME is ready to be used!"

			if [[ ! -n "$connect_migration_utility" ]]
			then
				# trick
				playground state set run.environment "ccloud"
			fi
            return
          else
            logwarn "$DELTA_CONFIGS_ENV has not been generated, doing it now..."
            break
          fi
        fi
    done

    export WARMUP_TIME=0
  fi

  check_expected_ccloud_details "$expected_cloud" "$expected_region"

  ccloud::create_ccloud_stack false  \
    && print_code_pass -c "ccloud::create_ccloud_stack false"

  CCLOUD_CONFIG_FILE=/tmp/tmp.config
  export CCLOUD_CONFIG_FILE=$CCLOUD_CONFIG_FILE
  ccloud::validate_ccloud_config $CCLOUD_CONFIG_FILE || exit 1

  ccloud::generate_configs $CCLOUD_CONFIG_FILE \
    && print_code_pass -c "ccloud::generate_configs $CCLOUD_CONFIG_FILE"

  if [ -f $DELTA_CONFIGS_ENV ]
  then
    source $DELTA_CONFIGS_ENV
  else
    logerror "❌ $DELTA_CONFIGS_ENV has not been generated"
    exit 1
  fi

  playground state set ccloud.ENVIRONMENT "$ENVIRONMENT"
  playground state set ccloud.CLUSTER_NAME "$CLUSTER_NAME"
  playground state set ccloud.CLUSTER_CLOUD "$CLUSTER_CLOUD"
  playground state set ccloud.CLUSTER_REGION "$CLUSTER_REGION"
  playground state set ccloud.CLUSTER_CREDS "$CLUSTER_CREDS"
  playground state set ccloud.SCHEMA_REGISTRY_CREDS "$SCHEMA_REGISTRY_CREDS"

  if [[ ! -n "$connect_migration_utility" ]]
  then
	# trick
	playground state set run.environment "ccloud"
  fi
}

function create_ccloud_connector() {
  file=$1

  log "🛠️ Creating connector from $file"
  confluent connect cluster create --config-file $file
  if [[ $? != 0 ]]
  then
    logerror "Exit status was not 0 while creating connector from $file.  Please troubleshoot and try again"
  fi

  return 0
}

function validate_ccloud_connector_up() {
  connector="$1"
  if [ -f "/tmp/config-$connector" ]
  then
    set +e
    playground connector create-or-update --connector "$connector" --no-clipboard < "/tmp/config-$connector" > /tmp/output.log 2>&1
    if [ $? -ne 0 ]
    then
      echo "💀"
    else
      echo "🔁"
      cat /tmp/output.log | grep "$connector" | grep -v "\"name\"" | grep -v "ℹ️" | grep -v "playground connector create-or-update"
    fi
  else
    echo "❌"
  fi
  set -e

  confluent connect cluster list -o json | jq -e 'map(select(.name == "'"$1"'" and .status == "RUNNING")) | .[]' > /dev/null 2>&1
}

function get_ccloud_connector_lcc() {
  confluent connect cluster list -o json | jq -r -e 'map(select(.name == "'"$1"'")) | .[].id'
}

function ccloud::retry() {
    local -r -i max_wait="$1"; shift
    local -r cmd="$@"

    local -i sleep_interval=5
    local -i curr_wait=0

    until $cmd
    do
        if (( curr_wait >= max_wait ))
        then
            echo "ERROR: Failed after $curr_wait seconds. Please troubleshoot and run again."
            return 1
        else
            curr_wait=$((curr_wait+sleep_interval))
            sleep $sleep_interval
        fi
    done
}

function wait_for_ccloud_connector_up() {
  connectorName=$1
  maxWait=$2

  connectorId=$(get_ccloud_connector_lcc $connectorName)
  log "⏳ waiting up to $maxWait seconds for connector $connectorName ($connectorId) to be RUNNING"
  ccloud::retry $maxWait validate_ccloud_connector_up $connectorName || exit 1
  log "🟢 connector $connectorName ($connectorId) is RUNNING"

  if [ -z "$GITHUB_RUN_NUMBER" ]
  then
    automatically=$(playground config get open-ccloud-connector-in-browser.automatically)
    if [ "$automatically" == "" ]
    then
        playground config set open-ccloud-connector-in-browser.automatically true
    fi

    browser=$(playground config get open-ccloud-connector-in-browser.browser)
    if [ "$browser" == "" ]
    then
        playground config set open-ccloud-connector-in-browser.browser ""
    fi

    if [ "$automatically" == "true" ] || [ "$automatically" == "" ]
    then
      if [ "$browser" != "" ]
      then
        log "🤖 automatically (disable with 'playground config open-ccloud-connector-in-browser automatically false') open fully managed connector $connectorName in browser $browser (you can change browser with 'playground config open-ccloud-connector-in-browser browser <browser>')"
        playground connector open-ccloud-connector-in-browser --connector $connectorName --browser $browser
      else
        log "🤖 automatically (disable with 'playground config open-ccloud-connector-in-browser automatically false') open fully managed connector $connectorName in default browser (you can set browser with 'playground config open-ccloud-connector-in-browser browser <browser>')"
        playground connector open-ccloud-connector-in-browser --connector $connectorName
      fi
    fi
  fi

  return 0
}

function delete_ccloud_connector() {
  connectorName=$1
  connectorId=$(get_ccloud_connector_lcc $connectorName)

  log "Deleting connector $connectorName ($connectorId)"
  confluent connect cluster delete $connectorId --force
  return 0
}

function wait_for_log () {
  message="$1"
  container=${2:-connect}
  max_wait=${3:-600}
  cur_wait=0
  log "⌛ Waiting up to $max_wait seconds for message $message to be present in $container container logs..."
  docker container logs ${container} > /tmp/out.txt 2>&1
  while ! grep "$message" /tmp/out.txt > /dev/null;
  do
  sleep 10
  docker container logs ${container} > /tmp/out.txt 2>&1
  cur_wait=$(( cur_wait+10 ))
  if [[ "$cur_wait" -gt "$max_wait" ]]; then
    logerror "The logs in $container container do not show '$message' after $max_wait seconds. Please troubleshoot with 'docker container ps' and 'playground container logs --open --container <container>'."
    return 1
  fi
  done
  grep "$message" /tmp/out.txt
  log "The log is there !"
}

CLI_MIN_VERSION=${CLI_MIN_VERSION:-4.0.0}

# --------------------------------------------------------------
# Library
# --------------------------------------------------------------

function ccloud::validate_expect_installed() {
  if [[ $(type expect 2>&1) =~ "not found" ]]; then
    echo "'expect' is not found. Install 'expect' and try again"
    exit 1
  fi

  return 0
}
function ccloud::validate_cli_installed() {
  if [[ $(type confluent 2>&1) =~ "not found" ]]; then
    echo "'confluent' is not found. Install the Confluent CLI (https://docs.confluent.io/confluent-cli/current/install.html) and try again."
    exit 1
  fi
}

function ccloud::validate_cli_v2() {
  ccloud::validate_cli_installed || exit 1

  if [[ -z $(confluent version 2>&1 | grep "Go") ]]; then
    echo "This example requires the new Confluent CLI. Please update your version and try again."
    exit 1
  fi

  return 0
}

function ccloud::validate_logged_in_cli() {
  ccloud::validate_cli_v2 || exit 1

  if [[ "$(confluent kafka cluster list 2>&1)" =~ "confluent login" ]]; then
    echo
    echo "ERROR: Not logged into Confluent Cloud."
    echo "Log in with the command 'confluent login --save' before running the example. The '--save' argument saves your Confluent Cloud user login credentials or refresh token (in the case of SSO) to the local netrc file."
    exit 1
  fi

  return 0
}

function ccloud::get_version_cli() {
  confluent version | grep "^Version:" | cut -d':' -f2 | cut -d'v' -f2
}

function ccloud::validate_version_cli() {
  ccloud::validate_cli_installed || exit 1

  CLI_VERSION=$(ccloud::get_version_cli)

  if ccloud::version_gt $CLI_MIN_VERSION $CLI_VERSION; then
    echo "confluent version ${CLI_MIN_VERSION} or greater is required. Current version: ${CLI_VERSION}"
    echo "To update, follow: https://docs.confluent.io/confluent-cli/current/migrate.html"
    exit 1
  fi
}

function ccloud::validate_psql_installed() {
  if [[ $(type psql 2>&1) =~ "not found" ]]; then
    echo "psql is not found. Install psql and try again"
    exit 1
  fi

  return 0
}

function ccloud::validate_aws_cli_installed() {
  if [[ $(type aws 2>&1) =~ "not found" ]]; then
    echo "AWS CLI is not found. Install AWS CLI and try again"
    exit 1
  fi

  return 0
}

function ccloud::get_version_aws_cli() {
  version_major=$(aws --version 2>&1 | awk -F/ '{print $2;}' | head -c 1)
  if [[ "$version_major" -eq 2 ]]; then
    echo "2"
  else
    echo "1"
  fi
  return 0
}

function ccloud::validate_gsutil_installed() {
  if [[ $(type gsutil 2>&1) =~ "not found" ]]; then
    echo "Google Cloud gsutil is not found. Install Google Cloud gsutil and try again"
    exit 1
  fi

  return 0
}

function ccloud::validate_az_installed() {
  if [[ $(type az 2>&1) =~ "not found" ]]; then
    echo "Azure CLI is not found. Install Azure CLI and try again"
    exit 1
  fi

  return 0
}

function ccloud::validate_cloud_source() {
  config=$1

  source $config

  if [[ "$DATA_SOURCE" == "kinesis" ]]; then
    ccloud::validate_aws_cli_installed || exit 1
    if [[ -z "$KINESIS_REGION" || -z "$AWS_PROFILE" ]]; then
      echo "ERROR: DATA_SOURCE=kinesis, but KINESIS_REGION or AWS_PROFILE is not set.  Please set these parameters in config/demo.cfg and try again."
      exit 1
    fi
    aws kinesis list-streams --profile $AWS_PROFILE --region $KINESIS_REGION > /dev/null \
      || { echo "Could not run 'aws kinesis list-streams'.  Check credentials and run again." ; exit 1; }
  elif [[ "$DATA_SOURCE" == "rds" ]]; then
    ccloud::validate_aws_cli_installed || exit 1
    if [[ -z "$RDS_REGION" || -z "$AWS_PROFILE" ]]; then
      echo "ERROR: DATA_SOURCE=rds, but RDS_REGION or AWS_PROFILE is not set.  Please set these parameters in config/demo.cfg and try again."
      exit 1
    fi
    aws rds describe-db-instances --profile $AWS_PROFILE --region $RDS_REGION > /dev/null \
      || { echo "Could not run 'aws rds describe-db-instances'.  Check credentials and run again." ; exit 1; }
  else
    echo "Cloud source $cloudsource is not valid.  Must be one of [kinesis|rds]."
    exit 1
  fi

  return 0
}

function ccloud::validate_cloud_storage() {
  config=$1

  source $config
  storage=$DESTINATION_STORAGE

  if [[ "$storage" == "s3" ]]; then
    ccloud::validate_aws_cli_installed || exit 1
    ccloud::validate_credentials_s3 $S3_PROFILE $S3_BUCKET || exit 1
    aws s3api list-buckets --profile $S3_PROFILE --region $STORAGE_REGION > /dev/null \
      || { echo "Could not run 'aws s3api list-buckets'.  Check credentials and run again." ; exit 1; }
  elif [[ "$storage" == "gcs" ]]; then
    ccloud::validate_gsutil_installed || exit 1
    ccloud::validate_credentials_gcp $GCS_CREDENTIALS_FILE $GCS_BUCKET || exit 1
  elif [[ "$storage" == "az" ]]; then
    ccloud::validate_az_installed || exit 1
    ccloud::validate_credentials_az $AZBLOB_STORAGE_ACCOUNT $AZBLOB_CONTAINER || exit 1
  else
    echo "Storage destination $storage is not valid.  Must be one of [s3|gcs|az]."
    exit 1
  fi

  return 0
}

function ccloud::validate_credentials_gcp() {
  GCS_CREDENTIALS_FILE=$1
  GCS_BUCKET=$2

  if [[ -z "$GCS_CREDENTIALS_FILE" || -z "$GCS_BUCKET" ]]; then
    echo "ERROR: DESTINATION_STORAGE=gcs, but GCS_CREDENTIALS_FILE or GCS_BUCKET is not set.  Please set these parameters in config/demo.cfg and try again."
    exit 1
  fi

  gcloud auth activate-service-account --key-file $GCS_CREDENTIALS_FILE || {
    echo "ERROR: Cannot activate service account with key file $GCS_CREDENTIALS_FILE. Verify your credentials and try again."
    exit 1
  }

  # Create JSON-formatted string of the GCS credentials
  export GCS_CREDENTIALS=$(python ./stringify-gcp-credentials.py $GCS_CREDENTIALS_FILE)
  # Remove leading and trailing double quotes, otherwise connector creation from CLI fails
  GCS_CREDENTIALS=$(echo "${GCS_CREDENTIALS:1:${#GCS_CREDENTIALS}-2}")

  return 0
}

function ccloud::validate_credentials_az() {
  AZBLOB_STORAGE_ACCOUNT=$1
  AZBLOB_CONTAINER=$2

  if [[ -z "$AZBLOB_STORAGE_ACCOUNT" || -z "$AZBLOB_CONTAINER" ]]; then
    echo "ERROR: DESTINATION_STORAGE=az, but AZBLOB_STORAGE_ACCOUNT or AZBLOB_CONTAINER is not set.  Please set these parameters in config/demo.cfg and try again."
    exit 1
  fi

  if [[ "$AZBLOB_STORAGE_ACCOUNT" == "default" ]]; then
    echo "ERROR: Azure Blob storage account name cannot be 'default'. Verify the value of the storage account name (did you create one?) in config/demo.cfg, as specified by the parameter AZBLOB_STORAGE_ACCOUNT, and try again."
    exit 1
  fi

  exists=$(az storage account check-name --name $AZBLOB_STORAGE_ACCOUNT | jq -r .reason)
  if [[ "$exists" != "AlreadyExists" ]]; then
    echo "ERROR: Azure Blob storage account name $AZBLOB_STORAGE_ACCOUNT does not exist. Check the value of AZBLOB_STORAGE_ACCOUNT in config/demo.cfg and try again."
    exit 1
  fi
  export AZBLOB_ACCOUNT_KEY=$(az storage account keys list --account-name $AZBLOB_STORAGE_ACCOUNT | jq -r '.[0].value')
  if [[ "$AZBLOB_ACCOUNT_KEY" == "" ]]; then
    echo "ERROR: Cannot get the key for Azure Blob storage account name $AZBLOB_STORAGE_ACCOUNT. Check the value of AZBLOB_STORAGE_ACCOUNT in config/demo.cfg, and your key, and try again."
    exit 1
  fi

  return 0
}

function ccloud::validate_credentials_s3() {
  S3_PROFILE=$1
  S3_BUCKET=$2

  if [[ -z "$S3_PROFILE" || -z "$S3_BUCKET" ]]; then
    echo "ERROR: DESTINATION_STORAGE=s3, but S3_PROFILE or S3_BUCKET is not set.  Please set these parameters in config/demo.cfg and try again."
    exit 1
  fi

  aws configure get aws_access_key_id --profile $S3_PROFILE 1>/dev/null || {
    echo "ERROR: Cannot determine aws_access_key_id from S3_PROFILE=$S3_PROFILE.  Verify your credentials and try again."
    exit 1
  }
  aws configure get aws_secret_access_key --profile $S3_PROFILE 1>/dev/null || {
    echo "ERROR: Cannot determine aws_secret_access_key from S3_PROFILE=$S3_PROFILE.  Verify your credentials and try again."
    exit 1
  }
  return 0
}

function ccloud::validate_schema_registry_up() {
  auth=$1
  sr_endpoint=$2

  curl --silent -u $auth $sr_endpoint > /dev/null || {
    echo "ERROR: Could not validate credentials to Confluent Cloud Schema Registry. Please troubleshoot"
    exit 1
  }

  echo "Validated credentials to Confluent Cloud Schema Registry at $sr_endpoint"
  return 0
}

function ccloud::get_environment_id_from_service_id() {
  SERVICE_ACCOUNT_ID=$1

  ENVIRONMENT_NAME_PREFIX=${ENVIRONMENT_NAME_PREFIX:-"pg-${USER}-$$SERVICE_ACCOUNT_ID"}
  local environment_id=$(confluent environment list -o json | jq -r 'map(select(.name | startswith("'"$ENVIRONMENT_NAME_PREFIX"'"))) | .[].id')

  echo $environment_id

  return 0
}

function ccloud::create_and_use_environment() {
  ENVIRONMENT_NAME=$1

  OUTPUT=$(confluent environment create $ENVIRONMENT_NAME --governance-package essentials -o json)
  (($? != 0)) && { echo "ERROR: Failed to create environment $ENVIRONMENT_NAME. Please troubleshoot and run again"; exit 1; }
  ENVIRONMENT=$(echo "$OUTPUT" | jq -r ".id")
  confluent environment use $ENVIRONMENT &>/dev/null

  echo $ENVIRONMENT

  return 0
}

function ccloud::find_cluster() {
  CLUSTER_NAME=$1
  CLUSTER_CLOUD=$2
  CLUSTER_REGION=$3

  local FOUND_CLUSTER=$(confluent kafka cluster list -o json | jq -c -r '.[] | select((.name == "'"$CLUSTER_NAME"'") and (.cloud == "'"$CLUSTER_CLOUD"'") and (.region == "'"$CLUSTER_REGION"'"))')
  [[ ! -z "$FOUND_CLUSTER" ]] && {
      echo "$FOUND_CLUSTER" | jq -r .id
      return 0
    } || {
      return 1
    }
}

function ccloud::create_and_use_cluster() {
  CLUSTER_NAME=$1
  CLUSTER_CLOUD=$2
  CLUSTER_REGION=$3
  CLUSTER_TYPE=$4

  OUTPUT=$(confluent kafka cluster create "$CLUSTER_NAME" --cloud $CLUSTER_CLOUD --region $CLUSTER_REGION --type $CLUSTER_TYPE --output json 2>&1)
  (($? != 0)) && { echo "$OUTPUT"; exit 1; }
  CLUSTER=$(echo "$OUTPUT" | jq -r .id)
  confluent kafka cluster use $CLUSTER 2>/dev/null

  # Wait until the cluster status is not PROVISIONING
  while true; do
    CLUSTER_STATUS=$(confluent kafka cluster describe $CLUSTER --output json | jq -r .status)
    if [ "$CLUSTER_STATUS" != "PROVISIONING" ]; then
      break
    fi
    sleep 5
  done

  echo $CLUSTER
  return 0
}

function ccloud::maybe_create_and_use_cluster() {
  CLUSTER_NAME=$1
  CLUSTER_CLOUD=$2
  CLUSTER_REGION=$3
  CLUSTER_TYPE=$4
  CLUSTER_ID=$(ccloud::find_cluster $CLUSTER_NAME $CLUSTER_CLOUD $CLUSTER_REGION)
  if [ $? -eq 0 ]
  then
    confluent kafka cluster use $CLUSTER_ID
    echo $CLUSTER_ID
  else

    # VINC: added
    if [[ ! -z "$CLUSTER_CREDS" ]]
    then
      echo "ERROR: Could not find your $CLUSTER_CLOUD cluster $CLUSTER_NAME in region $CLUSTER_REGION"
      echo "Make sure CLUSTER_CLOUD and CLUSTER_REGION are set with values that correspond to your cluster!"
      exit 1
    else
      OUTPUT=$(ccloud::create_and_use_cluster "$CLUSTER_NAME" "$CLUSTER_CLOUD" "$CLUSTER_REGION" "$CLUSTER_TYPE")
      (($? != 0)) && { echo "$OUTPUT"; exit 1; }
      echo "$OUTPUT"
    fi
  fi

  return 0
}

function ccloud::create_service_account() {
  SERVICE_NAME=$1

  CCLOUD_EMAIL=$(confluent prompt -f '%u')
  OUTPUT=$(confluent iam service-account create $SERVICE_NAME --description "SA for $EXAMPLE run by $CCLOUD_EMAIL"  -o json)
  SERVICE_ACCOUNT_ID=$(echo "$OUTPUT" | jq -r ".id")

  echo $SERVICE_ACCOUNT_ID

  return 0
}

function ccloud:get_service_account_from_current_cluster_name() {
  SERVICE_ACCOUNT_ID=$(confluent kafka cluster describe -o json | jq -r '.name' | awk -F'-' '{print $3 "-" $4;}')

  echo $SERVICE_ACCOUNT_ID

  return 0
}

function ccloud::get_schema_registry() {
  OUTPUT=$(confluent schema-registry cluster describe -o json)
  SCHEMA_REGISTRY=$(echo "$OUTPUT" | jq -r ".cluster")

  echo $SCHEMA_REGISTRY

  return 0
}

function ccloud::find_credentials_resource() {
  SERVICE_ACCOUNT_ID=$1
  RESOURCE=$2
  local FOUND_CRED=$(confluent api-key list -o json | jq -c -r 'map(select((.resource_id == "'"$RESOURCE"'") and (.owner_resource_id == "'"$SERVICE_ACCOUNT_ID"'")))')
  local FOUND_COUNT=$(echo "$FOUND_CRED" | jq 'length')
  [[ $FOUND_COUNT -ne 0 ]] && {
      echo "$FOUND_CRED" | jq -r '.[0].api_key'
      return 0
    } || {
      return 1
    }
}
function ccloud::create_credentials_resource() {
  SERVICE_ACCOUNT_ID=$1
  RESOURCE=$2

  OUTPUT=$(confluent api-key create --service-account $SERVICE_ACCOUNT_ID --resource $RESOURCE -o json)
  API_KEY_SA=$(echo "$OUTPUT" | jq -r ".api_key")
  API_SECRET_SA=$(echo "$OUTPUT" | jq -r ".api_secret")
  echo "${API_KEY_SA}:${API_SECRET_SA}"

  # vinc
  sleep 30
  return 0
}
# The return from this function will be a colon ':' delimited
#   list, if the api-key is created the second element of the
#   list will be the secret.  If the api-key is being reused
#   the second element of the list will be empty
function ccloud::maybe_create_credentials_resource() {
  SERVICE_ACCOUNT_ID=$1
  RESOURCE=$2

  local KEY=$(ccloud::find_credentials_resource $SERVICE_ACCOUNT_ID $RESOURCE)
  [[ -z $KEY ]] && {
    ccloud::create_credentials_resource $SERVICE_ACCOUNT_ID $RESOURCE
  } || {
    echo "$KEY:"; # the secret cannot be retrieved from a found key, caller needs to handle this
    return 0
  }
}

function ccloud::find_ksqldb_app() {
  KSQLDB_NAME=$1
  CLUSTER=$2

  local FOUND_APP=$(confluent ksql cluster list -o json | jq -c -r 'map(select((.name == "'"$KSQLDB_NAME"'") and (.kafka == "'"$CLUSTER"'")))')
  local FOUND_COUNT=$(echo "$FOUND_APP" | jq 'length')
  [[ $FOUND_COUNT -ne 0 ]] && {
      echo "$FOUND_APP" | jq -r '.[].id'
      return 0
    } || {
      return 1
    }
}

function ccloud::create_ksqldb_app() {
  KSQLDB_NAME=$1
  CLUSTER=$2
  # colon deliminated credentials (APIKEY:APISECRET)
  local ksqlDB_kafka_creds=$3
  local kafka_api_key=$(echo $ksqlDB_kafka_creds | cut -d':' -f1)
  local kafka_api_secret=$(echo $ksqlDB_kafka_creds | cut -d':' -f2)

  KSQLDB=$(confluent ksql cluster create --cluster $CLUSTER --api-key "$kafka_api_key" --api-secret "$kafka_api_secret" --csu 1 -o json "$KSQLDB_NAME" | jq -r ".id")
  echo $KSQLDB

  return 0
}
function ccloud::maybe_create_ksqldb_app() {
  KSQLDB_NAME=$1
  CLUSTER=$2
  # colon deliminated credentials (APIKEY:APISECRET)
  local ksqlDB_kafka_creds=$3

  APP_ID=$(ccloud::find_ksqldb_app $KSQLDB_NAME $CLUSTER)
  if [ $? -eq 0 ]
  then
    echo $APP_ID
  else
    ccloud::create_ksqldb_app "$KSQLDB_NAME" "$CLUSTER" "$ksqlDB_kafka_creds"
  fi

  return 0
}

function ccloud::create_acls_all_resources_full_access() {
  SERVICE_ACCOUNT_ID=$1
  # Setting default QUIET=false to surface potential errors
  QUIET="${QUIET:-false}"
  [[ $QUIET == "true" ]] &&
    local REDIRECT_TO="/dev/null" ||
    local REDIRECT_TO="/dev/tty"

  confluent kafka acl create --allow --service-account $SERVICE_ACCOUNT_ID --operations CREATE,DELETE,WRITE,READ,DESCRIBE,DESCRIBE_CONFIGS --topic '*' &>"$REDIRECT_TO"

  confluent kafka acl create --allow --service-account $SERVICE_ACCOUNT_ID --operations READ,WRITE,CREATE,DESCRIBE --consumer-group '*' &>"$REDIRECT_TO"

  confluent kafka acl create --allow --service-account $SERVICE_ACCOUNT_ID --operations DESCRIBE,WRITE --transactional-id '*' &>"$REDIRECT_TO"

  confluent kafka acl create --allow --service-account $SERVICE_ACCOUNT_ID --operations IDEMPOTENT-WRITE,DESCRIBE --cluster-scope &>"$REDIRECT_TO"

  return 0
}

function ccloud::delete_acls_ccloud_stack() {
  SERVICE_ACCOUNT_ID=$1
  # Setting default QUIET=false to surface potential errors
  QUIET="${QUIET:-false}"
  [[ $QUIET == "true" ]] &&
    local REDIRECT_TO="/dev/null" ||
    local REDIRECT_TO="/dev/tty"

  echo "Deleting ACLs for service account ID $SERVICE_ACCOUNT_ID"

  confluent kafka acl delete --allow --service-account $SERVICE_ACCOUNT_ID --operations CREATE,DELETE,WRITE,READ,DESCRIBE,DESCRIBE_CONFIGS --topic '*' &>"$REDIRECT_TO"

  confluent kafka acl delete --allow --service-account $SERVICE_ACCOUNT_ID --operations READ,WRITE,CREATE,DESCRIBE --consumer-group '*' &>"$REDIRECT_TO"

  confluent kafka acl delete --allow --service-account $SERVICE_ACCOUNT_ID --operations DESCRIBE,WRITE --transactional-id '*' &>"$REDIRECT_TO"

  confluent kafka acl delete --allow --service-account $SERVICE_ACCOUNT_ID --operations IDEMPOTENT-WRITE,DESCRIBE --cluster-scope &>"$REDIRECT_TO"

  return 0
}

function ccloud::validate_ccloud_config() {
  [ -z "$1" ] && {
    echo "ccloud::validate_ccloud_config expects one parameter (configuration file with Confluent Cloud connection information)"
    exit 1
  }

  local cfg_file="$1"
  local bootstrap=$(grep "bootstrap\.servers" "$cfg_file" | cut -d'=' -f2-)
  [ -z "$bootstrap" ] && {
    echo "ERROR: Cannot read the 'bootstrap.servers' key-value pair from $cfg_file."
    exit 1;
  }
  return 0;
}

function ccloud::validate_ksqldb_up() {
  [ -z "$1" ] && {
    echo "ccloud::validate_ksqldb_up expects one parameter (ksqldb endpoint)"
    exit 1
  }

  [ $# -gt 1 ] && echo "WARN: ccloud::validate_ksqldb_up function expects one parameter"

  local ksqldb_endpoint=$1

  ccloud::validate_logged_in_cli || exit 1

  local ksqldb_meta=$(confluent ksql cluster list -o json | jq -r 'map(select(.endpoint == "'"$ksqldb_endpoint"'")) | .[]')

  local ksqldb_appid=$(echo "$ksqldb_meta" | jq -r '.id')
  if [[ "$ksqldb_appid" == "" ]]; then
    echo "ERROR: Confluent Cloud ksqlDB endpoint $ksqldb_endpoint is not found. Provision a ksqlDB cluster via the Confluent Cloud UI and add the configuration parameter ksql.endpoint and ksql.basic.auth.user.info into your Confluent Cloud configuration file at $ccloud_config_file and try again."
    exit 1
  fi

  local ksqldb_status=$(echo "$ksqldb_meta" | jq -r '.status')
  if [[ $ksqldb_status != "UP" ]]; then
    echo "ERROR: Confluent Cloud ksqlDB endpoint $ksqldb_endpoint with id $ksqlDBAppId is not in UP state. Troubleshoot and try again."
    exit 1
  fi

  return 0
}

function ccloud::validate_azure_account() {
  AZBLOB_STORAGE_ACCOUNT=$1

  if [[ "$AZBLOB_STORAGE_ACCOUNT" == "default" ]]; then
    echo "ERROR: Azure Blob storage account name cannot be 'default'. Verify the value of the storage account name (did you create one?) in config/demo.cfg, as specified by the parameter AZBLOB_STORAGE_ACCOUNT, and try again."
    exit 1
  fi

  exists=$(az storage account check-name --name $AZBLOB_STORAGE_ACCOUNT | jq -r .reason)
  if [[ "$exists" != "AlreadyExists" ]]; then
    echo "ERROR: Azure Blob storage account name $AZBLOB_STORAGE_ACCOUNT does not exist. Check the value of STORAGE_PROFILE in config/demo.cfg and try again."
    exit 1
  fi
  export AZBLOB_ACCOUNT_KEY=$(az storage account keys list --account-name $AZBLOB_STORAGE_ACCOUNT | jq -r '.[0].value')
  if [[ "$AZBLOB_ACCOUNT_KEY" == "" ]]; then
    echo "ERROR: Cannot get the key for Azure Blob storage account name $AZBLOB_STORAGE_ACCOUNT. Check the value of STORAGE_PROFILE in config/demo.cfg, and your key, and try again."
    exit 1
  fi

  return 0
}

function ccloud::validate_credentials_ksqldb() {
  ksqldb_endpoint=$1
  ccloud_config_file=$2
  credentials=$3

  response=$(curl ${ksqldb_endpoint}/info \
             -H "Content-Type: application/vnd.ksql.v1+json; charset=utf-8" \
             --silent \
             -u $credentials)
  if [[ "$response" =~ "Unauthorized" ]]; then
    echo "ERROR: Authorization failed to the ksqlDB cluster. Check your ksqlDB credentials set in the configuration parameter ksql.basic.auth.user.info in your Confluent Cloud configuration file at $ccloud_config_file and try again."
    exit 1
  fi

  echo "Validated credentials to Confluent Cloud ksqlDB at $ksqldb_endpoint"
  return 0
}

function ccloud::create_connector() {
  file=$1

  echo -e "\nCreating connector from $file\n"

  # About the Confluent CLI command 'confluent connect cluster create':
  # - Typical usage of this CLI would be 'confluent connect cluster create --config-file <filename>'
  # - However, in this example, the connector's configuration file contains parameters that need to be first substituted
  #   so the CLI command includes eval and heredoc.
  # - The '-vvv' is added for verbose output
  confluent connect cluster create -vvv --config <(eval "cat <<EOF
$(<$file)
EOF
")
  if [[ $? != 0 ]]; then
    echo "ERROR: Exit status was not 0 while creating connector from $file.  Please troubleshoot and try again"
    exit 1
  fi

  return 0
}

function ccloud::validate_connector_up() {
  confluent connect cluster list -o json | jq -e 'map(select(.name == "'"$1"'" and .status == "RUNNING")) | .[]' > /dev/null 2>&1
}

function ccloud::wait_for_connector_up() {
  connectorName=$1
  maxWait=$2

  echo "Waiting up to $maxWait seconds for connector $filename ($connectorName) to be RUNNING"
  ccloud::retry $maxWait ccloud::validate_connector_up $connectorName || exit 1
  echo "Connector $filename ($connectorName) is RUNNING"

  return 0
}

function ccloud::validate_ccloud_ksqldb_endpoint_ready() {
  KSQLDB_ENDPOINT=$1

  STATUS=$(confluent ksql cluster list -o json | jq -r 'map(select(.endpoint == "'"$KSQLDB_ENDPOINT"'")) | .[].status' | grep UP)
  if [[ "$STATUS" == "" ]]; then
    return 1
  fi

  return 0
}

function ccloud::validate_ccloud_cluster_ready() {
  confluent kafka topic list --cluster "$CLUSTER" #&>/dev/null
  return $?
}

function ccloud::validate_topic_exists() {
  topic=$1

  confluent kafka topic describe $topic &>/dev/null
  return $?
}

function ccloud::validate_subject_exists() {
  subject=$1
  sr_url=$2
  sr_credentials=$3

  curl --silent -u $sr_credentials $sr_url/subjects/$subject/versions/latest | jq -r ".subject" | grep $subject > /dev/null
  return $?
}

function ccloud::login_cli(){
  URL=$1
  EMAIL=$2
  PASSWORD=$3

  ccloud::validate_expect_installed

  echo -e "\n# Login"
  OUTPUT=$(
  expect <<END
    log_user 1
    spawn confluent login --url $URL --prompt -vvvv
    expect "Email: "
    send "$EMAIL\r";
    expect "Password: "
    send "$PASSWORD\r";
    expect "Logged in as "
    set result $expect_out(buffer)
END
  )
  echo "$OUTPUT"
  if [[ ! "$OUTPUT" =~ "Logged in as" ]]; then
    echo "Failed to log into your cluster. Please check all parameters and run again."
  fi

  return 0
}

function ccloud::get_service_account() {

  [ -z "$1" ] && {
    echo "ccloud::get_service_account expects one parameter (API Key)"
    exit 1
  }

  [ $# -gt 1 ] && echo "WARN: ccloud::get_service_account function expects one parameter, received two"

  local key="$1"

  serviceAccount=$(confluent api-key list -o json | jq -r -c 'map(select((.api_key == "'"$key"'"))) | .[].owner_resource_id')
  if [[ "$serviceAccount" == "" ]]; then
    echo "ERROR: Could not associate key $key to a service account. Verify your credentials, ensure the API key has a set resource type, and try again."
    exit 1
  fi
  if ! [[ "$serviceAccount" =~ ^sa-[a-z0-9]+$ ]]; then
    echo "ERROR: $serviceAccount value is not a valid value for a service account. Verify your credentials, ensure the API key has a set resource type, and try again."
    exit 1
  fi

  echo "$serviceAccount"

  return 0
}

function ccloud::create_acls_connector() {
  serviceAccount=$1

  confluent kafka acl create --allow --service-account $serviceAccount --operations DESCRIBE --cluster-scope
  confluent kafka acl create --allow --service-account $serviceAccount --operations CREATE,WRITE --prefix --topic dlq-lcc
  confluent kafka acl create --allow --service-account $serviceAccount --operations READ --prefix --consumer-group connect-lcc

  return 0
}

function ccloud::create_acls_control_center() {
  serviceAccount=$1

  echo "Confluent Control Center: creating _confluent-command and ACLs for service account $serviceAccount"
  confluent kafka topic create _confluent-command --partitions 1

  confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ,CREATE --topic _confluent --prefix

  confluent kafka acl create --allow --service-account $serviceAccount --operations READ,WRITE,CREATE --consumer-group _confluent --prefix

  return 0
}

function ccloud::create_acls_replicator() {
  serviceAccount=$1
  topic=$2

  confluent kafka acl create --allow --service-account $serviceAccount --operations CREATE,WRITE,READ,DESCRIBE,DESCRIBE_CONFIGS,ALTER-CONFIGS,DESCRIBE --topic $topic

  return 0
}

function ccloud::create_acls_connect_topics() {
  serviceAccount=$1

  echo "Connect: creating topics and ACLs for service account $serviceAccount"

  TOPIC=connect-demo-configs
  confluent kafka topic create $TOPIC --partitions 1 --config "cleanup.policy=compact"
  confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ --topic $TOPIC --prefix

  TOPIC=connect-demo-offsets
  confluent kafka topic create $TOPIC --partitions 6 --config "cleanup.policy=compact"
  confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ --topic $TOPIC --prefix

  TOPIC=connect-demo-statuses
  confluent kafka topic create $TOPIC --partitions 3 --config "cleanup.policy=compact"
  confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ  --topic $TOPIC --prefix

  for TOPIC in _confluent-monitoring _confluent-command ; do
    confluent kafka topic create $TOPIC --partitions 1 &>/dev/null
    confluent kafka acl create --allow --service-account $serviceAccount --operations WRITE,READ  --topic $TOPIC --prefix
  done

  confluent kafka acl create --allow --service-account $serviceAccount --operations READ --consumer-group connect-cloud

  echo "Connectors: creating topics and ACLs for service account $serviceAccount"
  confluent kafka acl create --allow --service-account $serviceAccount --operations READ --consumer-group connect-replicator
  confluent kafka acl create --allow --service-account $serviceAccount --operations DESCRIBE --cluster-scope

  return 0
}

function ccloud::validate_ccloud_stack_up() {
  CLOUD_KEY=$1
  CCLOUD_CONFIG_FILE=$2
  enable_ksqldb=$3

  if [ -z "$enable_ksqldb" ]; then
    enable_ksqldb=true
  fi

  ccloud::validate_environment_set || exit 1
  ccloud::set_kafka_cluster_use_from_api_key "$CLOUD_KEY" || exit 1
  ccloud::validate_schema_registry_up "$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" "$SCHEMA_REGISTRY_URL" || exit 1
  if $enable_ksqldb ; then
    ccloud::validate_ksqldb_up "$KSQLDB_ENDPOINT" || exit 1
    ccloud::validate_credentials_ksqldb "$KSQLDB_ENDPOINT" "$CCLOUD_CONFIG_FILE" "$KSQLDB_BASIC_AUTH_USER_INFO" || exit 1
  fi
}

function ccloud::validate_environment_set() {
  confluent environment list | grep '*' &>/dev/null || {
    echo "ERROR: could not determine if environment is set. Run 'confluent environment list' and set 'confluent environment use' and try again"
    exit 1
  }

  return 0
}

function ccloud::set_kafka_cluster_use_from_api_key() {
  [ -z "$1" ] && {
    echo "ccloud::set_kafka_cluster_use_from_api_key expects one parameter (API Key)"
    exit 1
  }

  [ $# -gt 1 ] && echo "WARN: ccloud::set_kafka_cluster_use_from_api_key function expects one parameter, received two"

  local key="$1"

  local kafkaCluster=$(confluent api-key list -o json | jq -r -c 'map(select((.api_key == "'"$key"'" and .resource_type == "kafka"))) | .[].resource_id')
  if [[ "$kafkaCluster" == "" ]]; then
    echo "ERROR: Could not associate key $key to a Confluent Cloud Kafka cluster. Verify your credentials, ensure the API key has a set resource type, and try again."
    exit 1
  fi

  confluent kafka cluster use $kafkaCluster
  local endpoint=$(confluent kafka cluster describe $kafkaCluster -o json | jq -r ".endpoint" | cut -c 12-)
  echo -e "\nAssociated key $key to Confluent Cloud Kafka cluster $kafkaCluster at $endpoint"

  return 0
}

# Deprecated 10/28/2020, use ccloud::set_kafka_cluster_use_from_api_key
function ccloud::set_kafka_cluster_use() {
  echo "WARN: set_kafka_cluster_use is deprecated, use ccloud::set_kafka_cluster_use_from_api_key"
  ccloud::set_kafka_cluster_use_from_api_key "$@"
}

#
# ccloud-stack documentation:
# https://docs.confluent.io/platform/current/tutorials/examples/ccloud/docs/ccloud-stack.html
#
function ccloud::create_ccloud_stack() {
  ccloud::validate_version_cli $CLI_MIN_VERSION || exit 1
  QUIET="${QUIET:-false}"
  REPLICATION_FACTOR=${REPLICATION_FACTOR:-3}
  enable_ksqldb=${1:-false}
  EXAMPLE=${EXAMPLE:-ccloud-stack-function}
  CHECK_CREDIT_CARD="${CHECK_CREDIT_CARD:-false}"

  # Check if credit card is on file, which is required for cluster creation
  if $CHECK_CREDIT_CARD && [[ $(confluent admin payment describe) =~ "not found" ]]; then
    echo "ERROR: No credit card on file. Add a payment method and try again."
    echo "If you are using a cloud provider's Marketplace, see documentation for a workaround: https://docs.confluent.io/platform/current/tutorials/examples/ccloud/docs/ccloud-stack.html#running-with-marketplace"
    exit 1
  fi

  # VINC: added
  if [[ -z "$CLUSTER_CREDS" ]]
  then
    if [[ -z "$SERVICE_ACCOUNT_ID" ]]; then
      # Service Account is not received so it will be created
      local RANDOM_NUM=$((1 + RANDOM % 1000000))
      SERVICE_NAME=${SERVICE_NAME:-"pg-${USER}-app-$RANDOM_NUM"}
      SERVICE_ACCOUNT_ID=$(ccloud::create_service_account $SERVICE_NAME)
    fi

    if [[ "$SERVICE_NAME" == "" ]]; then
      echo "ERROR: SERVICE_NAME is not defined. If you are providing the SERVICE_ACCOUNT_ID to this function please also provide the SERVICE_NAME"
      exit 1
    fi

    echo "Creating Confluent Cloud stack for service account $SERVICE_NAME, ID: $SERVICE_ACCOUNT_ID."
  fi

  if [[ -z "$ENVIRONMENT" ]];
  then
    # Environment is not received so it will be created
    MAX_LENGTH=64
    ENVIRONMENT_NAME=${ENVIRONMENT_NAME:-"pg-${USER}-$SERVICE_ACCOUNT_ID-$EXAMPLE"}
    if [ ${#ENVIRONMENT_NAME} -gt $MAX_LENGTH ]
    then
      ENVIRONMENT_NAME=$(echo $ENVIRONMENT_NAME | cut -c 1-$MAX_LENGTH)
    fi

    ENVIRONMENT=$(ccloud::create_and_use_environment $ENVIRONMENT_NAME)
    (($? != 0)) && { echo "$ENVIRONMENT"; exit 1; }
  else
    confluent environment use $ENVIRONMENT || exit 1
  fi

  CLUSTER_NAME=${CLUSTER_NAME:-"pg-${USER}-cluster-$SERVICE_ACCOUNT_ID"}
  CLUSTER_CLOUD="${CLUSTER_CLOUD:-aws}"
  CLUSTER_REGION="${CLUSTER_REGION:-us-west-2}"
  CLUSTER_TYPE="${CLUSTER_TYPE:-basic}"
  CLUSTER=$(ccloud::maybe_create_and_use_cluster "$CLUSTER_NAME" $CLUSTER_CLOUD $CLUSTER_REGION $CLUSTER_TYPE)
  (($? != 0)) && { echo "$CLUSTER"; exit 1; }
  if [[ "$CLUSTER" == "" ]] ; then
    echo "Kafka cluster id is empty"
    echo "ERROR: Could not create cluster. Please troubleshoot."
    exit 1
  fi

  endpoint=$(confluent kafka cluster describe $CLUSTER -o json | jq -r ".endpoint")
  if [[ $endpoint == "SASL_SSL://"* ]]
  then
    BOOTSTRAP_SERVERS=$(echo "$endpoint" | cut -c 12-)
  else
    BOOTSTRAP_SERVERS="$endpoint"
  fi

  NEED_ACLS=0
  NEED_SR_PERMISSION=0
  # VINC: added
  if [[ -z "$CLUSTER_CREDS" ]]
  then
    CLUSTER_CREDS=$(ccloud::maybe_create_credentials_resource $SERVICE_ACCOUNT_ID $CLUSTER)
    NEED_ACLS=1
  fi

  MAX_WAIT=720
  confluent kafka cluster use $CLUSTER
  echo ""
  echo "Waiting up to $MAX_WAIT seconds for Confluent Cloud cluster $CLUSTER to be ready"
  ccloud::retry $MAX_WAIT ccloud::validate_ccloud_cluster_ready || exit 1

  # VINC: added
  if [[ $NEED_ACLS -eq 1 ]]
  then
    # Estimating another 80s wait still sometimes required
    WARMUP_TIME=${WARMUP_TIME:-80}
    echo "Sleeping an additional ${WARMUP_TIME} seconds to ensure propagation of all metadata"
    sleep $WARMUP_TIME

    ccloud::create_acls_all_resources_full_access $SERVICE_ACCOUNT_ID
  fi

  SCHEMA_REGISTRY=$(ccloud::get_schema_registry)

  # VINC: added
  if [[ -z "$SCHEMA_REGISTRY_CREDS" ]]
  then
    NEED_SR_PERMISSION=1
    if [[ -z "$SERVICE_ACCOUNT_ID" ]]; then
      # Service Account is not received so it will be created
      local RANDOM_NUM=$((1 + RANDOM % 1000000))
      SERVICE_NAME=${SERVICE_NAME:-"pg-${USER}-app-$RANDOM_NUM"}
      SERVICE_ACCOUNT_ID=$(ccloud::create_service_account $SERVICE_NAME)
    fi
    SCHEMA_REGISTRY_CREDS=$(ccloud::maybe_create_credentials_resource $SERVICE_ACCOUNT_ID $SCHEMA_REGISTRY)
  fi

  SCHEMA_REGISTRY_ENDPOINT=$(confluent schema-registry cluster describe -o json | jq -r ".endpoint_url")

  if [[ $NEED_ACLS -eq 1 ]] || [[ $NEED_SR_PERMISSION -eq 1 ]]
  then
    # VINC
    set +e
    if [ "$SERVICE_ACCOUNT_ID" != "" ]
    then
      log "Adding ResourceOwner RBAC role for all subjects"
      confluent iam rbac role-binding create --principal User:$SERVICE_ACCOUNT_ID --role ResourceOwner --environment $ENVIRONMENT --schema-registry-cluster $SCHEMA_REGISTRY --resource Subject:*
    fi
    set -e
  fi

  if $enable_ksqldb ; then
    KSQLDB_NAME=${KSQLDB_NAME:-"demo-ksqldb-$SERVICE_ACCOUNT_ID"}
    KSQLDB=$(ccloud::maybe_create_ksqldb_app "$KSQLDB_NAME" $CLUSTER "$CLUSTER_CREDS")
    KSQLDB_ENDPOINT=$(confluent ksql cluster describe $KSQLDB -o json | jq -r ".endpoint")
    KSQLDB_CREDS=$(ccloud::maybe_create_credentials_resource $SERVICE_ACCOUNT_ID $KSQLDB)
    confluent ksql cluster configure-acls $KSQLDB
  fi

  KAFKA_API_KEY=`echo $CLUSTER_CREDS | awk -F: '{print $1}'`
  KAFKA_API_SECRET=`echo $CLUSTER_CREDS | awk -F: '{print $2}'`
  # FIX THIS: added by me
  confluent api-key store "$KAFKA_API_KEY" "$KAFKA_API_SECRET" --resource ${CLUSTER} --force
  confluent api-key use $KAFKA_API_KEY --resource ${CLUSTER}

  if [[ -z "$SKIP_CONFIG_FILE_WRITE" ]]; then
    if [[ -z "$CCLOUD_CONFIG_FILE" ]]; then
      CCLOUD_CONFIG_FILE="/tmp/tmp.config"
    fi

    cat <<EOF > $CCLOUD_CONFIG_FILE
# --------------------------------------
# Confluent Cloud connection information
# --------------------------------------
# ENVIRONMENT ID: ${ENVIRONMENT}
# SERVICE ACCOUNT ID: ${SERVICE_ACCOUNT_ID}
# KAFKA CLUSTER ID: ${CLUSTER}
# SCHEMA REGISTRY CLUSTER ID: ${SCHEMA_REGISTRY}
EOF
    if $enable_ksqldb ; then
      cat <<EOF >> $CCLOUD_CONFIG_FILE
# KSQLDB APP ID: ${KSQLDB}
EOF
    fi
    cat <<EOF >> $CCLOUD_CONFIG_FILE
# --------------------------------------
sasl.mechanism=PLAIN
security.protocol=SASL_SSL
bootstrap.servers=${BOOTSTRAP_SERVERS}
sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='${KAFKA_API_KEY}' password='${KAFKA_API_SECRET}';
basic.auth.credentials.source=USER_INFO
schema.registry.url=${SCHEMA_REGISTRY_ENDPOINT}
basic.auth.user.info=`echo $SCHEMA_REGISTRY_CREDS | awk -F: '{print $1}'`:`echo $SCHEMA_REGISTRY_CREDS | awk -F: '{print $2}'`
replication.factor=${REPLICATION_FACTOR}
EOF
    if $enable_ksqldb ; then
      cat <<EOF >> $CCLOUD_CONFIG_FILE
ksql.endpoint=${KSQLDB_ENDPOINT}
ksql.basic.auth.user.info=`echo $KSQLDB_CREDS | awk -F: '{print $1}'`:`echo $KSQLDB_CREDS | awk -F: '{print $2}'`
EOF
    fi
  fi

  return 0
}

function ccloud::destroy_ccloud_stack() {
  if [ $# -eq 0 ];then
    echo "ccloud::destroy_ccloud_stack requires a single parameter, the service account id."
    exit 1
  fi

  SERVICE_ACCOUNT_ID=$1
  ENVIRONMENT=${ENVIRONMENT:-$(ccloud::get_environment_id_from_service_id $SERVICE_ACCOUNT_ID)}

  confluent environment use $ENVIRONMENT || exit 1

  PRESERVE_ENVIRONMENT="${PRESERVE_ENVIRONMENT:-false}"

  ENVIRONMENT_NAME_PREFIX=${ENVIRONMENT_NAME_PREFIX:-"pg-${USER}-$SERVICE_ACCOUNT_ID"}
  CLUSTER_NAME=${CLUSTER_NAME:-"pg-${USER}-cluster-$SERVICE_ACCOUNT_ID"}
  CCLOUD_CONFIG_FILE=${CCLOUD_CONFIG_FILE:-"/tmp/tmp.config"}
  KSQLDB_NAME=${KSQLDB_NAME:-"demo-ksqldb-$SERVICE_ACCOUNT_ID"}

  # Setting default QUIET=false to surface potential errors
  QUIET="${QUIET:-false}"
  [[ $QUIET == "true" ]] &&
    local REDIRECT_TO="/dev/null" ||
    local REDIRECT_TO="/dev/tty"

  echo "Destroying Confluent Cloud stack associated to service account id $SERVICE_ACCOUNT_ID"

  # Delete associated ACLs
  ccloud::delete_acls_ccloud_stack $SERVICE_ACCOUNT_ID

  ksqldb_id_found=$(confluent ksql cluster list -o json | jq -r 'map(select(.name == "'"$KSQLDB_NAME"'")) | .[].id')
  if [[ $ksqldb_id_found != "" ]]; then
    echo "Deleting KSQLDB: $KSQLDB_NAME : $ksqldb_id_found"
    confluent ksql cluster delete $ksqldb_id_found &> "$REDIRECT_TO"
  fi

  # Delete connectors associated to this Kafka cluster, otherwise cluster deletion fails
  local cluster_id=$(confluent kafka cluster list -o json | jq -r 'map(select(.name == "'"$CLUSTER_NAME"'")) | .[].id')
  confluent connect cluster list --cluster $cluster_id -o json | jq -r '.[].id' | xargs -I{} confluent connect cluster delete {} --force

  echo "Deleting CLUSTER: $CLUSTER_NAME : $cluster_id"
  confluent kafka cluster delete $cluster_id &> "$REDIRECT_TO"

  # Delete API keys associated to the service account
  confluent api-key list --service-account $SERVICE_ACCOUNT_ID -o json | jq -r '.[].api_key' | xargs -I{} confluent api-key delete {} --force

  # Delete service account
  confluent iam service-account delete $SERVICE_ACCOUNT_ID --force &>"$REDIRECT_TO"

  if [[ $PRESERVE_ENVIRONMENT == "false" ]]; then
    local environment_id=$(confluent environment list -o json | jq -r 'map(select(.name | startswith("'"$ENVIRONMENT_NAME_PREFIX"'"))) | .[].id')
    if [[ "$environment_id" == "" ]]; then
      echo "WARNING: Could not find environment with name that starts with $ENVIRONMENT_NAME_PREFIX (did you create this ccloud-stack reusing an existing environment?)"
    else
      echo "Deleting ENVIRONMENT: prefix $ENVIRONMENT_NAME_PREFIX : $environment_id"
      confluent environment delete $environment_id &> "$REDIRECT_TO"
    fi
  fi

  rm -f $CCLOUD_CONFIG_FILE

  return 0
}

function ccloud::generate_configs() {
  CCLOUD_CONFIG_FILE=$1
  if [[ -z "$CCLOUD_CONFIG_FILE" ]]; then
    CCLOUD_CONFIG_FILE=~/.ccloud/config
  fi
  if [[ ! -f "$CCLOUD_CONFIG_FILE" ]]; then
    echo "File $CCLOUD_CONFIG_FILE is not found.  Please create this properties file to connect to your Confluent Cloud cluster and then try again"
    echo "See https://docs.confluent.io/current/cloud/connect/auto-generate-configs.html for more information"
    return 1
  fi

  # log "Generating component configurations"
  # log "(If you want to run any of these components to talk to Confluent Cloud, these are the configurations to add to the properties file for each component)"

  # Set permissions
  PERM=600
  if ls --version 2>/dev/null | grep -q 'coreutils' ; then
    # GNU binutils
    PERM=$(stat -c "%a" $CCLOUD_CONFIG_FILE)
  else
    # BSD
    PERM=$(stat -f "%OLp" $CCLOUD_CONFIG_FILE)
  fi

  # Make destination
  get_kafka_docker_playground_dir
  DEST=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud
  mkdir -p $DEST
  # Glean parameters from the Confluent Cloud configuration file

  # Kafka cluster
  BOOTSTRAP_SERVERS=$( grep "^bootstrap.server" $CCLOUD_CONFIG_FILE | awk -F'=' '{print $2;}' )
  BOOTSTRAP_SERVERS=${BOOTSTRAP_SERVERS/\\/}
  SASL_JAAS_CONFIG=$( grep "^sasl.jaas.config" $CCLOUD_CONFIG_FILE | cut -d'=' -f2- )
  SASL_JAAS_CONFIG_PROPERTY_FORMAT=${SASL_JAAS_CONFIG/username\\=/username=}
  SASL_JAAS_CONFIG_PROPERTY_FORMAT=${SASL_JAAS_CONFIG_PROPERTY_FORMAT/password\\=/password=}
  CLOUD_KEY=$( echo $SASL_JAAS_CONFIG | awk '{print $3}' | awk -F"'" '$0=$2' )
  CLOUD_SECRET=$( echo $SASL_JAAS_CONFIG | awk '{print $4}' | awk -F"'" '$0=$2' )

  # Schema Registry
  BASIC_AUTH_CREDENTIALS_SOURCE=$( grep "^basic.auth.credentials.source" $CCLOUD_CONFIG_FILE | awk -F'=' '{print $2;}' )
  SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO=$( grep "^basic.auth.user.info" $CCLOUD_CONFIG_FILE | awk -F'=' '{print $2;}' )
  SCHEMA_REGISTRY_URL=$( grep "^schema.registry.url" $CCLOUD_CONFIG_FILE | awk -F'=' '{print $2;}' )

  # ksqlDB
  KSQLDB_ENDPOINT=$( grep "^ksql.endpoint" $CCLOUD_CONFIG_FILE | awk -F'=' '{print $2;}' )
  KSQLDB_BASIC_AUTH_USER_INFO=$( grep "^ksql.basic.auth.user.info" $CCLOUD_CONFIG_FILE | awk -F'=' '{print $2;}' )

  # AK command line tools
  AK_TOOLS_DELTA=$DEST/ak-tools-ccloud.delta
  #echo "$AK_TOOLS_DELTA"
  rm -f $AK_TOOLS_DELTA
  cp $CCLOUD_CONFIG_FILE $AK_TOOLS_DELTA
  chmod $PERM $AK_TOOLS_DELTA

  # librdkafka
  LIBRDKAFKA_CONFIG=$DEST/librdkafka.delta
  #echo "$LIBRDKAFKA_CONFIG"
  rm -f $LIBRDKAFKA_CONFIG

  cat <<EOF >> $LIBRDKAFKA_CONFIG
bootstrap.servers="$BOOTSTRAP_SERVERS"
security.protocol=SASL_SSL
sasl.mechanisms=PLAIN
sasl.username="$CLOUD_KEY"
sasl.password="$CLOUD_SECRET"
schema.registry.url="$SCHEMA_REGISTRY_URL"
basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO"
EOF
  chmod $PERM $LIBRDKAFKA_CONFIG

  # ENV
  get_kafka_docker_playground_dir
  DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta
  ENV_CONFIG=$DELTA_CONFIGS_ENV
  echo "$DELTA_CONFIGS_ENV"
  rm -f $DELTA_CONFIGS_ENV

  cat <<EOF >> $ENV_CONFIG
export BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS"
export SASL_JAAS_CONFIG="$SASL_JAAS_CONFIG"
export SASL_JAAS_CONFIG_PROPERTY_FORMAT="$SASL_JAAS_CONFIG_PROPERTY_FORMAT"
export REPLICATOR_SASL_JAAS_CONFIG="$REPLICATOR_SASL_JAAS_CONFIG"
export BASIC_AUTH_CREDENTIALS_SOURCE="$BASIC_AUTH_CREDENTIALS_SOURCE"
export SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO"
export SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL"
export CLOUD_KEY="$CLOUD_KEY"
export CLOUD_SECRET="$CLOUD_SECRET"
export KSQLDB_ENDPOINT="$KSQLDB_ENDPOINT"
export KSQLDB_BASIC_AUTH_USER_INFO="$KSQLDB_BASIC_AUTH_USER_INFO"
EOF
  chmod $PERM $ENV_CONFIG

  # GEMINI CLI
  GEMINI_MCP_CONFLUENT_CONFIG=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/.env
  echo "$GEMINI_MCP_CONFLUENT_CONFIG"
  rm -f $GEMINI_MCP_CONFLUENT_CONFIG

  SCHEMA_REGISTRY_API_KEY=$(echo $SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO | awk -F: '{print $1}')
  SCHEMA_REGISTRY_API_SECRET=$(echo $SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO | awk -F: '{print $2}')
  KAFKA_REST_ENDPOINT=$(confluent kafka cluster describe $CLUSTER -o json | jq -r ".rest_endpoint")

  if [ -z $CLOUD_API_KEY ]
  then
    logwarn "❌ environment variable CLOUD_API_KEY should be set to use MCP confluent server for Confluent Cloud"
    logwarn "Set it with Cloud API key, see https://docs.confluent.io/cloud/current/access-management/authenticate/api-keys/api-keys.html#cloud-cloud-api-keys"
  fi

  if [ -z $CLOUD_API_SECRET ]
  then
    logwarn "❌ environment variable CLOUD_API_SECRET should be set to use MCP confluent server for Confluent Cloud"
    logwarn "Set it with Cloud API secret, see https://docs.confluent.io/cloud/current/access-management/authenticate/api-keys/api-keys.html#cloud-cloud-api-keys"
  fi

  cat <<EOF >> $GEMINI_MCP_CONFLUENT_CONFIG
# .env file
BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS"
KAFKA_API_KEY="$CLOUD_KEY"
KAFKA_API_SECRET="$CLOUD_SECRET"
KAFKA_REST_ENDPOINT="$KAFKA_REST_ENDPOINT"
KAFKA_CLUSTER_ID="$CLUSTER"
KAFKA_ENV_ID="$ENVIRONMENT"
# FLINK_ENV_ID="env-..."
# FLINK_ORG_ID=""
# FLINK_REST_ENDPOINT="https://flink.us-east4.gcp.confluent.cloud"
# FLINK_ENV_NAME=""
# FLINK_DATABASE_NAME=""
# FLINK_API_KEY=""
# FLINK_API_SECRET=""
# FLINK_COMPUTE_POOL_ID="lfcp-..."
# TABLEFLOW_API_KEY=""
# TABLEFLOW_API_SECRET=""
CONFLUENT_CLOUD_API_KEY="$CLOUD_API_KEY"
CONFLUENT_CLOUD_API_SECRET="$CLOUD_API_SECRET"
CONFLUENT_CLOUD_REST_ENDPOINT="https://api.confluent.cloud"
SCHEMA_REGISTRY_API_KEY="$SCHEMA_REGISTRY_API_KEY"
SCHEMA_REGISTRY_API_SECRET="$SCHEMA_REGISTRY_API_SECRET"
SCHEMA_REGISTRY_ENDPOINT="$SCHEMA_REGISTRY_URL"
EOF
  chmod $PERM $GEMINI_MCP_CONFLUENT_CONFIG

  return 0
}

# These are some duplicate functions from
#  helper.sh to decouple the script files.  In
#  the future we can work to remove this
#  duplication if necessary
function ccloud::retry() {
    local -r -i max_wait="$1"; shift
    local -r cmd="$@"

    local -i sleep_interval=5
    local -i curr_wait=0

    until $cmd
    do
        if (( curr_wait >= max_wait ))
        then
            echo "ERROR: Failed after $curr_wait seconds. Please troubleshoot and run again."
            return 1
        else
            curr_wait=$((curr_wait+sleep_interval))
            sleep $sleep_interval
        fi
    done
}
function ccloud::version_gt() {
  test "$(printf '%s\n' "$@" | sort -V | head -n 1)" != "$1";
}

function check_arm64_support() {
  DIR="$1"
  DOCKER_COMPOSE_FILE="$2"
  set +e
  if [ "$(uname -m)" = "arm64" ]
  then
    test=$(echo "$DOCKER_COMPOSE_FILE" | awk -F"/" '{ print $(NF-2)"/"$(NF-1) }')
    base_folder=$(echo $test | cut -d "/" -f 1)
    base_test=$(echo $test | cut -d "/" -f 2)
    if [ "$base_folder" == "reproduction-models" ]
    then
      base_test=${base_test#*-}
    fi

    grep "${base_test}" ${DIR}/../../scripts/arm64-support-none.txt > /dev/null
    if [ $? = 0 ]
    then
        logerror "🖥️ This example is not working with ARM64 !"
        log "It is highly recommended to use 'playground ec2 command' (https://kafka-docker-playground.io/#/playground%20ec2) to run the example on ubuntu ec2 instance"
        log "You can also use gitpod https://gitpod.io/#https://github.com/vdesabou/kafka-docker-playground"
        log "Do you want to start the example anyway ?"
        check_if_continue
        return
    fi

    grep "${base_test}" ${DIR}/../../scripts/arm64-support-with-emulation.txt > /dev/null
    if [ $? = 0 ]
    then
        logwarn "🖥️ This example is working with ARM64 but requires emulation"
        return
    fi

    log "🖥️ This example should work natively with ARM64"
  fi
  set -e
}

function playground() {
  verbose_begin
  if [[ $(type -f playground 2>&1) =~ "not found" ]]
  then
    if [ -f ../../scripts/cli/playground ]
    then
      ../../scripts/cli/playground "$@"
    elif [ -f ../../../scripts/cli/playground ]
    then
      ../../../scripts/cli/playground "$@"
    else
      logerror "🔍 playground command not found, add it to your PATH https://kafka-docker-playground.io/#/cli?id=🦶-setup-path"
      exit 1
    fi
  else
    $(which playground) "$@"
  fi
  verbose_end
}

function force_enable () {
  flag=$1
  env_variable=$2

  logwarn "💪 Forcing $flag ($env_variable env variable)"
  line_final_source=$(grep -n 'source ${DIR}/../../scripts/utils.sh$' $test_file | cut -d ":" -f 1 | tail -n1)
  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
then
    trap 'rm -rf $tmp_dir' EXIT
else
    log "🐛📂 not deleting tmp dir $tmp_dir"
fi
  echo "# remove or comment those lines if you don't need it anymore" > $tmp_dir/tmp_force_enable
  echo "logwarn \"💪 Forcing $flag ($env_variable env variable) as it was set when reproduction model was created\"" >> $tmp_dir/tmp_force_enable
  echo "export $env_variable=true" >> $tmp_dir/tmp_force_enable
  cp $test_file $tmp_dir/tmp_file

  { head -n $(($line_final_source+1)) $tmp_dir/tmp_file; cat $tmp_dir/tmp_force_enable; tail -n  +$(($line_final_source+1)) $tmp_dir/tmp_file; } > $test_file
}

function load_env_variables () {
  for item in {ENABLE_CONTROL_CENTER,ENABLE_FLINK,ENABLE_KSQLDB,ENABLE_RESTPROXY,ENABLE_JMX_GRAFANA,ENABLE_KCAT,ENABLE_CONDUKTOR,SQL_DATAGEN,ENABLE_KAFKA_NODES,ENABLE_CONNECT_NODES}
  do
    i=$(playground state get "flags.${item}")
    if [ "$i" != "" ]
    then
      log "⛳ exporting environment variable ${item}"
      export "${item}"=1
    fi
  done
}

function get_connector_paths () {
    # determining the docker-compose file from from test_file
    docker_compose_file=""
    if [ -f "$test_file" ]
    then
      docker_compose_file=$(grep "start-environment" "$test_file" |  awk '{print $6}' | cut -d "/" -f 2 | cut -d '"' -f 1 | tail -n1 | xargs)
      test_file_directory="$(dirname "${test_file}")"
      docker_compose_file="${test_file_directory}/${docker_compose_file}"
    fi

    if [ "${docker_compose_file}" != "" ] && [ -f "${docker_compose_file}" ]
    then
      connector_paths=$(grep "CONNECT_PLUGIN_PATH" "${docker_compose_file}" | grep -v "KSQL_CONNECT_PLUGIN_PATH" | cut -d ":" -f 2  | tr -s " " | head -1)
    else
      echo ""
    fi
}

function generate_connector_versions () {
  get_connector_paths
  if [ "$connector_paths" == "" ]
  then
      return
  else
      connector_tags=""
      for connector_path in ${connector_paths//,/ }
      do
        full_connector_name=$(basename "$connector_path")
        owner=$(echo "$full_connector_name" | cut -d'-' -f1)
        name=$(echo "$full_connector_name" | cut -d'-' -f2-)

        if [ "$owner" == "java" ] || [ "$name" == "hub-components" ] || [ "$owner" == "filestream" ]
        then
          # happens when plugin is not coming from confluent hub
          continue
        fi

        playground connector-plugin versions --connector-plugin $owner/$name --force-refresh
      done
  fi
}

CONNECTOR_TYPE_FULLY_MANAGED="🌤️🤖fully managed"
CONNECTOR_TYPE_CUSTOM="🌤️🛃custom"
CONNECTOR_TYPE_SELF_MANAGED="⛈️👷self managed"
CONNECTOR_TYPE_ONPREM="🌎onprem"

EC2_INSTANCE_STATE_STOPPED="🛑stopped"
EC2_INSTANCE_STATE_RUNNING="✅running"
EC2_INSTANCE_STATE_STOPPING="⌛stopping"
EC2_INSTANCE_STATE_PENDING="⌛pending"

function get_connector_type () {
  get_connector_paths
  if [ "$connector_paths" == "" ]
  then
    if grep -q -e "fm-" <<< "$test_file"
    then
      echo "$CONNECTOR_TYPE_FULLY_MANAGED"
    elif grep -q -e "custom-connector" <<< "$test_file"
    then
      echo "$CONNECTOR_TYPE_CUSTOM"
    else
      echo ""
    fi
  else
    if grep -q -e "ccloud" <<< "$test_file"
    then
      echo "$CONNECTOR_TYPE_SELF_MANAGED"
    elif [[ -n "$environment" ]] && [ "$environment" == "ccloud" ]
    then
      echo "$CONNECTOR_TYPE_SELF_MANAGED"
    else
      echo "$CONNECTOR_TYPE_ONPREM"
    fi
  fi
}

function handle_ccloud_connect_rest_api () {
  curl_request="$1"
  get_ccloud_connect
  if [[ -n "$verbose" ]]
  then
    log "🐞 curl command used"
    echo "$curl_request"
  fi
  eval "curl_output=\$($curl_request)"
  ret=$?
  if [ $ret -eq 0 ]
  then
      if [ "$curl_output" == "[]" ]
      then
        # logerror "No connector running"
        # return 1
        echo ""
        return
      fi
      if echo "$curl_output" | jq 'if .error then .error | has("code") else has("error_code") end' 2> /dev/null | grep -q true
      then
        if echo "$curl_output" | jq '.error | has("code")' 2> /dev/null | grep -q true
        then
          code=$(echo "$curl_output" | jq -r .error.code)
          message=$(echo "$curl_output" | jq -r .error.message)
        else
          code=$(echo "$curl_output" | jq -r .error_code)
          message=$(echo "$curl_output" | jq -r .message)
        fi
        logerror "Command failed with error code $code"
        logerror "$message"
        return 1
      elif echo "$curl_output" | jq 'has("errors")' 2> /dev/null | grep -q true
      then
        code=$(echo "$curl_output" | jq -r '.errors[0].status')
        message=$(echo "$curl_output" | jq -r '.errors[0].detail')
        logerror "Command failed with error code $code"
        logerror "$message"
        return 1
      fi
  else
    logerror "❌ curl request failed with error code $ret!"
    return 1
  fi
}

function handle_onprem_connect_rest_api () {
  curl_request="$1"
  if [[ -n "$verbose" ]]
  then
    log "🐞 curl command used"
    echo "$curl_request"
  fi
  eval "curl_output=\$($curl_request)"
  ret=$?
  if [ $ret -eq 0 ]
  then
      if [ "$curl_output" == "[]" ]
      then
        # logerror "No connector running"
        # return 1
        echo ""
        return
      fi
      if echo "$curl_output" | jq '. | has("error_code")' 2> /dev/null | grep -q true

      then
        error_code=$(echo "$curl_output" | jq -r .error_code)
        message=$(echo "$curl_output" | jq -r .message)
        logerror "Command failed with error code $error_code"
        logerror "$message"
        return 1
      fi
  else
      logerror "❌ curl request failed with error code $ret!"
      return 1
  fi
}

function display_ngrok_warning () {
  if [ -z "$NGROK_AUTH_TOKEN" ]
  then
      logerror "NGROK_AUTH_TOKEN is not set. Export it as environment variable or pass it as argument"
      logerror "Sign up at: https://dashboard.ngrok.com/signup"
      logerror "If you have already signed up, make sure your authtoken is installed."
      logerror "Your authtoken is available on your dashboard: https://dashboard.ngrok.com/get-started/your-authtoken"
      exit 1
  fi

  if [ ! -z "$GITHUB_RUN_NUMBER" ]
  then
    test_file=$(playground state get run.test_file)

    DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
    dir1=$(echo ${DIR_CLI%/*})
    cli_folder=$(echo ${dir1%/*})

    # trick to use different ngrok token
    if [ ! -f $test_file ]
    then

      logerror "File $test_file retrieved from $cli_folder/../../playground.ini does not exist!"
      exit 1
    fi
    last_two_folders=$(basename $(dirname $(dirname $test_file)))/$(basename $(dirname $test_file))

    if grep "$last_two_folders" ${cli_folder}/../../.github/workflows/ci.yml | grep -q "2️⃣"
    then
      log "😋 Using NGROK_CI_AUTH_TOKEN_BACKUP"
      export NGROK_AUTH_TOKEN=$NGROK_CI_AUTH_TOKEN_BACKUP
    fi
  fi

  if [ "$USER" == "vsaboulin" ]
  then
    return
  fi
  check_if_continue
}

function login_and_maybe_set_azure_subscription () {

  if [ ! -z "$AZ_USER" ] && [ ! -z "$AZ_PASS" ]
  then
    log "🫐 Logging to Azure using environment variables AZ_USER and AZ_PASS "
    set +e
    az logout
    set -e
    az login -u "$AZ_USER" -p "$AZ_PASS" > /dev/null 2>&1
  else
    logerror "❌ AZ_USER and AZ_PASS environment variables are not set (for Confluent employees, that is simply your Confluent email address and Okta password)"
    exit 1
  fi

  # when AZURE_SUBSCRIPTION_NAME env var is set, we need to set the correct subscription
  if [ ! -z "$AZURE_SUBSCRIPTION_NAME" ]
  then
    log "💙 AZURE_SUBSCRIPTION_NAME ($AZURE_SUBSCRIPTION_NAME) is set, searching for subscription id..."
    if [ ! -z "$GITHUB_RUN_NUMBER" ]
    then
      az account list --query "[?name=='$AZURE_SUBSCRIPTION_NAME']" | jq -r '.[].id'
    fi
    subscriptionId=$(az account list --query "[?name=='$AZURE_SUBSCRIPTION_NAME']" | jq -r '.[].id')
    if [ -z "$GITHUB_RUN_NUMBER" ]
    then
      log "💙 setting up account to use subscription $AZURE_SUBSCRIPTION_NAME ($subscriptionId)"
    fi
    az account set --subscription $subscriptionId
  else
    # check if confluent employee, in that case enforce AZURE_SUBSCRIPTION_NAME
    userEmail=$(az account show | jq -r '.user.name')
    if [[ $userEmail == *"confluent.io"* ]]
    then
      logerror "🔒 Confluent employee detected, please set AZURE_SUBSCRIPTION_NAME environment variable to be sure to use correct subscription !"
      if [ -z "$GITHUB_RUN_NUMBER" ]
      then
        logerror "✨ Here is the list of subscriptions using az account list, please choose one accordingly (for GTS, it should be COPS)"
        az account list --query "[].{name:name, isDefault:isDefault, tenantId:tenantId}" | jq -r '.[] | "name: \(.name), isDefault: \(.isDefault), tenantId: \(.tenantId)"'
      fi
      exit 1
    fi

    default_subscription=$(az account list --query "[?isDefault].name" | jq -r '.[0]')
    log "💎 AZURE_SUBSCRIPTION_NAME is not set, using default subscription $default_subscription"
  fi
}

function handle_aws_credentials () {
  rm -rf /tmp/aws_credentials
  export AWS_CREDENTIALS_FILE_NAME="/tmp/aws_credentials"

  if [ -z "$AWS_SESSION_TOKEN" ]
  then
    if [ ! -f $HOME/.aws/credentials ] && ( [ -z "$AWS_ACCESS_KEY_ID" ] || [ -z "$AWS_SECRET_ACCESS_KEY" ] )
    then
      logerror "❌ either the file $HOME/.aws/credentials is not present or environment variables AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY are not set!"
      exit 1
    else
      if [ ! -z "$AWS_ACCESS_KEY_ID" ] && [ ! -z "$AWS_SECRET_ACCESS_KEY" ]
      then
          log "💭 Using environment variables AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY"
          export AWS_ACCESS_KEY_ID
          export AWS_SECRET_ACCESS_KEY
      else
          if [ -f $HOME/.aws/credentials ]
          then
              logwarn "💭 AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY are set based on $HOME/.aws/credentials"
              export AWS_ACCESS_KEY_ID=$( grep "^aws_access_key_id" $HOME/.aws/credentials | head -1 | awk -F'=' '{print $2;}' )
              export AWS_SECRET_ACCESS_KEY=$( grep "^aws_secret_access_key" $HOME/.aws/credentials | head -1 | awk -F'=' '{print $2;}' )

          fi
      fi

      cat << EOF > $AWS_CREDENTIALS_FILE_NAME
[default]
aws_access_key_id=$AWS_ACCESS_KEY_ID
aws_secret_access_key=$AWS_SECRET_ACCESS_KEY
EOF
      if [ -z "$AWS_REGION" ]
      then
          AWS_REGION=$(aws configure get region | tr '\r' '\n')
          if [ "$AWS_REGION" == "" ]
          then
              logerror "❌ either the file $HOME/.aws/config is not present or environment variables AWS_REGION is not set!"
              exit 1
          fi
      fi
    fi
  else
    if [ ! -z $AWS_PROFILE ] && [ -z "$AWS_SESSION_TOKEN" ]
    then
      logwarn "💭 AWS_PROFILE environment variable is set with $AWS_PROFILE"
      logwarn "🚀 run manually this command and re-run the example again:"
      echo "source <(aws configure export-credentials --profile $AWS_PROFILE --format env)"
      exit 1
    fi

    #
    # AWS short live credentials
    #
    if [ ! -z $AWS_SESSION_TOKEN ] || grep -q "aws_session_token" $HOME/.aws/credentials
    then
      if [ ! -z $AWS_SESSION_TOKEN ]
      then
          log "🔏 AWS_SESSION_TOKEN environment variable is set, using AWS short live credentials"
      else
          log "🔏 the file $HOME/.aws/credentials contains aws_session_token, using AWS short live credentials"
      fi

      connector_type=$(playground state get run.connector_type)

      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
        logerror "❌ AWS short live credentials are not supported for fully managed connectors or custom connectors"
        exit 1
      fi

      if [ ! -z $AWS_ACCESS_KEY_ID ] && [ ! -z "$AWS_SECRET_ACCESS_KEY" ] && [ ! -z "$AWS_SESSION_TOKEN" ]
      then
          log "💭 Using environment variables AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY and AWS_SESSION_TOKEN"
          export AWS_ACCESS_KEY_ID
          export AWS_SECRET_ACCESS_KEY
          export AWS_SESSION_TOKEN

      cat << EOF > $AWS_CREDENTIALS_FILE_NAME
[default]
aws_access_key_id=$AWS_ACCESS_KEY_ID
aws_secret_access_key=$AWS_SECRET_ACCESS_KEY
aws_session_token=$AWS_SESSION_TOKEN
EOF
      elif grep -q "aws_session_token" $HOME/.aws/credentials
      then
          head -4 $HOME/.aws/credentials > $AWS_CREDENTIALS_FILE_NAME

          set +e
          grep -q default $AWS_CREDENTIALS_FILE_NAME
          if [ $? != 0 ]
          then
              logerror "$HOME/.aws/credentials does not have expected format, the 4 first lines must be:"
              echo "[default]"
              echo "aws_access_key_id=<AWS_ACCESS_KEY_ID>"
              echo "aws_secret_access_key=<AWS_SECRET_ACCESS_KEY>"
              echo "aws_session_token=<AWS_SESSION_TOKEN>"
              exit 1
          fi
          grep -q aws_session_token $AWS_CREDENTIALS_FILE_NAME
          if [ $? != 0 ]
          then
              logerror "$HOME/.aws/credentials does not have expected format, the 4 first lines must be:"
              echo "[default]"
              echo "aws_access_key_id=<AWS_ACCESS_KEY_ID>"
              echo "aws_secret_access_key=<AWS_SECRET_ACCESS_KEY>"
              echo "aws_session_token=<AWS_SESSION_TOKEN>"
              exit 1
          fi
          set +e
      fi

      log "✨ Using AWS short live with credentials file $AWS_CREDENTIALS_FILE_NAME"
      export AWS_SHORT_LIVE_CREDENTIALS_USED=1
    else
      if [ ! -f $HOME/.aws/credentials ] && ( [ -z "$AWS_ACCESS_KEY_ID" ] || [ -z "$AWS_SECRET_ACCESS_KEY" ] )
      then
        logerror "❌ either the file $HOME/.aws/credentials is not present or environment variables AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY are not set!"
        exit 1
      fi
    fi
  fi

  if [ -z "$AWS_REGION" ]
  then
      AWS_REGION=$(aws configure get region | tr '\r' '\n')
      if [ "$AWS_REGION" == "" ]
      then
          logerror "❌ either the file $HOME/.aws/config is not present or environment variables AWS_REGION is not set!"
          exit 1
      fi
  fi

  if [[ "$TAG" == *ubi8 ]] || version_gt $TAG_BASE "5.9.0"
  then
      export CONNECT_CONTAINER_HOME_DIR="/home/appuser"
  else
      export CONNECT_CONTAINER_HOME_DIR="/root"
  fi
}

function wait_for_end_of_hibernation () {
     MAX_WAIT=600
     CUR_WAIT=0
     set +e
     log "⌛ Waiting up to $MAX_WAIT seconds for end of hibernation to happen (it can take several minutes)"
     curl -X POST "${SERVICENOW_URL}/api/now/table/incident" --user admin:"$SERVICENOW_PASSWORD" -H 'Accept: application/json' -H 'Content-Type: application/json' -H 'cache-control: no-cache' -d '{"short_description": "This is test"}' > /tmp/out.txt 2>&1
     while [[ $(cat /tmp/out.txt) =~ "Sign in to the site to wake your instance" ]] || ! [[ $(cat /tmp/out.txt) =~ "made_sla" ]]
     do
          sleep 10
          curl -X POST "${SERVICENOW_URL}/api/now/table/incident" --user admin:"$SERVICENOW_PASSWORD" -H 'Accept: application/json' -H 'Content-Type: application/json' -H 'cache-control: no-cache' -d '{"short_description": "This is test"}' > /tmp/out.txt 2>&1
          CUR_WAIT=$(( CUR_WAIT+10 ))
          if [[ "$CUR_WAIT" -gt "$MAX_WAIT" ]]; then
               echo -e "\nERROR: The logs still show 'Sign in to the site to wake your instance' after $MAX_WAIT seconds.\n"
               exit 1
          fi
     done
     log "The instance is ready !"
     set -e
}

function connect_cp_version_greater_than_8 () {
  if [ ! -z "$CP_CONNECT_TAG" ] && version_gt $CP_CONNECT_TAG "7.9.99"
  then
    return 0
  elif [ ! -z "$TAG_BASE" ] && version_gt $TAG_BASE "7.9.99"
  then
    return 0
  else
    return 1
  fi
}

# src/lib/validations/validate_date_format.sh
validate_date_format() {
  if [[ ! "$1" =~ ^[0-9]{4}-[0-9]{2}-[0-9]{2}$ ]]
  then
    logerror "must be in format yyyy-mm-dd"
    return
  fi

  if [[ "$OSTYPE" == "darwin"* ]]
  then
    # macOS: Validate the date format
    if ! date -j -f "%Y-%m-%d" "$1" &>/dev/null
    then
      logerror "must be a valid date"
      return
    fi
  else
    # Linux: Validate the date format
    if ! date -d "$1" &>/dev/null
    then
      logerror "must be a valid date"
      return
    fi
  fi

  return 0
}

# src/lib/validations/validate_dir_exists.sh
validate_dir_exists() {
  if [[ ! -d "$1" ]]; then
    logerror "must be an existing directory"
  fi
}

# src/lib/validations/validate_editor_exists.sh
validate_editor_exists() {
  local cmd="$1"
  if [[ $(type $cmd 2>&1) =~ "not found" ]]
  then
    logerror "this script requires $cmd. Please install $cmd and run again."
  fi
}

# src/lib/validations/validate_file_exists.sh
validate_file_exists() {
  file="$1"
  if [[ -f "$1" ]]; then
    return 0
  else
    logerror "<$file> does not correspond to the path of an existing file, please make sure to use absolute full path or correct relative path !"
    return
  fi
}

# src/lib/validations/validate_file_exists_and_avro.sh
validate_file_exists_and_avro() {
  file="$1"

  real_file=$file
  if [[ $file == *"@"* ]]
  then
    real_file=$(echo "$file" | cut -d "@" -f 2)
  fi

  if [[ -f "$real_file" ]]; then
    return 0
  else
    logerror "<$real_file> does not correspond to the path of an existing file, please make sure to use absolute full path or correct relative path !"
    return
  fi

  if [[ "$real_file" == *.avro ]]; then
    return 0
  else
    logerror "<$real_file> is not an Avro file. Please provide a file with .avro extension."
    return
  fi
}

# src/lib/validations/validate_file_exists_and_parquet.sh
validate_file_exists_and_parquet() {
  file="$1"

  real_file=$file
  if [[ $file == *"@"* ]]
  then
    real_file=$(echo "$file" | cut -d "@" -f 2)
  fi

  if [[ -f "$real_file" ]]; then
    return 0
  else
    logerror "<$real_file> does not correspond to the path of an existing file, please make sure to use absolute full path or correct relative path !"
    return
  fi

  if [[ "$real_file" == *.parquet ]]; then
    return 0
  else
    logerror "<$real_file> is not an Parquet file. Please provide a file with .parquet extension."
    return
  fi
}

# src/lib/validations/validate_file_exists_with_trick.sh
validate_file_exists_with_trick() {
  file="$1"

  real_file=$file
  if [[ $file == *"@"* ]]
  then
    real_file=$(echo "$file" | cut -d "@" -f 2)
  fi

  if [[ -f "$real_file" ]]; then
    return 0
  else
    logerror "<$real_file> does not correspond to the path of an existing file, please make sure to use absolute full path or correct relative path !"
    return
  fi
}

# src/lib/validations/validate_integer.sh
validate_integer() {
  if [[ "$1" == "-1" ]] || [[ "$1" =~ ^[0-9]+$ ]]
  then
    return 0
  else
    logerror "must be an integer"
    return
  fi
}

# src/lib/validations/validate_json.sh
validate_json() {

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  trap 'rm -rf $tmp_dir' EXIT
  json_file=$tmp_dir/connector.json

  echo "$1" > $json_file

  # JSON is invalid
  if ! echo "$1" | jq -e .  > /dev/null 2>&1
  then
      set +e
      jq_output=$(jq . "$json_file" 2>&1)
      error_line=$(echo "$jq_output" | grep -oE 'parse error.*at line [0-9]+' | grep -oE '[0-9]+')

      if [[ -n "$error_line" ]]; then
          logerror "❌ Invalid JSON at line $error_line"
      fi
      set -e

      if [ -z "$GITHUB_RUN_NUMBER" ]
      then
          if [[ $(type -f bat 2>&1) =~ "not found" ]]
          then
              cat -n $json_file
          else
              bat $json_file --highlight-line $error_line
          fi
      fi
      return
  fi
}

# src/lib/validations/validate_minimal_cp_version.sh
validate_minimal_cp_version() {
  version="$1"
  if ! version_gt $version "4.9.99"
  then
      logerror "CP version (--tag) must be > 5.0.0"
  fi
}

# src/lib/validations/validate_not_empty.sh
validate_not_empty() {
  if [[ -z "$1" ]]; then
    logerror "must not be empty"
  fi
}

# src/lib/validations/validate_percentage.sh
validate_percentage() {
  if [[ ! "$1" =~ ^[0-9]+$ ]]
  then
    logerror "must be an integer"
    return
  fi

  if [[ "$1" -lt 0 ]] || [[ "$1" -gt 100 ]]
  then
    logerror "must be between 0 and 100"
    return
  fi
}

# :command.command_functions
# :command.function
playground_help_command() {

  # src/commands/help.sh
  command="${args[command]}"
  long_usage=yes

  if [[ -z "$command" ]]; then
    # No command argument, show the global help
    help_function=playground_usage
  else
    # Show the help for the requested command
    help_function="playground_${command}_usage"
  fi

  # Call the help function if it exists
  if [[ $(type -t "$help_function") ]]; then
    "$help_function"
  else
    echo "No help available for this command"
    exit 1
  fi

}

# :command.function
playground_status_command() {

  # src/commands/status.sh
  test_file=$(playground state get run.test_file)

  if [ ! -f $test_file ]
  then

      logerror "File $test_file retrieved from $root_folder/playground.ini does not exist!"
      exit 1
  fi

  connector_type=$(playground state get run.connector_type)

  playground generate-fzf-find-files &
  last_two_folders=$(basename $(dirname $(dirname $test_file)))/$(basename $(dirname $test_file))
  filename=$(basename $test_file)
  last_folder=$(basename $(dirname $test_file))

  log "📊 Metrics"
  log "🚀 Number of examples ran so far: $(get_cli_metric nb_runs)"
  log "👷 Number of repro models created so far: $(get_cli_metric nb_reproduction_models)"

  log "🚀 Running example "
  echo $last_two_folders/$filename

  playground open-docs --only-show-url

  if [ "$connector_type" == "$CONNECTOR_TYPE_ONPREM" ] || [ "$connector_type" == "$CONNECTOR_TYPE_SELF_MANAGED" ]
  then
      playground connector versions | grep -v "applying command to all connectors"
      playground connector open-docs --only-show-url
  fi

  playground connector status | grep -v "applying command to all connectors"
  playground connector show-config | grep -v "applying command to all connectors"
  playground connector show-config-parameters --only-show-file-path | grep -v "applying command to all connectors"
  playground connector-plugin display-last-updated

  playground topic list

  check_for_ec2_instance_running
}

# :command.function
playground_get_docker_ports_command() {

  # src/commands/get-docker-ports.sh
  docker ps --format '{{.Ports}}' | tr ',' '\n' | awk -F '->' '{print $1}' | cut -d':' -f2 | tr -d '/tcp' | tr -d ' ' | awk '!/-/' | sort -n | uniq
}

# :command.function
playground_get_connector_list_command() {

  # src/commands/get-connector-list.sh
  connector_type=$(playground state get run.connector_type)

  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
      get_ccloud_connect
      handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors\" --header \"authorization: Basic $authorization\""
  else
      get_connect_url_and_security
      handle_onprem_connect_rest_api "curl $security -s \"$connect_url/connectors\""
  fi

  echo "$curl_output" | jq -r '.[]' | tr '\n' ' ' | sed -e 's/[[:space:]]*$//'
}

# :command.function
playground_get_ec2_instance_list_command() {

  # src/commands/get-ec2-instance-list.sh
  cur="${args[cur]}"

  get_ec2_instance_list_with_fzf "$cur"
}

# :command.function
playground_get_ec2_cloudformation_list_command() {

  # src/commands/get-ec2-cloudformation-list.sh
  cur="${args[cur]}"

  get_ec2_cloudformation_list_with_fzf "$cur"
}

# :command.function
playground_get_zazkia_connection_list_command() {

  # src/commands/get-zazkia-connection-list.sh
  get_zazkia_id_list
}

# :command.function
playground_generate_fzf_find_files_command() {

  # src/commands/generate-fzf-find-files.sh
  generate_fzf_find_files
}

# :command.function
playground_generate_tag_list_command() {

  # src/commands/generate-tag-list.sh
  function listAllTags() {

      local repo=${1}

      local page_size=${2:-100}

      [ -z "${repo}" ] && echo "Usage: listTags <repoName> [page_size]" 1>&2 && return 1

      local base_url="https://registry.hub.docker.com/v2/repositories/${repo}/tags"
      local page=1

      local res=$(curl "${base_url}?page_size=${page_size}&page=${page}" 2>/dev/null)
      echo ${res} | jq --raw-output '.results[].name' > /tmp/all_tags
      local tag_count=$(echo ${res} | jq '.count')
      ((page_count=(${tag_count}+${page_size}-1)/${page_size}))  # ceil(tag_count / page_size)
      for page in $(seq 2 $page_count); do
          curl "${base_url}?page_size=${page_size}&page=${page}" 2>/dev/null | jq --raw-output '.results[].name' >> /tmp/all_tags
      done
      cat /tmp/all_tags | sort
  }

  listAllTags "confluentinc/cp-server-connect-base" | grep -v "ubi8" | grep -v "ubi9" | grep -v "arm64" | grep -v "amd64" | grep -v "latest" | grep -v "deb8" > /tmp/tmp_tags

  rm -f $root_folder/scripts/cli/tag-list.txt
  rm -f $root_folder/scripts/cli/connect-tag-list.txt

  for tag in $(cat /tmp/tmp_tags)
  do
      # check if docker image locally exists
      if docker image inspect "confluentinc/cp-schema-registry:${tag}" > /dev/null 2>&1
      then
          echo "${tag} - already installed 💻" >> $root_folder/scripts/cli/tag-list.txt
      else
          echo "${tag} - not installed, will be downloaded🛜" >> $root_folder/scripts/cli/tag-list.txt
      fi

      # check if docker connect image locally exists
      if docker image inspect "confluentinc/cp-server-connect-base:${tag}" > /dev/null 2>&1
      then
          echo "${tag} - already installed 💻" >> $root_folder/scripts/cli/connect-tag-list.txt
      else
          echo "${tag} - not installed, will be downloaded🛜" >> $root_folder/scripts/cli/connect-tag-list.txt
      fi
  done
}

# :command.function
playground_generate_connector_plugin_list_command() {

  # src/commands/generate-connector-plugin-list.sh
  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  tmp_file=$tmp_dir/confluent-hub-plugin-list.txt
  tmp_file2=$tmp_dir/allmanis.json

  curl -s -S 'https://api.hub.confluent.io/api/plugins?per_page=100000' | jq '. | sort_by(.release_date) | reverse | .' > $tmp_file2
  jq -r '.[] | "\(.owner.username)/\(.name)|\(.source_url)"' $tmp_file2 | grep -v "NA/" | sort | uniq > $tmp_file
  rm -f $tmp_file2

  # confluent only
  cd $tmp_dir > /dev/null
  get_3rdparty_file "confluent-plugin-sourcecode-mapping-list.txt" > /dev/null
  cd - > /dev/null
  if [ -f $tmp_dir/confluent-plugin-sourcecode-mapping-list.txt ]
  then
      echo "# CONFLUENT EMPLOYEE VERSION" > $tmp_file2
      grep -v confluentinc $tmp_file >> $tmp_file2
      cat $tmp_dir/confluent-plugin-sourcecode-mapping-list.txt >> $tmp_file2
      cat $tmp_file2 | sort | uniq > $tmp_file
  fi

  cp $tmp_file $root_folder/scripts/cli/confluent-hub-plugin-list.txt
}

# :command.function
playground_generate_kafka_region_list_command() {

  # src/commands/generate-kafka-region-list.sh
  confluent kafka region list | awk -F'|' '{print $1"/"$3}' | sed 's/[[:blank:]]//g' | grep -v "CloudID" | grep -v "\-\-\-" | grep -v '^/' > $root_folder/scripts/cli/confluent-kafka-region-list.txt

}

# :command.function
playground_get_connector_plugin_command() {

  # src/commands/get-connector-plugin.sh
  cur="${args[cur]}"

  get_plugin_list "$cur"
}

# :command.function
playground_get_ccloud_environment_list_command() {

  # src/commands/get-ccloud-environment-list.sh
  cur="${args[cur]}"

  get_ccloud_environment_list_with_fzf "$cur"
}

# :command.function
playground_get_ccloud_cluster_list_command() {

  # src/commands/get-ccloud-cluster-list.sh
  cur="${args[cur]}"

  get_ccloud_cluster_list_with_fzf "$cur"
}

# :command.function
playground_get_tag_list_command() {

  # src/commands/get-tag-list.sh
  cur="${args[cur]}"
  connect_only="${args[--connect-only]}"

  if [[ -n "$connect_only" ]]
  then
      get_tag_list_with_fzf "$cur" "1"
  else
      get_tag_list_with_fzf "$cur" "0"
  fi

}

# :command.function
playground_get_kafka_region_list_command() {

  # src/commands/get-kafka-region-list.sh
  cur="${args[cur]}"

  get_confluent_kafka_region_list_with_fzf "$cur"
}

# :command.function
playground_get_topic_list_command() {

  # src/commands/get-topic-list.sh
  skip_connect_internal_topics="${args[--skip-connect-internal-topics]}"

  get_environment_used

  if [[ "$environment" == "ccloud" ]]
  then
    if [[ -n "$skip_connect_internal_topics" ]]
    then
      set +e
      confluent kafka topic list | grep -v "connect-" | grep -v "_confluent-monitoring" | grep -v "_confluent-command" | awk '{if(NR>2) print $1}'
      set -e
    else
      set +e
      confluent kafka topic list | awk '{if(NR>2) print $1}'
      set -e
    fi
  else
    get_broker_container
    # trick to be faster
    docker exec $broker_container ls /var/lib/kafka/data > /dev/null 2>&1
    if [ $? -eq 0 ]
    then
      if [[ -n "$skip_connect_internal_topics" ]]
      then
        docker exec $broker_container ls /var/lib/kafka/data | grep -v "checkpoint" | grep -v "meta.properties" | grep -v "connect-" | grep -v "^_" | grep -v "delete" | sed 's/[^-]*$//' | sed 's/.$//' | sort | uniq
      else
        docker exec $broker_container ls /var/lib/kafka/data | grep -v "checkpoint" | grep -v "meta.properties" | grep -v "^_" | grep -v "delete" | sed 's/[^-]*$//' | sed 's/.$//' | sort | uniq
      fi
    fi
  fi
}

# :command.function
playground_get_subject_list_command() {

  # src/commands/get-subject-list.sh
  get_sr_url_and_security
  deleted="${args[--deleted]}"

  if [[ -n "$deleted" ]]
  then
      curl $sr_security -s "${sr_url}/subjects?deleted=true" | jq -r '.[]'
  else
      curl $sr_security -s "${sr_url}/subjects" | jq -r '.[]'
  fi
}

# :command.function
playground_get_examples_list_with_fzf_command() {

  # src/commands/get-examples-list-with-fzf.sh
  without_repro="${args[--without-repro]}"
  sink_only="${args[--sink-only]}"
  ccloud_only="${args[--ccloud-only]}"

  connector_only="${args[--connector-only]}"
  repro_only="${args[--repro-only]}"
  environment_only="${args[--environment-only]}"
  fully_managed_connector_only="${args[--fully-managed-connector-only]}"
  ksql_only="${args[--ksql-only]}"
  schema_registry_only="${args[--schema-registry-only]}"
  rest_proxy_only="${args[--rest-proxy-only]}"
  academy_only="${args[--academy-only]}"
  other_playgrounds_only="${args[--other-playgrounds-only]}"

  cur="${args[cur]}"

  if [[ -n "$without_repro" ]] && [[ -n "$sink_only" ]]
  then
      if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_without_repro_sink_only ]
      then
          generate_get_examples_list_with_fzf_without_repro_sink_only
      fi
      get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_without_repro_sink_only"
      return
  fi

  if [[ -n "$without_repro" ]]
  then
      if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_without_repro ]
      then
          generate_get_examples_list_with_fzf_without_repro
      fi
      get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_without_repro"
      return
  fi

  if [[ -n "$ccloud_only" ]]
  then
      if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_ccloud_only ]
      then
          generate_get_examples_list_with_fzf_ccloud_only
      fi
      get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_ccloud_only"
      return
  fi

  if [[ -n "$connector_only" ]]
  then
      if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_connector_only ]
      then
          generate_get_examples_list_with_fzf_connector_only
      fi
      get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_connector_only"
      return
  fi

  if [[ -n "$repro_only" ]]
  then
      if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_repro_only ]
      then
          generate_get_examples_list_with_fzf_repro_only
      fi
      get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_repro_only"
      return
  fi

  if [[ -n "$environment_only" ]]
  then
      if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_environment_only ]
      then
          generate_get_examples_list_with_fzf_environment_only
      fi
      get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_environment_only"
      return
  fi

  if [[ -n "$fully_managed_connector_only" ]]
  then
      if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_fully_managed_connector_only ]
      then
          generate_get_examples_list_with_fzf_fully_managed_connector_only
      fi
      get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_fully_managed_connector_only"
      return
  fi

  if [[ -n "$ksql_only" ]]
  then
      if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_ksql_only ]
      then
          generate_get_examples_list_with_fzf_ksql_only
      fi
      get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_ksql_only"
      return
  fi

  if [[ -n "$schema_registry_only" ]]
  then
      if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_schema_registry_only ]
      then
          generate_get_examples_list_with_fzf_schema_registry_only
      fi
      get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_schema_registry_only"
      return
  fi

  if [[ -n "$rest_proxy_only" ]]
  then
      if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_rest_proxy_only ]
      then
          generate_get_examples_list_with_fzf_rest_proxy_only
      fi
      get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_rest_proxy_only"
      return
  fi

  if [[ -n "$academy_only" ]]
  then
      if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_academy_only ]
      then
          generate_get_examples_list_with_fzf_academy_only
      fi
      get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_academy_only"
      return
  fi

  if [[ -n "$other_playgrounds_only" ]]
  then
      if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_other_playgrounds_only ]
      then
          generate_get_examples_list_with_fzf_other_playgrounds_only
      fi
      get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_other_playgrounds_only"
      return
  fi

  if [ ! -f $root_folder/scripts/cli/get_examples_list_with_fzf_all ]
  then
      generate_get_examples_list_with_fzf
  fi
  get_examples_list_with_fzf "$cur" "$root_folder/scripts/cli/get_examples_list_with_fzf_all"
}

# :command.function
playground_get_zip_or_jar_with_fzf_command() {

  # src/commands/get-zip-or-jar-with-fzf.sh
  cur="${args[cur]}"
  type="${args[--type]}"

  get_zip_or_jar_with_fzf "$cur" "$type"
}

# :command.function
playground_get_specific_file_extension_command() {

  # src/commands/get-specific-file-extension.sh
  cur="${args[cur]}"
  extension="${args[--extension]}"

  get_specific_file_extension "$cur" "$extension"
}

# :command.function
playground_get_any_file_with_fzf_command() {

  # src/commands/get-any-file-with-fzf.sh
  cur="${args[cur]}"

  find $root_folder -type f ! -path '*/\.*' > /tmp/get_any_files_with_fzf
  get_any_files_with_fzf "$cur"
}

# :command.function
playground_get_playground_repro_export_with_fzf_command() {

  # src/commands/get-playground-repro-export-with-fzf.sh
  cur="${args[cur]}"

  get_playground_repro_export_with_fzf "$cur"
}

# :command.function
playground_get_predefined_schemas_command() {

  # src/commands/get-predefined-schemas.sh
  cur="${args[cur]}"

  get_predefined_schemas_with_fzf "$cur"
}

# :command.function
playground_update_cache_versions_command() {

  # src/commands/update-cache-versions.sh
  curl -H "Authorization: Token $GH_TOKEN" -s "https://raw.githubusercontent.com/confluentinc/cc-docker-connect/refs/heads/master/cc-connect/cache-versions.env" -o /tmp/cache-versions.env

  if [ ! -f /tmp/cache-versions.env ]
  then
      logerror "❌ could not download cache-versions.env"
      exit 1
  fi

  aws s3 cp --only-show-errors /tmp/cache-versions.env s3://kafka-docker-playground/3rdparty/cache-versions.env
  if [ $? -ne 0 ]
  then
      logerror "❌ could not upload cache-versions.env to s3://kafka-docker-playground/3rdparty/cache-versions.env"
      exit 1
  fi
}

# :command.function
playground_update_readme_command() {

  # src/commands/update-readme.sh
  tags="${args[--tags]}"
  generate_for_kb="${args[--generate-for-kb]}"

  set +e
  tmp_dir="/tmp/update-readme"
  rm -rf $tmp_dir
  mkdir -p "$tmp_dir"
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  cd ${root_folder}

  content_template_file=./docs/content-template.md
  content_file=./docs/content.md
  content_tmp_file=$tmp_dir/content.md
  badges_template_file=./docs/badges-template.md
  badges_file=./docs/badges.md
  badges_tmp_file=$tmp_dir/badges.md
  gh_msg_file=$tmp_dir/gh.txt
  gh_msg_file_intro=$tmp_dir/gh_intro.txt

  cp $content_template_file $content_file
  cp $badges_template_file $badges_file

  curl -s https://raw.githubusercontent.com/vdesabou/kafka-docker-playground-connect/master/README.md -o $tmp_dir/README.txt

  ci_folder="$tmp_dir/ci"
  log "Getting ci result files"
  rm -rf "$ci_folder"
  mkdir -p "$ci_folder"
  aws s3 cp --only-show-errors s3://kafka-docker-playground/ci/ "${ci_folder}/" --recursive --no-progress --region us-east-1

  ci_output_folder="$tmp_dir/ci_output"
  log "Getting ci output log files"
  rm -rf "$ci_output_folder"
  mkdir -p "$ci_output_folder"
  aws s3 cp --only-show-errors s3://kafka-docker-playground/ci_output/ "${ci_output_folder}/" --recursive --no-progress --region us-east-1

  test_list=$(grep "🚀" ${root_folder}/.github/workflows/ci.yml | cut -d '"' -f 2 | tr '\n' ' ')
  declare -a TEST_FAILED
  declare -a TEST_SUCCESS
  nb_total_tests=0
  nb_connector_tests=0
  nb_total_fail=0
  nb_total_success=0
  for test in $test_list
  do
    nb_tests=0
    nb_fail=0
    nb_success=0
    TEST_FAILED=()
    TEST_SUCCESS=()
    TEST_SKIPPED=()
    rm -f ${gh_msg_file}
    touch ${gh_msg_file}
    rm -f ${gh_msg_file_intro}
    touch ${gh_msg_file_intro}
    gh_issue_number=""
    if [ ! -d $test ]
    then
      # logwarn "####################################################"
      # logwarn "skipping test $test, not a directory"
      # logwarn "####################################################"
      continue
    fi
    log "################################"
    log "### 📁 ${test}"

    for script in ${test}/*.sh
    do
      script_name=$(basename ${script})
      if [[ "$script_name" = "stop.sh" ]]
      then
        continue
      fi

      # check for ignored scripts in scripts/tests-ignored.txt
      grep "$script_name" ${root_folder}/scripts/tests-ignored.txt > /dev/null
      if [ $? = 0 ]
      then
        log "####################################################"
        log "⏭ skipping $script_name in test $test"
        log "####################################################"
        continue
      fi

      # check for scripts containing "repro"
      if [[ "$script_name" == *"repro"* ]]
      then
        log "####################################################"
        log "⏭ skipping reproduction model $script_name in test $test"
        log "####################################################"
        continue
      fi

      connector_path=""
      if [[ "$test" == "connect"* ]]
      then
        # if it is a connector test, get connector_path
        docker_compose_file=$(grep "start-environment" "$script" |  awk '{print $6}' | cut -d "/" -f 2 | cut -d '"' -f 1 | tail -n1 | xargs)
        if [ "${docker_compose_file}" != "" ] && [ -f "${test}/${docker_compose_file}" ]
        then
          connector_path=$(grep "CONNECT_PLUGIN_PATH" "${test}/${docker_compose_file}" | grep -v KSQL_CONNECT_PLUGIN_PATH | cut -d "/" -f 5)
          # remove any extra comma at the end (when there are multiple connectors used, example S3 source)
          connector_path=$(echo "$connector_path" | cut -d "," -f 1)
        fi
      fi

      log "## 📄 ${script_name}"

      for image_version in $tags
      do
        let "nb_tests++"
        let "nb_total_tests++"
        image_version_no_dot=$(echo ${image_version} | sed 's/\.//g')
        time_day=""
        time_day_hour=""
        version=""
        release_date=""
        if [ "$connector_path" != "" ]
        then
          if [ "$connector_path" = "confluentinc-kafka-connect-jdbc" ]
          then
            if ! version_gt ${image_version} "5.9.0"
            then
              # for version less than 6.0.0, use JDBC with same version
              # see https://github.com/vdesabou/kafka-docker-playground/issues/221
              version=${image_version}
            else
              version=$(grep "$connector_path " $tmp_dir/README.txt | cut -d "|" -f 3 | sed 's/^[[:blank:]]*//;s/[[:blank:]]*$//')
              release_date=$(grep "$connector_path " $tmp_dir/README.txt | cut -d "|" -f 6 | sed 's/^[[:blank:]]*//;s/[[:blank:]]*$//')
            fi
          else
            version=$(grep "$connector_path " $tmp_dir/README.txt | cut -d "|" -f 3 | sed 's/^[[:blank:]]*//;s/[[:blank:]]*$//')
            release_date=$(grep "$connector_path " $tmp_dir/README.txt | cut -d "|" -f 6 | sed 's/^[[:blank:]]*//;s/[[:blank:]]*$//')
          fi
        fi
        if [ "$release_date" = "null" ]
        then
          release_date=""
        fi
        testdir=$(echo "$test" | sed 's/\//-/g')
        ci_file="${ci_folder}/${image_version}-${testdir}-${version}-${script_name}"
  	  ci_output_file="${ci_output_folder}/${image_version}-${testdir}-${version}-${script_name}.log"

        if [ -f ${ci_file} ]
        then
          last_execution_time=$(grep "$connector_path" ${ci_file} | tail -1 | cut -d "|" -f 2)
          status=$(grep "$connector_path" ${ci_file} | tail -1 | cut -d "|" -f 3)
          gh_run_id=$(grep "$connector_path" ${ci_file} | tail -1 | cut -d "|" -f 4)

          if [ ! -f $tmp_dir/${gh_run_id}_1.json ]
          then
            for i in {1..10}
            do

                # https://docs.github.com/en/rest/actions/workflow-runs?apiVersion=2022-11-28#get-a-workflow-run
                curl_output=$(curl -s -o $tmp_dir/${gh_run_id}_${i}.json -w %{http_code} -H "Accept: application/vnd.github+json" -H "X-GitHub-Api-Version: 2022-11-28"  -H "Authorization: Bearer $GH_TOKEN" "https://api.github.com/repos/vdesabou/kafka-docker-playground/actions/runs/${gh_run_id}/jobs?per_page=50&page=${i}")
                if [ $curl_output -ne 200 ]
                then
                    logerror "❌ curl request <https://api.github.com/repos/vdesabou/kafka-docker-playground/actions/runs/${gh_run_id}/jobs?per_page=50&page=${i}> failed with error code $curl_output!"
                    cat "/tmp/${gh_run_id}_${i}.json"
                    continue
                fi
            done
          fi

          v=$(echo $image_version | sed -e 's/\./[.]/g')
          for i in {1..10}
          do
            html_url=$(cat "$tmp_dir/${gh_run_id}_${i}.json" | jq ".jobs |= map(select(.name | test(\"${v}.*${test}\")))" | jq '[.jobs | .[] | {name: .name, html_url: .html_url }]' | jq '.[0].html_url' | sed -e 's/^"//' -e 's/"$//')
            if [ "$html_url" != "" ] && [ "$html_url" != "null" ]; then

                break
            fi
          done

          if [ "$html_url" = "" ] || [ "$html_url" = "null" ]
          then
            logerror "Could not retrieve job url! FIXTHIS: NOT Forcing re-run for next time..."
            # s3_file="s3://kafka-docker-playground/ci/${image_version}-${testdir}-${version}-${script_name}"
            # aws s3 rm $s3_file --region us-east-1
          fi
        else
          logerror "result_file: ${ci_file} does not exist !"
          continue
        fi

        if [ "$last_execution_time" != "" ]
        then
          if [[ "$OSTYPE" == "darwin"* ]]
          then
            time_day=$(date -r $last_execution_time "+%Y-%m-%d")
            time_day_hour=$(date -r $last_execution_time "+%Y-%m-%d %H:%M")
          else
            time_day=$(date -d @$last_execution_time "+%Y-%m-%d")
            time_day_hour=$(date -d @$last_execution_time "+%Y-%m-%d %H:%M")
          fi
        fi

        connector_version=""
        if [ "$version" != "" ]
        then
          if [ "$release_date" != "" ]
          then
            connector_version=" 🔢 Connector v$version (📅 release date $release_date)"
          else
            connector_version=" 🔢 Connector v$version"
          fi
        fi
        if [ "$status" == "failure" ]
        then
          let "nb_fail++"
          let "nb_total_fail++"
          TEST_FAILED[$image_version_no_dot]="[![CP $image_version](https://img.shields.io/badge/$nb_success/$nb_tests-CP%20$image_version-red)]($html_url)"
          echo -e "🔥 CP ${image_version}${connector_version} 🕐 ${time_day_hour} 📄 [${script_name}](https://github.com/vdesabou/kafka-docker-playground/blob/master/$test/$script_name) 🔗 $html_url\n" >> ${gh_msg_file}
          if [ -f ${ci_output_file} ]; then
              echo -e "<details><summary>Logs</summary>" >> ${gh_msg_file}
              echo -e "<pre>\n" >> ${gh_msg_file}
              echo -e "<code>\n" >> ${gh_msg_file}
              perl -pe 's/\e\[[0-9;]*[mGKH]//g; s/^-+$/###################################################################/' ${ci_output_file} >> ${gh_msg_file}
              echo -e "\n</code>" >> ${gh_msg_file}
              echo -e "</pre>\n" >> ${gh_msg_file}
              echo -e "</details>\n" >> ${gh_msg_file}
          fi
          log "🔥 CP $image_version 🕐 ${time_day_hour} 📄 ${script_name} 🔗 $html_url"
        elif [[ "$status" = known_issue* ]]
        then
          let "nb_success++"
          let "nb_total_success++"
          known_issue_gh_issue_number=$(echo "$status" | cut -d "#" -f 2)
          TEST_SUCCESS[$image_version_no_dot]="[![CP $image_version](https://img.shields.io/badge/known%20issue-CP%20$image_version-orange)](https://github.com/vdesabou/kafka-docker-playground/issues/$known_issue_gh_issue_number)"

          echo -e "💀 known issue 🐞 [#${known_issue_gh_issue_number}](https://github.com/vdesabou/kafka-docker-playground/issues/${known_issue_gh_issue_number}) CP ${image_version}${connector_version} 🕐 ${time_day_hour} 📄 [${script_name}](https://github.com/vdesabou/kafka-docker-playground/blob/master/$test/$script_name) 🔗 $html_url\n" >> ${gh_msg_file}
          log "💀 known issue 🐞 [#${known_issue_gh_issue_number}](https://github.com/vdesabou/kafka-docker-playground/issues/${known_issue_gh_issue_number}) CP ${image_version}${connector_version} 🕐 ${time_day_hour} 📄 [${script_name}](https://github.com/vdesabou/kafka-docker-playground/blob/master/$test/$script_name) 🔗 $html_url"
        elif [ "$status" == "skipped" ]
        then
          let "nb_success++"
          let "nb_total_success++"
          TEST_SKIPPED[$image_version_no_dot]="[![CP $image_version](https://img.shields.io/badge/skipped-CP%20$image_version-lightgrey)]($html_url)"
          echo -e "⏭ SKIPPED CP ${image_version}${connector_version} 🕐 ${time_day_hour} 📄 [${script_name}](https://github.com/vdesabou/kafka-docker-playground/blob/master/$test/$script_name) 🔗 $html_url\n" >> ${gh_msg_file}
          log "⏭ SKIPPED CP $image_version 🕐 ${time_day_hour} 📄 ${script_name} 🔗 $html_url"
        else
          let "nb_success++"
          let "nb_total_success++"
          TEST_SUCCESS[$image_version_no_dot]="$html_url"
          echo -e "👍 CP ${image_version}${connector_version} 🕐 ${time_day_hour} 📄 [${script_name}](https://github.com/vdesabou/kafka-docker-playground/blob/master/$test/$script_name) 🔗 $html_url\n" >> ${gh_msg_file}
          if [ -f ${ci_output_file} ]; then
          echo -e "<details><summary>Logs</summary>" >> ${gh_msg_file}
          echo -e "<pre>\n" >> ${gh_msg_file}
          echo -e "<code>\n" >> ${gh_msg_file}
          perl -pe 's/\e\[[0-9;]*[mGKH]//g; s/^-+$/###################################################################/' ${ci_output_file} >> ${gh_msg_file}
          echo -e "\n</code>" >> ${gh_msg_file}
          echo -e "</pre>\n" >> ${gh_msg_file}
          echo -e "</details>\n" >> ${gh_msg_file}
          fi
          log "👍 CP $image_version 🕐 ${time_day_hour} 📄 ${script_name} 🔗 $html_url"
        fi
      done #end image_version
    done #end script

    if [[ ! -n "$generate_for_kb" ]]
    then
      # GH issues
      if [ "$html_url" != "" ]
      then
        t=$(echo ${testdir} | sed 's/-/\//')
        title="🔥 ${t}"
        log "Number of successful tests: $nb_success/${nb_tests}"
        if [ ${nb_fail} -gt 0 ]
        then
          gh issue list --limit 500 | grep "$title" > /dev/null
          if [ $? != 0 ]
          then
            echo -e "🆕💥 New issue !\n" >> ${gh_msg_file_intro}
            msg=$(cat ${gh_msg_file_intro} ${gh_msg_file})
            log "Creating GH issue with title $title"
            gh issue create --title "$title" --body "$msg" --assignee vdesabou --label "new 🆕"
          else
            echo -e "🤦‍♂️💥 Still failing !\n" >> ${gh_msg_file_intro}
            msg=$(cat ${gh_msg_file_intro} ${gh_msg_file})
            log "GH issue with title $title already exist, adding comment..."
            issue_number=$(gh issue list --limit 500 | grep "$title" | awk '{print $1;}')
            gh issue comment ${issue_number} --body "$msg"
            gh issue edit ${issue_number} --add-label "CI failing 🔥" --remove-label "new 🆕"
          fi
          gh_issue_number=$(gh issue list --limit 500 | grep "$title" | awk '{print $1;}')
        fi
        if [ ${nb_success} -eq ${nb_tests} ]
        then
          # if all scripts in tests are now successful, close the issue
          gh issue list --limit 500 | grep "$title" > /dev/null
          if [ $? = 0 ]
          then
            issue_number=$(gh issue list --limit 500 | grep "$title" | head -1 | awk '{print $1;}')
            echo -e "👍✅ Issue fixed !\n" >> ${gh_msg_file_intro}
            msg=$(cat ${gh_msg_file_intro} ${gh_msg_file})
            gh issue comment ${issue_number} --body "$msg"
            log "Closing GH issue #${issue_number} with title $title"
            gh issue close ${issue_number}
          fi
        fi
      fi

      ci=""
      ci_nb_fail=0
      ci_nb_skipped=0
      nb_image_versions=0
      for image_version in $tags
      do
        let "nb_image_versions++"
        image_version_no_dot=$(echo ${image_version} | sed 's/\.//g')
        if [ "${TEST_FAILED[$image_version_no_dot]}" != "" ]
        then
          gh_issue_number=$(echo $gh_issue_number|tr -d '\n')
          if [ "${gh_issue_number}" != "" ]
          then
            ci="$ci [![issue $gh_issue_number](https://img.shields.io/badge/$nb_success/$nb_tests-CP%20$image_version-red)](https://github.com/vdesabou/kafka-docker-playground/issues/$gh_issue_number)"
          else
            ci="$ci ${TEST_FAILED[$image_version_no_dot]}"
          fi
          let "ci_nb_fail++"
        elif [ "${TEST_SKIPPED[$image_version_no_dot]}" != "" ]
        then
          ci="$ci ${TEST_SKIPPED[$image_version_no_dot]}"
          let "ci_nb_skipped++"
        elif [ "${TEST_SUCCESS[$image_version_no_dot]}" != "" ]
        then
          ci="$ci [![CP $image_version](https://img.shields.io/badge/$nb_success/$nb_tests-CP%20$image_version-green)](${TEST_SUCCESS[$image_version_no_dot]})"
        else
          logerror "TEST_SUCCESS, TEST_SKIPPED and TEST_FAILED are all empty !"
        fi
      done

      if [ ${ci_nb_fail} -eq 0 ] && [ ${ci_nb_skipped} -eq 0 ]
      then
          ci="[![CI ok](https://img.shields.io/badge/$nb_success/$nb_tests-ok!-green)]($html_url)"
      elif [ ${ci_nb_fail} -eq ${nb_image_versions} ]
      then
          ci="[![CI fail](https://img.shields.io/badge/$nb_success/$nb_tests-fail!-red)](https://github.com/vdesabou/kafka-docker-playground/issues/$gh_issue_number)"
      fi
    fi

    if [ "$connector_path" != "" ]
    then
      version=$(grep "$connector_path " $tmp_dir/README.txt | cut -d "|" -f 3 | sed 's/^[[:blank:]]*//;s/[[:blank:]]*$//')
      owner=$(grep "$connector_path " $tmp_dir/README.txt | cut -d "|" -f 5 | sed 's/^[[:blank:]]*//;s/[[:blank:]]*$//')
      release_date=$(grep "$connector_path " $tmp_dir/README.txt | cut -d "|" -f 6 | sed 's/^[[:blank:]]*//;s/[[:blank:]]*$//')
      documentation_url=$(grep "$connector_path " $tmp_dir/README.txt | cut -d "|" -f 7 | sed 's/^[[:blank:]]*//;s/[[:blank:]]*$//' | sed 's/.*(\(.*\))/\1/')
      if [ "$release_date" = "null" ]
      then
        release_date="unknown"
      fi

      owner_badge=""
      if [ "$owner" != "" ]
      then
        if [[ "$owner" != *"Confluent"* ]]
        then
          ownerencoded=$(echo "$owner" | sed -e 's/ /%20/g')
          owner_badge="![owner](https://img.shields.io/badge/-$ownerencoded-blue)"
        fi
      fi

      versionencoded=$(urlencode $version)
      versionencoded=$(echo $versionencoded | tr "-" "_")
      release_date_encoded=$(urlencode $release_date)
      release_date_encoded=$(echo $release_date_encoded | tr "-" "_")
      connector_badge="[![version](https://img.shields.io/badge/v-$versionencoded%20($release_date_encoded)-pink)]($documentation_url)"

      # M1 Mac arm64 support
      arm64=""
      grep "${test}" ${root_folder}/scripts/arm64-support-with-emulation.txt > /dev/null
      if [ $? = 0 ]
      then
          arm64="![arm64](https://img.shields.io/badge/arm64-emulation%20required-orange)"
      fi

      grep "${test}" ${root_folder}/scripts/arm64-support-none.txt > /dev/null
      if [ $? = 0 ]
      then
          arm64="![arm64](https://img.shields.io/badge/arm64-not%20working-red)"
      fi

      if [ "$arm64" == "" ]
      then
          arm64="![arm64](https://img.shields.io/badge/arm64-native%20support-green)"
      fi

      let "nb_connector_tests++"
      sed -e "s|:${test}:|\&nbsp; $connector_badge $owner_badge $arm64 $ci |g" \
          $content_file > $content_tmp_file

      cp $content_tmp_file $content_file
    else
      arm64=""
      grep "${test}" ${root_folder}/scripts/arm64-support-with-emulation.txt > /dev/null
      if [ $? = 0 ]
      then
          arm64="![arm64](https://img.shields.io/badge/arm64-emulation%20required-orange)"
      fi

      grep "${test}" ${root_folder}/scripts/arm64-support-none.txt > /dev/null
      if [ $? = 0 ]
      then
          arm64="![arm64](https://img.shields.io/badge/arm64-not%20working-red)"
      fi

      if [ "$arm64" == "" ]
      then
          arm64="![arm64](https://img.shields.io/badge/arm64-native%20support-green)"
      fi

      sed -e "s|:${test}:|\&nbsp; $arm64 $ci |g" \
          $content_file > $content_tmp_file

      cp $content_tmp_file $content_file
    fi
  done #end test_list

  cp_version_tested=""
  for image_version in $tags
  do
    cp_version_tested="$cp_version_tested%20$image_version"
  done

  tests_color="green"
  if [ $nb_total_fail -gt 0 ]; then
    tests_color="red"
  fi
  if [[ "$OSTYPE" == "darwin"* ]]
  then
    last_run=$(date "+%Y-%m-%d %H:%M")
  else
    last_run=$(date "+%Y-%m-%d %H:%M")
  fi
  last_run=${last_run// /%20}
  last_run=${last_run//-/--}

  # handle shields badges
  sed -e "s|:nb_total_success:|$nb_total_success|g" \
      -e "s|:nb_total_tests:|$nb_total_tests|g" \
      -e "s|:nb_connector_tests:|$nb_connector_tests|g" \
      -e "s|:cp_version_tested:|$cp_version_tested|g" \
      -e "s|:tests_color:|$tests_color|g" \
      -e "s|:last_run:|$last_run|g" \
      $badges_file > $badges_tmp_file
  cp $badges_tmp_file $badges_file

  # Create docs/introduction.md
  cat ./docs/introduction-header.md > ./docs/introduction.md
  cat $badges_file >> ./docs/introduction.md
  echo "" >> ./docs/introduction.md
  cat ./docs/introduction-footer.md >> ./docs/introduction.md

}

# :command.function
playground_force_ci_command() {

  # src/commands/force-ci.sh
  filename="${args[filename]}"
  all="${args[--all]}"
  force="${args[--force]}"

  if [[ -n "$all" ]]
  then
      log "removing all ci files in s3://kafka-docker-playground/ci/"
      check_if_continue
      aws s3 rm --only-show-errors s3://kafka-docker-playground/ci/ --recursive --region us-east-1
      exit 0
  fi

  if [[ -n "$force" ]]
  then
      GITHUB_RUN_NUMBER=1
  fi

  if [[ -n "$filename" ]]
  then
      log "checking if file exists in s3://kafka-docker-playground/ci/ containing '$filename' in its name"
      files=$(aws s3 ls s3://kafka-docker-playground/ci/ --region us-east-1 | grep "$filename" | awk '{print $4}')

      if [[ -n "$files" ]]; then
          log "file(s) found: $files. Deleting..."
          for file in $files
          do
              log "deleting $file"
              check_if_continue
              aws s3 rm "s3://kafka-docker-playground/ci/$file" --only-show-errors --region us-east-1
          done
          log "file(s) deleted successfully."
      else
          log "no file found containing '$filename' in its name."
      fi
  fi
}

# :command.function
playground_update_docs_command() {

  # src/commands/update-docs.sh
  cd ${root_folder}/scripts/cli

  docker run --rm -i --user $(id -u):$(id -g) --volume "$PWD:/app" dannyben/bashly render templates/markdown docs

  cat ${root_folder}/scripts/cli/docs-template/cli-template.md > ${root_folder}/docs/cli.md
  cat ${root_folder}/scripts/cli/docs/index.md >> ${root_folder}/docs/cli.md

  mv ${root_folder}/scripts/cli/docs/* ${root_folder}/docs/
}

# :command.function
playground_bashly_reload_command() {

  # src/commands/bashly-reload.sh
  cd $root_folder/scripts/cli
  bashly generate
  rm -f $root_folder/scripts/cli/completions.bash
  bashly add completions_script
  cd - > /dev/null
}

# :command.function
playground_state_show_command() {

  # src/commands/state/show.sh
  # Using the standard library (lib/ini.sh) to show the entire config file
  if [ ! -f "$root_folder/playground.ini" ]
  then
    touch $root_folder/playground.ini
  fi
  ini_load $root_folder/playground.ini
  ini_show
}

# :command.function
playground_state_get_command() {

  # src/commands/state/get.sh
  # Using the standard library (lib/ini.sh) to show a value from the config
  if [ ! -f "$root_folder/playground.ini" ]
  then
    touch $root_folder/playground.ini
  fi
  ini_load $root_folder/playground.ini

  key="${args[key]:-}"
  value=${ini[$key]:-}

  if [[ "$value" ]]
  then
    echo "$value"
  else
    echo ""
  fi
}

# :command.function
playground_state_set_command() {

  # src/commands/state/set.sh
  # Using the standard library (lib/ini.sh) to store a value to the config
  if [ ! -f "$root_folder/playground.ini" ]
  then
    touch $root_folder/playground.ini
  fi
  set -e
  ini_load $root_folder/playground.ini

  key="${args[key]}"
  value="${args[value]}"

  ini["$key"]="$value"
  ini_save $root_folder/playground.ini
}

# :command.function
playground_state_del_command() {

  # src/commands/state/del.sh
  # Using the standard library (lib/ini.sh) to delete a value from the config
  if [ ! -f "$root_folder/playground.ini" ]
  then
    touch $root_folder/playground.ini
  fi
  set -e
  ini_load $root_folder/playground.ini

  key="${args[key]}"
  unset "ini[$key]"

  ini_save $root_folder/playground.ini

}

# :command.function
playground_config_show_command() {

  # src/commands/config/show.sh
  # Using the standard library (lib/ini.sh) to show the entire config file
  if [ ! -f "$root_folder/playground_config.ini" ]
  then
      logerror "$root_folder/playground_config.ini does not exist !"
      logerror "Make sure to always use the CLI to run examples"
      exit 1
  fi
  ini_load $root_folder/playground_config.ini
  ini_show
}

# :command.function
playground_config_get_command() {

  # src/commands/config/get.sh
  # Using the standard library (lib/ini.sh) to show a value from the config
  if [ ! -f "$root_folder/playground_config.ini" ]
  then
      # set defaults
      playground config set editor code > /dev/null 2>&1
      playground config set clipboard true > /dev/null 2>&1
      playground config set folder_zip_or_jar ~ > /dev/null 2>&1
  fi
  ini_load $root_folder/playground_config.ini

  key="${args[key]:-}"
  value=${ini[$key]:-}

  if [[ "$value" ]]
  then
    echo "$value"
  else
    echo ""
  fi
}

# :command.function
playground_config_set_command() {

  # src/commands/config/set.sh
  # Using the standard library (lib/ini.sh) to store a value to the config
  if [ ! -f $root_folder/playground_config.ini ]
  then
      touch $root_folder/playground_config.ini
  fi
  set -e
  ini_load $root_folder/playground_config.ini

  key="${args[key]}"
  value="${args[value]}"

  ini["$key"]="$value"
  ini_save $root_folder/playground_config.ini
}

# :command.function
playground_config_editor_command() {

  # src/commands/config/editor.sh
  log "🔖 configuring editor with ${args[editor]}"
  playground config set editor "${args[editor]}"
}

# :command.function
playground_config_folder_zip_or_jar_command() {

  # src/commands/config/folder_zip_or_jar.sh
  # Convert the space delimited string to an array
  folders=''
  eval "folders=(${args[folder]:-})"

  folder_list=""
  for i in "${folders[@]}"
  do
      folder_list="$folder_list,$i"
  done

  log "📁 configuring folder_zip_or_jar with $folder_list"
  playground config set folder_zip_or_jar "$folder_list"
}

# :command.function
playground_config_clipboard_command() {

  # src/commands/config/clipboard.sh
  if [[ "$OSTYPE" != "darwin"* ]]
  then
      logerror "❌ clipboard is only working on MacOS"
      exit 1
  fi

  log "📋 configuring clipboard with ${args[enabled]}"
  playground config set clipboard "${args[enabled]}"
}

# :command.function
playground_config_open_ccloud_connector_in_browser_automatically_command() {

  # src/commands/config/open-ccloud-connector-in-browser/automatically.sh
  log "📋 configuring automatically with ${args[automatically]}"
  playground config set open-ccloud-connector-in-browser.automatically "${args[automatically]}"
}

# :command.function
playground_config_open_ccloud_connector_in_browser_browser_command() {

  # src/commands/config/open-ccloud-connector-in-browser/browser.sh
  log "🔖 configuring browser for open-ccloud-connector-in-browser with ${args[browser]}"
  playground config set open-ccloud-connector-in-browser.browser "${args[browser]}"
}

# :command.function
playground_config_open_grafana_in_browser_automatically_command() {

  # src/commands/config/open-grafana-in-browser/automatically.sh
  log "📋 configuring automatically with ${args[automatically]}"
  playground config set open-grafana-in-browser.automatically "${args[automatically]}"
}

# :command.function
playground_config_open_grafana_in_browser_browser_command() {

  # src/commands/config/open-grafana-in-browser/browser.sh
  log "🔖 configuring browser for open-grafana-in-browser with ${args[browser]}"
  playground config set open-grafana-in-browser.browser "${args[browser]}"
}

# :command.function
playground_config_container_kill_all_before_run_command() {

  # src/commands/config/container-kill-all-before-run.sh
  log "📋 configuring container-kill-all-before-run with ${args[enabled]}"
  playground config set container-kill-all-before-run "${args[enabled]}"
}

# :command.function
playground_config_check_and_update_repo_version_command() {

  # src/commands/config/check-and-update-repo-version.sh
  log "📋 configuring check-and-update-repo-version with ${args[enabled]}"
  playground config set check-and-update-repo-version "${args[enabled]}"
}

# :command.function
playground_ai_command() {

  # src/commands/ai.sh
  arguments="${args[arguments]}"

  cd $root_folder

  get_environment_used

  set +e
  docker pull vdesabou/mcp-playground-server:latest > /dev/null 2>&1
  set +e

  if [[ "$environment" == "ccloud" ]]
  then
  	if [ -f .ccloud/.env ]
  	then
  		log "🌩️ ccloud environment is used, using mcp-confluent server (https://github.com/confluentinc/mcp-confluent) to interact with confluent cloud"
  		gemini mcp remove mcp-kafka > /dev/null 2>&1 || true
  		gemini mcp remove mcp-ccloud > /dev/null 2>&1 || true
  		gemini mcp add --trust mcp-ccloud npx "-y" "@confluentinc/mcp-confluent@latest" -- "-e" "$root_folder/.ccloud/.env"
  	else
  		logerror "❌ .ccloud/.env file is not present!"
  		exit 1
  	fi
  else
  	# https://github.com/google-gemini/gemini-cli/issues/9766
  	gemini mcp remove mcp-ccloud > /dev/null 2>&1 || true

  	if [[ "$environment" == "plaintext" ]]
  	then
  		log "🌩️ plaintext environment is used, using kafka-mcp-server (https://docs.tuannvm.com/kafka-mcp-server) to interact with the cluster"
  		gemini mcp remove mcp-kafka > /dev/null 2>&1 || true
  		gemini mcp add --trust mcp-kafka kafka-mcp-server -e "KAFKA_BROKERS=localhost:29092" -e "KAFKA_CLIENT_ID=kafka-mcp-server" -e "MCP_TRANSPORT=stdio"
  	else
  		logwarn "🔐 $environment environment is used, using kafka-mcp-server (https://docs.tuannvm.com/kafka-mcp-server) to interact with the cluster will not be used, only works with plaintext for now"
  	fi
  fi

  log "🧞‍♂️ calling gemini cli: gemini ${other_args[*]}"
  gemini "${other_args[*]}"
}

# :command.function
playground_ccloud_costs_command() {

  # src/commands/ccloud-costs.sh
  start_date="${args[--start-date]}"
  end_date="${args[--end-date]}"
  display_only_total_cost="${args[--display-only-total-cost]}"

  if [[ ! -n "$start_date" ]]
  then
      if [[ "$OSTYPE" == "darwin"* ]]
      then
          start_date=$(date -v-1m +%Y-%m-%d)
      else
          start_date=$(date -d "1 month ago" +%Y-%m-%d)
      fi

      if [[ ! -n "$end_date" ]]
      then
          if [[ "$OSTYPE" == "darwin"* ]]
          then
              end_date=$(date -v-3d +%Y-%m-%d)
          else
              end_date=$(date -d "3 days ago" +%Y-%m-%d)
          fi
      fi
  else
      # start_date is set
      if [[ "$OSTYPE" == "darwin"* ]]
      then
          # macOS: Check if the date is more than one year ago
          if [[ $(date -j -f "%Y-%m-%d" "$start_date" +%s) -lt $(date -v-1y +%s) ]]
          then
              logerror "start_date must be less than one year old"
              return 1
          fi
      else
          # Linux: Check if the date is more than one year ago
          if [[ $(date -d "$start_date" +%s) -lt $(date -d "1 year ago" +%s) ]]
          then
              logerror "start_date must be less than one year old"
              return 1
          fi
      fi

      if [[ ! -n "$end_date" ]]
      then
          if [[ "$OSTYPE" == "darwin"* ]]
          then
              #end_date set with start_date +30 days
              end_date=$(date -v+30d -j -f "%Y-%m-%d" "$start_date" +%Y-%m-%d)
          else
              #end_date set with start_date +30 days
              end_date=$(date -d "$start_date +30 days" +%Y-%m-%d)
          fi
      fi
  fi

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  INPUT_FILE="$tmp_dir/out.json"

  if [[ ! -n "$display_only_total_cost" ]]
  then
      log "💰 Retrieve ccloud costs for a range from $start_date to $end_date "
  fi
  confluent billing cost list --start-date "$start_date" --end-date "$end_date" --output json > $INPUT_FILE
  if [[ $? -ne 0 ]]
  then
      logerror "❌ failed to retrieve ccloud costs with command: confluent billing cost list --start-date $start_date --end-date $end_date"
      cat "$INPUT_FILE"
      exit 1
  fi
  if [[ ! -n "$display_only_total_cost" ]]
  then
      log "⏳ costs retrieved successfully. processing results..."
  fi

  display_histogram() {
      local file=$1

      total_cost_local=$(awk '{sum += $2} END {print sum}' $file)
      echo ""
      echo "---------------------------------"
      echo "TOTAL COST: 💰 \$$total_cost_local"
      echo "---------------------------------"

      while read -r line; do
          resource_name=$(echo "$line" | awk '{print $1}')
          cost=$(echo "$line" | awk '{print $2}')
          resource=$(echo "$line" | awk '{print $3}')
          # proportion=$(echo "scale=1; $cost / $total_cost_local * 100" | bc) # Calculate percentage
          # bar=$(printf '💰%.0s' $(seq 1 ${proportion%.*})) # Generate the bar based on the integer part of the proportion

          # calculate the percentage of cost
          if [[ "$total_cost_local" == "0" ]]; then
              percentage=0
          else
              percentage=$(echo "scale=2; 100 * $cost / $total_cost_local" | bc)
          fi
          inverse_percentage=$(echo "100 - $percentage" | bc)

          # create the cost bar
          bar_length=50
          filled_length=$(echo "$inverse_percentage * $bar_length / 100" | bc)
          empty_length=$((bar_length - filled_length))
          bar=$(printf "%${empty_length}s" | tr ' ' '💰')
          bar+=$(printf "%${filled_length}s" | tr ' ' '⬛')

          resource_no_comma=$(echo "${resource//,/}")
          printf "%-50s (%s) | %s $%.2f (%.2f%%)\n" "$resource_name" "$resource_no_comma" "$bar" "$cost" "$percentage"

      done < "$file"
      echo ""
  }

  jq -r '.[] | "\(.product) \(.amount | sub("\\$"; ""; "g") | tonumber)"' "$INPUT_FILE" | \
  awk '{sum[$1] += $2} END {for (product in sum) print product, sum[product]}' | sort -k2 -nr > $tmp_dir/product_costs.txt

  # Calculate and display the total cost across all products
  total_cost=$(awk '{sum += $2} END {print sum}' $tmp_dir/product_costs.txt)

  if [[ -n "$display_only_total_cost" ]]
  then
      echo "$total_cost"
      exit 0
  fi
  echo "---------------------------------"
  echo "TOTAL COST ACROSS ALL PRODUCTS: 💰 $total_cost"
  echo "---------------------------------"

  while read -r line
  do
      product=$(echo "$line" | awk '{print $1}')
      log "👛 $(echo "$product" | tr '[:upper:]' '[:lower:]') product costs"
      TMP_FILE="$tmp_dir/product_costs_$product.txt"
      jq -r '.[] | select(.product == "'"$product"'") | "\(.resource_name) \(.amount | sub("\\$"; ""; "g") | tonumber) \(.resource)"' "$INPUT_FILE" | \
      awk '{sum[$1] += $2; resources[$1] = (resources[$1] ? resources[$1] ", " : "") $3} END {for (resource in sum) print resource, sum[resource], resources[resource]}' | sort -k2 -nr > "$TMP_FILE"
      display_histogram "$TMP_FILE"
  done < $tmp_dir/product_costs.txt

  jq -r '.[] | "\(.environment) \(.amount | sub("\\$"; ""; "g") | tonumber)"' "$INPUT_FILE" | \
  awk '{sum[$1] += $2} END {for (env in sum) print env, sum[env]}' | sort -k2 -nr > $tmp_dir/environment_costs.txt

  log "👛 environment costs"
  display_histogram "$tmp_dir/environment_costs.txt"

}

# :command.function
playground_ccloud_costs_history_command() {

  # src/commands/ccloud-costs-history.sh
  detailed="${args[--detailed]}"

  if [[ "$OSTYPE" == "darwin"* ]]
  then
      start_date=$(date -v-1y +%Y-%m-%d) # macOS: 1 year ago
  else
      start_date=$(date -d "1 year ago" +%Y-%m-%d) # Linux: 1 year ago
  fi

  # Add one day
  if [[ "$OSTYPE" == "darwin"* ]]
  then
      start_date=$(date -v+1d -j -f "%Y-%m-%d" "$start_date" +%Y-%m-%d) # macOS: Add 1 day
  else
      start_date=$(date -d "$start_date +1 day" +%Y-%m-%d) # Linux: Add 1 day
  fi

  current_date="$start_date"

  # Function to display histograms
  display_histogram() {
      local label=$1
      local value=$2
      local bar=$(printf '💰%.0s' $(seq 1 $(echo "$value / 10" | bc))) # Each 💰 represents $10
      printf "%-20s | %s $%.2f\n" "$label" "$bar" "$value"
  }

  readable_date () {
      if [[ "$OSTYPE" == "darwin"* ]]
      then
          date -j -f "%Y-%m-%d" "$1" +"%b %d, %Y"
      else
          date -d "$1" +"%b %d, %Y"
      fi
  }
  # Collect costs and display histograms
  while true; do
      if [[ "$OSTYPE" == "darwin"* ]]; then
          end_date=$(date -j -v+1m -f "%Y-%m-%d" "$current_date" +%Y-%m-%d) # macOS: Add 1 month
      else
          end_date=$(date -d "$current_date +1 month" +%Y-%m-%d) # Linux: Add 1 month
      fi

      # Break the loop if end_date is in the future
      if [[ "$end_date" > "$(date +%Y-%m-%d)" ]]; then
          end_date=$(date +%Y-%m-%d) # Set end_date to today
          cost=$(playground  --output-level ERROR ccloud-costs --start-date "$current_date" --end-date "$end_date" --display-only-total-cost)
          display_histogram "$(readable_date $current_date) to $(readable_date $end_date)" "$cost"
          if [[ -n "$detailed" ]]
          then
              playground  --output-level ERROR ccloud-costs --start-date "$current_date" --end-date "$end_date"

          fi
          break
      fi

      # Call playground  --output-level ERROR ccloud-costs for the current range
      cost=$(playground  --output-level ERROR ccloud-costs --start-date "$current_date" --end-date "$end_date" --display-only-total-cost)
      display_histogram "$(readable_date $current_date) to $(readable_date $end_date)" "$cost"

      if [[ -n "$detailed" ]]
      then
          playground  --output-level ERROR ccloud-costs --start-date "$current_date" --end-date "$end_date"

      fi

      # Move to the next range
      current_date="$end_date"
  done
}

# :command.function
playground_run_command() {

  # src/commands/run.sh
  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

  root_folder=${DIR_CLI}/../..

  test_file="${args[--file]}"
  open="${args[--open]}"
  environment="${args[--environment]}"
  tag="${args[--tag]}"
  connect_tag="${args[--connect-tag]}"
  connector_tag="${args[--connector-tag]}"
  connector_zip="${args[--connector-zip]}"
  connector_jar="${args[--connector-jar]}"

  enable_ksqldb="${args[--enable-ksqldb]}"
  enable_rest_proxy="${args[--enable-rest-proxy]}"
  enable_c3="${args[--enable-control-center]}"
  enable_flink="${args[--enable-flink]}"
  enable_conduktor="${args[--enable-conduktor]}"
  enable_multiple_brokers="${args[--enable-multiple-brokers]}"
  enable_multiple_connect_workers="${args[--enable-multiple-connect-workers]}"
  enable_jmx_grafana="${args[--enable-jmx-grafana]}"
  enable_kcat="${args[--enable-kcat]}"
  enable_sql_datagen="${args[--enable-sql-datagen]}"

  cluster_type="${args[--cluster-type]}"
  cluster_cloud="${args[--cluster-cloud]}"
  cluster_region="${args[--cluster-region]}"
  cluster_environment="${args[--cluster-environment]}"
  cluster_name="${args[--cluster-name]}"
  cluster_creds="${args[--cluster-creds]}"
  cluster_schema_registry_creds="${args[--cluster-schema-registry-creds]}"
  force_interactive_re_run="${args[--force-interactive-re-run]}"
  force_interactive_repro="${args[--force-interactive-repro]}"

  interactive_mode=0

  if [[ -n "$force_interactive_repro" ]]
  then
    interactive_mode=1
  fi

  declare -a array_flag_list=()
  if [[ -n "$force_interactive_re_run" ]]
  then
    interactive_mode=1
  fi

  if [[ ! -n "$test_file" ]]
  then
    interactive_mode=1
    display_interactive_menu_categories
  fi

  if [[ $test_file == *"@"* ]]
  then
    test_file=$(echo "$test_file" | cut -d "@" -f 2)
  fi

  if [ ! -f "$test_file" ]
  then
    logerror "❌ test_file $test_file does not exist!"
    exit 1
  fi

  if [[ "$test_file" != /* ]]
  then
    test_file="$PWD/$test_file"
  fi

  if [[ "$test_file" != *".sh" ]]
  then
    logerror "❌ test_file $test_file is not a .sh file!"
    exit 1
  fi

  if [[ $test_file == *"ccloud"* ]]
  then
    verify_installed "confluent"
  fi

  set +e
  container_kill_all_before_run=$(playground config get container-kill-all-before-run)
  if [ "$container_kill_all_before_run" == "" ]
  then
      playground config set container-kill-all-before-run false
  fi

  if [ "$container_kill_all_before_run" == "true" ] || [ "$container_kill_all_before_run" == "" ]
  then
    log "💀 kill all docker containers (disable with 'playground config container-kill-all-before-run false')"
    playground container kill-all
  else
    playground stop
  fi
  set -e

  playground state set run.test_file "$test_file"
  test_file_directory="$(dirname "${test_file}")"
  filename=$(basename -- "$test_file")

  docs_available=1
  set +e
  playground open-docs --only-show-url > /dev/null 2>&1
  if [ $? -eq 1 ]
  then
    docs_available=0
  fi
  set -e
  if [[ -n "$tag" ]]
  then
    if [[ $tag == *"@"* ]]
    then
      tag=$(echo "$tag" | cut -d "@" -f 2)
    fi
    array_flag_list+=("--tag=$tag")
    export TAG=$tag
  fi

  if [[ -n "$connect_tag" ]]
  then
    if [[ $connect_tag == *"@"* ]]
    then
      connect_tag=$(echo "$connect_tag" | cut -d "@" -f 2)
    fi
    array_flag_list+=("--connect-tag=$connect_tag")
    export CP_CONNECT_TAG=$connect_tag
  fi

  if [[ -n "$environment" ]]
  then
    get_connector_paths
    if [ "$connector_paths" == "" ] && [ "$environment" != "plaintext" ]
    then
      logerror "❌ using --environment is only supported with connector examples"
      exit 1
    fi

    if [ "$environment" != "plaintext" ]
    then
      array_flag_list+=("--environment=$environment")
      export PLAYGROUND_ENVIRONMENT=$environment
    fi
  fi

  if [[ -n "$connector_tag" ]]
  then
    if [ "$connector_tag" == " " ]
    then
      get_connector_paths
      if [ "$connector_paths" == "" ]
      then
          logwarn "❌ skipping as it is not an example with connector, but --connector-tag is set"
          exit 1
      else
          connector_tags=""
          for connector_path in ${connector_paths//,/ }
          do
            full_connector_name=$(basename "$connector_path")
            owner=$(echo "$full_connector_name" | cut -d'-' -f1)
            name=$(echo "$full_connector_name" | cut -d'-' -f2-)

            if [ "$owner" == "java" ] || [ "$name" == "hub-components" ] || [ "$owner" == "filestream" ]
            then
              # happens when plugin is not coming from confluent hub
              # logwarn "skipping as plugin $owner/$name does not appear to be coming from confluent hub"
              continue
            fi

            ret=$(choose_connector_tag "$owner/$name")
            connector_tag=$(echo "$ret" | cut -d ' ' -f 2 | sed 's/^v//')

            if [ -z "$connector_tags" ]; then
              connector_tags="$connector_tag"
            else
              connector_tags="$connector_tags,$connector_tag"
            fi
          done

          connector_tag="$connector_tags"
      fi
    fi

    array_flag_list+=("--connector-tag=$connector_tag")
    export CONNECTOR_TAG="$connector_tag"
  fi

  if [[ -n "$connector_zip" ]]
  then
    if [[ $connector_zip == *"@"* ]]
    then
      connector_zip=$(echo "$connector_zip" | cut -d "@" -f 2)
    fi
    array_flag_list+=("--connector-zip=$connector_zip")
    export CONNECTOR_ZIP=$connector_zip
  fi

  if [[ -n "$connector_jar" ]]
  then
    if [[ $connector_jar == *"@"* ]]
    then
      connector_jar=$(echo "$connector_jar" | cut -d "@" -f 2)
    fi
    array_flag_list+=("--connector-jar=$connector_jar")
    export CONNECTOR_JAR=$connector_jar
  fi

  if [[ -n "$enable_ksqldb" ]]
  then
    if [[ $test_file == *"ccloud"* ]]
    then
      logwarn "❌ --enable-ksqldb is not supported with ccloud examples"
      exit 1
    fi
    array_flag_list+=("--enable-ksqldb")
    export ENABLE_KSQLDB=true
  fi

  if [[ -n "$enable_rest_proxy" ]]
  then
    if [[ $test_file == *"ccloud"* ]]
    then
      logwarn "❌ --enable-rest-proxy is not supported with ccloud examples"
      exit 1
    fi
    array_flag_list+=("--enable-rest-proxy")
    export ENABLE_RESTPROXY=true
  fi

  if [[ -n "$enable_c3" ]]
  then
    array_flag_list+=("--enable-control-center")
    export ENABLE_CONTROL_CENTER=true
  fi

  if [[ -n "$enable_flink" ]]
  then
    array_flag_list+=("--enable-flink")
    export ENABLE_FLINK=true
  fi

  if [[ -n "$enable_conduktor" ]]
  then
    array_flag_list+=("--enable-conduktor")
    export ENABLE_CONDUKTOR=true
  fi

  if [[ -n "$enable_multiple_brokers" ]]
  then
    if [[ $test_file == *"ccloud"* ]]
    then
      logwarn "❌ --enable-multiple-brokers is not supported with ccloud examples"
      exit 1
    fi
    array_flag_list+=("--enable-multiple-brokers")
    export ENABLE_KAFKA_NODES=true
  fi

  if [[ -n "$enable_multiple_connect_workers" ]]
  then
    if [[ $test_file == *"ccloud"* ]]
    then
      logwarn "❌ --enable-multiple-connect-workers is not supported with ccloud examples"
      exit 1
    fi

    array_flag_list+=("--enable-multiple-connect-workers")
    export ENABLE_CONNECT_NODES=true

    # determining the docker-compose file from from test_file
    docker_compose_file=$(grep "start-environment" "$test_file" |  awk '{print $6}' | cut -d "/" -f 2 | cut -d '"' -f 1 | tail -n1 | xargs)
    docker_compose_file="${test_file_directory}/${docker_compose_file}"
    if [ -f $docker_compose_file ]
    then
      cp $docker_compose_file /tmp/playground-backup-docker-compose.yml
      yq -i '.services.connect2 = .services.connect' /tmp/playground-backup-docker-compose.yml
      yq -i '.services.connect3 = .services.connect' /tmp/playground-backup-docker-compose.yml
      cp /tmp/playground-backup-docker-compose.yml $docker_compose_file
    fi
  fi

  if [[ -n "$enable_jmx_grafana" ]]
  then
    array_flag_list+=("--enable-jmx-grafana")
    export ENABLE_JMX_GRAFANA=true

    if [[ -n "$force_interactive_repro" ]]
    then
      force_enable --enable-jmx-grafana ENABLE_JMX_GRAFANA
    fi
  fi

  if [[ -n "$enable_kcat" ]]
  then
    array_flag_list+=("--enable-kcat")
    export ENABLE_KCAT=true
  fi

  if [[ -n "$enable_sql_datagen" ]]
  then
    array_flag_list+=("--enable-sql-datagen")
    export SQL_DATAGEN=true

    if [[ $test_file != *"fully-managed"* ]]
    then
      log "📊 automatically enabling Grafana as --enable-sql-datagen is set"
      array_flag_list+=("--enable-jmx-grafana")
      export ENABLE_JMX_GRAFANA=true

      if [[ -n "$force_interactive_repro" ]]
      then
        force_enable --enable-sql-datagen SQL_DATAGEN
        force_enable --enable-jmx-grafana ENABLE_JMX_GRAFANA
      fi
    fi
  fi

  if [[ -n "$cluster_type" ]] || [[ -n "$cluster_cloud" ]] || [[ -n "$cluster_region" ]] || [[ -n "$cluster_environment" ]] || [[ -n "$cluster_name" ]] || [[ -n "$cluster_creds" ]] || [[ -n "$cluster_schema_registry_creds" ]]
  then
    playground state set ccloud.suggest_use_previous_example_ccloud "0"
    if [ ! -z "$CLUSTER_TYPE" ]
    then
      log "🙈 ignoring environment variable CLUSTER_TYPE as one of the flags is set"
      unset CLUSTER_TYPE
    fi
    if [ ! -z "$CLUSTER_CLOUD" ]
    then
      log "🙈 ignoring environment variable CLUSTER_CLOUD as one of the flags is set"
      unset CLUSTER_CLOUD
    fi
    if [ ! -z "$CLUSTER_REGION" ]
    then
      log "🙈 ignoring environment variable CLUSTER_REGION as one of the flags is set"
      unset CLUSTER_REGION
    fi
    if [ ! -z "$ENVIRONMENT" ]
    then
      log "🙈 ignoring environment variable ENVIRONMENT as one of the flags is set"
      unset ENVIRONMENT
    fi
    if [ ! -z "$CLUSTER_NAME" ]
    then
      log "🙈 ignoring environment variable CLUSTER_NAME as one of the flags is set"
      unset CLUSTER_NAME
    fi
    if [ ! -z "$CLUSTER_CREDS" ]
    then
      log "🙈 ignoring environment variable CLUSTER_CREDS as one of the flags is set"
      unset CLUSTER_CREDS
    fi

    if [ ! -z "$SCHEMA_REGISTRY_CREDS" ]
    then
      log "🙈 ignoring environment variable SCHEMA_REGISTRY_CREDS as one of the flags is set"
      unset SCHEMA_REGISTRY_CREDS
    fi
  else
    playground state set ccloud.suggest_use_previous_example_ccloud "1"
  fi

  if [[ -n "$cluster_type" ]]
  then
    array_flag_list+=("--cluster-type $cluster_type")
    export CLUSTER_TYPE=$cluster_type
  elif [ $interactive_mode == 0 ]
  then
    if [ -z "$CLUSTER_TYPE" ]
    then
      export CLUSTER_TYPE="basic"
    fi
  fi

  if [[ -n "$cluster_cloud" ]]
  then
    array_flag_list+=("--cluster-cloud $cluster_cloud")
    export CLUSTER_CLOUD=$cluster_cloud
  elif [ $interactive_mode == 0 ]
  then
    if [ -z "$CLUSTER_CLOUD" ]
    then
      export CLUSTER_CLOUD="aws"
    fi
  fi

  if [[ -n "$cluster_region" ]]
  then
    array_flag_list+=("--cluster-region $cluster_region")
    export CLUSTER_REGION=$cluster_region
  elif [ $interactive_mode == 0 ]
  then
    if [ -z "$CLUSTER_REGION" ]
    then
      case "${CLUSTER_CLOUD}" in
        aws)
          export CLUSTER_REGION="eu-west-2"
        ;;
        azure)
          export CLUSTER_REGION="westeurope"
        ;;
        gcp)
          export CLUSTER_REGION="europe-west2"
        ;;
      esac
    fi
  fi

  if [[ -n "$cluster_environment" ]]
  then
    if [[ $cluster_environment == *"@"* ]]
    then
      cluster_environment=$(echo "$cluster_environment" | cut -d "@" -f 2)
    fi
    if [[ $cluster_environment == *"/"* ]]
    then
      cluster_environment=$(echo "$cluster_environment" | sed 's/[[:blank:]]//g' | cut -d "/" -f 2)
    fi
    array_flag_list+=("--cluster-environment $cluster_environment")
    export ENVIRONMENT=$cluster_environment
  fi

  if [[ -n "$cluster_name" ]]
  then
    if [[ $cluster_name == *"@"* ]]
    then
      cluster_name=$(echo "$cluster_name" | cut -d "@" -f 2)
    fi
    if [[ $cluster_name == *"/"* ]]
    then
      cluster_name=$(echo "$cluster_name" | sed 's/[[:blank:]]//g' | cut -d "/" -f 2)
    fi
    array_flag_list+=("--cluster-name $cluster_name")
    export CLUSTER_NAME=$cluster_name
  fi

  if [[ -n "$cluster_creds" ]]
  then
    array_flag_list+=("--cluster-creds $cluster_creds")
    export CLUSTER_CREDS=$cluster_creds
  fi

  if [[ -n "$cluster_schema_registry_creds" ]]
  then
    array_flag_list+=("--cluster-schema-registry-creds $cluster_schema_registry_creds")
    export SCHEMA_REGISTRY_CREDS=$cluster_schema_registry_creds
  fi

  if [[ -n "$open" ]]
  then
    if [[ $test_file == *"fully-managed"* ]] || [[ $test_file == *"custom-"* ]]
    then
      playground open --file "${test_file}"
    else
      playground open --file "${test_file}" --open-docker-compose
    fi
    check_if_continue
  fi

  if [ $interactive_mode == 1 ]
  then
    terminal_columns=$(tput cols)
    if [[ $terminal_columns -gt 180 ]]
    then
      MAX_LENGTH=$((${terminal_columns}-120))
      fzf_version=$(get_fzf_version)
      if version_gt $fzf_version "0.38"
      then
        fzf_option_wrap="--preview-window=30%,wrap"
        fzf_option_pointer="--pointer=👉"
        fzf_option_empty_pointer=""
        fzf_option_rounded="--border=rounded"
      else
        fzf_option_wrap=""
        fzf_option_pointer=""
        fzf_option_empty_pointer=""
        fzf_option_rounded=""
      fi
    else
      MAX_LENGTH=$((${terminal_columns}-65))
      fzf_version=$(get_fzf_version)
      if version_gt $fzf_version "0.38"
      then
        fzf_option_wrap="--preview-window=20%,wrap"
        fzf_option_pointer="--pointer=👉"
        fzf_option_empty_pointer=""
        fzf_option_rounded="--border=rounded"
      else
        fzf_option_wrap=""
        fzf_option_pointer=""
        fzf_option_empty_pointer=""
        fzf_option_rounded=""
      fi
    fi
    RED='\033[0;31m'
    YELLOW='\033[0;33m'
    CYAN='\033[0;36m'
    GREEN='\033[0;32m'
    NC='\033[0m' # No Color

    if [[ -n "$force_interactive_repro" ]]
    then
      MENU_LETS_GO="🚀 Run the reproduction model !" #0
    else
      MENU_LETS_GO="🚀 Run the example !" #0
    fi

    MENU_PROBLEM="❌ The example cannot be executed, check error(s) 👉" #1
    if [[ $test_file == *"fully-managed"* ]] || [[ $test_file == *"custom-"* ]]
    then
      MENU_OPEN_FILE="📖 Open the example file in text editor"
    else
      MENU_OPEN_FILE="📖 Open the example files (including docker-compose file) in text editor"
    fi
    set +e
    if [[ $(type -f open 2>&1) =~ "not found" ]]
    then
      MENU_OPEN_DOCS="🌐 Show link to the docs"
    else
      MENU_OPEN_DOCS="🌐 Open the docs in browser"
    fi
    set -e
    # readonly MENU_SEPARATOR="--------------------------------------------------" #4

    MENU_TAG="🎯 CP version (all components) $(printf '%*s' $((${MAX_LENGTH}-30-${#MENU_TAG})) ' ') --tag" #5
    MENU_CONNECT_TAG="🔗 CP version (connect only) $(printf '%*s' $((${MAX_LENGTH}-28-${#MENU_CONNECT_TAG})) ' ') --connect-tag"
    MENU_CONNECTOR_TAG="🔌 Connector version $(printf '%*s' $((${MAX_LENGTH}-20-${#MENU_CONNECTOR_TAG})) ' ') --connector-tag"
    MENU_CONNECTOR_ZIP="🤐 Connector zip $(printf '%*s' $((${MAX_LENGTH}-16-${#MENU_CONNECTOR_ZIP})) ' ') --connector-zip"
    MENU_CONNECTOR_JAR="🤎 Connector jar $(printf '%*s' $((${MAX_LENGTH}-16-${#MENU_CONNECTOR_JAR})) ' ') --connector-jar"
    MENU_ENVIRONMENT="🔐 Environment $(printf '%*s' $((${MAX_LENGTH}-14-${#MENU_ENVIRONMENT})) ' ') --environment"

    readonly MENU_SEPARATOR="--------------------------------------------------" #10

    MENU_ENABLE_KSQLDB="🎏 Enable ksqlDB $(printf '%*s' $((${MAX_LENGTH}-16-${#MENU_ENABLE_KSQLDB})) ' ') --enable-ksqldb" #11
    MENU_ENABLE_C3="💠 Enable Control Center $(printf '%*s' $((${MAX_LENGTH}-24-${#MENU_ENABLE_C3})) ' ') --enable-control-center"
    MENU_ENABLE_CONDUKTOR="🐺 Enable Conduktor Platform $(printf '%*s' $((${MAX_LENGTH}-28-${#MENU_ENABLE_CONDUKTOR})) ' ') --enable-conduktor"
    MENU_ENABLE_RP="🧲 Enable Rest Proxy $(printf '%*s' $((${MAX_LENGTH}-20-${#MENU_ENABLE_RP})) ' ') --enable-rest-proxy"

    MENU_ENABLE_GRAFANA="📊 Enable Grafana $(printf '%*s' $((${MAX_LENGTH}-17-${#MENU_ENABLE_GRAFANA})) ' ') --enable-jmx-grafana"
    MENU_ENABLE_BROKERS="3️⃣  Enabling multiple brokers $(printf '%*s' $((${MAX_LENGTH}-28-${#MENU_ENABLE_BROKERS})) ' ') --enable-multiple-brokers"
    MENU_ENABLE_CONNECT_WORKERS="🥉 Enabling multiple connect workers $(printf '%*s' $((${MAX_LENGTH}-36-${#MENU_ENABLE_CONNECT_WORKERS})) ' ') --enable-multiple-connect-workers"
    MENU_ENABLE_KCAT="🐈 Enabling kcat $(printf '%*s' $((${MAX_LENGTH}-16-${#MENU_ENABLE_KCAT})) ' ') --enable-kcat"
    MENU_ENABLE_SQL_DATAGEN="🌪️  Enable SQL Datagen injection $(printf '%*s' $((${MAX_LENGTH}-31-${#MENU_ENABLE_SQL_DATAGEN})) ' ') --enable-sql-datagen" #19
    MENU_ENABLE_FLINK="🐿️  Enable Flink $(printf '%*s' $((${MAX_LENGTH}-15-${#MENU_ENABLE_FLINK})) ' ') --enable-flink" #20

    readonly MENU_DISABLE_KSQLDB="❌🎏 Disable ksqlDB" #21
    readonly MENU_DISABLE_C3="❌💠 Disable Control Center"
    readonly MENU_DISABLE_CONDUKTOR="❌🐺 Disable Conduktor Platform"
    readonly MENU_DISABLE_RP="❌🧲 Disable Rest Proxy"
    readonly MENU_DISABLE_GRAFANA="❌📊 Disable Grafana"
    readonly MENU_DISABLE_BROKERS="❌3️⃣ Disabling multiple brokers"
    readonly MENU_DISABLE_CONNECT_WORKERS="❌🥉 Disabling multiple connect workers"
    readonly MENU_DISABLE_KCAT="❌🐈 Disabling kcat"
    readonly MENU_DISABLE_SQL_DATAGEN="❌🌪️ Disable SQL Datagen injection" #29
    readonly MENU_DISABLE_FLINK="❌🐿️ Disable Flink" #30

    readonly MENU_SEPARATOR_FEATURES="--------------------options-----------------------"

    MENU_CLUSTER_TYPE="🔋 Cluster type $(printf '%*s' $((${MAX_LENGTH}-15-${#MENU_CLUSTER_TYPE})) ' ') --cluster-type" #31
    MENU_CLUSTER_CLOUD="🌤  Cloud provider $(printf '%*s' $((${MAX_LENGTH}-17-${#MENU_CLUSTER_CLOUD})) ' ') --cluster-cloud"
    MENU_CLUSTER_REGION="🗺  Cloud region $(printf '%*s' $((${MAX_LENGTH}-15-${#MENU_CLUSTER_REGION})) ' ') --cluster-region"
    MENU_CLUSTER_ENVIRONMENT="🌐 Environment id $(printf '%*s' $((${MAX_LENGTH}-17-${#MENU_CLUSTER_ENVIRONMENT})) ' ') --cluster-environment"

    MENU_CLUSTER_NAME="🎰 Cluster name $(printf '%*s' $((${MAX_LENGTH}-15-${#MENU_CLUSTER_NAME})) ' ') --cluster-name"
    MENU_CLUSTER_CREDS="🔒 Kafka api key & secret $(printf '%*s' $((${MAX_LENGTH}-25-${#MENU_CLUSTER_CREDS})) ' ') --cluster-creds"
    MENU_CLUSTER_SR_CREDS="🔰 Schema registry api key & secret $(printf '%*s' $((${MAX_LENGTH}-35-${#MENU_CLUSTER_SR_CREDS})) ' ') --cluster-schema-registry-creds"

    readonly MENU_SEPARATOR_CLOUD="-----------------confluent cloud------------------" #38

    readonly MENU_GO_BACK="🔙 Go back"

    last_two_folders=$(basename $(dirname $(dirname $test_file)))/$(basename $(dirname $test_file))
    example="$last_two_folders/$filename"

    connector_example=0
    get_connector_paths
    if [ "$connector_paths" != "" ]
    then
      connector_tags=""
      for connector_path in ${connector_paths//,/ }
      do
        full_connector_name=$(basename "$connector_path")
        owner=$(echo "$full_connector_name" | cut -d'-' -f1)
        name=$(echo "$full_connector_name" | cut -d'-' -f2-)

        if [ "$owner" == "java" ] || [ "$name" == "hub-components" ] || [ "$owner" == "filestream" ]
        then
          # happens when plugin is not coming from confluent hub
          continue
        else
          connector_example=1
        fi
      done
    fi

    sql_datagen=0
    if [[ $test_file == *"connect-debezium-sqlserver"* ]] || [[ $test_file == *"connect-debezium-mysql"* ]] || [[ $test_file == *"connect-debezium-postgresql"* ]] || [[ $test_file == *"connect-debezium-oracle"* ]] || [[ $test_file == *"connect-cdc-oracle"* ]] || [[ $test_file == *"connect-jdbc-sqlserver"* ]] || [[ $test_file == *"connect-jdbc-mysql"* ]] || [[ $test_file == *"connect-jdbc-postgresql"* ]] || [[ $test_file == *"connect-jdbc-oracle"* ]] || [[ $test_file == *"connect-cdc-xstream"* ]] || [[ $test_file == *"fm-debezium"* ]] || [[ $test_file == *"fm-cdc"* ]]
    then
      sql_datagen=1
    fi

    stop=0
    while [ $stop != 1 ]
    do
      has_error=0
      options=("$MENU_LETS_GO" "$MENU_PROBLEM" "$MENU_OPEN_FILE" "$MENU_OPEN_DOCS" "$MENU_SEPARATOR" "$MENU_TAG" "$MENU_CONNECT_TAG" "$MENU_CONNECTOR_TAG" "$MENU_CONNECTOR_ZIP" "$MENU_CONNECTOR_JAR" "$MENU_ENVIRONMENT" "$MENU_SEPARATOR" "$MENU_ENABLE_KSQLDB" "$MENU_ENABLE_C3" "$MENU_ENABLE_CONDUKTOR" "$MENU_ENABLE_RP" "$MENU_ENABLE_GRAFANA" "$MENU_ENABLE_BROKERS" "$MENU_ENABLE_CONNECT_WORKERS" "$MENU_ENABLE_KCAT" "$MENU_ENABLE_SQL_DATAGEN" "$MENU_ENABLE_FLINK" "$MENU_DISABLE_KSQLDB" "$MENU_DISABLE_C3" "$MENU_DISABLE_CONDUKTOR" "$MENU_DISABLE_RP" "$MENU_DISABLE_GRAFANA" "$MENU_DISABLE_BROKERS" "$MENU_DISABLE_CONNECT_WORKERS" "$MENU_DISABLE_KCAT" "$MENU_DISABLE_SQL_DATAGEN" "$MENU_DISABLE_FLINK" "$MENU_SEPARATOR_FEATURES" "$MENU_CLUSTER_TYPE" "$MENU_CLUSTER_CLOUD" "$MENU_CLUSTER_REGION" "$MENU_CLUSTER_ENVIRONMENT" "$MENU_CLUSTER_NAME" "$MENU_CLUSTER_CREDS" "$MENU_CLUSTER_SR_CREDS" "$MENU_SEPARATOR_CLOUD" "$MENU_GO_BACK")

      if [[ $test_file == *"ccloud"* ]] || [ "$PLAYGROUND_ENVIRONMENT" == "ccloud" ]
      then
        if [[ $test_file == *"fully-managed"* ]]
        then
          for((i=5;i<20;i++)); do
            unset "options[$i]"
          done

          for((i=21;i<33;i++)); do
            unset "options[$i]"
          done
        fi
        unset 'options[15]'
        unset 'options[16]'
        unset 'options[17]'
        unset 'options[18]'

        unset 'options[25]'
        unset 'options[26]'
        unset 'options[27]'
        unset 'options[28]'

      #   if [[ -n "$cluster_type" ]] || [[ -n "$cluster_cloud" ]] || [[ -n "$cluster_region" ]] || [[ -n "$cluster_environment" ]] || [[ -n "$cluster_creds" ]] || [[ -n "$cluster_schema_registry_creds" ]]
      #   then
      #     if [ ! -z "$CLUSTER_TYPE" ]
      #     then
      #       unset CLUSTER_TYPE
      #     fi
      #     if [ ! -z "$CLUSTER_CLOUD" ]
      #     then
      #       unset CLUSTER_CLOUD
      #     fi
      #     if [ ! -z "$CLUSTER_REGION" ]
      #     then
      #       unset CLUSTER_REGION
      #     fi
      #     if [ ! -z "$ENVIRONMENT" ]
      #     then
      #       unset ENVIRONMENT
      #     fi
      #     if [ ! -z "$CLUSTER_NAME" ]
      #     then
      #       unset CLUSTER_NAME
      #       cluster_name=""
      #     fi
      #     if [ ! -z "$CLUSTER_CREDS" ]
      #     then
      #       unset CLUSTER_CREDS
      #     fi

      #     if [ ! -z "$SCHEMA_REGISTRY_CREDS" ]
      #     then
      #       unset SCHEMA_REGISTRY_CREDS
      #     fi
      #   fi
        if [ ! -z "$CLUSTER_NAME" ] || [[ -n "$cluster_name" ]]
        then
          if [ ! -z "$CLUSTER_NAME" ]
          then
            cluster_name=$CLUSTER_NAME
  		  export CLUSTER_NAME=$cluster_name
          fi
          #
          # CLUSTER_NAME is set
          #
          ccloud_preview="🎯 ${YELLOW}cluster-name is set, your existing ccloud cluster will be used...${NC}\n\n"
          ccloud_preview="${ccloud_preview}🎰 ${YELLOW}cluster-name=$cluster_name${NC}\n"

          if [ -z $ENVIRONMENT ]

          then
            ccloud_preview="${ccloud_preview}❌ 🌐${RED}environment is missing!${NC}\n"
            unset 'options[0]'
            has_error=1
          else
            ccloud_preview="${ccloud_preview}🌐 ${YELLOW}environment=$ENVIRONMENT${NC}\n"
          fi

          if [ -z $CLUSTER_CLOUD ]

          then
            ccloud_preview="${ccloud_preview}❌  🌤${RED}cluster-cloud is missing!${NC}\n"
            unset 'options[0]'
            has_error=1
          else
            ccloud_preview="${ccloud_preview}🌤 ${YELLOW}cluster-cloud=$CLUSTER_CLOUD${NC}\n"
          fi

          if [ -z $CLUSTER_REGION ]

          then
            ccloud_preview="${ccloud_preview}❌ 🗺${RED}cluster-region is missing!${NC}\n"
            unset 'options[0]'
            has_error=1
          else
            ccloud_preview="${ccloud_preview}🗺  ${YELLOW}cluster-region=$CLUSTER_REGION${NC}\n"
          fi

          if [ -z $CLUSTER_CREDS ]

          then
            ccloud_preview="${ccloud_preview}❌ 🔒${RED}cluster-creds is missing!${NC}\n"
            unset 'options[0]'
            has_error=1
          fi

          if [ -z $SCHEMA_REGISTRY_CREDS ]

          then
            ccloud_preview="${ccloud_preview}🔒 ${YELLOW}cluster-schema-registry-creds is missing, new credentials will be created${NC}\n"
          else
            ccloud_preview="${ccloud_preview}🔒 ${YELLOW}cluster-schema-registry-creds are set${NC}\n"
          fi
        else # CLUSTER_NAME is set
          #
          # CLUSTER_NAME is not set
          #
          ccloud_preview="✨ ${YELLOW}cluster-name is not set, a new ccloud cluster will be created...${NC}\n\n"

          if [ -z $ENVIRONMENT ] && [[ ! -n "$cluster_environment" ]]
          then
            ccloud_preview="${ccloud_preview}🌐 ${CYAN}environment is missing, new environment will be created${NC}\n"
          else
            if [ ! -z "$ENVIRONMENT" ]
            then
              cluster_environment=$ENVIRONMENT
            fi
            ccloud_preview="${ccloud_preview}🌐 ${YELLOW}cluster-environment=$cluster_environment${NC}\n"
          fi

          if [ -z $CLUSTER_TYPE ] && [[ ! -n "$cluster_type" ]]
          then
            ccloud_preview="${ccloud_preview}🔋 ${CYAN}cluster-type is missing, basic will be used${NC}\n"
          else
            if [ ! -z "$CLUSTER_TYPE" ]
            then
              cluster_type=$CLUSTER_TYPE
            fi
            ccloud_preview="${ccloud_preview}🔋 ${YELLOW}cluster-type=$cluster_type${NC}\n"
          fi

          if [ -z $CLUSTER_CLOUD ] && [[ ! -n "$cluster_cloud" ]]
          then
            ccloud_preview="${ccloud_preview}🌤  ${CYAN}cluster-cloud is missing, aws will be used${NC}\n"
          else
            if [ ! -z "$CLUSTER_CLOUD" ]
            then
              cluster_cloud=$CLUSTER_CLOUD
            fi
            ccloud_preview="${ccloud_preview}🌤 ${YELLOW}cluster-cloud=$cluster_cloud${NC}\n"
          fi

          if [ -z $CLUSTER_REGION ] && [[ ! -n "$cluster_region" ]]
          then
            ccloud_preview="${ccloud_preview}🗺 ${CYAN}cluster-region is missing, default region for provider will be used${NC}\n"
          else
            if [ ! -z "$CLUSTER_REGION" ]
            then
              cluster_region=$CLUSTER_REGION
            fi
            ccloud_preview="${ccloud_preview}🗺  ${YELLOW}cluster-region=$cluster_region${NC}\n"
          fi
        fi
      else # end of ccloud
        unset 'options[33]'
        unset 'options[34]'
        unset 'options[35]'
        unset 'options[36]'
        unset 'options[37]'
        unset 'options[38]'
        unset 'options[39]'
        unset 'options[40]'

        unset 'options[42]'
        unset 'options[43]'
        unset 'options[44]'
        unset 'options[45]'
      fi

      if [ $connector_example == 0 ]
      then
        unset 'options[7]'
        unset 'options[8]'
        unset 'options[9]'
        unset 'options[10]'
      fi

      if [ $docs_available == 0 ]
      then
        unset 'options[3]'
      fi

      if [ $sql_datagen == 0 ]
      then
        unset 'options[20]'
      fi

      if [ ! -z $ENABLE_KSQLDB ]
      then
        unset 'options[12]'
      else
        unset 'options[22]'
      fi
      if [ ! -z $ENABLE_CONTROL_CENTER ]
      then
        unset 'options[13]'
      else
        unset 'options[23]'
      fi
      if [ ! -z $ENABLE_CONDUKTOR ]
      then
        unset 'options[14]'
      else
        unset 'options[24]'
      fi
      if [ ! -z $ENABLE_RESTPROXY ]
      then
        unset 'options[15]'
      else
        unset 'options[25]'
      fi
      if [ ! -z $ENABLE_JMX_GRAFANA ]
      then
        unset 'options[16]'
      else
        unset 'options[26]'
      fi
      if [ ! -z $ENABLE_KAFKA_NODES ]
      then
        unset 'options[17]'
      else
        unset 'options[27]'
      fi
      if [ ! -z $ENABLE_CONNECT_NODES ]
      then
        unset 'options[18]'
      else
        unset 'options[28]'
      fi
      if [ ! -z $ENABLE_KCAT ]
      then
        unset 'options[19]'
      else
        unset 'options[29]'
      fi
      if [ ! -z $SQL_DATAGEN ]
      then
        unset 'options[20]'
      else
        unset 'options[30]'
      fi
      if [ ! -z $ENABLE_FLINK ]
      then
        unset 'options[21]'
      else
        unset 'options[31]'
      fi

      missing_env=""
      declare -a missing_env_list=()

      # generic check
      for mandatory_environment_variable in $(grep "Export it as environment variable or pass it as argument" $test_file | cut -d "\"" -f2 | cut -d " " -f 1)
      do
        if [ ! -v $mandatory_environment_variable ]
        then
          missing_env="${missing_env}❌ ${RED}${mandatory_environment_variable} is missing!${NC}\n"
          unset 'options[0]'
          has_error=1

          missing_env_list+=("$mandatory_environment_variable")
        else
          if [[ $mandatory_environment_variable == *"PASSWORD"* ]] || [[ $mandatory_environment_variable == *"SECRET"* ]] || [[ $mandatory_environment_variable == *"TOKEN"* ]] || [[ $mandatory_environment_variable == *"KEY"* ]]
          then
            missing_env="${missing_env}🔑 ${GREEN}${mandatory_environment_variable} is set${NC}\n"
          else
            missing_env="${missing_env}🔑 ${GREEN}${mandatory_environment_variable}=${!mandatory_environment_variable}${NC}\n"
          fi
        fi
      done

      if [[ $test_file == *"aws"* ]]
      then
        if [ ! -f $HOME/.aws/credentials ] && ( [ -z "$AWS_ACCESS_KEY_ID" ] || [ -z "$AWS_SECRET_ACCESS_KEY" ] )
        then
          if [ ! -f "$HOME/.aws/credentials" ]
          then
            missing_env="${missing_env}❌ ${RED}$HOME/.aws/credentials is missing!${NC}\n"
            unset 'options[0]'
            has_error=1
          fi

          if [ -z "$AWS_ACCESS_KEY_ID" ]
          then
            missing_env="${missing_env}❌ ${RED}AWS_ACCESS_KEY_ID is missing!${NC}\n"
            unset 'options[0]'
            has_error=1
            missing_env_list+=("AWS_ACCESS_KEY_ID")
          fi

          if [ -z "$AWS_SECRET_ACCESS_KEY" ]
          then
            missing_env="${missing_env}❌ ${RED}AWS_SECRET_ACCESS_KEY is missing!${NC}\n"
            unset 'options[0]'
            has_error=1
            missing_env_list+=("AWS_SECRET_ACCESS_KEY")
          fi
        fi

        if [ -f "$HOME/.aws/credentials" ]
        then
          missing_env="${missing_env}🔑 ${GREEN}$HOME/.aws/credentials is present${NC}\n"
        fi

        if [ ! -z "$AWS_ACCESS_KEY_ID" ]
        then
          missing_env="${missing_env}🔑 ${GREEN}AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}${NC}\n"
        fi

        if [ ! -z "$AWS_SECRET_ACCESS_KEY" ]
        then
          missing_env="${missing_env}🔑 ${GREEN}AWS_SECRET_ACCESS_KEY is set${NC}\n"
        fi
      fi

      if [[ $test_file == *"gcp"* ]]
      then
        if [ ! -f "$test_file_directory/keyfile.json" ] && [ -z "$GCP_KEYFILE_CONTENT" ]
        then
          if [ ! -f "$test_file_directory/keyfile.json" ]
          then
            missing_env="${missing_env}❌ ${RED}$test_file_directory/keyfile.json is missing!${NC}\n"
            unset 'options[0]'
            has_error=1
          fi

          if [ -z "$GCP_KEYFILE_CONTENT" ]
          then
            missing_env="${missing_env}❌ ${RED}GCP_KEYFILE_CONTENT is missing!${NC}\n"
            unset 'options[0]'
            has_error=1
            missing_env_list+=("GCP_KEYFILE_CONTENT")
          fi
        fi

        if [ -f "$test_file_directory/keyfile.json" ]
        then
          missing_env="${missing_env}🔑 ${GREEN}$test_file_directory/keyfile.json is present${NC}\n"
        fi

        if [ ! -z "$GCP_KEYFILE_CONTENT" ]
        then
          missing_env="${missing_env}🔑 ${GREEN}GCP_KEYFILE_CONTENT is set${NC}\n"
        fi
      fi

      if [ ${#missing_env_list[@]} -gt 0 ]
      then
        oldifs=$IFS
        IFS=$',' missing_env_list_string="${missing_env_list[*]}"
        IFS=$oldifs

        if [ ${#missing_env_list[@]} -eq 1 ]
        then
          MENU_PROBLEM="❌ ${missing_env_list_string} is missing! Click here to fix it"
        else
          MENU_PROBLEM="❌ ${missing_env_list_string} are missing! Click here to fix it"
        fi

        options[1]="$MENU_PROBLEM"
      fi

      if [ $has_error == 0 ]
      then
        unset 'options[1]'
      fi

      oldifs=$IFS
      IFS=$'\n' flag_string="${array_flag_list[*]}"
      IFS=$oldifs

      arm64_support=$(arm64_support)

      if [[ "$arm64_support" == *"❌"* ]]
      then
        unset 'options[0]'
        options[1]="❌🖥️ this example is not working with ARM64 !"
      fi
      preview="${ccloud_preview}\n${missing_env}\n${arm64_support}\n🚀 number of examples ran so far: $(get_cli_metric nb_runs)\n\n⛳ flag list:\n$flag_string\n"
      res=$(printf '%s\n' "${options[@]}" | fzf --multi --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🚀" --header="select option(s) for $example (use tab to select more than one)" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer --preview "echo -e \"$preview\"")

      if [[ $res == *"$MENU_LETS_GO"* ]]
      then
        stop=1
      fi

      if [[ $res == *"$MENU_PROBLEM"* ]]
      then
        for mandatory_environment_variable in ${missing_env_list[*]}
        do
          if [ ! -v $mandatory_environment_variable ]
          then
            set +e
            mandatory_environment_variable_value=$(echo "" | fzf --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🔐" --header="Enter the value for environment variable $mandatory_environment_variable" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_empty_pointer --print-query)
            set -e

            export $mandatory_environment_variable="$mandatory_environment_variable_value"
          fi
        done
      fi

      if [[ $res == *"$MENU_OPEN_FILE"* ]]
      then
        if [[ $test_file == *"fully-managed"* ]] || [[ $test_file == *"custom-"* ]]
        then
          playground open --file "${test_file}"
        else
          playground open --file "${test_file}" --open-docker-compose
        fi
      fi

      if [[ $res == *"$MENU_OPEN_DOCS"* ]]
      then
        if [[ $(type -f open 2>&1) =~ "not found" ]]
        then
          playground open-docs --only-show-url
        else
          playground open-docs
        fi
      fi

      if [[ $res == *"$MENU_GO_BACK"* ]]
      then
        stop=1
        playground run
      fi

      if [[ $res == *"$MENU_ENABLE_KSQLDB"* ]]
      then
        array_flag_list+=("--enable-ksqldb")
        export ENABLE_KSQLDB=true
        interactive_enable_ksqldb="true"
      fi
      if [[ $res == *"$MENU_DISABLE_KSQLDB"* ]]
      then
        array_flag_list=("${array_flag_list[@]/"--enable-ksqldb"}")
        unset ENABLE_KSQLDB
        interactive_enable_ksqldb=""
      fi

      if [[ $res == *"$MENU_ENABLE_C3"* ]]
      then
        array_flag_list+=("--enable-control-center")
        export ENABLE_CONTROL_CENTER=true
        interactive_enable_c3="true"
      fi
      if [[ $res == *"$MENU_DISABLE_C3"* ]]
      then
        array_flag_list=("${array_flag_list[@]/"--enable-control-center"}")
        unset ENABLE_CONTROL_CENTER
        interactive_enable_c3=""
      fi

      if [[ $res == *"$MENU_ENABLE_FLINK"* ]]
      then
        array_flag_list+=("--enable-flink")
        export ENABLE_FLINK=true
        interactive_enable_flink="true"
      fi
      if [[ $res == *"$MENU_DISABLE_FLINK"* ]]
      then
        array_flag_list=("${array_flag_list[@]/"--enable-flink"}")
        unset ENABLE_FLINK
        interactive_enable_flink=""
      fi

      if [[ $res == *"$MENU_ENABLE_RP"* ]]
      then
        array_flag_list+=("--enable-rest-proxy")
        export ENABLE_RESTPROXY=true
        interactive_enable_rp="true"
      fi
      if [[ $res == *"$MENU_DISABLE_RP"* ]]
      then
        array_flag_list=("${array_flag_list[@]/"--enable-rest-proxy"}")
        unset ENABLE_RESTPROXY
        interactive_enable_rp=""
      fi

      if [[ $res == *"$MENU_ENABLE_CONDUKTOR"* ]]
      then
        array_flag_list+=("--enable-conduktor")
        export ENABLE_CONDUKTOR=true
        interactive_enable_conduktor="true"
      fi

      if [[ $res == *"$MENU_DISABLE_CONDUKTOR"* ]]
      then
        array_flag_list=("${array_flag_list[@]/"--enable-conduktor"}")
        unset ENABLE_CONDUKTOR
        interactive_enable_conduktor=""
      fi

      if [[ $res == *"$MENU_ENABLE_GRAFANA"* ]]
      then
        array_flag_list+=("--enable-jmx-grafana")
        export ENABLE_JMX_GRAFANA=true
        interactive_enable_grafana="true"

      fi
      if [[ $res == *"$MENU_DISABLE_GRAFANA"* ]]
      then
        array_flag_list=("${array_flag_list[@]/"--enable-jmx-grafana"}")
        unset ENABLE_JMX_GRAFANA
        interactive_enable_grafana=""
      fi

      if [[ $res == *"$MENU_ENABLE_BROKERS"* ]]
      then
        array_flag_list+=("--enable-multiple-brokers")
        export ENABLE_KAFKA_NODES=true
        interactive_enable_broker="true"
      fi

      if [[ $res == *"$MENU_DISABLE_BROKERS"* ]]
      then
        array_flag_list=("${array_flag_list[@]/"--enable-multiple-brokers"}")
        unset ENABLE_KAFKA_NODES
        interactive_enable_broker=""
      fi

      if [[ $res == *"$MENU_ENABLE_CONNECT_WORKERS"* ]]
      then
        array_flag_list+=("--enable-multiple-connect-workers")
        export ENABLE_CONNECT_NODES=true
        interactive_enable_connect="true"

        # determining the docker-compose file from from test_file
        docker_compose_file=$(grep "start-environment" "$test_file" |  awk '{print $6}' | cut -d "/" -f 2 | cut -d '"' -f 1 | tail -n1 | xargs)
        docker_compose_file="${test_file_directory}/${docker_compose_file}"
        if [ -f $docker_compose_file ]
        then
          cp $docker_compose_file /tmp/playground-backup-docker-compose.yml
          yq -i '.services.connect2 = .services.connect' /tmp/playground-backup-docker-compose.yml
          yq -i '.services.connect3 = .services.connect' /tmp/playground-backup-docker-compose.yml
          cp /tmp/playground-backup-docker-compose.yml $docker_compose_file
        fi
      fi

      if [[ $res == *"$MENU_DISABLE_CONNECT_WORKERS"* ]]
      then
        array_flag_list=("${array_flag_list[@]/"--enable-multiple-connect-workers"}")
        unset ENABLE_CONNECT_NODES
        interactive_enable_connect=""
        if [ -f /tmp/playground-backup-docker-compose.yml ]
        then
          mv /tmp/playground-backup-docker-compose.yml $docker_compose_file
        fi
      fi

      if [[ $res == *"$MENU_ENABLE_KCAT"* ]]
      then
        array_flag_list+=("--enable-kcat")
        export ENABLE_KCAT=true
        interactive_enable_kcat="true"
      fi

      if [[ $res == *"$MENU_DISABLE_KCAT"* ]]
      then
        array_flag_list=("${array_flag_list[@]/"--enable-kcat"}")
        unset ENABLE_KCAT
        interactive_enable_kcat=""
      fi

      if [[ $res == *"$MENU_ENABLE_SQL_DATAGEN"* ]]
      then
        array_flag_list+=("--enable-sql-datagen")
        export SQL_DATAGEN=true
        interactive_enable_sql="true"

        array_flag_list+=("--enable-jmx-grafana")
        export ENABLE_JMX_GRAFANA=true
        interactive_enable_grafana="true"
      fi
      if [[ $res == *"$MENU_DISABLE_SQL_DATAGEN"* ]]
      then
        array_flag_list=("${array_flag_list[@]/"--enable-sql-datagen"}")
        unset SQL_DATAGEN
        interactive_enable_sql=""

        if [[ $test_file != *"fully-managed"* ]]
        then
          array_flag_list=("${array_flag_list[@]/"--enable-jmx-grafana"}")
          unset ENABLE_JMX_GRAFANA
          interactive_enable_grafana=""
        fi
      fi

      if [[ $res == *"$MENU_ENVIRONMENT"* ]]
      then
        maybe_remove_flag "--environment"

        options=(plaintext ccloud 2way-ssl kerberos ldap-authorizer-sasl-plain ldap-sasl-plain rbac-sasl-plain sasl-plain sasl-scram sasl-ssl ssl_kerberos)
        environment=$(printf '%s\n' "${options[@]}" | fzf --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🔐" --header="select an environment" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer)

        array_flag_list+=("--environment=$environment")
        export PLAYGROUND_ENVIRONMENT=$environment
      fi

      if [[ $res == *"$MENU_TAG"* ]]
      then
        maybe_remove_flag "--tag"

        tag=$(playground get-tag-list)
        if [[ $tag == *"@"* ]]
        then
          tag=$(echo "$tag" | cut -d "@" -f 2)
        fi
        if [[ $tag == *" "* ]]
        then
          tag=$(echo "$tag" | cut -d " " -f 1)
        fi
        array_flag_list+=("--tag=$tag")
        export TAG=$tag
      fi

      if [[ $res == *"$MENU_CONNECT_TAG"* ]]
      then
        maybe_remove_flag "--connect-tag"

        connect_tag=$(playground get-tag-list --connect-only)
        if [[ $connect_tag == *"@"* ]]
        then
          connect_tag=$(echo "$connect_tag" | cut -d "@" -f 2)
        fi
        if [[ $connect_tag == *" "* ]]
        then
          connect_tag=$(echo "$connect_tag" | cut -d " " -f 1)
        fi
        array_flag_list+=("--connect-tag=$connect_tag")
        export CP_CONNECT_TAG=$connect_tag
      fi

      if [[ $res == *"$MENU_CONNECTOR_TAG"* ]]
      then
        maybe_remove_flag "--connector-zip"
        maybe_remove_flag "--connector-tag"
        connector_tags=""
        for connector_path in ${connector_paths//,/ }
        do
          full_connector_name=$(basename "$connector_path")
          owner=$(echo "$full_connector_name" | cut -d'-' -f1)
          name=$(echo "$full_connector_name" | cut -d'-' -f2-)

          if [ "$owner" == "java" ] || [ "$name" == "hub-components" ] || [ "$owner" == "filestream" ]
          then
            # happens when plugin is not coming from confluent hub
            continue
          fi

          ret=$(choose_connector_tag "$owner/$name")
          connector_tag=$(echo "$ret" | cut -d ' ' -f 2 | sed 's/^v//')

          if [ -z "$connector_tags" ]; then
            connector_tags="$connector_tag"
          else
            connector_tags="$connector_tags,$connector_tag"
          fi
        done

        connector_tag="$connector_tags"
        array_flag_list+=("--connector-tag=$connector_tag")
        export CONNECTOR_TAG="$connector_tag"
      fi

      if [[ $res == *"$MENU_CONNECTOR_ZIP"* ]]
      then
        maybe_remove_flag "--connector-zip"
        maybe_remove_flag "--connector-tag"
        maybe_remove_flag "--connector-jar"
        cd $test_file_directory
        connector_zip=$(playground get-zip-or-jar-with-fzf --type zip)
        if [[ $connector_zip == *"@"* ]]
        then
          connector_zip=$(echo "$connector_zip" | cut -d "@" -f 2)
        fi
        array_flag_list+=("--connector-zip=$connector_zip")
        export CONNECTOR_ZIP=$connector_zip
      fi

      if [[ $res == *"$MENU_CONNECTOR_JAR"* ]]
      then
        maybe_remove_flag "--connector-zip"
        maybe_remove_flag "--connector-jar"
        cd $test_file_directory
        connector_jar=$(playground get-zip-or-jar-with-fzf --type jar)
        if [[ $connector_jar == *"@"* ]]
        then
          connector_jar=$(echo "$connector_jar" | cut -d "@" -f 2)
        fi
        array_flag_list+=("--connector-jar=$connector_jar")
        export CONNECTOR_JAR=$connector_jar
      fi

      if [[ $res == *"$MENU_CLUSTER_TYPE"* ]]
      then
        maybe_remove_flag "--cluster-type"
        options=(basic standard dedicated)
        cluster_type=$(printf '%s\n' "${options[@]}" | fzf --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🔋" --header="select a cluster type" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer)
        array_flag_list+=("--cluster-type $cluster_type")
  	  export CLUSTER_TYPE=$cluster_type
      fi

      if [[ $res == *"$MENU_CLUSTER_CLOUD"* ]]
      then
        maybe_remove_flag "--cluster-cloud"
        options=(aws gcp azure)
        cluster_cloud=$(printf '%s\n' "${options[@]}" | fzf --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🔋" --header="select a cluster type" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer)
        array_flag_list+=("--cluster-cloud $cluster_cloud")
  	  export CLUSTER_CLOUD=$cluster_cloud
      fi

      if [[ $res == *"$MENU_CLUSTER_REGION"* ]]
      then
        maybe_remove_flag "--cluster-region"
        cluster_region=$(playground get-kafka-region-list $cluster_cloud)

        if [[ $cluster_region == *"@"* ]]
        then
          cluster_region=$(echo "$cluster_region" | cut -d "@" -f 2)
        fi
        cluster_region=$(echo "$cluster_region" | sed 's/[[:blank:]]//g' | cut -d "/" -f 2)
        array_flag_list+=("--cluster-region $cluster_region")
  	  export CLUSTER_REGION=$cluster_region
      fi

      if [[ $res == *"$MENU_CLUSTER_ENVIRONMENT"* ]]
      then
        maybe_remove_flag "--cluster-environment"
        cluster_environment=$(playground get-ccloud-environment-list)

        if [[ $cluster_environment == *"@"* ]]
        then
          cluster_environment=$(echo "$cluster_environment" | cut -d "@" -f 2)
        fi
        if [[ $cluster_environment == *"/"* ]]
        then
          cluster_environment=$(echo "$cluster_environment" | sed 's/[[:blank:]]//g' | cut -d "/" -f 1)
        fi
        array_flag_list+=("--cluster-environment $cluster_environment")
  	  export ENVIRONMENT=$cluster_environment
      fi

      if [[ $res == *"$MENU_CLUSTER_NAME"* ]]
      then
        maybe_remove_flag "--cluster-name"
        cluster_name=$(playground get-ccloud-cluster-list)

        if [[ $cluster_name == *"@"* ]]
        then
          cluster_name=$(echo "$cluster_name" | cut -d "@" -f 2)
        fi
        if [[ $cluster_name == *"/"* ]]
        then
          cluster_name=$(echo "$cluster_name" | sed 's/[[:blank:]]//g' | cut -d "/" -f 2)
        fi
        array_flag_list+=("--cluster-name $cluster_name")
  	  export CLUSTER_NAME=$cluster_name
      fi

      if [[ $res == *"$MENU_CLUSTER_CREDS"* ]]
      then
        maybe_remove_flag "--cluster-creds"
        set +e
        cluster_creds=$(echo "" | fzf --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🔐" --header="Enter the Kafka api key and secret to use, it should be separated with colon (example: <API_KEY>:<API_KEY_SECRET>)" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_empty_pointer --print-query)
        set -e
        array_flag_list+=("--cluster-creds $cluster_creds")
  	  export CLUSTER_CREDS=$cluster_creds
      fi

      if [[ $res == *"$MENU_CLUSTER_SR_CREDS"* ]]
      then
        maybe_remove_flag "--cluster-schema-registry-creds"
        set +e
        cluster_schema_registry_creds=$(echo "" | fzf --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🔐" --header="Enter the Schema Registry api key and secret to use, it should be separated with colon (example: <SR_API_KEY>:<SR_API_KEY_SECRET>)" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_empty_pointer --print-query)
        set -e
        array_flag_list+=("--cluster-schema-registry-creds $cluster_schema_registry_creds")
  	  export SCHEMA_REGISTRY_CREDS=$cluster_schema_registry_creds
      fi
    done # end while loop stop

    if [ "$interactive_enable_ksqldb" == "true" ]
    then
      if [[ -n "$force_interactive_repro" ]]
      then
        force_enable --enable-ksqldb ENABLE_KSQLDB
      fi
    fi

    if [ "$interactive_enable_rp" == "true" ]
    then
      if [[ -n "$force_interactive_repro" ]]
      then
        force_enable --enable-rest-proxy ENABLE_RESTPROXY
      fi
    fi

    if [ "$interactive_enable_c3" == "true" ]
    then
      if [[ -n "$force_interactive_repro" ]]
      then
        force_enable --enable-control-center ENABLE_CONTROL_CENTER
      fi
    fi

    if [ "$interactive_enable_flink" == "true" ]
    then
      if [[ -n "$force_interactive_repro" ]]
      then
        force_enable --enable-flink ENABLE_FLINK
      fi
    fi

    if [ "$interactive_enable_conduktor" == "true" ]
    then
      if [[ -n "$force_interactive_repro" ]]
      then
        force_enable --enable-conduktor ENABLE_CONDUKTOR
      fi
    fi

    if [ "$interactive_enable_broker" == "true" ]
    then
      if [[ -n "$force_interactive_repro" ]]
      then
        force_enable --enable-multiple-brokers ENABLE_KAFKA_NODES
      fi
    fi

    if [ "$interactive_enable_connect" == "true" ]
    then
      if [[ -n "$force_interactive_repro" ]]
      then
        force_enable --enable-multiple-connect-workers ENABLE_CONNECT_NODES
      fi
    fi

    if [ "$interactive_enable_grafana" == "true" ]
    then
      if [[ -n "$force_interactive_repro" ]]
      then
        force_enable --enable-jmx-grafana ENABLE_JMX_GRAFANA
      fi
    fi

    if [ "$interactive_enable_kcat" == "true" ]
    then
      if [[ -n "$force_interactive_repro" ]]
      then
        force_enable --enable-kcat ENABLE_KCAT
      fi
    fi

    if [ "$interactive_enable_sql" == "true" ]
    then
      if [[ $test_file != *"fully-managed"* ]]
      then
        log "📊 automatically enabling Grafana as --enable-sql-datagen is set"
        if [[ -n "$force_interactive_repro" ]]
        then
          force_enable --enable-sql-datagen SQL_DATAGEN
          force_enable --enable-jmx-grafana ENABLE_JMX_GRAFANA
        fi
      fi
    fi

    if [[ -n "$cluster_type" ]] || [[ -n "$cluster_cloud" ]] || [[ -n "$cluster_region" ]] || [[ -n "$cluster_environment" ]] || [[ -n "$cluster_name" ]] || [[ -n "$cluster_creds" ]] || [[ -n "$cluster_schema_registry_creds" ]]
    then
      playground state set ccloud.suggest_use_previous_example_ccloud "0"

      if [[ -n "$cluster_type" ]]
      then
        export CLUSTER_TYPE=$cluster_type
      fi

      # default
      if [ -z "$CLUSTER_TYPE" ]
      then
        export CLUSTER_TYPE="basic"
      fi

      if [[ -n "$cluster_cloud" ]]
      then
        export CLUSTER_CLOUD=$cluster_cloud
      fi

      # default
      if [ -z "$CLUSTER_CLOUD" ]
      then
        export CLUSTER_CLOUD="aws"
      fi

      if [[ -n "$cluster_region" ]]
      then
        export CLUSTER_REGION=$cluster_region
      fi

      # default
      if [ -z "$CLUSTER_REGION" ]
      then
        case "${CLUSTER_CLOUD}" in
          aws)
            export CLUSTER_REGION="eu-west-2"
          ;;
          azure)
            export CLUSTER_REGION="westeurope"
          ;;
          gcp)
            export CLUSTER_REGION="europe-west2"
          ;;
        esac
      fi

      if [[ -n "$cluster_type" ]]
      then
        export CLUSTER_TYPE=$cluster_type
      fi

      if [[ -n "$cluster_environment" ]]
      then
        export ENVIRONMENT=$cluster_environment
      fi

      if [[ -n "$cluster_name" ]]
      then
        export CLUSTER_NAME=$cluster_name
      fi

      if [[ -n "$cluster_creds" ]]
      then
        export CLUSTER_CREDS=$cluster_creds
      fi

      if [[ -n "$cluster_schema_registry_creds" ]]
      then
        export SCHEMA_REGISTRY_CREDS=$cluster_schema_registry_creds
      fi
    else
      playground state set ccloud.suggest_use_previous_example_ccloud "1"
    fi
  fi # end of interactive_mode

  IFS=' ' flag_list="${array_flag_list[*]}"
  array_declaration=$(declare -p array_flag_list)
  encoded_array=$(echo "$array_declaration" | base64)
  playground state set run.array_flag_list_base64 "$encoded_array"

  if [ "$flag_list" != "" ]
  then
    if [[ $test_file == *"ccloud"* ]]
    then
      log "🚀⛅ Running ccloud example with flags"
    else
      log "🚀 Running example with flags"
    fi
    log "⛳ Flags used are $flag_list"
  else
    if [[ $test_file == *"ccloud"* ]]
    then
      log "🚀⛅ Running ccloud example without any flags"
    else
      log "🚀 Running example without any flags"
    fi
  fi

  playground state set run.connector_type "$(get_connector_type | tr -d '\n')"
  playground state set run.test_file "$test_file"
  echo "" >> "$root_folder/playground-run-history"
  echo "playground run -f $test_file $flag_list" >> "$root_folder/playground-run-history"

  if [[ "$OSTYPE" == "darwin"* ]]
  then
      clipboard=$(playground config get clipboard)
      if [ "$clipboard" == "" ]
      then
          playground config set clipboard true
      fi

      if [ "$clipboard" == "true" ] || [ "$clipboard" == "" ]
      then
          echo "playground run -f $test_file $flag_list" | pbcopy
          log "📋 command to run again example has been copied to the clipboard (disable with 'playground config clipboard false')"
      fi
  fi

  increment_cli_metric nb_runs
  log "🚀 Number of examples ran so far: $(get_cli_metric nb_runs)"
  set +e
  playground get-ci-result
  set -e
  log "####################################################"
  log "🚀 Executing $filename in dir $test_file_directory"
  log "####################################################"
  SECONDS=0
  cd $test_file_directory
  function cleanup {
    # 💡 Capture the original exit status immediately!
    local original_exit_status=$?
    set +e
    if [[ -n "$enable_multiple_connect_workers" ]]
    then
      if [ -f /tmp/playground-backup-docker-compose.yml ]
      then
        mv /tmp/playground-backup-docker-compose.yml $docker_compose_file
      fi
    fi
    rm /tmp/playground-run-command-used
    echo ""
    sleep 3

    connector_type=$(playground state get run.connector_type)

    if [ "$connector_type" == "$CONNECTOR_TYPE_ONPREM" ] || [ "$connector_type" == "$CONNECTOR_TYPE_SELF_MANAGED" ]
    then
        # playground connector-plugin display-last-updated
      if ! pgrep -f "playground connector-plugin display-last-updated" > /dev/null
      then
        if [ -f ${connector_plugin_display_last_updated_file} ]
        then
          cat ${connector_plugin_display_last_updated_file}
        fi
      fi

      playground connector versions
    fi

    if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
    then
      if [ "$connector_name" != "" ]
      then
        playground connector status --connector "$connector_name"
      fi
    elif [ "$connector_type" == "$CONNECTOR_TYPE_ONPREM" ] || [ "$connector_type" == "$CONNECTOR_TYPE_SELF_MANAGED" ]
    then
      playground connector status
    fi

    playground open-docs --only-show-url

      if [ -z "$GITHUB_RUN_NUMBER" ]
      then
          if [ "$connector_type" == "$CONNECTOR_TYPE_ONPREM" ] || [ "$connector_type" == "$CONNECTOR_TYPE_SELF_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ]

          then
              playground connector sourcecode --only-show-url
          fi
      fi

    if [ "$connector_type" == "$CONNECTOR_TYPE_ONPREM" ] || [ "$connector_type" == "$CONNECTOR_TYPE_SELF_MANAGED" ]
    then
      playground connector open-docs --only-show-url
    fi
    # 💡 Exit the function (and the script) with the captured status
    exit "$original_exit_status"
  }
  trap cleanup EXIT

  playground generate-fzf-find-files &
  generate_connector_versions > /dev/null 2>&1 &
  set +e

  connector_plugin_display_last_updated_file="/tmp/connector-plugin-display-last-updated-$(date +%Y-%m-%d).txt"
  connector_type=$(playground state get run.connector_type)
  if [ "$connector_type" == "$CONNECTOR_TYPE_ONPREM" ] || [ "$connector_type" == "$CONNECTOR_TYPE_SELF_MANAGED" ]
  then
    if [ ! -f ${connector_plugin_display_last_updated_file} ]
    then
      playground connector-plugin display-last-updated --days 3 --vendor confluentinc > ${connector_plugin_display_last_updated_file} &
    fi
  fi
  set -e
  touch /tmp/playground-run-command-used
  set +e
  bash $filename
  ret=$?
  ELAPSED="took: $((($SECONDS / 60) % 60))min $(($SECONDS % 60))sec"
  let ELAPSED_TOTAL+=$SECONDS
  # keep those lists up to date
  playground generate-tag-list > /dev/null 2>&1 &
  playground generate-connector-plugin-list > /dev/null 2>&1 &
  playground generate-kafka-region-list > /dev/null 2>&1 &
  set -e
  if [ $ret -eq 0 ]
  then
    log "####################################################"
    log "✅ RESULT: SUCCESS for $filename ($ELAPSED - $CUMULATED)"
    log "####################################################"
  else
    logerror "####################################################"
    logerror "🔥 RESULT: FAILURE for $filename ($ELAPSED - $CUMULATED)"
    logerror "####################################################"

    if [[ $test_file != *"fully-managed"* ]]
    then
      log "🧑‍🚒 you can troubleshoot the issue by running:"
      echo "playground container display-error-all-containers"
      log "🧑‍🚒 open full logs with '<playground container logs --open --container <container>', example:"
      echo "playground container logs --open --container connect"
    fi
    exit $ret
  fi
  check_for_ec2_instance_running

  if [ ! -z "$ENABLE_JMX_GRAFANA" ]
  then
    echo ""
    if [[ $test_file == *"ccloud"* ]]
    then
      log "🛡️ Prometheus is reachable at http://127.0.0.1:9090"
      log "📊 Grafana is reachable at http://127.0.0.1:3000 (login/password is admin/password)"
    else
      log "📛 Pyroscope is reachable at http://127.0.0.1:4040"
      log "🛡️ Prometheus is reachable at http://127.0.0.1:9090"
      log "📊 Grafana is reachable at http://127.0.0.1:3000 (login/password is admin/password) or JMX metrics are available locally on those ports:"
    fi

    if [ -z "$GITHUB_RUN_NUMBER" ]
    then
      automatically=$(playground config get open-grafana-in-browser.automatically)
      if [ "$automatically" == "" ]
      then
          playground config set open-grafana-in-browser.automatically true
      fi

      browser=$(playground config get open-grafana-in-browser.browser)
      if [ "$browser" == "" ]
      then
          playground config set open-grafana-in-browser.browser ""
      fi

      if [ "$automatically" == "true" ] || [ "$automatically" == "" ]
      then

        if [[ $(type -f open 2>&1) =~ "not found" ]]
        then
          log "🔗 Cannot open browser, use url:"
          echo "http://127.0.0.1:3000"
        else
          if [ "$browser" != "" ]
          then
            log "🤖 automatically (disable with 'playground config open-grafana-in-browser automatically false') open grafana in browser $browser (you can change browser with 'playground config open-grafana-in-browser browser <browser>')"
            log "🤖 Open grafana with browser $browser (login/password is admin/password)"
            open -a "$browser" "http://127.0.0.1:3000"
          else
            log "🤖 automatically (disable with 'playground config open-grafana-in-browser automatically false') open grafana in default browser (you can set browser with 'playground config open-grafana-in-browser browser <browser>')"
            log "🤖 Open grafana (login/password is admin/password)"
            open "http://127.0.0.1:3000"
          fi
        fi
      fi
    fi
  fi

  if [ -z "$GITHUB_RUN_NUMBER" ]
  then
    if [[ $test_file == *"ccloud"* ]]
    then
      echo ""
      # wait that process with "playground ccloud-costs-history" is finished
      set +e
      while pgrep -f "playground ccloud-costs-history" > /dev/null
      do
        log "⌛ wait for monthly ccloud costs..."
        sleep 5
      done
      set -e
      if [ -f /tmp/ccloud-costs-history.txt ]
      then
        log "📅💰 monthly ccloud costs"
        cat /tmp/ccloud-costs-history.txt
      fi
      log "👀 if you want more details, run <playground ccloud-costs-history --detailed>"
    fi
  fi
}

# :command.function
playground_re_run_command() {

  # src/commands/re-run.sh
  test_file=$(playground state get run.test_file)

  if [ ! -f $test_file ]
  then
    logerror "❌ file $test_file retrieved from $root_folder/playground.ini does not exist!"
    exit 1
  fi

  declare -a array_flag_list=()
  encoded_array="$(playground state get run.array_flag_list_base64)"
  eval "$(echo "$encoded_array" | base64 -d)"
  IFS=' ' flag_list="${array_flag_list[*]}"

  log "⚡ re-run with playground run -f \"$test_file\" $flag_list"
  playground run -f "$test_file" $flag_list --force-interactive-re-run
}

# :command.function
playground_get_ci_result_command() {

  # src/commands/get-ci-result.sh
  test_file=$(playground state get run.test_file)

  if [ ! -f $test_file ]
  then

      logerror "File $test_file retrieved from $root_folder/playground.ini does not exist!"
      exit 1
  fi

  test_file_directory="$(dirname "${test_file}")"
  base1="${test_file_directory##*/}" # connect-cdc-oracle12-source
  dir1="${test_file_directory%/*}" #connect
  dir2="${dir1##*/}/$base1" # connect/connect-cdc-oracle12-source

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  if [[ "$dir2" == reproduction-models* ]]
  then
      exit 0
  fi

  content_file="$tmp_dir/content.md"
  curl -s -o $content_file  https://raw.githubusercontent.com/vdesabou/kafka-docker-playground-docs/main/docs/content.md

  result_ok="$(grep "$dir2" $content_file | sed -n 's/.*\[CI \(ok\)\].*(\(https[^)]*\)).*/🤖CI status: 🟢 ok\n🔗test url: \2/p')"
  result_fail="$(grep "$dir2" $content_file | sed -n 's/.*\[CI \(fail\)\].*(\(https[^)]*\)).*/🤖CI status: 🔴 fail\n🐛 github issue: \2/p')"
  result_not_tested="$(grep "$dir2" $content_file | sed -n 's/.*\[not tested\].*/🤖CI status: 🤷‍♂️ not tested/p')"

  # print only result not empty
  if [ -n "$result_ok" ]
  then
      log "$result_ok"
  fi

  if [ -n "$result_fail" ]
  then
      logwarn "$result_fail"
  fi

  if [ -n "$result_not_tested" ]
  then
      log "$result_not_tested"
  fi
}

# :command.function
playground_history_command() {

  # src/commands/history.sh
  if [ ! -f $root_folder/playground-run-history ]
  then
      logerror "❌ history could not be found !"
      logerror "$root_folder/playground-run-history does not exist"
      exit 1
  fi

  fzf_version=$(get_fzf_version)
  if version_gt $fzf_version "0.38"
  then
      fzf_option_wrap="--preview-window=40%,wrap"
      fzf_option_pointer="--pointer=👉"
      fzf_option_rounded="--border=rounded"
  else
      fzf_options=""
      fzf_option_pointer=""
      fzf_option_rounded=""
  fi

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  tac $root_folder/playground-run-history > $tmp_dir/tmp
  awk '!seen[$0]++' $tmp_dir/tmp > $tmp_dir/tmp2
  res=$(cat $tmp_dir/tmp2 | sed '/^$/d' | fzf --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🏰" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" --delimiter "kafka-docker-playground" --with-nth "2,3,4" $fzf_option_wrap $fzf_option_pointer)

  # Prompt the user to edit the res variable
  read -e -p "" -i "$res" edited_res

  # Use the edited value if it is not empty
  if [[ -n "$edited_res" ]]
  then
    res="$edited_res"
  fi

  $res
}

# :command.function
playground_start_environment_command() {

  # src/commands/start-environment.sh
  IGNORE_CHECK_FOR_DOCKER_COMPOSE=true

  environment="${args[--environment]}"
  docker_compose_override_file="${args[--docker-compose-override-file]}"
  wait_for_control_center="${args[--wait-for-control-center]}"

  if [ "$environment" = "ccloud" ]
  then
    test_file="$root_folder/ccloud/environment/start.sh"
  else
    test_file="$root_folder/environment/$environment/start.sh"
  fi
  test_file_directory="$(dirname "${test_file}")"

  set +e
  container_kill_all_before_run=$(playground config get container-kill-all-before-run)
  if [ "$container_kill_all_before_run" == "" ]
  then
      playground config set container-kill-all-before-run false
  fi

  if [ "$container_kill_all_before_run" == "true" ] || [ "$container_kill_all_before_run" == "" ]
  then
    log "💀 kill all docker containers (disable with 'playground config container-kill-all-before-run false')"
    playground container kill-all
  else
    playground stop
  fi
  set -e

  if [[ -n "$wait_for_control_center" ]]
  then
    export WAIT_FOR_CONTROL_CENTER=1
  fi

  cd $test_file_directory
  if [ -f $docker_compose_override_file ]
  then
    $test_file "$docker_compose_override_file"
  else
    $test_file
  fi
}

# :command.function
playground_switch_ccloud_command() {

  # src/commands/switch-ccloud.sh
  log "🌩️ switch to ccloud environment"

  for item in {ENVIRONMENT,CLUSTER_NAME,CLUSTER_CLOUD,CLUSTER_REGION,CLUSTER_CREDS,SCHEMA_REGISTRY_CREDS}
  do
      i=$(playground state get "ccloud.${item}")
      if [ "$i" == "" ]
      then
          logerror "ccloud.${item} is missing"
          logerror "a ccloud example was probably not executed before"
          exit 1
      fi
  done

  ENVIRONMENT=$(playground state get ccloud.ENVIRONMENT)
  CLUSTER_NAME=$(playground state get ccloud.CLUSTER_NAME)
  CLUSTER_CLOUD=$(playground state get ccloud.CLUSTER_CLOUD)
  CLUSTER_REGION=$(playground state get ccloud.CLUSTER_REGION)
  CLUSTER_CREDS=$(playground state get ccloud.CLUSTER_CREDS)
  SCHEMA_REGISTRY_CREDS=$(playground state get ccloud.SCHEMA_REGISTRY_CREDS)

  playground state set run.environment_before_switch "$(playground state get run.environment)"
  playground state set run.connector_type_before_switch "$(playground state get run.connector_type)"
  playground state set run.connector_type "$CONNECTOR_TYPE_FULLY_MANAGED"

  log "🔌 boostrapping ccloud environment"
  bootstrap_ccloud_environment
}

# :command.function
playground_switch_back_command() {

  # src/commands/switch-back.sh
  environment_before_switch=$(playground state get run.environment_before_switch)
  if [ "$environment_before_switch" == "" ]
  then
      logerror "switch-ccloud was probably not executed before"
      exit 1
  fi
  connector_type_before_switch=$(playground state get run.connector_type_before_switch)

  if [ "$connector_type_before_switch" != "" ]
  then
      log "💺 Switch back to previous environment ($environment_before_switch) with $connector_type_before_switch connector"
  else
      log "💺 Switch back to previous environment ($environment_before_switch)"
  fi

  playground state set run.environment "$environment_before_switch"
  playground state del run.environment_before_switch
  playground state set run.connector_type "$connector_type_before_switch"
  playground state del run.connector_type_before_switch

  test_file=$(playground state get run.test_file)

  if [ ! -f $test_file ]
  then

      logerror "File $test_file retrieved from $root_folder/playground.ini does not exist!"
      exit 1
  fi

  last_two_folders=$(basename $(dirname $(dirname $test_file)))/$(basename $(dirname $test_file))
  filename=$(basename $test_file)

  log "🚀 Running example "
  echo $last_two_folders/$filename
}

# :command.function
playground_update_version_command() {

  # src/commands/update-version.sh
  tag="${args[--tag]}"
  connect_tag="${args[--connect-tag]}"
  connector_tag="${args[--connector-tag]}"
  connector_zip="${args[--connector-zip]}"
  connector_jar="${args[--connector-jar]}"

  test_file=$(playground state get run.test_file)

  if [ ! -f $test_file ]
  then

      logerror "File $test_file retrieved from $root_folder/playground.ini does not exist!"
      exit 1
  fi

  # determining the docker-compose file from from test_file
  docker_compose_file=$(grep "start-environment" "$test_file" |  awk '{print $6}' | cut -d "/" -f 2 | cut -d '"' -f 1 | tail -n1 | xargs)
  test_file_directory="$(dirname "${test_file}")"
  docker_compose_file="${test_file_directory}/${docker_compose_file}"

  docker_compose_file_available=1
  if [ "${docker_compose_file}" != "" ] && [ ! -f "${docker_compose_file}" ]
  then
    docker_compose_file_available=0
  fi

  current_tag=$(docker inspect -f '{{.Config.Image}}' broker 2> /dev/null | cut -d ":" -f 2)
  if [ "$current_tag" == "" ]
  then
    logerror "❌ Could not retrieve current cp version (using broker container)"
    exit 1
  fi

  current_connect_tag=$(docker inspect -f '{{.Config.Image}}' connect 2> /dev/null | cut -d ":" -f 2)
  if [ "$current_connect_tag" == "" ]
  then
    logerror "❌ Could not retrieve current cp connect version (using connect container)"
    exit 1
  fi

  declare -a array_flag_list=()
  if [[ -n "$tag" ]]
  then
    if [[ $tag == *"@"* ]]
    then
      tag=$(echo "$tag" | cut -d "@" -f 2)
    fi
    array_flag_list+=("--tag=$tag")
    export TAG=$tag
  fi

  if [[ -n "$connect_tag" ]]
  then
    if [[ $connect_tag == *"@"* ]]
    then
      connect_tag=$(echo "$connect_tag" | cut -d "@" -f 2)
    fi
    array_flag_list+=("--connect-tag=$connect_tag")
    export CP_CONNECT_TAG=$connect_tag
  fi

  if [[ -n "$connector_tag" ]]
  then
    if [ "$connector_tag" == " " ]
    then
      get_connector_paths
      if [ "$connector_paths" == "" ]
      then
          logwarn "❌ skipping as it is not an example with connector, but --connector-tag is set"
          exit 1
      else
          connector_tags=""
          for connector_path in ${connector_paths//,/ }
          do
            full_connector_name=$(basename "$connector_path")
            owner=$(echo "$full_connector_name" | cut -d'-' -f1)
            name=$(echo "$full_connector_name" | cut -d'-' -f2-)

            if [ "$owner" == "java" ] || [ "$name" == "hub-components" ] || [ "$owner" == "filestream" ]
            then
              # happens when plugin is not coming from confluent hub
              # logwarn "skipping as plugin $owner/$name does not appear to be coming from confluent hub"
              continue
            fi

            ret=$(choose_connector_tag "$owner/$name")
            connector_tag=$(echo "$ret" | cut -d ' ' -f 2 | sed 's/^v//')

            if [ -z "$connector_tags" ]; then
              connector_tags="$connector_tag"
            else
              connector_tags="$connector_tags,$connector_tag"
            fi
          done

          connector_tag="$connector_tags"
      fi
    fi

    array_flag_list+=("--connector-tag=$connector_tag")
    export CONNECTOR_TAG="$connector_tag"
  fi

  if [[ -n "$connector_zip" ]]
  then
    if [[ $connector_zip == *"@"* ]]
    then
      connector_zip=$(echo "$connector_zip" | cut -d "@" -f 2)
    fi
    array_flag_list+=("--connector-zip=$connector_zip")
    export CONNECTOR_ZIP=$connector_zip
  fi

  if [[ -n "$connector_jar" ]]
  then
    if [[ $connector_jar == *"@"* ]]
    then
      connector_jar=$(echo "$connector_jar" | cut -d "@" -f 2)
    fi
    array_flag_list+=("--connector-jar=$connector_jar")
    export CONNECTOR_JAR=$connector_jar
  fi

  IFS=' ' flag_list="${array_flag_list[*]}"
  if [ "$flag_list" == "" ]
  then
    docs_available=1
    set +e
    playground open-docs --only-show-url > /dev/null 2>&1
    if [ $? -eq 1 ]
    then
      docs_available=0
    fi
    set -e

    terminal_columns=$(tput cols)
    if [[ $terminal_columns -gt 180 ]]
    then
      MAX_LENGTH=$((${terminal_columns}-120))
      fzf_version=$(get_fzf_version)
      if version_gt $fzf_version "0.38"
      then
        fzf_option_wrap="--preview-window=30%,wrap"
        fzf_option_pointer="--pointer=👉"
        fzf_option_empty_pointer=""
        fzf_option_rounded="--border=rounded"
      else
        fzf_option_wrap=""
        fzf_option_pointer=""
        fzf_option_empty_pointer=""
        fzf_option_rounded=""
      fi
    else
      MAX_LENGTH=$((${terminal_columns}-65))
      fzf_version=$(get_fzf_version)
      if version_gt $fzf_version "0.38"
      then
        fzf_option_wrap="--preview-window=20%,wrap"
        fzf_option_pointer="--pointer=👉"
        fzf_option_empty_pointer=""
        fzf_option_rounded="--border=rounded"
      else
        fzf_option_wrap=""
        fzf_option_pointer=""
        fzf_option_empty_pointer=""
        fzf_option_rounded=""
      fi
    fi

    connector_example=0
    current_versions=""
    get_connector_paths
    if [ "$connector_paths" != "" ]
    then
      connector_tags=""
      for connector_path in ${connector_paths//,/ }
      do
        full_connector_name=$(basename "$connector_path")
        owner=$(echo "$full_connector_name" | cut -d'-' -f1)
        name=$(echo "$full_connector_name" | cut -d'-' -f2-)

        if [ "$owner" == "java" ] || [ "$name" == "hub-components" ] || [ "$owner" == "filestream" ]
        then
          # happens when plugin is not coming from confluent hub
          continue
        else

          manifest_file="$root_folder/confluent-hub/$full_connector_name/manifest.json"
          if [ -f $manifest_file ]
          then
            current_version=$(cat $manifest_file | jq -r '.version')
            # release_date=$(cat $manifest_file | jq -r '.release_date')

            if [ -z "$current_versions" ]; then
              current_versions="$current_version"
            else
              current_versions="$current_versions,$current_version"
            fi
          else
            change_detected=1
          fi
          connector_example=1
        fi
      done
    fi

    # readonly MENU_LETS_GO="🚀 Run the example !" #0
    readonly MENU_OPEN_FILE="📖 Open the file in text editor"
    set +e
    if [[ $(type -f open 2>&1) =~ "not found" ]]
    then
      MENU_OPEN_DOCS="🌐 Show link to the docs"
    else
      MENU_OPEN_DOCS="🌐 Open the docs in browser"
    fi
    set -e
    readonly MENU_SEPARATOR="--------------------------------------------------" #3
    MENU_TAG="🎯 CP version (all components) (current $current_tag) $(printf '%*s' $((${MAX_LENGTH}-46-${#MENU_TAG})) ' ') --tag" #4
    MENU_CONNECT_TAG="🔗 CP version (connect only) (current $current_connect_tag) $(printf '%*s' $((${MAX_LENGTH}-44-${#MENU_CONNECT_TAG})) ' ') --connect-tag"
    MENU_CONNECTOR_TAG="🔌 Connector version (current $current_versions) $(printf '%*s' $((${MAX_LENGTH}-37-${#MENU_CONNECTOR_TAG})) ' ') --connector-tag"
    MENU_CONNECTOR_ZIP="🤐 Connector zip $(printf '%*s' $((${MAX_LENGTH}-16-${#MENU_CONNECTOR_ZIP})) ' ') --connector-zip"
    MENU_CONNECTOR_JAR="🤎 Connector jar $(printf '%*s' $((${MAX_LENGTH}-16-${#MENU_CONNECTOR_JAR})) ' ') --connector-jar"

    readonly MENU_GO_BACK="🔙 Go back"

    last_two_folders=$(basename $(dirname $(dirname $test_file)))/$(basename $(dirname $test_file))
    example="$last_two_folders/$filename"

    stop=0
    change_detected=0
    while [ $stop != 1 ]
    do
      if [ $change_detected -eq 0 ]
      then
        MENU_LETS_GO="❌ No version change detected !" #0
      else
        MENU_LETS_GO="🚀 Run the example !" #0
      fi
      options=("$MENU_LETS_GO" "$MENU_OPEN_FILE" "$MENU_OPEN_DOCS" "$MENU_SEPARATOR" "$MENU_TAG" "$MENU_CONNECT_TAG" "$MENU_CONNECTOR_TAG" "$MENU_CONNECTOR_ZIP" "$MENU_CONNECTOR_JAR" "$MENU_GO_BACK")

      if [[ $test_file == *"ccloud"* ]] || [ "$PLAYGROUND_ENVIRONMENT" == "ccloud" ]
      then
        if [[ $test_file == *"fully-managed"* ]]
        then
          unset 'options[5]'
          unset 'options[6]'
          unset 'options[7]'
          unset 'options[8]'
        fi
      fi

      if [ $connector_example == 0 ] || [ $docker_compose_file_available == 0 ]
      then
        unset 'options[6]'
        unset 'options[7]'
        unset 'options[8]'
      fi

      if [ $docs_available == 0 ]
      then
        unset 'options[2]'
      fi

      oldifs=$IFS
      IFS=$'\n' flag_string="${array_flag_list[*]}"
      IFS=$oldifs

      preview="\n🚀 number of examples ran so far: $(get_cli_metric nb_runs)\n\n⛳ flag list:\n$flag_string\n"
      res=$(printf '%s\n' "${options[@]}" | fzf --multi --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🚀" --header="select option(s) for $example (use tab to select more than one)" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer --preview "echo -e \"$preview\"")

      if [[ $res == *"$MENU_LETS_GO"* ]]
      then
        stop=1
      fi

      if [[ $res == *"$MENU_OPEN_FILE"* ]]
      then
        playground open --file "${test_file}"
      fi

      if [[ $res == *"$MENU_OPEN_DOCS"* ]]
      then
        if [[ $(type -f open 2>&1) =~ "not found" ]]
        then
          playground open-docs --only-show-url
        else
          playground open-docs
        fi
      fi

      if [[ $res == *"$MENU_GO_BACK"* ]]
      then
        stop=1
        playground update-versions
      fi

      if [[ $res == *"$MENU_TAG"* ]]
      then
        tag=$(playground get-tag-list)
        if [[ $tag == *"@"* ]]
        then
          tag=$(echo "$tag" | cut -d "@" -f 2)
        fi
        if [[ $tag == *" "* ]]
        then
          tag=$(echo "$tag" | cut -d " " -f 1)
        fi

        if [ "$current_tag" != "$tag" ]
        then
          change_detected=1
          maybe_remove_flag "--tag"
          array_flag_list+=("--tag=$tag")
          export TAG=$tag
        fi
      fi

      if [[ $res == *"$MENU_CONNECT_TAG"* ]]
      then
        connect_tag=$(playground get-tag-list --connect-only)
        if [[ $connect_tag == *"@"* ]]
        then
          connect_tag=$(echo "$connect_tag" | cut -d "@" -f 2)
        fi
        if [[ $connect_tag == *" "* ]]
        then
          connect_tag=$(echo "$connect_tag" | cut -d " " -f 1)
        fi

        if [ "$current_connect_tag" != "$connect_tag" ]
        then
          change_detected=1
          maybe_remove_flag "--connect-tag"
          array_flag_list+=("--connect-tag=$connect_tag")
          export CP_CONNECT_TAG=$connect_tag
        fi
      fi

      if [[ $res == *"$MENU_CONNECTOR_TAG"* ]]
      then
        maybe_remove_flag "--connector-zip"
        maybe_remove_flag "--connector-tag"
        connector_tags=""
        for connector_path in ${connector_paths//,/ }
        do
          full_connector_name=$(basename "$connector_path")
          owner=$(echo "$full_connector_name" | cut -d'-' -f1)
          name=$(echo "$full_connector_name" | cut -d'-' -f2-)

          if [ "$owner" == "java" ] || [ "$name" == "hub-components" ] || [ "$owner" == "filestream" ]
          then
            # happens when plugin is not coming from confluent hub
            continue
          fi

          manifest_file="$root_folder/confluent-hub/$full_connector_name/manifest.json"
          if [ -f $manifest_file ]
          then
            current_version=$(cat $manifest_file | jq -r '.version')
            # release_date=$(cat $manifest_file | jq -r '.release_date')
          else
            change_detected=1
          fi

          ret=$(choose_connector_tag "$owner/$name")
          connector_tag=$(echo "$ret" | cut -d ' ' -f 2 | sed 's/^v//')

          if [ "$current_version" != "$connector_tag" ]
          then
            change_detected=1
          fi

          if [ -z "$connector_tags" ]; then
            connector_tags="$connector_tag"
          else
            connector_tags="$connector_tags,$connector_tag"
          fi
        done

        connector_tag="$connector_tags"
        array_flag_list+=("--connector-tag=$connector_tag")
        export CONNECTOR_TAG="$connector_tag"
      fi

      if [[ $res == *"$MENU_CONNECTOR_ZIP"* ]]
      then
        maybe_remove_flag "--connector-zip"
        maybe_remove_flag "--connector-tag"
        maybe_remove_flag "--connector-jar"
        connector_zip=$(playground get-zip-or-jar-with-fzf --type zip)
        if [[ $connector_zip == *"@"* ]]
        then
          connector_zip=$(echo "$connector_zip" | cut -d "@" -f 2)
        fi
        change_detected=1
        array_flag_list+=("--connector-zip=$connector_zip")
        export CONNECTOR_ZIP=$connector_zip
      fi

      if [[ $res == *"$MENU_CONNECTOR_JAR"* ]]
      then
        maybe_remove_flag "--connector-zip"
        maybe_remove_flag "--connector-jar"
        connector_jar=$(playground get-zip-or-jar-with-fzf --type jar)
        if [[ $connector_jar == *"@"* ]]
        then
          connector_jar=$(echo "$connector_jar" | cut -d "@" -f 2)
        fi
        change_detected=1
        array_flag_list+=("--connector-jar=$connector_jar")
        export CONNECTOR_JAR=$connector_jar
      fi
    done # end while loop stop
  fi

  tag_changed=0
  IFS=' ' flag_list="${array_flag_list[*]}"
  if [[ -n "$tag" ]]
  then
    current_tag=$(docker inspect -f '{{.Config.Image}}' broker 2> /dev/null | cut -d ":" -f 2)

    if [ "$current_tag" == "" ]
    then
      logerror "❌ Could not retrieve current cp version (using broker container)"
      exit 1
    fi

    if [ "$current_tag" == "$tag" ]
    then
      logwarn "--tag=$tag is same as current tag, ignoring..."
      array_flag_list=("${array_flag_list[@]/"--tag"}")
    else
      tag_changed=1
    fi
  fi

  if [[ -n "$connect_tag" ]]
  then
    current_connect_tag=$(docker inspect -f '{{.Config.Image}}' connect 2> /dev/null | cut -d ":" -f 2)

    if [ "$current_connect_tag" == "" ]
    then
      logerror "❌ Could not retrieve current cp version (using connect container)"
      exit 1
    fi

    if [ "$current_connect_tag" == "$connect_tag" ]
    then
      logwarn "--connect-tag=$connect_tag is same as current connect-tag, ignoring..."
      array_flag_list=("${array_flag_list[@]/"--connect-tag"}")
    else
      tag_changed=1
    fi
  fi

  if [ $docker_compose_file_available == 1 ]
  then
    export DOCKER_COMPOSE_FILE_UPDATE_VERSION="$docker_compose_file"
  fi

  IFS=' ' flag_list="${array_flag_list[*]}"
  if [ "$flag_list" != "" ]
  then
    log "✨ Loading new version(s) based on flags ⛳ $flag_list"
  else
    log "✨ Loading new version(s) without any flags ⛳"
  fi

  if [ $tag_changed -eq 1 ]
  then
      log "💣 Detected confluent version change, restarting containers"
      playground container recreate --ignore-current-versions
  else
      # in case there is a change in docker-compose...
      playground container recreate
  fi

  if [[ -n "$connector_tag" ]] || [[ -n "$connector_zip" ]] || [[ -n "$connector_jar" ]]
  then
      if [ $tag_changed -eq 0 ]
      then
          log "🧩 a connector flag is set: restarting connect container to make sure new version(s) are used"
          playground container restart --container connect
      fi
      sleep 5

      wait_container_ready

      sleep 10

      playground connector versions
  else
      sleep 4

      wait_container_ready
  fi
}

# :command.function
playground_open_command() {

  # src/commands/open.sh
  test_file="${args[--file]}"
  wait="${args[--wait]}"
  open_docker_compose="${args[--open-docker-compose]}"

  if [[ -n "$test_file" ]]
  then
    if [[ $test_file == *"@"* ]]
    then
      test_file=$(echo "$test_file" | cut -d "@" -f 2)
    fi
  else
    test_file=$(playground state get run.test_file)

    if [ ! -f $test_file ]
    then

        logerror "File $test_file retrieved from $root_folder/playground.ini does not exist!"
        exit 1
    fi
  fi

  do_wait=""
  if [[ -n "$wait" ]]
  then
    do_wait="wait"
  fi

  if [[ -n "$open_docker_compose" ]]
  then
    # determining the docker-compose file from from test_file
    docker_compose_file=$(grep "start-environment" "$test_file" |  awk '{print $6}' | cut -d "/" -f 2 | cut -d '"' -f 1 | tail -n1 | xargs)
    test_file_directory="$(dirname "${test_file}")"
    docker_compose_file="${test_file_directory}/${docker_compose_file}"
    if [ ! -f $docker_compose_file ]
    then
      logwarn "--open-docker-compose is set but docker compose file could not be retrieved from $test_file"
    else
      open_file_with_editor "${docker_compose_file}"
    fi

  fi

  open_file_with_editor "${test_file}" "${do_wait}"
}

# :command.function
playground_stop_command() {

  # src/commands/stop.sh
  test_file=$(playground state get run.test_file)

  if [ ! -f $test_file ]
  then

      logerror "File $test_file retrieved from $root_folder/playground.ini does not exist!"
      exit 1
  fi
  export flink_connectors=""
  filename=$(basename -- "$test_file")
  test_file_directory="$(dirname "${test_file}")"

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  log "🛑 Stopping example $filename in dir $test_file_directory"
  docker_command=$(playground state get run.docker_command)
  echo "$docker_command" > $tmp_dir/tmp

  sed -e "s|up -d|down -v --remove-orphans|g" \
      $tmp_dir/tmp > $tmp_dir/tmp2

  sed -e "s|--quiet-pull||g" \
      $tmp_dir/tmp2 > $tmp_dir/playground-command-stop

  bash $tmp_dir/playground-command-stop
}

# :command.function
playground_remove_all_docker_images_command() {

  # src/commands/remove-all-docker-images.sh
  log "🧨 Remove all docker images (including docker volumes)"
  check_if_continue

  set +e
  playground container kill-all
  docker image rm $(docker image list | grep -v "oracle/database"  | grep -v "db-prebuilt" | awk 'NR>1 {print $3}') -f
  docker system prune -a -f
  docker volume rm $(docker volume ls -qf dangling=true)
}

# :command.function
playground_remove_cp_docker_images_command() {

  # src/commands/remove-cp-docker-images.sh
  version=${args[--version]}

  if [[ -n "$version" ]]
  then
      log "🧹 removing Confluent Platform docker images: $version"
      check_if_continue
      docker image ls | grep confluentinc | grep $version | awk '{print $3}' | xargs docker rmi -f
      exit 0
  fi

  LATEST_TAG=$(grep "export TAG" $root_folder/scripts/utils.sh | head -1 | cut -d "=" -f 2 | cut -d " " -f 1)
  if [ -z "$LATEST_TAG" ]
  then
      logerror "❌ error while getting default TAG "
      exit 1
  fi

  for version in $(docker image ls | grep confluentinc | grep -v "<none>" | grep -Ev "latest|2.0.0|$LATEST_TAG"  | awk '{print $2}' | sort | uniq);
  do
      log "🧹 removing Confluent Platform docker images: $version (skipping default TAG $LATEST_TAG)"
      check_if_continue
      docker image ls | grep confluentinc | grep $version | awk '{print $3}' | xargs docker rmi -f
  done

}

# :command.function
playground_refresh_cp_docker_images_command() {

  # src/commands/refresh-cp-docker-images.sh
  version=${args[--version]}

  docker pull amazon/aws-cli
  docker pull mcr.microsoft.com/azure-cli:azurelinux3.0
  docker pull google/cloud-sdk:latest

  if [[ -n "$version" ]]
  then
      log "🔄 Pulling Confluent Platform docker images for $version"
      docker image ls | grep confluentinc | grep $version | awk '{print $1":"$2}' | xargs -I {} docker pull {}
      exit 0
  fi
}

# :command.function
playground_cleanup_cloud_details_command() {

  # src/commands/cleanup-cloud-details.sh
  if [ -d $root_folder/.ccloud ]
  then
      log "🧼 removing folder $root_folder/.ccloud"
      rm -rf $root_folder/.ccloud
  fi

  playground state del ccloud.ENVIRONMENT
  playground state del ccloud.CLUSTER_NAME
  playground state del ccloud.CLUSTER_CLOUD
  playground state del ccloud.CLUSTER_REGION
  playground state del ccloud.CLUSTER_CREDS
  playground state del ccloud.SCHEMA_REGISTRY_CREDS
  playground state del ccloud.suggest_use_previous_example_ccloud
}

# :command.function
playground_open_docs_command() {

  # src/commands/open-docs.sh
  only_show_url="${args[--only-show-url]}"
  test_file=$(playground state get run.test_file)

  if [ ! -f $test_file ]
  then

      logerror "File $test_file retrieved from $root_folder/playground.ini does not exist!"
      exit 1
  fi

  readme_file="$(dirname $test_file)/README.md"
  if [ ! -f $readme_file ]
  then

      logwarn "README file $readme_file does not exist, ignoring"
      exit 0
  fi

  string=$(grep "Quickly test " $readme_file)
  url=$(echo "$string" | grep -oE 'https?://[^ ]+')
  url=${url//)/}

  if [[ $url =~ "http" ]]
  then
      short_url=$(echo $url | cut -d '#' -f 1)
      if [[ -n "$only_show_url" ]] || [[ $(type -f open 2>&1) =~ "not found" ]]
      then
          log "🌐 documentation is available at:"
          echo "$short_url"
      else
          log "🌐 opening documentation $short_url"
          open "$short_url"
      fi
  else
      logerror "Could not find documentation link in README file $readme_file"
      exit 1
  fi
}

# :command.function
playground_open_changelog_command() {

  # src/commands/open-changelog.sh
  only_show_url="${args[--only-show-url]}"

  if [[ -n "$only_show_url" ]] || [[ $(type -f open 2>&1) =~ "not found" ]]
  then
      log "📜 changelog is available at:"
      echo "https://kafka-docker-playground.io/#/changelog"
  else
      log "📜 opening changelog https://kafka-docker-playground.io/#/changelog"
      open "https://kafka-docker-playground.io/#/changelog"
  fi
}

# :command.function
playground_cleanup_cloud_resources_command() {

  # src/commands/cleanup-cloud-resources.sh
  user="${args[--user]}"
  force="${args[--force]}"
  # Convert the space delimited string to an array
  eval "resources=(${args[--resource]})"

  set +e
  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  if [[ ! -n "$user" ]]
  then
      user="${USER}"
  fi

  function cleanup_aws () {
      if [ ! -f $HOME/.aws/credentials ] && ( [ -z "$AWS_ACCESS_KEY_ID" ] || [ -z "$AWS_SECRET_ACCESS_KEY" ] )
      then
          logerror "❌ either the file $HOME/.aws/credentials is not present or environment variables AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY are not set!"
          exit 1
      else
          if [ ! -z "$AWS_ACCESS_KEY_ID" ] && [ ! -z "$AWS_SECRET_ACCESS_KEY" ]
          then
              log "💭 Using environment variables AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY"
              export AWS_ACCESS_KEY_ID
              export AWS_SECRET_ACCESS_KEY
          else
              if [ -f $HOME/.aws/credentials ]
              then
                  logwarn "💭 AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY are set based on $HOME/.aws/credentials"
                  export AWS_ACCESS_KEY_ID=$( grep "^aws_access_key_id" $HOME/.aws/credentials | head -1 | awk -F'=' '{print $2;}' )
                  export AWS_SECRET_ACCESS_KEY=$( grep "^aws_secret_access_key" $HOME/.aws/credentials | head -1 | awk -F'=' '{print $2;}' )

              fi
          fi
          if [ -z "$AWS_REGION" ]
          then
              AWS_REGION=$(aws configure get region | tr '\r' '\n')
              if [ "$AWS_REGION" == "" ]
              then
                  logerror "❌ either the file $HOME/.aws/config is not present or environment variables AWS_REGION is not set!"
                  exit 1
              fi
          fi
      fi

      log "Cleanup AWS Kinesis streams"
      for stream in $(aws kinesis list-streams --region $AWS_REGION | jq '.StreamNames[]' -r)
      do
          if [[ $stream = *pg${user}* ]]
          then
              log "Removing AWS Kinesis stream $stream"
              check_if_skip "aws kinesis delete-stream --stream-name $stream --region $AWS_REGION"
          fi
      done

      log "Cleanup AWS SQS queues"
      for queue in $(aws sqs list-queues --region $AWS_REGION | jq '.QueueUrls[]' -r)
      do
          if [[ $queue = *pg${user}* ]]
          then
              log "Removing AWS SQS queue $queue"
              check_if_skip "aws sqs delete-queue --queue-url ${queue}"
          fi
      done

      log "Cleanup AWS Lambda functions"
      for function in $(aws lambda list-functions --region $AWS_REGION | jq '.Functions[].FunctionName' -r)
      do
          if [[ $function = *pglambdafunction* ]] || [[ $function = *pg${user}* ]]
          then
              log "Removing AWS Lambda function $function"
              check_if_skip "aws lambda delete-function --function-name ${function}"
          fi
      done

      log "Cleanup AWS Lambda IAM roles"
      for role in $(aws iam list-roles --region $AWS_REGION | jq '.Roles[].RoleName' -r)
      do
          if [[ $role = *pglambdarole* ]] || [[ $role = *pg${user}* ]]
          then
              log "Removing AWS Lambda role $role"
              check_if_skip "aws iam delete-role --role-name ${role}"
          fi
      done

      log "Cleanup AWS CloudWatch log group"
      for log_group in $(aws logs describe-log-groups --region $AWS_REGION | jq '.logGroups[].logGroupName' -r)
      do
          if [[ $log_group = *myloggroup* ]] || [[ $log_group = *pg${user}* ]]
          then
              for log_stream in $(aws logs describe-log-streams --log-group-name $log_group --region $AWS_REGION | jq '.logStreams[].logStreamName' -r)
              do
                  log "Removing AWS CloudWatch log stream $log_stream for log group $log_group"
                  check_if_skip "aws logs delete-log-stream --log-group-name ${log_group} --log-stream-name ${log_stream}"
              done

              log "Removing AWS CloudWatch log group $log_group"
              check_if_skip "aws logs delete-log-group --log-group-name ${log_group}"
          fi
      done

      log "Cleanup AWS Redshift clusters"
      for cluster in $(aws redshift describe-clusters --region $AWS_REGION | jq '.Clusters[].ClusterIdentifier' -r)
      do
          if [[ $cluster = pg${user}redshift* ]] || [[ $cluster = pg${user}jdbcredshift* ]]
          then
              log "Delete AWS Redshift $cluster"
              check_if_skip "aws redshift delete-cluster --cluster-identifier $cluster --skip-final-cluster-snapshot --region $AWS_REGION"
              sleep 60
              log "Delete AWS security group sg$cluster"
              check_if_skip "aws ec2 delete-security-group --group-name sg$cluster --region $AWS_REGION"
          fi
      done

      log "Cleanup AWS DynamoDB tables"
      for dynamo_table in $(aws dynamodb list-tables --region $AWS_REGION | jq '.TableNames[].TableName' -r)
      do
          if [[ $dynamo_table = *pg${user}* ]]
          then
              log "Removing AWS dynamodb table $dynamo_table"
              check_if_skip "aws dynamodb delete-table --table-name ${dynamo_table}"
          fi
      done
  }

  function cleanup_azure () {
      if [ ! -z "$AZ_USER" ] && [ ! -z "$AZ_PASS" ]
      then
          az logout
          az login -u "$AZ_USER" -p "$AZ_PASS" > /dev/null 2>&1
      fi

      login_and_maybe_set_azure_subscription

      log "Cleanup Azure Resource groups"
      for group in $(az group list --query '[].name' --output tsv)
      do
      if [[ $group = pg${user}* ]]
      then
          if [ ! -z "$GITHUB_RUN_NUMBER" ]
          then
          job=$(echo $GITHUB_RUN_NUMBER | cut -d "." -f 1)
          if [[ $group = pg$user$job* ]]
          then
              log "Skipping current github actions $job"
              continue
          fi
          fi
          log "Deleting Azure resource group $group"
          check_if_skip "az group delete --name $group --yes --no-wait"
      fi
      done
  }

  function cleanup_gcp () {
      log "Cleanup GCP GCS buckets"
      GCP_KEYFILE="$tmp_dir/keyfile.json"
      echo -e "$GCP_KEYFILE_CONTENT" | sed 's/\\"/"/g' > ${GCP_KEYFILE}
      docker rm -f gcloud-config-cleanup-resources > /dev/null 2>&1
      docker run -i -v ${GCP_KEYFILE}:/tmp/keyfile.json --name gcloud-config-cleanup-resources google/cloud-sdk:latest gcloud auth activate-service-account --project ${GCP_PROJECT} --key-file /tmp/keyfile.json > /dev/null 2>&1

      for bucket in $(docker run -i --volumes-from gcloud-config-cleanup-resources google/cloud-sdk:latest gsutil ls)
      do
          if [[ $bucket = *kafkadockerplaygroundbucket${user}* ]]
          then
              log "Removing GCS bucket $bucket"
              check_if_skip "docker run -i --volumes-from gcloud-config-cleanup-resources google/cloud-sdk:latest gsutil -m rm -r $bucket"
          fi
      done

      log "Cleanup GCP BQ datasets"
      for dataset in $(docker run -i --volumes-from gcloud-config-cleanup-resources google/cloud-sdk:latest bq --project_id "$GCP_PROJECT" ls)
      do
          if [[ $dataset = *pg${user}* ]]
          then
              log "Remove GCP BQ dataset $dataset"
              check_if_skip "docker run -i --volumes-from gcloud-config-cleanup-resources google/cloud-sdk:latest bq --project_id \"$GCP_PROJECT\" rm -r -f -d \"$dataset\""
          fi
      done

      GCP_SPANNER_INSTANCE="spanner-instance-$USER"
      GCP_SPANNER_DATABASE="spanner-db-$USER"
      log "Deleting Spanner database $GCP_SPANNER_DATABASE"
      docker run -i --volumes-from gcloud-config-cleanup-resources google/cloud-sdk:latest gcloud spanner databases delete $GCP_SPANNER_DATABASE --instance $GCP_SPANNER_INSTANCE --project $GCP_PROJECT << EOF > /dev/null 2>&1
Y
EOF
      log "Deleting Spanner instance $GCP_SPANNER_INSTANCE"
      docker run -i --volumes-from gcloud-config-cleanup-resources google/cloud-sdk:latest gcloud spanner instances delete $GCP_SPANNER_INSTANCE --project $GCP_PROJECT  << EOF > /dev/null 2>&1
Y
EOF

      GCP_BIGTABLE_INSTANCE="pg${USER}bg${TAG}"
      GCP_BIGTABLE_INSTANCE=${GCP_BIGTABLE_INSTANCE//[-.]/}
      log "Delete BigTable table kafka_big_query_stats"
      docker run -i --volumes-from gcloud-config-cleanup-resources google/cloud-sdk:latest cbt -project $GCP_PROJECT -instance $GCP_BIGTABLE_INSTANCE deletetable kafka_big_query_stats

      log "Deleting BigTable instance $GCP_BIGTABLE_INSTANCE"
      docker run -i --volumes-from gcloud-config-cleanup-resources google/cloud-sdk:latest gcloud bigtable instances delete $GCP_BIGTABLE_INSTANCE --project $GCP_PROJECT << EOF > /dev/null 2>&1
Y
EOF
  }

  function cleanup_ccloud () {
      cleanup_confluent_cloud_resources

      if [ ! -z "$AWS_DATABRICKS_CLUSTER_NAME" ]
      then
          log "AWS_DATABRICKS_CLUSTER_NAME environment variable is set, forcing the cluster $AWS_DATABRICKS_CLUSTER_NAME to be used !"
          export CLUSTER_NAME=$AWS_DATABRICKS_CLUSTER_NAME
          export CLUSTER_REGION=$AWS_DATABRICKS_CLUSTER_REGION
          export CLUSTER_CLOUD=$AWS_DATABRICKS_CLUSTER_CLOUD
          export CLUSTER_CREDS=$AWS_DATABRICKS_CLUSTER_CREDS

          cleanup_confluent_cloud_resources
      fi

      if [ ! -z "$AWS_CLUSTER_NAME" ]
      then
          log "AWS_CLUSTER_NAME environment variable is set, forcing the cluster $AWS_CLUSTER_NAME to be used !"
          export CLUSTER_NAME=$AWS_CLUSTER_NAME
          export CLUSTER_REGION=$AWS_CLUSTER_REGION
          export CLUSTER_CLOUD=$AWS_CLUSTER_CLOUD
          export CLUSTER_CREDS=$AWS_CLUSTER_CREDS

          cleanup_confluent_cloud_resources
      fi

      if [ ! -z "$GCP_CLUSTER_NAME" ]
      then
          log "GCP_CLUSTER_NAME environment variable is set, forcing the cluster $GCP_CLUSTER_NAME to be used !"
          export CLUSTER_NAME=$GCP_CLUSTER_NAME
          export CLUSTER_REGION=$GCP_CLUSTER_REGION
          export CLUSTER_CLOUD=$GCP_CLUSTER_CLOUD
          export CLUSTER_CREDS=$GCP_CLUSTER_CREDS

          cleanup_confluent_cloud_resources
      fi

      if [ ! -z "$AZURE_CLUSTER_NAME" ]
      then
          log "AZURE_CLUSTER_NAME environment variable is set, forcing the cluster $AZURE_CLUSTER_NAME to be used !"
          export CLUSTER_NAME=$AZURE_CLUSTER_NAME
          export CLUSTER_REGION=$AZURE_CLUSTER_REGION
          export CLUSTER_CLOUD=$AZURE_CLUSTER_CLOUD
          export CLUSTER_CREDS=$AZURE_CLUSTER_CREDS

          cleanup_confluent_cloud_resources
      fi
  }

  function cleanup_salesforce () {

      SALESFORCE_INSTANCE=${SALESFORCE_INSTANCE:-"https://login.salesforce.com"}
      if [ ! -z $SALESFORCE_USERNAME ]
      then
          log "Cleanup Salesforce Leads on account with $SALESFORCE_USERNAME"
          docker run -i --rm vdesabou/sfdx-cli:latest sh -c "sfdx sfpowerkit:auth:login -u \"$SALESFORCE_USERNAME\" -p \"$SALESFORCE_PASSWORD\" -r \"$SALESFORCE_INSTANCE\" -s \"$SALESFORCE_SECURITY_TOKEN\" && sfdx data:query --target-org \"$SALESFORCE_USERNAME\" -q \"SELECT Id FROM Lead\" --result-format csv > /tmp/out.csv && sfdx force:data:bulk:delete --target-org \"$SALESFORCE_USERNAME\" -s Lead -f /tmp/out.csv"

          log "Cleanup Salesforce Contacts on account with $SALESFORCE_USERNAME"
          docker run -i --rm vdesabou/sfdx-cli:latest sh -c "sfdx sfpowerkit:auth:login -u \"$SALESFORCE_USERNAME\" -p \"$SALESFORCE_PASSWORD\" -r \"$SALESFORCE_INSTANCE\" -s \"$SALESFORCE_SECURITY_TOKEN\" && sfdx data:query --target-org \"$SALESFORCE_USERNAME\" -q \"SELECT Id FROM Contact\" --result-format csv > /tmp/out.csv && sfdx force:data:bulk:delete --target-org \"$SALESFORCE_USERNAME\" -s Contact -f /tmp/out.csv"

          log "Cleanup PushTopics on account with $SALESFORCE_USERNAME"
          docker run -i --rm vdesabou/sfdx-cli:latest sh -c "sfdx sfpowerkit:auth:login -u \"$SALESFORCE_USERNAME\" -p \"$SALESFORCE_PASSWORD\" -r \"$SALESFORCE_INSTANCE\" -s \"$SALESFORCE_SECURITY_TOKEN\" && sfdx apex run --target-org \"$SALESFORCE_USERNAME\"" << EOF
List<PushTopic> pts = [SELECT Id FROM PushTopic];
Database.delete(pts);
EOF
      fi

      SALESFORCE_INSTANCE_ACCOUNT2=${SALESFORCE_INSTANCE_ACCOUNT2:-"https://login.salesforce.com"}
      if [ ! -z $SALESFORCE_USERNAME_ACCOUNT2 ]
      then
          log "Cleanup Salesforce Leads on account with $SALESFORCE_USERNAME_ACCOUNT2"
          docker run -i --rm vdesabou/sfdx-cli:latest sh -c "sfdx sfpowerkit:auth:login -u \"$SALESFORCE_USERNAME_ACCOUNT2\" -p \"$SALESFORCE_PASSWORD_ACCOUNT2\" -r \"$SALESFORCE_INSTANCE_ACCOUNT2\" -s \"$SALESFORCE_SECURITY_TOKEN_ACCOUNT2\" && sfdx data:query --target-org \"$SALESFORCE_USERNAME_ACCOUNT2\" -q \"SELECT Id FROM Lead\" --result-format csv > /tmp/out.csv && sfdx force:data:bulk:delete --target-org \"$SALESFORCE_USERNAME_ACCOUNT2\" -s Lead -f /tmp/out.csv"

          log "Cleanup Salesforce Contacts on account with $SALESFORCE_USERNAME_ACCOUNT2"
          docker run -i --rm vdesabou/sfdx-cli:latest sh -c "sfdx sfpowerkit:auth:login -u \"$SALESFORCE_USERNAME_ACCOUNT2\" -p \"$SALESFORCE_PASSWORD_ACCOUNT2\" -r \"$SALESFORCE_INSTANCE_ACCOUNT2\" -s \"$SALESFORCE_SECURITY_TOKEN_ACCOUNT2\" && sfdx data:query --target-org \"$SALESFORCE_USERNAME_ACCOUNT2\" -q \"SELECT Id FROM Contact\" --result-format csv > /tmp/out.csv && sfdx force:data:bulk:delete --target-org \"$SALESFORCE_USERNAME_ACCOUNT2\" -s Contact -f /tmp/out.csv"

          log "Cleanup PushTopics on account with $SALESFORCE_USERNAME_ACCOUNT2"
          docker run -i --rm vdesabou/sfdx-cli:latest sh -c "sfdx sfpowerkit:auth:login -u \"$SALESFORCE_USERNAME_ACCOUNT2\" -p \"$SALESFORCE_PASSWORD_ACCOUNT2\" -r \"$SALESFORCE_INSTANCE_ACCOUNT2\" -s \"$SALESFORCE_SECURITY_TOKEN_ACCOUNT2\" && sfdx apex run --target-org \"$SALESFORCE_USERNAME_ACCOUNT2\"" << EOF
List<PushTopic> pts = [SELECT Id FROM PushTopic];
Database.delete(pts);
EOF
      fi
  }

  for resource in "${resources[@]}"
  do
      case "${resource}" in

          "aws")
              cleanup_aws
          ;;
          "gcp")
              cleanup_gcp
          ;;
          "azure")
              cleanup_azure
          ;;
          "ccloud")
              cleanup_ccloud
          ;;
          "salesforce")
              cleanup_salesforce
          ;;
          *)
              logerror "default (none of above)"
          ;;
      esac
  done

  # always exit with success
  exit 0

}

# :command.function
playground_repro_export_command() {

  # src/commands/repro/export.sh
  all="${args[--all]}"

  if [ ! -z "$OUTPUT_FOLDER" ]
  then
    output_folder="$OUTPUT_FOLDER"
  else
    output_folder="reproduction-models"
  fi

  if [ "$output_folder" != "reproduction-models" ]
  then
      logerror "❌ OUTPUT_FOLDER $output_folder is not set with reproduction-models, this is the only supported value !"
      exit 1
  fi

  repro_dir=$root_folder/$output_folder
  cd $repro_dir

  output_filename="playground_repro_export.tgz"
  final_archive=$repro_dir/$output_filename
  if [ -f $final_archive ]
  then
      rm -rf $final_archive
  fi
  set +e
  if [[ -n "$all" ]]
  then
      if [ -e .git ]
      then
          new_files=$(git status --porcelain 2>/dev/null  | grep "^?? " | cut -d " " -f2-)
          if [[ -n "$new_files" ]]
          then
              log "💫 detected new files:"
              echo "$new_files"
              tar cvfz "$output_filename" $new_files > /dev/null 2>&1
              if [ -f $final_archive ]
              then
                  log "📤 Exported archive is available: $final_archive"
              else
                  logerror "❌ export failed as archive could not be created !"
                  exit 1
              fi
          else
              logerror "❌ No new files found !"
              exit 1
          fi
      else
          logwarn "output folder is not managed by git, creating a full tgz of $output_folder"
          tar cvfz "$output_filename" * > /dev/null 2>&1
          if [ -f $final_archive ]
          then
              log "📤 Exported archive is available: $final_archive"
          else
              logerror "❌ export failed as archive could not be created !"
              exit 1
          fi
      fi
  else
      # copy only current example
      test_file=$(playground state get run.test_file)

      if [ ! -f $test_file ]
      then

          logerror "File $test_file retrieved from $root_folder/playground.ini does not exist!"
          exit 1
      fi

      test_file_directory="$(dirname "${test_file}")"
      base1="${test_file_directory##*/}" # connect-connect-aws-s3-sink
      dir1="${test_file_directory%/*}" # reproduction-models
      dir2="${dir1##*/}/$base1" # reproduction-models/connect-connect-aws-s3-sink

      if [[ "$dir2" != ${output_folder}* ]]
      then
          logerror "example <$dir2> is not from OUTPUT_FOLDER ${output_folder} folder, only examples in there can be exported"
          exit 1
      fi

      if [ -e .git ]
      then
          cd $test_file_directory

          new_files=$(git status --porcelain . 2>/dev/null  | grep "^?? " | cut -d " " -f2-)
          if [[ -n "$new_files" ]]
          then
              log "💫 detected new files:"
              echo "$new_files"
              cd - >/dev/null
              tar cvfz "$output_filename" $new_files > /dev/null 2>&1
              if [ -f $final_archive ]
              then
                  log "📤 Exported archive is available: $final_archive"
              else
                  logerror "❌ export failed as archive could not be created !"
                  exit 1
              fi
          else
              logerror "❌ No new files found !"
              exit 1
          fi
      else
          logwarn "output folder is not managed by git, creating a full tgz of $test_file_directory"
          tar cvfz "$output_filename" $test_file_directory > /dev/null 2>&1
          if [ -f $final_archive ]
          then
              log "📤 Exported archive is available: $final_archive"
          else
              logerror "❌ export failed as archive could not be created !"
              exit 1
          fi
      fi
  fi

}

# :command.function
playground_repro_import_command() {

  # src/commands/repro/import.sh
  file="${args[--file]}"

  if [ ! -z "$OUTPUT_FOLDER" ]
  then
    output_folder="$OUTPUT_FOLDER"
  else
    output_folder="reproduction-models"
  fi

  if [ "$output_folder" != "reproduction-models" ]
  then
      logerror "❌ OUTPUT_FOLDER $output_folder is not set with reproduction-models, this is the only supported value !"
      exit 1
  fi

  if [[ $file == *"@"* ]]
  then
    file=$(echo "$file" | cut -d "@" -f 2)
  fi

  filename=$(basename $file)

  if [ "playground_repro_export.tgz" != ${filename} ]
  then
      logerror "file $file is not named playground_repro_export.tgz"
      exit 1
  fi

  repro_dir=$root_folder/$output_folder
  cd $repro_dir

  log "📥 Installing $file"
  tar xvfz $file
}

# :command.function
playground_repro_bootstrap_command() {

  # src/commands/repro/bootstrap.sh
  IGNORE_CHECK_FOR_DOCKER_COMPOSE=true

  test_file="${args[--file]}"
  description="${args[--description]}"
  producer="${args[--producer]}"
  nb_producers="${args[--nb-producers]}"
  add_custom_smt="${args[--custom-smt]}"

  eval "pipeline_array=(${args[--pipeline]})"

  schema_file_key="${args[--producer-schema-key]}"
  schema_file_value="${args[--producer-schema-value]}"

  if [[ ! -n "$test_file" ]]
  then
    display_interactive_menu_categories 1

    if [[ $test_file == *"@"* ]]
    then
      test_file=$(echo "$test_file" | cut -d "@" -f 2)
    fi

    declare -a array_flag_list=()
    terminal_columns=$(tput cols)
    if [[ $terminal_columns -gt 180 ]]
    then
      MAX_LENGTH=$((${terminal_columns}-120))
      fzf_version=$(get_fzf_version)
      if version_gt $fzf_version "0.38"
      then
        fzf_option_wrap="--preview-window=30%,wrap"
        fzf_option_pointer="--pointer=👉"
        fzf_option_empty_pointer=""
        fzf_option_rounded="--border=rounded"
      else
        fzf_option_wrap=""
        fzf_option_pointer=""
        fzf_option_empty_pointer=""
        fzf_option_rounded=""
      fi
    else
      MAX_LENGTH=$((${terminal_columns}-65))
      fzf_version=$(get_fzf_version)
      if version_gt $fzf_version "0.38"
      then
        fzf_option_wrap="--preview-window=20%,wrap"
        fzf_option_pointer="--pointer=👉"
        fzf_option_empty_pointer=""
        fzf_option_rounded="--border=rounded"
      else
        fzf_option_wrap=""
        fzf_option_pointer=""
        fzf_option_empty_pointer=""
        fzf_option_rounded=""
      fi
    fi
    readonly MENU_LETS_GO="🏭 Create the reproduction model !" #0

    MENU_ENABLE_CUSTOM_SMT="🔧 Add custom SMT $(printf '%*s' $((${MAX_LENGTH}-17-${#MENU_ENABLE_CUSTOM_SMT})) ' ') --custom-smt"

    readonly MENU_DISABLE_CUSTOM_SMT="❌🔧 Disable custom SMT" #3
    readonly MENU_GO_BACK="🔙 Go back"

    last_two_folders=$(basename $(dirname $(dirname $test_file)))/$(basename $(dirname $test_file))
    example="$last_two_folders/$filename"

    stop=0
    description=""
    while [ $stop != 1 ]
    do
      length=${#pipeline_array[@]}
      if ((length > 0))
      then
        MENU_PIPELINE="🔖 Add another sink to pipeline $(printf '%*s' $((${MAX_LENGTH}-32-${#MENU_PIPELINE})) ' ') --pipeline"
      else
        MENU_PIPELINE="🔖 Create pipeline with sink $(printf '%*s' $((${MAX_LENGTH}-28-${#MENU_PIPELINE})) ' ') --pipeline"
      fi

      options=("$MENU_LETS_GO" "$MENU_PIPELINE" "$MENU_ENABLE_CUSTOM_SMT" "$MENU_DISABLE_CUSTOM_SMT" "$MENU_GO_BACK")

      connector_example=0
      get_connector_paths
      if [ "$connector_paths" != "" ]
      then
        for connector_path in ${connector_paths//,/ }
        do
          full_connector_name=$(basename "$connector_path")
          owner=$(echo "$full_connector_name" | cut -d'-' -f1)
          name=$(echo "$full_connector_name" | cut -d'-' -f2-)

          if [ "$owner" == "java" ] || [ "$name" == "hub-components" ] || [ "$owner" == "filestream" ]
          then
            # happens when plugin is not coming from confluent hub
            continue
          else
            connector_example=1
          fi
        done
      fi

      if [ $connector_example == 0 ]
      then
        for((i=1;i<4;i++)); do
          unset "options[$i]"
        done
      else
        if [[ $test_file == *"sink"* ]]
        then
          unset 'options[1]'
        fi
      fi

      if [ ! -z $CUSTOM_SMT ]
      then
        unset 'options[2]'
      else
        unset 'options[3]'
      fi

      if [ "$description" == "" ]
      then
        maybe_remove_flag "--description"
        set +e
        description=$(echo "" | fzf --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="💭 " --header="enter a description for this repro model (it cannot be empty !)" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_empty_pointer --print-query)
        set -e
        if [ "$description" == "" ]
        then
          continue
        fi
        array_flag_list+=("--description=$description")
      fi

      oldifs=$IFS
      IFS=$'\n' flag_string="${array_flag_list[*]}"
      IFS=$oldifs
      res=$(printf '%s\n' "${options[@]}" | fzf --multi --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🛠 " --header="select option(s) for $example (use tab to select more than one)" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer --preview "echo -e \"👷 Number of repro models created so far: $(get_cli_metric nb_reproduction_models)\n\n🛠️  Number of repro models available: $(get_cli_metric nb_existing_reproduction_models)\n\n⛳ flag list:\n$flag_string\"")

      if [[ $res == *"$MENU_LETS_GO"* ]]
      then
        stop=1
      fi

      if [[ $res == *"$MENU_GO_BACK"* ]]
      then
        stop=1
        playground repro bootstrap
      fi

      if [[ $res == *"$MENU_ENABLE_CUSTOM_SMT"* ]]
      then
        array_flag_list+=("--custom-smt")
        export CUSTOM_SMT=true
        add_custom_smt="true"
      fi
      if [[ $res == *"$MENU_DISABLE_CUSTOM_SMT"* ]]
      then
        array_flag_list=("${array_flag_list[@]/"--custom-smt"}")
        unset CUSTOM_SMT
        add_custom_smt=""
      fi

      if [[ $res == *"$MENU_PIPELINE"* ]]
      then
        sink_file=$(playground get-examples-list-with-fzf --without-repro --sink-only )
        if [[ $sink_file == *"@"* ]]
        then
          sink_file=$(echo "$sink_file" | cut -d "@" -f 2)
        fi
        array_flag_list+=("--pipeline=$sink_file")
        pipeline_array+=("$sink_file")
      fi
    done # end while loop stop
  fi

  if [[ $test_file == *"@"* ]]
  then
    test_file=$(echo "$test_file" | cut -d "@" -f 2)
  fi

  if [[ "$test_file" != *".sh" ]]
  then
    logerror "❌ test_file $test_file is not a .sh file!"
    exit 1
  fi

  if [[ "$(dirname $test_file)" != /* ]]
  then
    logerror "❌ do not use relative path for test file!"
    exit 1
  fi

  if [ "$nb_producers" == "" ]
  then
    nb_producers=1
  fi

  if [[ -n "$schema_file_key" ]]
  then
    if [ "$producer" == "none" ]
    then
      logerror "❌ --producer-schema-key is set but not --producer"
      exit 1
    fi

    if [[ "$producer" != *"with-key" ]]
    then
      logerror "❌ --producer-schema-key is set but --producer is not set with <with-key>"
      exit 1
    fi
  fi

  if [[ -n "$schema_file_value" ]]
  then
    if [ "$producer" == "none" ]
    then
      logerror "❌ --producer-schema-value is set but not --producer"
      exit 1
    fi
  fi

  test_file_directory="$(dirname "${test_file}")"
  cd ${test_file_directory}

  topic_name="customer-$producer"
  topic_name=$(echo $topic_name | tr '-' '_')
  filename=$(basename -- "$test_file")
  extension="${filename##*.}"
  filename="${filename%.*}"

  base1="${test_file_directory##*/}" # connect-cdc-oracle12-source
  dir1="${test_file_directory%/*}" #connect
  dir2="${dir1##*/}/$base1" # connect/connect-cdc-oracle12-source
  final_dir=$(echo $dir2 | tr '/' '-') # connect-connect-cdc-oracle12-source

  length=${#pipeline_array[@]}
  if ((length > 0))
  then
    if [[ "$base1" != *source ]]
    then
      logerror "example <$base1> must be source connector example when building a pipeline !"
      exit 1
    fi

    if [[ "$dir2" != connect* ]]
    then
      logerror "example <$dir2> is not from connect folder, only connect in connect folder are supported"
      exit 1
    fi
  fi

  if [ "$producer" != "none" ]
  then
    if [[ "$base1" != *sink ]]
    then
      logerror "example <$base1> must be sink connector example when using a java producer !"
      exit 1
    fi
  fi

  if [ ! -z "$OUTPUT_FOLDER" ]
  then
    output_folder="$OUTPUT_FOLDER"
    log "📂 Output folder is $output_folder (set with OUTPUT_FOLDER environment variable)"
  else
    output_folder="reproduction-models"
    log "📂 Output folder is default $output_folder (you can change it by setting OUTPUT_FOLDER environment variable)"
  fi

  repro_dir=$root_folder/$output_folder/$final_dir
  mkdir -p $repro_dir
  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  description_kebab_case="${description// /-}"
  description_kebab_case=$(echo "$description_kebab_case" | tr '[:upper:]' '[:lower:]')
  # only keep alphanumeric characters and hyphens
  description_kebab_case=$(echo "$description_kebab_case" | tr -cd '[:alnum:]-')
  repro_test_file="$repro_dir/$filename-repro-$description_kebab_case.$extension"

  # determining the docker-compose file from from test_file
  docker_compose_file=$(grep "start-environment" "$test_file" |  awk '{print $6}' | cut -d "/" -f 2 | cut -d '"' -f 1 | tail -n1 | xargs)
  docker_compose_file="${test_file_directory}/${docker_compose_file}"

  log "✨ Creating file $repro_test_file"
  rm -f $repro_test_file
  cp $test_file $repro_test_file

  if [ "${docker_compose_file}" != "" ] && [ ! -f "${docker_compose_file}" ]
  then
    set +e
    grep 'DOCKER_COMPOSE_FILE_OVERRIDE=$1' "$test_file"
    if [ $? -eq 0 ]
    then
      # it means it is an environment example
      # need to create the docker-compose file
      docker_compose_file=""
      docker_compose_test_file="$repro_dir/docker-compose.repro-$description_kebab_case.yml"
      log "✨ Creating empty file $docker_compose_test_file"

      echo "---" > $docker_compose_test_file
      echo "" >> $docker_compose_test_file
      echo "# override the services here, example " >> $docker_compose_test_file
      echo "# services:" >> $docker_compose_test_file
      echo "#    connect:" >> $docker_compose_test_file
      echo "#      environment:" >> $docker_compose_test_file
      echo "#        CONNECT_BOOTSTRAP_SERVERS: \"broker:9092\"" >> $docker_compose_test_file

      docker_compose_test_file_name=$(basename -- "$docker_compose_test_file")
      cp $test_file $tmp_dir/tmp_file
      line=$(grep -n 'DOCKER_COMPOSE_FILE_OVERRIDE=$1' $test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line-1)) $tmp_dir/tmp_file; echo "DOCKER_COMPOSE_FILE_OVERRIDE=../../$output_folder/$final_dir/$docker_compose_test_file_name"; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $repro_test_file
    else
      docker_compose_file=""
      logwarn "📁 Could not determine docker-compose override file from $test_file !"
    fi
    set -e
  fi

  if [ "${docker_compose_file}" != "" ] && [ -f "${docker_compose_file}" ]
  then
    filename=$(basename -- "${docker_compose_file}")
    extension="${filename##*.}"
    filename="${filename%.*}"

    docker_compose_test_file="$repro_dir/$filename.repro-$description_kebab_case.$extension"
    log "✨ Creating file $docker_compose_test_file"
    rm -f $docker_compose_test_file
    cp ${docker_compose_file} $docker_compose_test_file

    docker_compose_test_file_name=$(basename -- "$docker_compose_test_file")
  fi

  if [ "${docker_compose_file}" != "" ]
  then
    filename=$(basename -- "${docker_compose_file}")
    sed -e "s|$filename|$docker_compose_test_file_name|g" \
      $test_file > $repro_test_file
  fi

  set +e
  echo "#!/bin/bash" > $tmp_dir/intro
  echo "###############################################" >> $tmp_dir/intro
  echo "# 🗓️ date: `date`" >> $tmp_dir/intro
  echo "# 👤 author: `whoami`" >> $tmp_dir/intro
  echo "# 💡 description: $description" >> $tmp_dir/intro
  if [[ $description =~ ^[0-9]{6} ]]
  then
    numbers="${BASH_REMATCH[0]}"
    echo "# 🔮 ticket: https://confluent.zendesk.com/agent/tickets/$numbers" >> $tmp_dir/intro
  fi
  echo "# 🙋 how to use: https://github.com/confluentinc/kafka-docker-playground-internal/tree/master#how-to-use" >> $tmp_dir/intro
  if [ -z "$OUTPUT_FOLDER" ] || [ "$OUTPUT_FOLDER" == "reproduction-models" ]
  then
    last_folder=$(basename $(dirname $repro_test_file))
    f=$(basename $repro_test_file)
    echo "# 🔗 github file url: https://github.com/confluentinc/kafka-docker-playground-internal/blob/master/$last_folder/$f" >> $tmp_dir/intro
  fi
  string=$(grep "Quickly test " README.md)
  url=$(echo "$string" | grep -oE 'https?://[^ ]+')
  url=${url//)/}

  if [[ $url =~ "http" ]]
  then
    short_url=$(echo $url | cut -d '#' -f 1)
    echo "# 🌐 documentation: $short_url" >> $tmp_dir/intro
  fi
  echo "# 🐳 playground website: https://kafka-docker-playground.io" >> $tmp_dir/intro
  echo "# 💬 comments:" >> $tmp_dir/intro
  echo "#" >> $tmp_dir/intro
  echo "###############################################" >> $tmp_dir/intro
  echo "" >> $tmp_dir/intro

  cat $tmp_dir/intro > $tmp_dir/tmp_file
  cat $repro_test_file | grep -v "#!/bin/bash" >> $tmp_dir/tmp_file
  mv $tmp_dir/tmp_file $repro_test_file

  for file in README.md docker-compose*.yml keyfile.json stop.sh sql-datagen
  do
    if [ -f $file ]
    then
      cd $repro_dir > /dev/null
      ln -sf ../../$dir2/$file .
      cd - > /dev/null
    fi
  done

  for file in .gitignore
  do
    if [ -f $file ]
    then
      cd $repro_dir > /dev/null
      cp ../../$dir2/$file .
      cd - > /dev/null
    fi
  done

  if [ "$producer" != "none" ]
  then
    case "${producer}" in
      avro)
        echo "               \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\"," > $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.avro.AvroConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter
      ;;
      avro-with-key)
        echo "               \"key.converter\": \"io.confluent.connect.avro.AvroConverter\"," > $tmp_dir/key_converter
        echo "               \"key.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.avro.AvroConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter
      ;;
      json-schema)
        echo "               \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\"," > $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.json.JsonSchemaConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter
      ;;
      json-schema-with-key)
        echo "               \"key.converter\": \"io.confluent.connect.json.JsonSchemaConverter\"," > $tmp_dir/key_converter
        echo "               \"key.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.json.JsonSchemaConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter
      ;;
      protobuf)
        echo "               \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\"," > $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.protobuf.ProtobufConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter
      ;;
      protobuf-with-key)
        echo "               \"key.converter\": \"io.confluent.connect.protobuf.ProtobufConverter\"," > $tmp_dir/key_converter
        echo "               \"key.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/key_converter
        echo "               \"value.converter\": \"io.confluent.connect.protobuf.ProtobufConverter\"," > $tmp_dir/value_converter
        echo "               \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $tmp_dir/value_converter
      ;;
      none)
      ;;
      *)
        logerror "producer name not valid ! Should be one of avro, avro-with-key, json-schema, json-schema-with-key, protobuf or protobuf-with-key"
        exit 1
      ;;
    esac
    original_topic_name=$(grep "\"topics\"" $repro_test_file | cut -d "\"" -f 4 | head -1)
    if [ "$original_topic_name" != "" ]
    then
      tmp=$(echo $original_topic_name | tr '-' '\-')
      sed -e "s|$tmp|$topic_name|g" \
          $repro_test_file > /tmp/tmp

      mv /tmp/tmp $repro_test_file
      # log "✨ Replacing topic $original_topic_name with $topic_name"
    fi

    for((i=1;i<=$nb_producers;i++)); do
      # looks like there is a maximum size for hostname in docker (container init caused: sethostname: invalid argument: unknown)
      producer_hostname=""
      producer_hostname="producer-repro-$description_kebab_case"
      producer_hostname=${producer_hostname:0:21}
      if [ $nb_producers -eq 1 ]
      then
        producer_hostname="${producer_hostname}"
      else
        producer_hostname="${producer_hostname}$i"
      fi

      rm -rf $producer_hostname
      mkdir -p $repro_dir/$producer_hostname/
      cp -Ra ${test_file_directory}/../../other/schema-format-$producer/producer/* $repro_dir/$producer_hostname/

      if [[ -n "$schema_file_key" ]]
      then
        log "✨ Copy and paste the schema you want to use for the key, save and close the file to continue"
        playground open --file "$tmp_dir/key_schema" --wait

        case "${producer}" in
          avro-with-key)
            original_namespace=$(cat $tmp_dir/key_schema | jq -r .namespace)
            if [ "$original_namespace" != "null" ]
            then
              sed -e "s|$original_namespace|com.github.vdesabou|g" \
                  $tmp_dir/key_schema  > /tmp/tmp

              mv /tmp/tmp $tmp_dir/key_schema
              log "✨ Replacing namespace $original_namespace with com.github.vdesabou"
            else
              # need to add namespace
              cp $tmp_dir/key_schema /tmp/tmp
              line=2
              { head -n $(($line-1)) /tmp/tmp; echo "    \"namespace\": \"com.github.vdesabou\","; tail -n +$line /tmp/tmp; } > $tmp_dir/key_schema
            fi
            # replace record name with MyKey
            jq '.name = "MyKey"' $tmp_dir/key_schema > /tmp/tmp
            mv /tmp/tmp $tmp_dir/key_schema

            cp $tmp_dir/key_schema $repro_dir/$producer_hostname/src/main/resources/schema/mykey.avsc
          ;;
          json-schema-with-key)
            # replace title name with ID
            jq '.title = "ID"' $tmp_dir/key_schema > /tmp/tmp
            mv /tmp/tmp $tmp_dir/key_schema

            cp $tmp_dir/key_schema $repro_dir/$producer_hostname/src/main/resources/schema/Id.json
          ;;
          protobuf-with-key)
            original_package=$(grep "package " $tmp_dir/key_schema | cut -d " " -f 2 | cut -d ";" -f 1 | head -1)
            if [ "$original_package" != "" ]
            then
              sed -e "s|$original_package|com.github.vdesabou|g" \
                  $tmp_dir/key_schema  > /tmp/tmp

              mv /tmp/tmp $tmp_dir/key_schema
              log "✨ Replacing package $original_package with com.github.vdesabou"
            else
              # need to add package
              cp $tmp_dir/key_schema /tmp/tmp
              line=2
              { head -n $(($line-1)) /tmp/tmp; echo "package com.github.vdesabou;"; tail -n +$line /tmp/tmp; } > $tmp_dir/key_schema
            fi

            original_java_outer_classname=$(grep "java_outer_classname" $tmp_dir/key_schema | cut -d "\"" -f 2 | cut -d "\"" -f 1 | head -1)
            if [ "$original_java_outer_classname" != "" ]
            then
              sed -e "s|$original_java_outer_classname|IdImpl|g" \
                  $tmp_dir/key_schema  > /tmp/tmp

              mv /tmp/tmp $tmp_dir/key_schema
              log "✨ Replacing java_outer_classname $original_java_outer_classname with IdImpl"
            else
              # need to add java_outer_classname
              cp $tmp_dir/key_schema /tmp/tmp
              line=3
              { head -n $(($line-1)) /tmp/tmp; echo "option java_outer_classname = \"IdImpl\";"; tail -n +$line /tmp/tmp; } > $tmp_dir/key_schema
            fi

            cp $tmp_dir/key_schema $repro_dir/$producer_hostname/src/main/resources/schema/Id.proto
          ;;

          none)
          ;;
          *)
            logerror "producer name not valid ! Should be one of avro, avro-with-key, json-schema, json-schema-with-key, protobuf or protobuf-with-key"
            exit 1
          ;;
        esac
      fi

      if [[ -n "$schema_file_value" ]]
      then
        log "✨ Copy and paste the schema you want to use for the value, save and close the file to continue"
        playground open --file "$tmp_dir/value_schema" --wait

        case "${producer}" in
          avro|avro-with-key)
            original_namespace=$(cat $tmp_dir/value_schema | jq -r .namespace)
            if [ "$original_namespace" != "null" ]
            then
              sed -e "s|$original_namespace|com.github.vdesabou|g" \
                  $tmp_dir/value_schema  > /tmp/tmp

              mv /tmp/tmp $tmp_dir/value_schema
              log "✨ Replacing namespace $original_namespace with com.github.vdesabou"
            else
              # need to add namespace
              cp $tmp_dir/value_schema /tmp/tmp
              line=2
              { head -n $(($line-1)) /tmp/tmp; echo "    \"namespace\": \"com.github.vdesabou\","; tail -n +$line /tmp/tmp; } > $tmp_dir/value_schema
            fi
            # replace record name with Customer
            jq '.name = "Customer"' $tmp_dir/value_schema > /tmp/tmp
            mv /tmp/tmp $tmp_dir/value_schema

            cp $tmp_dir/value_schema $repro_dir/$producer_hostname/src/main/resources/schema/customer.avsc
          ;;
          json-schema|json-schema-with-key)
            # replace title name with Customer
            jq '.title = "Customer"' $tmp_dir/value_schema > /tmp/tmp
            mv /tmp/tmp $tmp_dir/value_schema

            cp $tmp_dir/value_schema $repro_dir/$producer_hostname/src/main/resources/schema/Customer.json
          ;;
          protobuf|protobuf-with-key)
            original_package=$(grep "package " $tmp_dir/value_schema | cut -d " " -f 2 | cut -d ";" -f 1 | head -1)
            if [ "$original_package" != "" ]
            then
              sed -e "s|$original_package|com.github.vdesabou|g" \
                  $tmp_dir/value_schema  > /tmp/tmp

              mv /tmp/tmp $tmp_dir/value_schema
              log "✨ Replacing package $original_package with com.github.vdesabou"
            else
              # need to add package
              cp $tmp_dir/value_schema /tmp/tmp
              line=2
              { head -n $(($line-1)) /tmp/tmp; echo "package com.github.vdesabou;"; tail -n +$line /tmp/tmp; } > $tmp_dir/value_schema
            fi

            original_java_outer_classname=$(grep "java_outer_classname" $tmp_dir/value_schema | cut -d "\"" -f 2 | cut -d "\"" -f 1 | head -1)
            if [ "$original_java_outer_classname" != "" ]
            then
              sed -e "s|$original_java_outer_classname|CustomerImpl|g" \
                  $tmp_dir/value_schema  > /tmp/tmp

              mv /tmp/tmp $tmp_dir/value_schema
              log "✨ Replacing java_outer_classname $original_java_outer_classname with CustomerImpl"
            else
              # need to add java_outer_classname
              cp $tmp_dir/value_schema /tmp/tmp
              line=3
              { head -n $(($line-1)) /tmp/tmp; echo "option java_outer_classname = \"CustomerImpl\";"; tail -n +$line /tmp/tmp; } > $tmp_dir/value_schema
            fi

            cp $tmp_dir/value_schema $repro_dir/$producer_hostname/src/main/resources/schema/Customer.proto
          ;;

          none)
          ;;
          *)
            logerror "producer name not valid ! Should be one of avro, avro-with-key, json-schema, json-schema-with-key, protobuf or protobuf-with-key"
            exit 1
          ;;
        esac
      fi

      # update docker compose with producer container
      if [[ "$dir1" = *connect ]]
      then
          cat << EOF >> $tmp_dir/producer

  $producer_hostname:
    build:
      context: ../../$output_folder/$final_dir/$producer_hostname/
    hostname: producer
    container_name: $producer_hostname
    environment:
      KAFKA_BOOTSTRAP_SERVERS: broker:9092
      TOPIC: "$topic_name"
      REPLICATION_FACTOR: 1
      NUMBER_OF_PARTITIONS: 1
      NB_MESSAGES: 10 # -1 for MAX_VALUE
      MESSAGE_BACKOFF: 100 # Frequency of message injection
      KAFKA_ACKS: "all" # default: "1"
      KAFKA_REQUEST_TIMEOUT_MS: 20000
      KAFKA_RETRY_BACKOFF_MS: 500
      KAFKA_CLIENT_ID: "my-java-$producer_hostname"
      KAFKA_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      JAVA_OPTS: \${GRAFANA_AGENT_PRODUCER}
    volumes:
      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/
      - ../../$output_folder/$final_dir/$producer_hostname/target/producer-1.0.0-jar-with-dependencies.jar:/producer-1.0.0-jar-with-dependencies.jar

EOF
      fi

      if [[ "$dir1" = *ccloud ]]
      then
          cat << EOF >> $tmp_dir/producer

  $producer_hostname:
    build:
      context: ../../$output_folder/$final_dir/$producer_hostname/
    hostname: producer
    container_name: $producer_hostname
    environment:
      KAFKA_BOOTSTRAP_SERVERS: \$BOOTSTRAP_SERVERS
      KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM: "https"
      KAFKA_SASL_MECHANISM: "PLAIN"
      KAFKA_SASL_JAAS_CONFIG: \$SASL_JAAS_CONFIG
      KAFKA_SECURITY_PROTOCOL: "SASL_SSL"
      TOPIC: "$topic_name"
      REPLICATION_FACTOR: 3
      NUMBER_OF_PARTITIONS: 1
      NB_MESSAGES: 10 # -1 for MAX_VALUE
      MESSAGE_BACKOFF: 100 # Frequency of message injection
      KAFKA_ACKS: "all" # default: "1"
      KAFKA_REQUEST_TIMEOUT_MS: 20000
      KAFKA_RETRY_BACKOFF_MS: 500
      KAFKA_CLIENT_ID: "my-java-$producer_hostname"
      KAFKA_SCHEMA_REGISTRY_URL: \$SCHEMA_REGISTRY_URL
      KAFKA_BASIC_AUTH_CREDENTIALS_SOURCE: \$BASIC_AUTH_CREDENTIALS_SOURCE
      KAFKA_SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO: \$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO
      JAVA_OPTS: \${GRAFANA_AGENT_PRODUCER}
      EXTRA_ARGS:

    volumes:
      - ../../environment/plaintext/jmx-exporter:/usr/share/jmx_exporter/
      - ../../$output_folder/$final_dir/$producer_hostname/target/producer-1.0.0-jar-with-dependencies.jar:/producer-1.0.0-jar-with-dependencies.jar

EOF
      fi
    done

    if [ "${docker_compose_file}" != "" ]
    then
      cp $docker_compose_test_file $tmp_dir/tmp_file
      line=$(grep -n 'services:' $docker_compose_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/producer; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $docker_compose_test_file

    else

      logwarn "As docker-compose override file could not be determined, you will need to add this manually:"
      cat $tmp_dir/producer
    fi

    for((i=1;i<=$nb_producers;i++)); do
      log "✨ Adding Java $producer producer in $repro_dir/$producer_hostname"
      producer_hostname=""
      producer_hostname="producer-repro-$description_kebab_case"
      producer_hostname=${producer_hostname:0:21}

      if [ $nb_producers -eq 1 ]
      then
        producer_hostname="${producer_hostname}"
      else
        producer_hostname="${producer_hostname}$i"
      fi

      list="$list $producer_hostname"

    done
      cat << EOF > $tmp_dir/build_producer
for component in $list
do
    set +e
    log "🏗 Building jar for \${component}"
    docker run -i --rm -e KAFKA_CLIENT_TAG=\$KAFKA_CLIENT_TAG -e TAG=\$TAG_BASE -v "\${DIR}/\${component}":/usr/src/mymaven -v "\$HOME/.m2":/root/.m2 -v "\$PWD/../../scripts/settings.xml:/tmp/settings.xml" -v "\${DIR}/\${component}/target:/usr/src/mymaven/target" -w /usr/src/mymaven maven:3.6.1-jdk-11 mvn -s /tmp/settings.xml -Dkafka.tag=\$TAG -Dkafka.client.tag=\$KAFKA_CLIENT_TAG package > /tmp/result.log 2>&1
    if [ \$? != 0 ]
    then
        logerror "❌ failed to build java component $component"
        tail -500 /tmp/result.log
        exit 1
    fi
    set -e
done

EOF
    # log "✨ Adding command to build jar for $producer_hostname to $repro_test_file"
    cp $repro_test_file $tmp_dir/tmp_file
    line=$(grep -n 'playground start-environment' $repro_test_file | cut -d ":" -f 1 | tail -n1)

    { head -n $(($line-1)) $tmp_dir/tmp_file; cat $tmp_dir/build_producer; tail -n +$line $tmp_dir/tmp_file; } > $repro_test_file

    kafka_cli_producer_error=0
    kafka_cli_producer_eof=0
    line_kafka_cli_producer=$(grep -En "kafka-console-producer|kafka-avro-console-producer|kafka-json-schema-console-producer|kafka-protobuf-console-producer" $repro_test_file | cut -d ":" -f 1 | tail -n1)
    if [ $? != 0 ] || [ "$line_kafka_cli_producer" == "" ]
    then
        logwarn "Could not find kafka cli producer!"
        kafka_cli_producer_error=1
    fi
    set +e
    grep -E "kafka-console-producer|kafka-avro-console-producer|kafka-json-schema-console-producer|kafka-protobuf-console-producer" $repro_test_file | grep EOF > /dev/null
    if [ $? = 0 ]
    then
        kafka_cli_producer_eof=1

        sed -n "$line_kafka_cli_producer,$(($line_kafka_cli_producer + 10))p" $repro_test_file > /tmp/tmp
        tmp=$(grep -n "^EOF" /tmp/tmp | cut -d ":" -f 1 | tail -n1)
        if [ $tmp == "" ]
        then
          logwarn "Could not determine EOF for kafka cli producer!"
          kafka_cli_producer_error=1
        fi
        line_kafka_cli_producer_end=$(($line_kafka_cli_producer + $tmp))
    fi
    set -e
    if [ $kafka_cli_producer_error = 1 ]
    then
      cat << EOF >> $tmp_dir/java_producer
# 🚨🚨🚨 FIXTHIS: move it to the correct place 🚨🚨🚨
EOF
    fi

    for((i=1;i<=$nb_producers;i++)); do
      producer_hostname=""
      producer_hostname="producer-repro-$description_kebab_case"
      producer_hostname=${producer_hostname:0:21}

      if [ $nb_producers -eq 1 ]
      then
        producer_hostname="${producer_hostname}"
      else
        producer_hostname="${producer_hostname}$i"
      fi
      get_producer_run_heredoc
    done
    if [ $kafka_cli_producer_error = 1 ]
    then
      cat << EOF >> $tmp_dir/java_producer
# 🚨🚨🚨 FIXTHIS: move it to the correct place 🚨🚨🚨
EOF
    fi
    # log "✨ Adding command to run producer to $repro_test_file"
    cp $repro_test_file $tmp_dir/tmp_file

    if [ $kafka_cli_producer_error == 1 ]
    then
        { head -n $(($line-1)) $tmp_dir/tmp_file; cat $tmp_dir/java_producer; tail -n +$line $tmp_dir/tmp_file; } > $repro_test_file
    else
      if [ $kafka_cli_producer_eof == 0 ]
      then
        line_kafka_cli_producer_end=$(($line_kafka_cli_producer + 1))
      fi
      { head -n $(($line_kafka_cli_producer - 2)) $tmp_dir/tmp_file; cat $tmp_dir/java_producer; tail -n +$line_kafka_cli_producer_end $tmp_dir/tmp_file; } > $repro_test_file
    fi

    # deal with converters

    sink_key_converter=$(grep "\"key.converter\"" $repro_test_file | cut -d '"' -f 4)
    if [ "$sink_key_converter" == "" ]
    then
      log "💱 Sink connector is using default key.converter, i.e org.apache.kafka.connect.storage.StringConverter"
    else
      if [ "$sink_key_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
      then
        # check schemas.enable
        sink_key_json_converter_schemas_enable=$(grep "\"key.converter.schemas.enable\"" $repro_test_file | cut -d '"' -f 4)
        if [ "$sink_key_json_converter_schemas_enable" == "" ]
        then
          log "💱 Sink connector is using key.converter $sink_key_converter with schemas.enable=true"
        else
          log "💱 Sink connector is using key.converter $sink_key_converter with schemas.enable=$sink_key_json_converter_schemas_enable"
        fi
      else
        log "💱 Sink connector is using key.converter $sink_key_converter"
      fi
    fi

    sink_value_converter=$(grep "\"value.converter\"" $repro_test_file | cut -d '"' -f 4)
    if [ "$sink_value_converter" == "" ]
    then
      log "💱 Sink connector is using default value.converter, i.e io.confluent.connect.avro.AvroConverter"
    else
      if [ "$sink_value_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
      then
        # check schemas.enable
        sink_value_json_converter_schemas_enable=$(grep "\"value.converter.schemas.enable\"" $repro_test_file | cut -d '"' -f 4)
        if [ "$sink_value_json_converter_schemas_enable" == "" ]
        then
          log "💱 Sink connector is using value.converter $sink_value_converter with schemas.enable=true"
        else
          log "💱 Sink connector is using value.converter $sink_value_converter with schemas.enable=$sink_value_json_converter_schemas_enable"
        fi
      else
        log "💱 Sink connector is using value.converter $sink_value_converter"
      fi
    fi

    if [ "$sink_value_converter" == "" ]
    then
      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $repro_test_file; cat $tmp_dir/value_converter; tail -n +$(($line+1)) $repro_test_file; } > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file
    else
      # remove existing value.converter
      grep -vwE "\"value.converter" $repro_test_file > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file

      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $repro_test_file; cat $tmp_dir/value_converter; tail -n +$(($line+1)) $repro_test_file; } > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file
    fi
    log "🔮 Changing Sink connector value.converter to use same as producer:"
    cat $tmp_dir/value_converter

    if [ "$sink_key_converter" == "" ]
    then
      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $repro_test_file; cat $tmp_dir/key_converter; tail -n +$(($line+1)) $repro_test_file; } > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file
    else
      # remove existing key.converter
      grep -vwE "\"key.converter" $repro_test_file > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file

      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $repro_test_file; cat $tmp_dir/key_converter; tail -n +$(($line+1)) $repro_test_file; } > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file
    fi
    log "🔮 Changing Sink connector key.converter to use same as producer:"
    cat $tmp_dir/key_converter
  fi

  if [[ -n "$add_custom_smt" ]]
  then
    custom_smt_name=""
    custom_smt_name="MyCustomSMT-$description_kebab_case"
    custom_smt_name=${custom_smt_name:0:18}
    mkdir -p $repro_dir/$custom_smt_name/
    cp -Ra ../../other/custom-smt/MyCustomSMT/* $repro_dir/$custom_smt_name/
      cat << EOF > $tmp_dir/build_custom_smt
for component in $custom_smt_name
do
    set +e
    log "🏗 Building jar for \${component}"
    docker run -i --rm -e KAFKA_CLIENT_TAG=\$KAFKA_CLIENT_TAG -e TAG=\$TAG_BASE -v "\${DIR}/\${component}":/usr/src/mymaven -v "\$HOME/.m2":/root/.m2 -v "\$PWD/../../scripts/settings.xml:/tmp/settings.xml" -v "\${DIR}/\${component}/target:/usr/src/mymaven/target" -w /usr/src/mymaven maven:3.6.1-jdk-11 mvn -s /tmp/settings.xml -Dkafka.tag=\$TAG -Dkafka.client.tag=\$KAFKA_CLIENT_TAG package > /tmp/result.log 2>&1
    if [ \$? != 0 ]
    then
        logerror "❌ failed to build java component $component"
        tail -500 /tmp/result.log
        exit 1
    fi
    set -e
done

EOF

    # log "✨ Adding command to build jar for $custom_smt_name to $repro_test_file"
    cp $repro_test_file $tmp_dir/tmp_file
    line=$(grep -n 'playground start-environment' $repro_test_file | cut -d ":" -f 1 | tail -n1)

    { head -n $(($line-1)) $tmp_dir/tmp_file; cat $tmp_dir/build_custom_smt; tail -n +$line $tmp_dir/tmp_file; } > $repro_test_file

    get_connector_paths
    if [ "$connector_paths" == "" ]
    then
        logwarn "❌ skipping as it is not an example with connector, but --custom-smt is set"
        exit 1
    else
      #  Loop on all connectors in CONNECT_PLUGIN_PATH and install custom SMT jar in lib folder
      for connector_path in ${connector_paths//,/ }
      do
        echo "log \"📂 Copying custom jar to connector folder $connector_path/lib/\"" >> $tmp_dir/build_custom_docker_cp_smt
        echo "docker cp $repro_dir/$custom_smt_name/target/MyCustomSMT-1.0.0-SNAPSHOT-jar-with-dependencies.jar connect:$connector_path/lib/" >> $tmp_dir/build_custom_docker_cp_smt
      done
      echo "log \"♻️ Restart connect worker to load\"" >> $tmp_dir/build_custom_docker_cp_smt
      echo "docker restart connect" >> $tmp_dir/build_custom_docker_cp_smt
      echo "sleep 45" >> $tmp_dir/build_custom_docker_cp_smt
    fi

    cp $repro_test_file $tmp_dir/tmp_file
    line=$(grep -n 'playground start-environment' $repro_test_file | cut -d ":" -f 1 | tail -n1)

    { head -n $(($line+2)) $tmp_dir/tmp_file; cat $tmp_dir/build_custom_docker_cp_smt; tail -n +$(($line+2)) $tmp_dir/tmp_file; } > $repro_test_file

    existing_transforms=$(grep "\"transforms\"" $repro_test_file | cut -d '"' -f 4)
    if [ "$existing_transforms" == "" ]
    then
      echo "              \"transforms\": \"MyCustomSMT\"," >> $tmp_dir/build_custom_smt_json_config
      echo "              \"transforms.MyCustomSMT.type\": \"com.github.vdesabou.kafka.connect.transforms.MyCustomSMT\"," >> $tmp_dir/build_custom_smt_json_config

      cp $repro_test_file $tmp_dir/tmp_file
      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/build_custom_smt_json_config; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $repro_test_file
    else
      log "🤖 Connector is using existing transforms $existing_transforms, the new custom SMT will be added to the list."

      # remove existing transforms
      grep -vwE "\"transforms\"" $repro_test_file > $tmp_dir/tmp_file2
      cp $tmp_dir/tmp_file2 $repro_test_file

      echo "              \"transforms\": \"MyCustomSMT,$existing_transforms\"," >> $tmp_dir/build_custom_smt_json_config
      echo "              \"transforms.MyCustomSMT.type\": \"com.github.vdesabou.kafka.connect.transforms.MyCustomSMT\"," >> $tmp_dir/build_custom_smt_json_config

      cp $repro_test_file $tmp_dir/tmp_file
      line=$(grep -n 'connector.class' $repro_test_file | cut -d ":" -f 1 | tail -n1)

      { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/build_custom_smt_json_config; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $repro_test_file
    fi

  fi
  for sink_file in "${pipeline_array[@]}"; do
    if [[ -n "$sink_file" ]]
    then
      if [[ $sink_file == *"@"* ]]
      then
        sink_file=$(echo "$sink_file" | cut -d "@" -f 2)
      fi
      test_sink_file_directory="$(dirname "${sink_file}")"
      # docker-compose part
      # determining the docker-compose file from from test_file
      docker_compose_sink_file=$(grep "start-environment" "$sink_file" |  awk '{print $6}' | cut -d "/" -f 2 | cut -d '"' -f 1 | tail -n1 | xargs)
      docker_compose_sink_file="${test_sink_file_directory}/${docker_compose_sink_file}"
      cp $docker_compose_test_file /tmp/1.yml
      cp $docker_compose_sink_file /tmp/2.yml
      yq ". *= load(\"/tmp/1.yml\")" /tmp/2.yml > $docker_compose_test_file

      connector_paths=$(grep "CONNECT_PLUGIN_PATH" "${docker_compose_file}" | grep -v "KSQL_CONNECT_PLUGIN_PATH" | cut -d ":" -f 2  | tr -s " " | head -1)
      sink_connector_paths=$(grep "CONNECT_PLUGIN_PATH" "${docker_compose_sink_file}" | grep -v "KSQL_CONNECT_PLUGIN_PATH" | cut -d ":" -f 2  | tr -s " " | head -1)
      if [ "$sink_connector_paths" == "" ]
      then
        logerror "cannot find CONNECT_PLUGIN_PATH in  ${docker_compose_sink_file}"
        exit 1
      else
        tmp_new_connector_paths="$connector_paths,$sink_connector_paths"
        new_connector_paths=$(echo "$tmp_new_connector_paths" | sed 's/ //g')
        cp $docker_compose_test_file /tmp/1.yml

        yq -i ".services.connect.environment.CONNECT_PLUGIN_PATH = \"$new_connector_paths\"" /tmp/1.yml
        cp /tmp/1.yml $docker_compose_test_file
      fi

      # sh part

      line_final_source=$(grep -n 'source ${DIR}/../../scripts/utils.sh' $repro_test_file | cut -d ":" -f 1 | tail -n1)
      line_final_environment=$(grep -n 'playground start-environment' $repro_test_file | cut -d ":" -f 1 | tail -n1)
      line_sink_source=$(grep -n 'source ${DIR}/../../scripts/utils.sh' $sink_file | cut -d ":" -f 1 | tail -n1)

      line_sink_environment=$(grep -n 'playground start-environment' $sink_file | cut -d ":" -f 1 | tail -n1)

      # get converter info
      source_key_converter=$(grep "\"key.converter\"" $repro_test_file | cut -d '"' -f 4)
      if [ "$source_key_converter" == "" ]
      then
        log "💱 Source connector is using default key.converter, i.e org.apache.kafka.connect.storage.StringConverter"
      else
        if [ "$source_key_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
        then
          # check schemas.enable
          source_key_json_converter_schemas_enable=$(grep "\"key.converter.schemas.enable\"" $repro_test_file | cut -d '"' -f 4)
          if [ "$source_key_json_converter_schemas_enable" == "" ]
          then
            log "💱 Source connector is using key.converter $source_key_converter with schemas.enable=true"
          else
            log "💱 Source connector is using key.converter $source_key_converter with schemas.enable=$source_key_json_converter_schemas_enable"
          fi
        else
          log "💱 Source connector is using key.converter $source_key_converter"
        fi
      fi

      source_value_converter=$(grep "\"value.converter\"" $repro_test_file | cut -d '"' -f 4)
      if [ "$source_value_converter" == "" ]
      then
        log "💱 Source connector is using default value.converter, i.e io.confluent.connect.avro.AvroConverter"
      else
        if [ "$source_value_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
        then
          # check schemas.enable
          source_value_json_converter_schemas_enable=$(grep "\"value.converter.schemas.enable\"" $repro_test_file | cut -d '"' -f 4)
          if [ "$source_value_json_converter_schemas_enable" == "" ]
          then
            log "💱 Source connector is using value.converter $source_value_converter with schemas.enable=true"
          else
            log "💱 Source connector is using value.converter $source_value_converter with schemas.enable=$source_value_json_converter_schemas_enable"
          fi
        else
          log "💱 Source connector is using value.converter $source_value_converter"
        fi
      fi

      sink_key_converter=$(grep "\"key.converter\"" $sink_file | cut -d '"' -f 4)
      if [ "$sink_key_converter" == "" ]
      then
        log "💱 Sink connector is using default key.converter, i.e org.apache.kafka.connect.storage.StringConverter"
      else
        if [ "$sink_key_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
        then
          # check schemas.enable
          sink_key_json_converter_schemas_enable=$(grep "\"key.converter.schemas.enable\"" $sink_file | cut -d '"' -f 4)
          if [ "$sink_key_json_converter_schemas_enable" == "" ]
          then
            log "💱 Sink connector is using key.converter $sink_key_converter with schemas.enable=true"
          else
            log "💱 Sink connector is using key.converter $sink_key_converter with schemas.enable=$sink_key_json_converter_schemas_enable"
          fi
        else
          log "💱 Sink connector is using key.converter $sink_key_converter"
        fi
      fi

      sink_value_converter=$(grep "\"value.converter\"" $sink_file | cut -d '"' -f 4)
      if [ "$sink_value_converter" == "" ]
      then
        log "💱 Sink connector is using default value.converter, i.e io.confluent.connect.avro.AvroConverter"
      else
        if [ "$sink_value_converter" == "org.apache.kafka.connect.json.JsonConverter" ]
        then
          # check schemas.enable
          sink_value_json_converter_schemas_enable=$(grep "\"value.converter.schemas.enable\"" $sink_file | cut -d '"' -f 4)
          if [ "$sink_value_json_converter_schemas_enable" == "" ]
          then
            log "💱 Sink connector is using value.converter $sink_value_converter with schemas.enable=true"
          else
            log "💱 Sink connector is using value.converter $sink_value_converter with schemas.enable=$sink_value_json_converter_schemas_enable"
          fi
        else
          log "💱 Sink connector is using value.converter $sink_value_converter"
        fi
      fi

      sed -n "$(($line_sink_source+1)),$(($line_sink_environment-1))p" $sink_file > $tmp_dir/pre_sink
      cp $repro_test_file $tmp_dir/tmp_file

      { head -n $(($line_final_environment-1)) $tmp_dir/tmp_file; cat $tmp_dir/pre_sink; tail -n +$line_final_environment $tmp_dir/tmp_file; } > $repro_test_file

      sed -n "$(($line_sink_environment+1)),$ p" $sink_file > $tmp_dir/tmp_file

      # deal with converters
      set +e
      if [ "$source_value_converter" == "" ] && [ "$sink_value_converter" == "" ]
      then
        # do nothing
        :
      else
        grep "\"value.converter" $repro_test_file > $tmp_dir/source_value_converter
        if [ "$sink_value_converter" == "" ]
        then
          line=$(grep -n 'connector.class' $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)

          { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/source_value_converter; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $tmp_dir/tmp_file2
          cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file
        else
          # remove existing value.converter
          grep -vwE "\"value.converter" $tmp_dir/tmp_file > $tmp_dir/tmp_file2
          cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file

          line=$(grep -n 'connector.class' $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)

          { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/source_value_converter; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $tmp_dir/tmp_file2
          cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file
        fi
        log "🔮 Changing Sink connector value.converter to use same as source:"
        cat $tmp_dir/source_value_converter
      fi
      if [ "$source_key_converter" == "" ] && [ "$sink_key_converter" == "" ]
      then
        # do nothing
        :
      else
        grep "\"key.converter" $repro_test_file > $tmp_dir/source_key_converter
        if [ "$sink_key_converter" == "" ]
        then
          line=$(grep -n 'connector.class' $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)

          { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/source_key_converter; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $tmp_dir/tmp_file2
          cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file
        else
          # remove existing key.converter
          grep -vwE "\"key.converter" $tmp_dir/tmp_file > $tmp_dir/tmp_file2
          cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file

          line=$(grep -n 'connector.class' $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)

          { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/source_key_converter; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $tmp_dir/tmp_file2
          cp $tmp_dir/tmp_file2 $tmp_dir/tmp_file
        fi
        log "🔮 Changing Sink connector key.converter to use same as source:"
        cat $tmp_dir/source_key_converter
      fi
      set -e
      # need to remove cli which produces and change topic
      kafka_cli_producer_error=0
      kafka_cli_producer_eof=0
      line_kafka_cli_producer=$(grep -En "kafka-console-producer|kafka-avro-console-producer|kafka-json-schema-console-producer|kafka-protobuf-console-producer" $tmp_dir/tmp_file | cut -d ":" -f 1 | tail -n1)
      if [ $? != 0 ]
      then
          logwarn "Could not find kafka cli producer!"
          kafka_cli_producer_error=1
      fi
      set +e
      grep -E "kafka-console-producer|kafka-avro-console-producer|kafka-json-schema-console-producer|kafka-protobuf-console-producer" $tmp_dir/tmp_file | grep EOF > /dev/null
      if [ $? = 0 ]
      then
          kafka_cli_producer_eof=1

          sed -n "$line_kafka_cli_producer,$(($line_kafka_cli_producer + 10))p" $tmp_dir/tmp_file > /tmp/tmp
          tmp=$(grep -n "^EOF" /tmp/tmp | cut -d ":" -f 1 | tail -n1)
          if [ $tmp == "" ]
          then
            logwarn "Could not determine EOF for kafka cli producer!"
            kafka_cli_producer_error=1
          fi
          line_kafka_cli_producer_end=$(($line_kafka_cli_producer + $tmp))
      fi

      if [ $kafka_cli_producer_error == 0 ]
      then
        if [ $kafka_cli_producer_eof == 0 ]
        then
          line_kafka_cli_producer_end=$(($line_kafka_cli_producer + 1))
        fi
        { head -n $(($line_kafka_cli_producer - 2)) $tmp_dir/tmp_file; tail -n +$line_kafka_cli_producer_end $tmp_dir/tmp_file; } >  $tmp_dir/tmp_file2
        cat  $tmp_dir/tmp_file2 >> $repro_test_file
      fi
      set -e

      awk -F'--topic ' '{print $2}' $repro_test_file > $tmp_dir/tmp
      sed '/^$/d' $tmp_dir/tmp > $tmp_dir/tmp2
      original_topic_name=$(head -1 $tmp_dir/tmp2 | cut -d " " -f1)

      if [ "$original_topic_name" != "" ]
      then
        cp $repro_test_file $tmp_dir/tmp_file
        line=$(grep -n '"topics"' $repro_test_file | cut -d ":" -f 1 | tail -n1)

        echo "              \"topics\": \"$original_topic_name\"," > $tmp_dir/topic_line
        { head -n $(($line)) $tmp_dir/tmp_file; cat $tmp_dir/topic_line; tail -n +$(($line+1)) $tmp_dir/tmp_file; } > $repro_test_file
      else

        logwarn "Could not find original topic name! "
        logwarn "You would need to change topics config for sink by yourself."
      fi
    fi
  done

  cat $repro_test_file > $tmp_dir/tmp_file
  echo "" >> $tmp_dir/tmp_file

  echo "#################################################################################################" >> $tmp_dir/tmp_file
  echo "# 🧠 below is a list of cli commands that are helpful at the end of an example" >> $tmp_dir/tmp_file
  echo "# 🧠 for full documentation, visit https://kafka-docker-playground.io/#/cli !" >> $tmp_dir/tmp_file
  echo "#################################################################################################" >> $tmp_dir/tmp_file
  echo "" >> $tmp_dir/tmp_file
  echo "# 🕵️ to check logs (see https://kafka-docker-playground.io/#/cli?id=%f0%9f%95%b5%ef%b8%8f-logs)" >> $tmp_dir/tmp_file
  echo "# Example: check logs" >> $tmp_dir/tmp_file
  echo "# playground container logs --container connect" >> $tmp_dir/tmp_file
  echo "# playground container logs --container connect --open" >> $tmp_dir/tmp_file
  echo "" >> $tmp_dir/tmp_file
  echo "# 😴 use this command if you want to wait for a specific message to appear in logs" >> $tmp_dir/tmp_file
  echo "# playground container logs --container connect --wait-for-log \"<text to search>\" --max-wait 600" >> $tmp_dir/tmp_file
  echo "" >> $tmp_dir/tmp_file
  echo "# 🐢 use this command if you want to wait for connector consumer lag to be zero" >> $tmp_dir/tmp_file
  echo "# playground connector show-lag" >> $tmp_dir/tmp_file

  echo "exit 0" >> $tmp_dir/tmp_file
  echo "" >> $tmp_dir/tmp_file
  echo "" >> $tmp_dir/tmp_file

  echo "#################################################################################################" >> $tmp_dir/tmp_file
  echo "# 🚀 below is a list of snippets that can help you to build your example !" >> $tmp_dir/tmp_file
  echo "# 🚀 for full documentation, visit https://kafka-docker-playground.io/#/ !" >> $tmp_dir/tmp_file
  echo "#################################################################################################" >> $tmp_dir/tmp_file
  echo "" >> $tmp_dir/tmp_file
  if [[ "$base1" == *sink ]]
  then
    cat $root_folder/scripts/cli/snippets/sink.sh | grep -v "#!/bin/bash" >> $tmp_dir/tmp_file
  fi

  mv $tmp_dir/tmp_file $repro_test_file

  chmod u+x $repro_test_file
  repro_test_filename=$(basename -- "$repro_test_file")

  log "🌟 command to run generated example"
  echo "playground run -f $repro_dir/$repro_test_filename"

  if [[ "$OSTYPE" == "darwin"* ]]
  then
      clipboard=$(playground config get clipboard)
      if [ "$clipboard" == "" ]
      then
          playground config set clipboard true
      fi

      if [ "$clipboard" == "true" ] || [ "$clipboard" == "" ]
      then
          echo "playground run -f $repro_dir/$repro_test_filename"| pbcopy
          log "📋 command to run generated example has been copied to the clipboard (disable with 'playground config clipboard false')"
      fi
  fi

  playground state set run.test_file "$repro_dir/$repro_test_filename"
  playground state set run.connector_type "$(get_connector_type | tr -d '\n')"

  playground open --file "$repro_dir/$repro_test_filename"

  increment_cli_metric nb_reproduction_models
  log "👷 Number of repro models created so far: $(get_cli_metric nb_reproduction_models)"

  nb=$(find $root_folder -name *repro*.sh | wc -l)
  set_cli_metric nb_existing_reproduction_models $nb
  log "🛠️ Number of repro models available: $(get_cli_metric nb_existing_reproduction_models)"

  playground generate-fzf-find-files &
  playground open-docs --only-show-url

  if [[ "$repro_test_filename" == *"perf"* ]]
  then
    if [[ $test_file == *"connect-debezium-sqlserver"* ]] || [[ $test_file == *"connect-debezium-mysql"* ]] || [[ $test_file == *"connect-debezium-postgresql"* ]] || [[ $test_file == *"connect-debezium-oracle"* ]] || [[ $test_file == *"connect-cdc-oracle"* ]] || [[ $test_file == *"connect-jdbc-sqlserver"* ]] || [[ $test_file == *"connect-jdbc-mysql"* ]] || [[ $test_file == *"connect-jdbc-postgresql"* ]] || [[ $test_file == *"connect-jdbc-oracle"* ]] || [[ $test_file == *"connect-cdc-xstream"* ]]
    then
      log "🌪️ automatically enabling SQL Datagen injection as repro name contains <perf>"
      playground run -f $repro_dir/$repro_test_filename --enable-sql-datagen --force-interactive-repro $flag_list
    else
      if [[ $test_file != *"fully-managed"* ]]
      then
        log "📊 automatically enabling Grafana as repro name contains <perf>"
        playground run -f $repro_dir/$repro_test_filename --enable-jmx-grafana --force-interactive-repro $flag_list
      else

        playground run -f $repro_dir/$repro_test_filename --force-interactive-repro $flag_list
      fi
    fi
  else
    playground run -f $repro_dir/$repro_test_filename --force-interactive-repro $flag_list
  fi

}

# :command.function
playground_get_docker_compose_command() {

  # src/commands/get-docker-compose.sh
  # keep TAG, CONNECT TAG and ORACLE_IMAGE
  export TAG=$(docker inspect -f '{{.Config.Image}}' broker 2> /dev/null | cut -d ":" -f 2)
  export CP_CONNECT_TAG=$(docker inspect -f '{{.Config.Image}}' connect 2> /dev/null | cut -d ":" -f 2)
  export ORACLE_IMAGE=$(docker inspect -f '{{.Config.Image}}' oracle 2> /dev/null)

  handle_aws_credentials

  docker_command=$(playground state get run.docker_command)
  if [ "$docker_command" == "" ]
  then
    logerror "docker_command retrieved from $root_folder/playground.ini is empty !"
    exit 1
  fi
  echo "$docker_command" > /tmp/tmp
  sed -e "s|up -d|config|g" \
      -e "s|--quiet-pull||g" \
      /tmp/tmp > /tmp/playground-command-config

  bash /tmp/playground-command-config

}

# :command.function
playground_schema_get_command() {

  # src/commands/schema/get.sh
  subject="${args[--subject]}"
  id="${args[--id]}"
  deleted="${args[--deleted]}"
  verbose="${args[--verbose]}"
  store_in_tmp="${args[--store-in-tmp]}"

  get_sr_url_and_security

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi
  #log "tmp_dir is $tmp_dir"

  if [[ -n "$id" ]]
  then
      if [[ -n "$verbose" ]]
      then
          log "🐞 curl command used"
          echo "curl $sr_security -s "${sr_url}/schemas/ids/${id}""
      fi

      curl_output=$(curl $sr_security -s "${sr_url}/schemas/ids/${id}")
      ret=$?
      if [ $ret -eq 0 ]
      then
          if echo "$curl_output" | jq '. | has("error_code")' 2> /dev/null | grep -q true

          then
              error_code=$(echo "$curl_output" | jq -r .error_code)
              message=$(echo "$curl_output" | jq -r .message)
              logerror "❌ Command failed with error code $error_code"
              logerror "$message"
              exit 1
          else
              versions=$(curl $sr_security -s "${sr_url}/schemas/ids/${id}")
          fi
      else
          logerror "❌ curl request failed with error code $ret!"
          exit 1
      fi
      echo "$curl_output" | jq .
      exit 0
  fi

  if [[ ! -n "$subject" ]]
  then
      log "✨ --subject flag was not provided, applying command to all subjects"
      if [[ -n "$deleted" ]]
      then
          subject=$(playground get-subject-list)
          echo "$subject" > $tmp_dir/subjects-all
          log "🧟 deleted subjects are included"
          subject=$(playground get-subject-list --deleted)
          echo "$subject" > $tmp_dir/subjects-deleted-tmp

          sort $tmp_dir/subjects-all $tmp_dir/subjects-deleted-tmp | uniq -u > $tmp_dir/subjects-deleted
      else
          subject=$(playground get-subject-list)
      fi
      if [ "$subject" == "" ]
      then
          logerror "❌ No subject found !"
          exit 1
      fi
  fi

  maybe_include_deleted=""
  if [[ -n "$deleted" ]]
  then
      maybe_include_deleted="?deleted=true"
  fi

  found=0
  items=($subject)
  for subject in ${items[@]}
  do
      if [[ -n "$verbose" ]]
      then
          log "🐞 curl command used"
          echo "curl $sr_security -s "${sr_url}/subjects/${subject}/versions$maybe_include_deleted""
      fi

      curl_output=$(curl $sr_security -s "${sr_url}/subjects/${subject}/versions$maybe_include_deleted")
      ret=$?
      if [ $ret -eq 0 ]
      then
          if echo "$curl_output" | jq '. | has("error_code")' 2> /dev/null | grep -q true

          then
              error_code=$(echo "$curl_output" | jq -r .error_code)
              message=$(echo "$curl_output" | jq -r .message)
              if [ "$error_code" == "40401" ]
              then
                  continue
              fi
          else
              versions=$(curl $sr_security -s "${sr_url}/subjects/${subject}/versions$maybe_include_deleted")
          fi
      else
          logerror "❌ curl request failed with error code $ret!"
          exit 1
      fi

      for version in $(echo "${versions}" | jq -r '.[]')
      do
          schema_type=$(curl $sr_security -s "${sr_url}/subjects/${subject}/versions/${version}$maybe_include_deleted" | jq -r .schemaType)
          id=$(curl $sr_security -s "${sr_url}/subjects/${subject}/versions/${version}$maybe_include_deleted" | jq -r .id)
          case "${schema_type}" in
          JSON|AVRO|null)
              schema=$(curl $sr_security -s "${sr_url}/subjects/${subject}/versions/${version}/schema$maybe_include_deleted" | jq .)
          ;;
          PROTOBUF)
              schema=$(curl $sr_security -s "${sr_url}/subjects/${subject}/versions/${version}/schema$maybe_include_deleted")
          ;;
          esac

          if [ -f $tmp_dir/subjects-deleted ] && grep "${subject}" $tmp_dir/subjects-deleted
          then
              log "🧟 (deleted) subject ${subject} 💯 version ${version} (id $id)"
          else
              log "🔰 subject ${subject} 💯 version ${version} (id $id)"
          fi
          found=1

          if [[ -n "$verbose" ]]
          then
              log "🐞 curl command used"
              echo "curl $sr_security -s "${sr_url}/subjects/${subject}/versions/${version}$maybe_include_deleted""
          fi
          echo "${schema}"

          if [[ -n "$store_in_tmp" ]] && [ "$store_in_tmp" != "" ]
          then
              echo "${schema}" > $store_in_tmp/schema_$id.txt
          fi
      done
  done

  if [[ -n "$subject" ]]
  then
      if [ $found -eq 0 ]
      then
          logerror "❌ No schema found !"
          exit 1
      fi
  fi
}

# :command.function
playground_schema_register_command() {

  # src/commands/schema/register.sh
  subject="${args[--subject]}"
  schema="${args[--schema]}"
  id="${args[--id]}"
  verbose="${args[--verbose]}"

  eval "metadata_property=(${args[--metadata-property]})"
  get_sr_url_and_security

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi
  #log "tmp_dir is $tmp_dir"
  schema_file=$tmp_dir/value_schema

  if [ "$schema" = "-" ]
  then
      schema_content=$(cat "$schema")
      echo "$schema_content" > $schema_file
  else
      if [[ $schema == @* ]]
      then
          # this is a schema file
          argument_schema_file=$(echo "$schema" | cut -d "@" -f 2)
          cp $argument_schema_file $schema_file
      elif [ -f "$schema" ]
      then
          cp $schema $schema_file
      else
          schema_content=$schema
          echo "$schema_content" > $schema_file
      fi
  fi

  if grep -q "\"references\"\s*:" $schema_file
  then
      :
  elif grep -q "proto3" $schema_file
  then
      log "🔮 schema was identified as protobuf"
      schema_type=PROTOBUF
  elif grep -q "\"type\"\s*:\s*\"object\"" $schema_file
  then
      log "🔮 schema was identified as json schema"
      schema_type=JSON
  elif grep -q "\"type\"\s*:\s*\"record\"" $schema_file
  then
      log "🔮 schema was identified as avro"
      schema_type=AVRO
  else
      logerror "❌ no known schema could be identified"
      exit 1
  fi

  if grep -q "\"references\"\s*:" $schema_file
  then
      log "🔮 schema was identified with references, sending as is"
      json_new=$(cat $schema_file | tr -d '\n' | tr -s ' ')
  else
      json="{\"schemaType\":\"$schema_type\"}"
      content=$(cat $schema_file | tr -d '\n' | tr -s ' ')
      json_new=$(echo $json | jq --arg content "$content" '. + { "schema": $content }')
  fi

  # Check if the array contains multiple results
  if [ "${#metadata_property[@]}" -gt 1 ]
  then
      log "🟡 schema metadata are present, adding them"
      # Construct metadata_json using jq
      metadata_json=$(jq -n --argjson props "$(printf '%s\n' "${metadata_property[@]}" | jq -R 'split("=") | { (.[0]): .[1] }' | jq -s 'add')" '{properties: $props}')
      json_new=$(echo $json_new | jq --argjson metadata "$metadata_json" '. + { "metadata": $metadata }')
  fi

  if [[ -n "$id" ]]
  then
      function set_back_read_write {
          set +e
          curl $sr_security --request PUT -s "${sr_url}/mode/${subject}" --header 'Content-Type: application/json' --data '{"mode": "READWRITE"}' > /dev/null 2>&1
          set -e
      }
      trap set_back_read_write EXIT

      # backup
      playground schema get --subject "${subject}" --store-in-tmp "$tmp_dir" > /dev/null 2>&1

      log "Deleting subject 🔰 ${subject}"
      playground schema delete --subject "${subject}" --permanent > /dev/null 2>&1

      log "Setting mode to IMPORT"
      curl_output=$(curl $sr_security --request PUT -s "${sr_url}/mode/${subject}" --header 'Content-Type: application/json' --data '{"mode": "IMPORT"}' | jq .)
      ret=$?
      if [ $ret -eq 0 ]
      then
          if echo "$curl_output" | jq '. | has("error_code")' 2> /dev/null | grep -q true

          then
              error_code=$(echo "$curl_output" | jq -r .error_code)
              if [ "$error_code" != "40403" ] && [ "$error_code" != "40401" ]
              then
                  message=$(echo "$curl_output" | jq -r .message)
                  logerror "Command failed with error code $error_code"
                  logerror "$message"
                  exit 1
              fi
          fi
      else
          logerror "❌ curl request failed with error code $ret!"
          exit 1
      fi
      echo "$curl_output"

      # https://docs.confluent.io/platform/current/schema-registry/installation/migrate.html#migrate-an-individual-schema-to-an-already-populated-sr-subject-level-migration
      log "⏺️☢️ Registering schema to subject ${subject} with id $id"
      json_new_force_id=$(echo $json_new | jq --arg id "$id" '. + { "id": $id }')
      curl_output=$(curl $sr_security --request POST -s "${sr_url}/subjects/${subject}/versions" --header 'Content-Type: application/vnd.schemaregistry.v1+json' --data "$json_new_force_id" | jq .)
      ret=$?
      if [ $ret -eq 0 ]
      then
          if echo "$curl_output" | jq '. | has("error_code")' 2> /dev/null | grep -q true

          then
              error_code=$(echo "$curl_output" | jq -r .error_code)
              if [ "$error_code" != "40403" ] && [ "$error_code" != "40401" ]
              then
                  message=$(echo "$curl_output" | jq -r .message)
                  logerror "Command failed with error code $error_code"
                  logerror "$message"
                  exit 1
              fi
          fi
      else
          logerror "❌ curl request failed with error code $ret!"
          exit 1
      fi
      echo "$curl_output"

      log "Setting mode to READWRITE"
      curl_output=$(curl $sr_security --request PUT -s "${sr_url}/mode/${subject}" --header 'Content-Type: application/json' --data '{"mode": "READWRITE"}' | jq .)
      ret=$?
      if [ $ret -eq 0 ]
      then
          if echo "$curl_output" | jq '. | has("error_code")' 2> /dev/null | grep -q true

          then
              error_code=$(echo "$curl_output" | jq -r .error_code)
              if [ "$error_code" != "40403" ] && [ "$error_code" != "40401" ]
              then
                  message=$(echo "$curl_output" | jq -r .message)
                  logerror "Command failed with error code $error_code"
                  logerror "$message"
                  exit 1
              fi
          fi
      else
          logerror "❌ curl request failed with error code $ret!"
          exit 1
      fi
      echo "$curl_output"

      for schema_file in $tmp_dir/schema_*.txt
      do
          [ -e "$schema_file" ] || continue
          log "Restoring schema from $schema_file"
          playground schema register --subject "${subject}" --schema "$(cat $schema_file)"
      done
      exit 0
  fi

  # check if schema already exists
  # https://docs.confluent.io/platform/current/schema-registry/develop/api.html#post--subjects-(string-%20subject)
  # curl_output=$(curl $sr_security --request POST -s "${sr_url}/subjects/${subject}" \
  # --header 'Content-Type: application/vnd.schemaregistry.v1+json' \
  # --data "$json_new" | jq .)
  # ret=$?
  # if [ $ret -eq 0 ]
  # then
  #     if echo "$curl_output" | jq '. | has("error_code")' 2> /dev/null | grep -q true

  #     then
  #         error_code=$(echo "$curl_output" | jq -r .error_code)
  #         if [ "$error_code" != "40403" ] && [ "$error_code" != "40401" ]
  #         then
  #             message=$(echo "$curl_output" | jq -r .message)
  #             logerror "Command failed with error code $error_code"
  #             logerror "$message"
  #             exit 1
  #         fi
  #     else
  #         id=$(echo "$curl_output" | jq -r .id)
  #         version=$(echo "$curl_output" | jq -r .version)
  #         log "🚪 Skipping as schema already exists with id $id (version $version)"
  #         exit 0
  #     fi
  # else
  #     logerror "❌ curl request failed with error code $ret!"
  #     exit 1
  # fi

  log "⏺️ Registering schema to subject ${subject}"
  if [[ -n "$verbose" ]]
  then
      log "🐞 curl command used"
      echo "curl $sr_security --request POST -s "${sr_url}/subjects/${subject}/versions" --header 'Content-Type: application/vnd.schemaregistry.v1+json' --data "$json_new""
  fi
  curl $sr_security --request POST -s "${sr_url}/subjects/${subject}/versions" --header 'Content-Type: application/vnd.schemaregistry.v1+json' --data "$json_new" | jq .

}

# :command.function
playground_schema_get_compatibility_command() {

  # src/commands/schema/get-compatibility.sh
  subject="${args[--subject]}"
  verbose="${args[--verbose]}"

  get_sr_url_and_security

  log "🛡️ Get compatibility for subject ${subject}"
  if [[ -n "$verbose" ]]
  then
      log "🐞 curl command used"
      echo "curl $sr_security -s -H "Content-Type: application/vnd.schemaregistry.v1+json" "${sr_url}/config/${subject}""
  fi
  curl_output=$(curl $sr_security -s -H "Content-Type: application/vnd.schemaregistry.v1+json" "${sr_url}/config/${subject}")
  ret=$?
  if [ $ret -eq 0 ]
  then
      if echo "$curl_output" | jq '. | has("error_code")' 2> /dev/null | grep -q true

      then
          error_code=$(echo "$curl_output" | jq -r .error_code)
          message=$(echo "$curl_output" | jq -r .message)
          logerror "Command failed with error code $error_code"
          logerror "$message"
          exit 1
      else
          compatibilityLevel=$(echo "$curl_output" | jq -r .compatibilityLevel)
          echo "$compatibilityLevel"
      fi
  else
      logerror "❌ curl request failed with error code $ret!"
      exit 1
  fi
}

# :command.function
playground_schema_set_compatibility_command() {

  # src/commands/schema/set-compatibility.sh
  subject="${args[--subject]}"
  compatibility="${args[--compatibility]}"
  verbose="${args[--verbose]}"

  get_sr_url_and_security

  log "🛡️ Set compatibility for subject ${subject} to $compatibility"
  if [[ -n "$verbose" ]]
  then
      log "🐞 curl command used"
      echo "curl $sr_security -s -X PUT -H "Content-Type: application/vnd.schemaregistry.v1+json" --data "{\"compatibility\": \"$compatibility\"}" "${sr_url}/config/${subject}""
  fi
  curl_output=$(curl $sr_security -s -X PUT -H "Content-Type: application/vnd.schemaregistry.v1+json" --data "{\"compatibility\": \"$compatibility\"}" "${sr_url}/config/${subject}" | jq .)
  ret=$?
  if [ $ret -eq 0 ]
  then
      error_code=$(echo "$curl_output" | jq -r .error_code)
      if [ "$error_code" != "null" ]
      then
          message=$(echo "$curl_output" | jq -r .message)
          logerror "Command failed with error code $error_code"
          logerror "$message"
          exit 1
      else
          compatibilityLevel=$(echo "$curl_output" | jq -r .compatibilityLevel)
          echo "$compatibilityLevel"
      fi
  else
      logerror "❌ curl request failed with error code $ret!"
      exit 1
  fi
}

# :command.function
playground_schema_get_mode_command() {

  # src/commands/schema/get-mode.sh
  subject="${args[--subject]}"
  verbose="${args[--verbose]}"

  get_sr_url_and_security

  log "🔏 Get mode for subject ${subject}"
  if [[ -n "$verbose" ]]
  then
      log "🐞 curl command used"
      echo "curl $sr_security -s -H "Content-Type: application/vnd.schemaregistry.v1+json" "${sr_url}/mode/${subject}""
  fi
  curl_output=$(curl $sr_security -s -H "Content-Type: application/vnd.schemaregistry.v1+json" "${sr_url}/mode/${subject}")
  ret=$?
  if [ $ret -eq 0 ]
  then
      if echo "$curl_output" | jq '. | has("error_code")' 2> /dev/null | grep -q true

      then
          error_code=$(echo "$curl_output" | jq -r .error_code)
          message=$(echo "$curl_output" | jq -r .message)
          logerror "Command failed with error code $error_code"
          logerror "$message"
          exit 1
      else
          mode=$(echo "$curl_output" | jq -r .mode)
          echo "$mode"
      fi
  else
      logerror "❌ curl request failed with error code $ret!"
      exit 1
  fi
}

# :command.function
playground_schema_set_mode_command() {

  # src/commands/schema/set-mode.sh
  subject="${args[--subject]}"
  mode="${args[--mode]}"
  verbose="${args[--verbose]}"

  get_sr_url_and_security

  log "🔏 Set mode for subject ${subject} to $mode"
  if [[ -n "$verbose" ]]
  then
      log "🐞 curl command used"
      echo "curl $sr_security -s -X PUT -H "Content-Type: application/vnd.schemaregistry.v1+json" --data "{\"mode\": \"$mode\"}" "${sr_url}/mode/${subject}""
  fi
  curl_output=$(curl $sr_security -s -X PUT -H "Content-Type: application/vnd.schemaregistry.v1+json" --data "{\"mode\": \"$mode\"}" "${sr_url}/mode/${subject}" | jq .)
  ret=$?
  if [ $ret -eq 0 ]
  then
      if echo "$curl_output" | jq '. | has("error_code")' 2> /dev/null | grep -q true

      then
          error_code=$(echo "$curl_output" | jq -r .error_code)
          message=$(echo "$curl_output" | jq -r .message)
          logerror "Command failed with error code $error_code"
          logerror "$message"
          exit 1
      else
          mode=$(echo "$curl_output" | jq -r .mode)
          echo "$mode"
      fi
  else
      logerror "❌ curl request failed with error code $ret!"
      exit 1
  fi
}

# :command.function
playground_schema_set_normalize_command() {

  # src/commands/schema/set-normalize.sh
  value="${args[--value]}"
  verbose="${args[--verbose]}"

  get_sr_url_and_security

  log "🧽 Set normalize to $value at schema registry level"
  if [[ -n "$verbose" ]]
  then
      log "🐞 curl command used"
      echo "curl $sr_security -s -X PUT -H "Content-Type: application/vnd.schemaregistry.v1+json" --data "{\"normalize\": \"${value}\"}" "${sr_url}/config""
  fi
  curl_output=$(curl $sr_security -s -X PUT -H "Content-Type: application/vnd.schemaregistry.v1+json" --data "{\"normalize\": \"${value}\"}" "${sr_url}/config" | jq .)
  ret=$?
  if [ $ret -eq 0 ]
  then
      if echo "$curl_output" | jq '. | has("error_code")' 2> /dev/null | grep -q true

      then
          error_code=$(echo "$curl_output" | jq -r .error_code)
          message=$(echo "$curl_output" | jq -r .message)
          logerror "Command failed with error code $error_code"
          logerror "$message"
          exit 1
      else
          normalize=$(echo "$curl_output" | jq -r .normalize)
          echo "$normalize"
      fi
  else
      logerror "❌ curl request failed with error code $ret!"
      exit 1
  fi
}

# :command.function
playground_schema_delete_command() {

  # src/commands/schema/delete.sh
  subject="${args[--subject]}"
  version="${args[--version]}"
  permanent="${args[--permanent]}"
  verbose="${args[--verbose]}"

  get_sr_url_and_security

  if [[ -n "$version" ]]
  then
      if [[ ! -n "$subject" ]]
      then
          logerror "❌ --version is set without --subject being set"
          exit 1
      fi
  fi

  # https://docs.confluent.io/platform/current/schema-registry/develop/api.html#delete--subjects-(string-%20subject)-versions-(versionId-%20version)
  if [[ -n "$subject" ]]
  then
      if [[ -n "$version" ]]
      then
          log "🧟 Soft deleting 💯 version ${version} from subject 🔰 ${subject}"
          if [[ -n "$verbose" ]]
          then
              log "🐞 curl command used"
              echo "curl $sr_security -X DELETE -s "${sr_url}/subjects/${subject}/versions/${version}""
          fi
          curl $sr_security -X DELETE -s "${sr_url}/subjects/${subject}/versions/${version}" | jq .
          if [[ -n "$permanent" ]]
          then
              log "💀 Hard deleting 💯 version ${version} from subject 🔰 ${subject}"
              if [[ -n "$verbose" ]]
              then
                  log "🐞 curl command used"
                  echo "curl $sr_security -X DELETE -s "${sr_url}/subjects/${subject}/versions/${version}?permanent=true""
              fi
              curl $sr_security -X DELETE -s "${sr_url}/subjects/${subject}/versions/${version}?permanent=true" | jq .
          fi
      else
          logwarn "--version is not set, deleting all versions !"
          log "🧟 Soft deleting subject 🔰 ${subject}"
          if [[ -n "$verbose" ]]
          then
              log "🐞 curl command used"
              echo "curl $sr_security -X DELETE -s "${sr_url}/subjects/${subject}""
          fi
          curl $sr_security -X DELETE -s "${sr_url}/subjects/${subject}" | jq .
          if [[ -n "$permanent" ]]
          then
              log "💀 Hard deleting subject 🔰 ${subject}"
              if [[ -n "$verbose" ]]
              then
                  log "🐞 curl command used"
                  echo "curl $sr_security -X DELETE -s "${sr_url}/subjects/${subject}?permanent=true""
              fi
              curl $sr_security -X DELETE -s "${sr_url}/subjects/${subject}?permanent=true" | jq .
          fi
      fi
  fi
}

# :command.function
playground_schema_derive_schema_command() {

  # src/commands/schema/derive-schema.sh
  schema_type="${args[--schema-type]}"
  payload="${args[--payload]}"
  verbose="${args[--verbose]}"

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  payload_file=$tmp_dir/payload_file

  if [ "$payload" = "-" ]
  then
      # stdin
      if [ -t 0 ]
      then
          logerror "❌ stdin is empty you probably forgot to set --payload !"
          exit 1
      else
          payload_content=$(cat "$payload")
          echo "$payload_content" > $payload_file
      fi
  else
      if [[ $payload == @* ]]
      then
          # this is a payload file
          argument_payload_file=$(echo "$payload" | cut -d "@" -f 2)
          cp $argument_payload_file $payload_file
      elif [ -f "$payload" ]
      then
          cp $payload $payload_file
      else
          payload_content=$payload
          echo "$payload_content" > $payload_file
      fi
  fi

  if jq -e . >/dev/null 2>&1 <<< "$(head -1 "$payload_file")"
  then
      log "💫 payload is one json per line, one json record per line will be used"
  elif jq -e . >/dev/null 2>&1 <<< "$(cat "$payload_file")"
  then
      log "💫 payload is single json, it will be used as one record"
      jq -c . "$payload_file" > $tmp_dir/minified.json
      cp $tmp_dir/minified.json $payload_file
  else
      logerror "❌ payload is not a valid json"
      exit 1
  fi

  LATEST_TAG=$(grep "export TAG" $root_folder/scripts/utils.sh | head -1 | cut -d "=" -f 2 | cut -d " " -f 1)
  if [ -z "$LATEST_TAG" ]
  then
      logerror "❌ error while getting default TAG "
      exit 1
  fi

  cat << EOF > $tmp_dir/pom.xml
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0

http://maven.apache.org/xsd/maven-4.0.0.xsd">
  <modelVersion>4.0.0</modelVersion>
  <groupId>io.confluent.app</groupId>
  <artifactId>my-app</artifactId>
  <version>1</version>
  <pluginRepositories>
    <pluginRepository>
      <id>confluent</id>
      <url>https://packages.confluent.io/maven/</url>
    </pluginRepository>
  </pluginRepositories>
  <build>
    <plugins>
      <plugin>
        <groupId>io.confluent</groupId>
        <artifactId>kafka-schema-registry-maven-plugin</artifactId>
        <version>$LATEST_TAG</version>
        <configuration>
          <messagePath>/usr/src/mymaven/payload_file</messagePath>
          <schemaType>$schema_type</schemaType>
          <outputPath>/usr/src/mymaven/schema_file</outputPath>
        </configuration>
      </plugin>
    </plugins>
  </build>
</project>
EOF

  set +e
  log "🔮 Calling derive-schema maven plugin (see https://docs.confluent.io/platform/current/schema-registry/develop/maven-plugin.html#schema-registry-derive-schema)"
  docker run -i --rm -v "${tmp_dir}":/usr/src/mymaven -v "$HOME/.m2":/root/.m2 -v "$root_folder/scripts/settings.xml:/tmp/settings.xml" -w /usr/src/mymaven maven:3.6.1-jdk-11 mvn -s /tmp/settings.xml io.confluent:kafka-schema-registry-maven-plugin:derive-schema > /tmp/result.log 2>&1
  if [ $? != 0 ]
  then
      logerror "❌ error while calling derive-schema"
      tail -500 /tmp/result.log
      exit 1
  fi

  set -e
  log "🪄 Schema file generated"
  cat $tmp_dir/schema_file | jq -r '.schemas[]|del(.messagesMatched)|.schema'
}

# :command.function
playground_tcp_proxy_start_command() {

  # src/commands/tcp-proxy/start.sh
  hostname="${args[--hostname]}"
  port="${args[--port]}"
  throttle_service_response="${args[--throttle-service-response]}"
  delay_service_response="${args[--delay-service-response]}"
  break_service_response="${args[--break-service-response]}"
  service_response_corrupt="${args[--service-response-corrupt]}"
  skip_automatic_connector_config=${args[--skip-automatic-connector-config]}

  # keep TAG, CONNECT TAG and ORACLE_IMAGE
  export TAG=$(docker inspect -f '{{.Config.Image}}' broker 2> /dev/null | cut -d ":" -f 2)
  export CP_CONNECT_TAG=$(docker inspect -f '{{.Config.Image}}' connect 2> /dev/null | cut -d ":" -f 2)
  export ORACLE_IMAGE=$(docker inspect -f '{{.Config.Image}}' oracle 2> /dev/null)

  docker_command=$(playground state get run.docker_command)
  if [ "$docker_command" == "" ]
  then
    logerror "docker_command retrieved from $root_folder/playground.ini is empty !"
    exit 1
  fi

  service_response_corrupt_method=""
  if [[ -n "$service_response_corrupt" ]]
  then
      service_response_corrupt_method="randomize"
  fi

  mkdir -p /tmp/zazkia
    cat << EOF > /tmp/zazkia/zazkia-routes.json
[
    {
        "label": "tcp-proxy",
        "service-hostname": "$hostname",
        "service-port": $port,
        "listen-port": 49998,
        "transport": {
            "accept-connections": true,
            "throttle-service-response": $throttle_service_response,
            "delay-service-response": $delay_service_response,
            "break-service-response": $break_service_response,
            "service-response-corrupt-method": "$service_response_corrupt_method",
            "sending-to-client": true,
            "receiving-from-client": true,
            "sending-to-service": true,
            "receiving-from-service": true,
            "verbose": true
        }
    }
]
EOF

    cat << EOF > /tmp/docker-compose.override.zazkia.yml
services:
  zazkia:
    hostname: zazkia
    container_name: zazkia
    # use my own image because of https://github.com/emicklei/zazkia/issues/4
    image: vdesabou/zazkia:latest
    ports:
      - "9191:9191"
    volumes:
      - /tmp/zazkia:/data
    environment:
      DUMMY: $RANDOM
EOF

  echo "$docker_command" > /tmp/playground-command-zazkia
  sed -i -E -e "s|up -d --quiet-pull|-f /tmp/docker-compose.override.zazkia.yml up -d --quiet-pull|g" /tmp/playground-command-zazkia
  log "💫 adding container zazkia listening on port 49998"
  bash /tmp/playground-command-zazkia

  log "💗 you can now use zazkia tcp proxy using <zazkia:49998>"
  log "🌐 zazkia UI is available on http://localhost:9191"
  if [[ $(type -f open 2>&1) =~ "not found" ]]
  then
    :
  else
    open "http://localhost:9191"
  fi

  if [[ -n "$skip_automatic_connector_config" ]]
  then
      log "🤖 --skip-automatic-connector-config is set"
  else
    connector=$(playground get-connector-list)
    if [ "$connector" == "" ]
    then
        log "💤 No connector is running, skipping automatic update of connector configuration with tcp proxy"
        exit 0
    fi

    tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
    if [ -z "$PG_VERBOSE_MODE" ]
    then
        trap 'rm -rf $tmp_dir' EXIT
    else
        log "🐛📂 not deleting tmp dir $tmp_dir"
    fi

    items=($connector)
    for connector in "${items[@]}"
    do
      is_modified=0
      log "🔮 checking existence of hostname $hostname and port $port in connector $connector configuration to replace with zazkia and port 49998"

      playground --output-level ERROR connector show-config --connector $connector > "$tmp_dir/create-$connector-config.sh"

      if grep -q "$hostname:$port" "$tmp_dir/create-$connector-config.sh"; then
        sed -i -E -e "s|$hostname:$port|zazkia:49998|g" "$tmp_dir/create-$connector-config.sh"
        log "replacing $hostname:$port by zazkia:49998"
        is_modified=1
      fi

      if grep -q "\"$hostname\"" "$tmp_dir/create-$connector-config.sh"; then
        sed -i -E -e "s|\"$hostname\"|\"zazkia\"|g" "$tmp_dir/create-$connector-config.sh"
        log "replacing \"$hostname\" by \"zazkia\""
        is_modified=1
      fi
      if grep -q "$port" "$tmp_dir/create-$connector-config.sh"; then
        sed -i -E -e "s|$port|49998|g" "$tmp_dir/create-$connector-config.sh"
        log "replacing $port by 49998"
        is_modified=1
      fi

      if [ $is_modified -eq 1 ]
      then
        log "💫 updating connector $connector configuration with"
        cat "$tmp_dir/create-$connector-config.sh"
        check_if_continue
        bash "$tmp_dir/create-$connector-config.sh"
      else
        logwarn "💅 could not replace automatically hostname $hostname and port $port in connector $connector configuration, please do it manually !"
      fi
    done
  fi
}

# :command.function
playground_tcp_proxy_get_connections_command() {

  # src/commands/tcp-proxy/get-connections.sh
  connection_id="${args[--connection-id]}"

  handle_onprem_connect_rest_api "curl -s -X GET -H \"Content-Type: application/json\" \"http://localhost:9191/links/\""
  if [[ $(echo "$curl_output" | jq -r '.[].links[]') != "" ]]
  then
      if [[ ! -n "$connection_id" ]]
      then
          echo "$curl_output" | jq -r '.[].links[] | select(.serviceReceiveError != "EOF") | {id, state, stats}'
      else
          echo "$curl_output" | jq -r '.[].links[] | select(.id == '$connection_id' and .serviceReceiveError != "EOF") | {id, state, stats}'
      fi
  else
      log "❌ No active Zazkia TCP connection found, make sure that Zazkia is being used!"
  fi
}

# :command.function
playground_tcp_proxy_delay_command() {

  # src/commands/tcp-proxy/delay.sh
  delay_service_response="${args[--delay-service-response]}"
  connection_id="${args[--connection-id]}"

  if [[ ! -n "$connection_id" ]]
  then
      connection_id=$(playground get-zazkia-connection-list)
      if [ "$connection_id" == "" ]
      then
          logerror "❌ No active Zazkia TCP connection found, make sure that Zazkia is being used!"
          exit 1
      fi
  fi

  items=($connection_id)
  length=${#items[@]}
  if ((length > 1))
  then
      log "🧲 --connection-id flag was not provided, applying command to all active Zazkia TCP connections"
  fi
  for id in "${items[@]}"
  do
      log "⏲️ Add $delay_service_response milliseconds delay to service response for connection id $id"
      handle_onprem_connect_rest_api "curl -s -X POST -H \"Content-Type: application/json\" \"http://localhost:9191/links/$id/delay-response?ms=$delay_service_response\""

      echo "$curl_output"

      sleep 1

      playground tcp-proxy get-connections --connection-id $id
  done
}

# :command.function
playground_tcp_proxy_break_command() {

  # src/commands/tcp-proxy/break.sh
  break_service_response="${args[--break-service-response]}"
  connection_id="${args[--connection-id]}"

  if [[ ! -n "$connection_id" ]]
  then
      connection_id=$(playground get-zazkia-connection-list)
      if [ "$connection_id" == "" ]
      then
          logerror "❌ No active Zazkia TCP connection found, make sure that Zazkia is being used!"
          exit 1
      fi
  fi

  items=($connection_id)
  length=${#items[@]}
  if ((length > 1))
  then
      log "🧲 --connection-id flag was not provided, applying command to all active Zazkia TCP connections"
  fi
  for id in "${items[@]}"
  do
      log "💔 Break sending the response to the client for $break_service_response % for connection id $id"
      handle_onprem_connect_rest_api "curl -s -X POST -H \"Content-Type: application/json\" \"http://localhost:9191/links/$id/break-response?pct=$break_service_response\""

      echo "$curl_output"

      sleep 1

      playground tcp-proxy get-connections --connection-id $id
  done
}

# :command.function
playground_tcp_proxy_close_connection_command() {

  # src/commands/tcp-proxy/close-connection.sh
   connection_id="${args[--connection-id]}"

  if [[ ! -n "$connection_id" ]]
  then
      connection_id=$(playground get-zazkia-connection-list)
      if [ "$connection_id" == "" ]
      then
          logerror "❌ No active Zazkia TCP connection found, make sure that Zazkia is being used!"
          exit 1
      fi
  fi

  items=($connection_id)
  length=${#items[@]}
  if ((length > 1))
  then
      log "🧲 --connection-id flag was not provided, applying command to all active Zazkia TCP connections"
  fi
  for id in "${items[@]}"
  do
      log "❌ closing connection id $id"
      handle_onprem_connect_rest_api "curl -s -X POST -H \"Content-Type: application/json\" \"http://localhost:9191/links/$id/close\""

      echo "$curl_output"
  done
}

# :command.function
playground_tcp_proxy_close_all_connection_with_error_command() {

  # src/commands/tcp-proxy/close-all-connection-with-error.sh
  log "🧹 Close all Zazkia TCP connections which are in error state"
  handle_onprem_connect_rest_api "curl -o /dev/null -w '%{http_code}' -s -X POST -H \"Content-Type: application/json\" \"http://localhost:9191/links/closeAllWithError\""
  echo "$curl_output"
}

# :command.function
playground_tcp_proxy_toggle_accept_connections_command() {

  # src/commands/tcp-proxy/toggle-accept-connections.sh
  log "🙅‍♂️ Change whether new connections can be accepted"
  handle_onprem_connect_rest_api "curl -s -X POST -H \"Content-Type: application/json\"  --header 'Accept: application/json' \"http://localhost:9191/routes/tcp-proxy/toggle-accept\""

  echo "$curl_output" | jq -r '.'
}

# :command.function
playground_tcp_proxy_toggle_reads_client_command() {

  # src/commands/tcp-proxy/toggle-reads-client.sh
  connection_id="${args[--connection-id]}"

  if [[ ! -n "$connection_id" ]]
  then
      connection_id=$(playground get-zazkia-connection-list)
      if [ "$connection_id" == "" ]
      then
          logerror "❌ No active Zazkia TCP connection found, make sure that Zazkia is being used!"
          exit 1
      fi
  fi

  items=($connection_id)
  length=${#items[@]}
  if ((length > 1))
  then
      log "🧲 --connection-id flag was not provided, applying command to all active Zazkia TCP connections"
  fi
  for id in "${items[@]}"
  do
      log "✅ toggle-reads-client for connection id $id"
      handle_onprem_connect_rest_api "curl -o /dev/null -w '%{http_code}' -s -X POST -H \"Content-Type: application/json\" \"http://localhost:9191/links/$id/toggle-reads-client\""
      echo "$curl_output"
  done
}

# :command.function
playground_tcp_proxy_toggle_reads_service_command() {

  # src/commands/tcp-proxy/toggle-reads-service.sh
  connection_id="${args[--connection-id]}"

  if [[ ! -n "$connection_id" ]]
  then
      connection_id=$(playground get-zazkia-connection-list)
      if [ "$connection_id" == "" ]
      then
          logerror "❌ No active Zazkia TCP connection found, make sure that Zazkia is being used!"
          exit 1
      fi
  fi

  items=($connection_id)
  length=${#items[@]}
  if ((length > 1))
  then
      log "🧲 --connection-id flag was not provided, applying command to all active Zazkia TCP connections"
  fi
  for id in "${items[@]}"
  do
      log "✅ toggle-reads-service for connection id $id"
      handle_onprem_connect_rest_api "curl -o /dev/null -w '%{http_code}' -s -X POST -H \"Content-Type: application/json\" \"http://localhost:9191/links/$id/toggle-reads-service\""
      echo "$curl_output"
  done
}

# :command.function
playground_tcp_proxy_toggle_writes_client_command() {

  # src/commands/tcp-proxy/toggle-writes-client.sh
  connection_id="${args[--connection-id]}"

  if [[ ! -n "$connection_id" ]]
  then
      connection_id=$(playground get-zazkia-connection-list)
      if [ "$connection_id" == "" ]
      then
          logerror "❌ No active Zazkia TCP connection found, make sure that Zazkia is being used!"
          exit 1
      fi
  fi

  items=($connection_id)
  length=${#items[@]}
  if ((length > 1))
  then
      log "🧲 --connection-id flag was not provided, applying command to all active Zazkia TCP connections"
  fi
  for id in "${items[@]}"
  do
      log "✅ toggle-writes-client for connection id $id"
      handle_onprem_connect_rest_api "curl -o /dev/null -w '%{http_code}' -s -X POST -H \"Content-Type: application/json\" \"http://localhost:9191/links/$id/toggle-writes-client\""
      echo "$curl_output"
  done
}

# :command.function
playground_tcp_proxy_toggle_writes_service_command() {

  # src/commands/tcp-proxy/toggle-writes-service.sh
  connection_id="${args[--connection-id]}"

  if [[ ! -n "$connection_id" ]]
  then
      connection_id=$(playground get-zazkia-connection-list)
      if [ "$connection_id" == "" ]
      then
          logerror "❌ No active Zazkia TCP connection found, make sure that Zazkia is being used!"
          exit 1
      fi
  fi

  items=($connection_id)
  length=${#items[@]}
  if ((length > 1))
  then
      log "🧲 --connection-id flag was not provided, applying command to all active Zazkia TCP connections"
  fi
  for id in "${items[@]}"
  do
      log "✅ toggle-writes-service for connection id $id"
      handle_onprem_connect_rest_api "curl -o /dev/null -w '%{http_code}' -s -X POST -H \"Content-Type: application/json\" \"http://localhost:9191/links/$id/toggle-writes-service\""
      echo "$curl_output"
  done
}

# :command.function
playground_tcp_proxy_open_ui_command() {

  # src/commands/tcp-proxy/open-ui.sh
  if [[ $(type -f open 2>&1) =~ "not found" ]]
  then
      log "🔗 Cannot open browser, use url:"
      echo "http://localhost:9191"
  else
      log "🧲 Open Zazkia UI"
      open "http://localhost:9191"
  fi

}

# :command.function
playground_tools_install_vscode_extension_command() {

  # src/commands/tools/install-vscode-extension.sh
  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  extension_dir=$tmp_dir/extension

  mkdir $extension_dir
  cd $extension_dir

  log "🪄 Installing Shell Script Command Completion extension"

  curl -s -L https://tetradresearch.gallery.vsassets.io/_apis/public/gallery/publisher/tetradresearch/extension//vscode-h2o/latest/assetbyname/Microsoft.VisualStudio.Services.VSIXPackage -o extension.zip
  unzip extension.zip > /dev/null 2>&1

  if [ ! -f extension/out/cacheFetcher.js ]
  then
    logerror "❌ cacheFetcher.js is not present !"
    exit 1
  fi

  if grep 'https://raw.githubusercontent.com/yamaton/h2o-curated-data/main/${kind}/json/${name}.json' extension/out/cacheFetcher.js
  then
      sed -i -E -e "s|https://raw.githubusercontent.com/yamaton/h2o-curated-data/main/\${kind}/json/\${name}.json|https://raw.githubusercontent.com/vdesabou/kafka-docker-playground/master/scripts/cli/playground.json|g" extension/out/cacheFetcher.js > /dev/null 2>&1
      zip -r extension.zip extension > /dev/null 2>&1
      mv extension.zip extension.vsix

      set +e
      code --uninstall-extension extension.vsix > /dev/null 2>&1

      code --install-extension extension.vsix > /dev/null 2>&1
      if [ $? -eq 0 ]
      then
          log "👏 extension is now installed"
      else
          logerror "❌ Failed to install Shell Script Command Completion extension"
      fi
  else
    logerror "❌ cannot retrieve experimental url"
    exit 1
  fi
}

# :command.function
playground_tools_read_avro_file_command() {

  # src/commands/tools/read-avro-file.sh
  file="${args[--file]}"

  if [[ $file == *"@"* ]]
  then
    file=$(echo "$file" | cut -d "@" -f 2)
  fi

  filename=$(basename $file)

  log "🔖 ${filename}.avro metadata"
  docker run --quiet --rm -v ${file}:/tmp/${filename} vdesabou/avro-tools getmeta /tmp/${filename}

  log "🔖 ${filename}.avro schema"
  docker run --quiet --rm -v ${file}:/tmp/${filename} vdesabou/avro-tools getschema /tmp/${filename}

  log "🔖 ${filename}.avro content"
  docker run --quiet --rm -v ${file}:/tmp/${filename} vdesabou/avro-tools tojson /tmp/${filename}

}

# :command.function
playground_tools_read_parquet_file_command() {

  # src/commands/tools/read-parquet-file.sh
  file="${args[--file]}"

  if [[ $file == *"@"* ]]
  then
    file=$(echo "$file" | cut -d "@" -f 2)
  fi

  filename=$(basename $file)

  log "🔖 ${filename}.parquet metadata"
  docker run --quiet --rm -v ${file}:/tmp/${filename} nathanhowell/parquet-tools meta /tmp/${filename}

  log "🔖 ${filename}.parquet schema"
  docker run --quiet --rm -v ${file}:/tmp/${filename} nathanhowell/parquet-tools schema /tmp/${filename}

  log "🔖 ${filename}.parquet content"
  docker run --quiet --rm -v ${file}:/tmp/${filename} nathanhowell/parquet-tools cat /tmp/${filename}

}

# :command.function
playground_tools_certs_create_command() {

  # src/commands/tools/certs-create.sh
  output_folder="${args[--output-folder]}"
  verbose="${args[--verbose]}"
  # Convert the space delimited string to an array
  eval "containers=(${args[--container]})"

  function cleanup {
      set +e
      rm -f "${output_folder}/certs-create.sh"
  }
  trap cleanup EXIT

  maybe_redirect_output="> /dev/null 2>&1"
  if [[ -n "$verbose" ]]
  then
      maybe_redirect_output=""
  fi

  container_list="${containers[*]}"

  get_connect_image
  new_open_ssl=0
  if version_gt $CP_CONNECT_TAG "7.7.99"
  then
      new_open_ssl=1
  fi
  mkdir -p "${output_folder}"
  cd "${output_folder}"
  cp $root_folder/scripts/cli/src/ssl/certs-create.sh .
  log "🔐 Generate keys and certificates in folder ${output_folder}"
    docker run -u0 --rm -v $root_folder/scripts/cli/src/openssl.cnf:/usr/local/ssl/openssl.cnf -v $PWD:/tmp ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} bash -c "/tmp/certs-create.sh $maybe_redirect_output \"$container_list\" $new_open_ssl && chown -R $(id -u $USER):$(id -g $USER) /tmp/"
}

# :command.function
playground_debug_enable_remote_debugging_command() {

  # src/commands/debug/enable-remote-debugging.sh
  containers="${args[--container]}"

  # Convert space-separated string to array
  IFS=' ' read -ra container_array <<< "$containers"

  for container in "${container_array[@]}"
  do
  	log "✨ enable remote debugging for $container"
  	playground container set-environment-variables --container "${container}" --env "KAFKA_DEBUG: 'true'" --env "JAVA_DEBUG_OPTS: '-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=0.0.0.0:5005'"

  	log "If you use Visual Studio Code:"
  	log "Edit .vscode/launch.json with"

  	log "
  	{
  		\"version\": \"0.2.0\",
  		\"configurations\": [

  			{
  				\"type\": \"java\",
  				\"name\": \"Debug $component container\",
  				\"request\": \"attach\",
  				\"hostName\": \"127.0.0.1\",
  				\"port\": 5005,
  				\"timeout\": 30000
  			}
  		]
  	}
  	"

  	log "See https://kafka-docker-playground.io/#/reusables?id=✨-remote-debugging"
  done
}

# :command.function
playground_debug_testssl_command() {

  # src/commands/debug/testssl.sh
  uri="${args[--uri]}"

  if [[ ${#other_args[@]} -gt 0 ]]
  then
  	log "🔐 Testing TLS/SSL encryption with uri $uri and arguments ${other_args[*]}"
  	docker run --quiet --rm -ti  drwetter/testssl.sh "${other_args[*]}" "$uri"
  else
  	log "🔐 Testing TLS/SSL encryption with uri $uri"
  	docker run --quiet --rm -ti  drwetter/testssl.sh "$uri"
  fi

}

# :command.function
playground_debug_generate_diagnostics_command() {

  # src/commands/debug/generate-diagnostics.sh
  containers="${args[--container]}"

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  # Convert space-separated string to array
  IFS=' ' read -ra container_array <<< "$containers"

  for container in "${container_array[@]}"
  do
  	if [[ "$container" == "connect" ]] || [[ "$container" == "broker" ]]
  	then
  		log "⛑️ Creating diagnostics bundle for container ${container}"
  		log "⏳ please wait..."
  	else
  		logerror "❌ only connect and broker containers are supported"
  		exit 1
  	fi

  	docker exec $container curl -L https://packages.confluent.io/tools/diagnostics-bundle/diagnostics-bundle-1.0.0.jar -o /tmp/diagnostics-bundle-1.0.0.jar > /dev/null 2>&1

  	fifo_path="$tmp_dir/collect_fifo"
  	mkfifo "$fifo_path"

  	set +e
  	docker exec $container java -jar /tmp/diagnostics-bundle-1.0.0.jar collect > "$fifo_path" 2>&1 &

  	# Loop through each line in the named pipe
  	while read -r line
  	do
  		echo "$line"
  		echo "$line" >> $tmp_dir/result.log

  	done < "$fifo_path"

  	nb=$(grep -c "Diagnostics output has been zipped and written to" $tmp_dir/result.log)
  	if [ $nb -eq 0 ]
  	then
  		logerror "❌ Failed to generate bundle"
  		cat $tmp_dir/result.log
  		exit 1
  	fi
  	bundle_file=$(cat $tmp_dir/result.log | grep "Diagnostics output has been zipped and written to" | cut -d ":" -f 4 | sed 's/ //g')
  	bundle_file_filename=$(basename -- "$bundle_file")
  	log "⛑️ diagnostics bundle is available at ${bundle_file_filename}"
  	docker cp ${container}:${bundle_file} ${bundle_file_filename}
  done
}

# :command.function
playground_debug_thread_dump_command() {

  # src/commands/debug/thread-dump.sh
  containers="${args[--container]}"

  # Convert space-separated string to array
  IFS=' ' read -ra container_array <<< "$containers"

  for container in "${container_array[@]}"
  do
  	filename="/tmp/thread-dump-$container-$(date '+%Y-%m-%d-%H-%M-%S').log"

  	set +e
  	docker exec $container type jstack > /dev/null 2>&1
  	if [ $? != 0 ]
  	then
  		logerror "❌ jstack is not installed on container $container"
  		exit 1
  	fi
  	set -e
  	log "🎯 Taking thread dump on container ${container} for pid 1"
  	docker exec $container jstack 1 > "$filename" 2>&1
  	if [ $? -eq 0 ]
  	then
  		playground open --file "${filename}"
  	else
  		logerror "❌ Failed to take thread dump"
  	fi
  done

}

# :command.function
playground_debug_heap_dump_command() {

  # src/commands/debug/heap-dump.sh
  containers="${args[--container]}"
  live="${args[--live]}"
  histo="${args[--histo]}"

  set +e

  # Convert space-separated string to array
  IFS=' ' read -ra container_array <<< "$containers"

  for container in "${container_array[@]}"
  do
  	docker exec $container type jmap > /dev/null 2>&1
  	if [ $? != 0 ]
  	then
  		logerror "❌ jmap is not installed on container $container"
  		exit 1
  	fi

  	if [[ -n "$histo" ]]
  	then
  		filename="heap-dump-$container-histo-$(date '+%Y-%m-%d-%H-%M-%S').txt"
  		set -e
  		if [[ -n "$live" ]]
  		then
  			log "📊 Taking histo (with live option) heap dump on container ${container}"
  			docker exec $container jmap -histo:live 1 > /tmp/${filename}
  		else
  			log "📊 Taking histo (without live option) heap dump on container ${container}"
  			docker exec $container jmap -histo 1 > /tmp/${filename}
  		fi
  		if [ $? -eq 0 ]
  		then
  			log "👻 heap dump is available at /tmp/${filename}"
  		else
  			logerror "❌ Failed to take heap dump"
  		fi
  	else
  		filename="heap-dump-$container-$(date '+%Y-%m-%d-%H-%M-%S').hprof"
  		set -e
  		if [[ -n "$live" ]]
  		then
  			log "🎯 Taking heap dump (with live option) on container ${container}"
  			docker exec $container jmap -dump:live,format=b,file=/tmp/${filename} 1
  		else
  			log "🎯 Taking heap dump (without live option) on container ${container}"
  			docker exec $container jmap -dump:format=b,file=/tmp/${filename} 1
  		fi
  		if [ $? -eq 0 ]
  		then
  			log "👻 heap dump is available at ${filename}"
  			docker cp ${container}:/tmp/${filename} ${filename}
  		else
  			logerror "❌ Failed to take heap dump"
  		fi
  	fi
  done
}

# :command.function
playground_debug_tcp_dump_command() {

  # src/commands/debug/tcp-dump.sh
  containers="${args[--container]}"
  port="${args[--port]}"
  duration="${args[--duration]}"
  filename="tcp-dump-$container-$port-$(date '+%Y-%m-%d-%H-%M-%S').pcap"

  # Convert space-separated string to array
  IFS=' ' read -ra container_array <<< "$containers"

  for container in "${container_array[@]}"
  do
  	set +e
  	docker exec $container type tcpdump > /dev/null 2>&1
  	if [ $? != 0 ]
  	then

  	tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  	if [ -z "$PG_VERBOSE_MODE" ]
  	then
  		trap 'rm -rf $tmp_dir' EXIT
  	else
  		log "🐛📂 not deleting tmp dir $tmp_dir"
  	fi
  	output_install_log="$tmp_dir/output_install.log"

  	logwarn "tcpdump is not installed on container $container, attempting to install it"
  	echo "using rpm" > $output_install_log
  	docker exec --privileged --user root $container bash -c "rpm -i --nosignature https://rpmfind.net/linux/centos/8-stream/AppStream/aarch64/os/Packages/tcpdump-4.9.3-2.el8.aarch64.rpm" >> $output_install_log 2>&1
  	echo "using yum" >> $output_install_log
  	docker exec --privileged --user root $container bash -c "yum update -y && yum install tcpdump -y" >> $output_install_log 2>&1

  	if [ "$container" == "ngrok" ]
  	then
  		playground container exec -c ngrok --command "adduser --force-badname --system --no-create-home _apt --gid 1000" --root >> $output_install_log 2>&1
  	fi
  	echo "using apt-get" >> $output_install_log
  	docker exec --privileged --user root $container bash -c "apt-get update && echo tcpdump | xargs -n 1 apt-get install --force-yes -y && rm -rf /var/lib/apt/lists/*" >> $output_install_log 2>&1
  	fi
  	docker exec $container type tcpdump > /dev/null 2>&1
  	if [ $? != 0 ]
  	then
  		logerror "❌ tcpdump could not be installed, see output below"
  		cat $output_install_log
  		exit 1
  	fi
  	set -e

  	set +e
  	docker exec --privileged --user root ${container} bash -c "killall tcpdump" > /dev/null 2>&1
  	set -e

  	if [[ -n "$port" ]]
  	then
  	log "🕵️‍♂️ Taking tcp dump on container ${container} and port ${port} for ${duration} seconds..."
  	docker exec -d --privileged --user root ${container} bash -c "tcpdump -w /tmp/${filename} -i any port ${port}"
  	else
  	log "🕵️‍♂️ Taking tcp dump on container ${container} and all ports for ${duration} seconds..."
  	docker exec -d --privileged --user root ${container} bash -c "tcpdump -w /tmp/${filename} -i any"
  	fi

  	if [ $? -eq 0 ]
  	then
  		playground container get-ip-addresses
  		sleep $duration
  		set +e
  		docker exec --privileged --user root ${container} bash -c "killall tcpdump" > /dev/null 2>&1
  		set -e
  		log "🌶️ tcp dump is available at ${filename}"
  		docker cp ${container}:/tmp/${filename} ${filename}
  		if [[ $(type -f wireshark 2>&1) =~ "not found" ]]
  		then
  			logwarn "🦈 wireshark is not installed, grab it at https://www.wireshark.org/"
  			exit 0
  		else
  			log "🦈 Opening ${filename} with wireshark"
  			wireshark ${filename}
  		fi

  	else
  		logerror "❌ Failed to take tcp dump"
  	fi
  done
}

# :command.function
playground_debug_block_traffic_command() {

  # src/commands/debug/block-traffic.sh
  containers="${args[--container]}"
  port="${args[--port]}"
  destination="${args[--destination]}"
  action="${args[--action]}"

  # Convert space-separated string to array
  IFS=' ' read -ra container_array <<< "$containers"

  # Function to install iptables on a container if needed
  install_iptables_if_needed() {
      local container=$1
      set +e
      docker exec $container type iptables > /dev/null 2>&1
      if [ $? != 0 ]
      then
          tag=$(docker ps --format '{{.Image}}' | grep -E 'confluentinc/cp-.*-connect-.*:' | awk -F':' '{print $2}')
          if [ $? != 0 ] || [ "$tag" == "" ]
          then
              logerror "Could not find current CP version from docker ps"
              exit 1
          fi
          logwarn "iptables is not installed on container $container, attempting to install it"
          if [[ "$tag" == *ubi8 ]] || version_gt $tag "5.9.0"
          then
            docker exec --privileged --user root $container bash -c "yum -y install --disablerepo='Confluent*' iptables"
          else
            docker exec --privileged --user root $container bash -c "apt-get update && echo iptables | xargs -n 1 apt-get install --force-yes -y && rm -rf /var/lib/apt/lists/*"
          fi
      fi
      docker exec $container type iptables > /dev/null 2>&1
      if [ $? != 0 ]
      then
          logerror "❌ iptables could not be installed on container $container"
          exit 1
      fi
      set -e
  }

  # Install iptables on all containers if needed
  for container in "${container_array[@]}"
  do
      install_iptables_if_needed "$container"
  done

  ip_pattern="^([0-9]{1,3}\.){3}[0-9]{1,3}$"

  function get_container_ip() {
      local container_ip=$(docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' "$1")
      if [ $? -eq 0 ]
      then
          echo "$container_ip"
      fi
  }

  function get_ip_by_nslookup() {
      local ip_address=$(nslookup "$1" | awk '/^Address: / { print $2 }')
      if [ $? -eq 0 ]
      then
          echo "$ip_address"
      fi
  }

  ip=""
  if [[ $destination =~ $ip_pattern ]]
  then
      ip=$destination
  else
      ip_address=$(get_container_ip "$destination")
      if [[ -n $ip_address ]]
      then
          ip=$ip_address
      else
          log "🌐 Using nslookup to get IP address..."
          ip_address=$(get_ip_by_nslookup "$destination")
          if [[ -n $ip_address ]]
          then
              ip=$ip_address
          else
              logerror "❌ Unable to retrieve IP address for $destination using nslookup"
              exit 1
          fi
      fi
  fi

  case "${action}" in
      start)
          action="A"
          if [[ -n "$port" ]]
          then
              log "🚫 Blocking traffic on containers ${containers} and port ${port} for destination ${destination} (${ip})"
          else
              log "🚫 Blocking traffic on containers ${containers} for all ports for destination ${destination} (${ip})"
          fi
      ;;
      stop)
          action="D"

          if [[ -n "$port" ]]
          then
              log "🟢 Unblocking traffic on containers ${containers} and port ${port} for destination ${destination} (${ip})"
          else
              log "🟢 Unblocking traffic on containers ${containers} for all ports from destination ${destination} (${ip})"
          fi
      ;;
      *)
          logerror "should not happen"
          exit 1
      ;;
  esac

  # Apply iptables rules to all containers
  for container in "${container_array[@]}"
  do
      log "Applying iptables rule to container: $container"
      if [[ -n "$port" ]]
      then
        docker exec --privileged --user root ${container} bash -c "iptables -${action} INPUT -p tcp -s ${ip} --sport ${port} -j DROP"
      else
        docker exec --privileged --user root ${container} bash -c "iptables -${action} INPUT -p tcp -s ${ip} -j DROP"
      fi

      log "Output of command iptables-save for container $container"
      docker exec --privileged --user root ${container} bash -c "iptables-save"
  done

}

# :command.function
playground_debug_java_debug_command() {

  # src/commands/debug/java-debug.sh
  containers="${args[--container]}"
  type="${args[--type]}"
  action="${args[--action]}"

  # Convert space-separated string to array
  IFS=' ' read -ra container_array <<< "$containers"

  for container in "${container_array[@]}"
  do
  	if [[ "$action" == "enable" ]]
  	then
  		case "${type}" in
  			"ssl_all")
  				OPTS="-Djavax.net.debug=all"
  			;;
  			"ssl_handshake")
  				OPTS="-Djavax.net.debug=ssl:handshake"
  			;;
  			"class_loading")
  				OPTS="-verbose:class"
  			;;
  			"kerberos")
  				OPTS="-Dsun.security.krb5.debug=true"
  			;;
  		esac

  		playground container set-environment-variables --container "${container}" --env "KAFKA_OPTS: ${OPTS}"
  	else
  		playground container set-environment-variables --container "${container}" --restore-original-values
  	fi
  done
}

# :command.function
playground_debug_jscissors_command() {

  # src/commands/debug/jscissors.sh
  containers="${args[--container]}"
  # Convert the space delimited string to an array
  eval "operations=(${args[--operation]})"
  class="${args[--class]}"
  method="${args[--method]}"
  action="${args[--action]}"

  # Convert space-separated string to array
  IFS=' ' read -ra container_array <<< "$containers"

  for container in "${container_array[@]}"
  do
  	if [[ "$action" == "enable" ]]
  	then
  		operation_string=$(printf "+%s" "${operations[@]}")
  		# remove + at beginning and end of operation_string
  		operation_string=${operation_string%+}
  		operation_string=${operation_string#+}

  		log "🔧 enabling jscissors for container ${container} with operation(s) ${operation_string}, class ${class} and method ${method}"
  		echo "${class}{${method}}=$operation_string" > /tmp/scissors.props

  		playground container set-environment-variables --container "${container}" --env "_JAVA_OPTIONS: -javaagent:/tmp/jscissors-1.0-SNAPSHOT.jar=configFile=/tmp/scissors.props" --mount-jscissors-files

  		playground container logs --container "${container}" --wait-for-log "Core Logger" --max-wait 30

  		scissors_file=$(playground --output-level WARN container logs --container "${container}" --wait-for-log "Core Logger" | tail -1 | cut -d " " -f 4)

  		log "✂️ jscissors file is available ${scissors_file}"
  		playground open --file "${scissors_file}"
  	else
  		playground container set-environment-variables --container "${container}" --restore-original-values
  	fi
  done
}

# :command.function
playground_debug_flight_recorder_command() {

  # src/commands/debug/flight-recorder.sh
  containers="${args[--container]}"
  action="${args[--action]}"

  # Convert space-separated string to array
  IFS=' ' read -ra container_array <<< "$containers"

  for container in "${container_array[@]}"
  do
  	filename="flight-recorder-$container-$(date '+%Y-%m-%d-%H-%M-%S').jfr"

  	set +e
  	docker exec $container type jcmd > /dev/null 2>&1
  	if [ $? != 0 ]
  	then
  		tag=$(docker ps --format '{{.Image}}' | grep -E 'confluentinc/cp-.*-connect-.*:' | awk -F':' '{print $2}')
  		if [ $? != 0 ] || [ "$tag" == "" ]
  		then
  			logerror "Could not find current CP version from docker ps"
  			exit 1
  		fi

  		logwarn "jcmd is not installed on container $container, attempting to install it"

  		if [[ "$tag" == *ubi8 ]] || version_gt $tag "5.9.0"
  		then
  		docker exec --privileged --user root $container bash -c "yum -y install --disablerepo='Confluent*' openjdk"
  		else
  		docker exec --privileged --user root $container bash -c "apt-get update && echo openjdk | xargs -n 1 apt-get install --force-yes -y && rm -rf /var/lib/apt/lists/*"
  		fi
  	fi
  	docker exec $container type jcmd > /dev/null 2>&1
  	if [ $? != 0 ]
  	then
  		logerror "❌ jcmd could not be installed"
  		exit 1
  	fi
  	set -e

  	case "${action}" in
  		start)
  			set +e
  			output=$(docker exec ${container} jcmd 1 JFR.check)
  			echo "$output" | grep "running" | grep "dump1"
  			if [ $? -eq 0 ]
  			then
  				logwarn "🛩️ flight recorder is already started !"
  				exit 0
  			fi
  			set -e

  			docker cp ${root_folder}/scripts/cli/all.jfc ${container}:/tmp/all.jfc > /dev/null 2>&1
  			docker exec ${container} jcmd 1 JFR.start name=dump1 filename=/tmp/${filename} settings=/tmp/all.jfc
  			if [ $? -eq 0 ]
  			then
  				log "🛩️ flight recorder is now started"
  			else
  				logerror "❌ Failed to start flight recorder"
  			fi
  		;;
  		stop)
  			set +e
  			output=$(docker exec ${container} jcmd 1 JFR.check)
  			echo "$output" | grep "running" | grep "dump1"
  			if [ $? -ne 0 ]
  			then
  				logerror "🛩️ flight recorder is not started !"
  				exit 1
  			fi
  			set -e
  			docker exec ${container} jcmd 1 JFR.stop name=dump1 filename=/tmp/${filename}
  			if [ $? -eq 0 ]
  			then
  				log "🛩️ flight recorder is available at ${filename}"
  				log "use JDK Mission Control JMC (https://jdk.java.net/jmc/) to open it"
  				docker cp ${container}:/tmp/${filename} ${filename}
  			else
  				logerror "❌ Failed to stop flight recorder"
  			fi
  		;;
  		*)
  			logerror "should not happen"
  			exit 1
  		;;
  	esac
  done
}

# :command.function
playground_debug_log_level_get_command() {

  # src/commands/debug/log-level/get.sh
  get_connect_url_and_security

  package="${args[--package]}"

  if [[ -n "$package" ]]
  then
    log "🧬 Get log level for package $package"
    curl $security -s "$connect_url/admin/loggers/$package"
  else
    log "🧬 Get log level for all packages"
    curl $security -s "$connect_url/admin/loggers" | jq .
  fi
}

# :command.function
playground_debug_log_level_set_command() {

  # src/commands/debug/log-level/set.sh
  get_connect_url_and_security

  package="${args[--package]}"
  level="${args[--level]}"

  current_level=$(curl $security -s "$connect_url/admin/loggers/$package" | jq -r '.level')

  if [ "$current_level" != "$level" ]
  then
      log "🧬 Set log level for package $package to $level"
      curl $security -s --request PUT \
      --url "$connect_url/admin/loggers/$package" \
      --header 'Accept: application/json' \
      --header 'Content-Type: application/json' \
      --data "{
      \"level\": \"$level\"
      }" | jq .

      playground debug log-level get -p "$package"
  else
      log "🧬⏭️ Skipping as log level for package $package was already set to $level"
  fi
}

# :command.function
playground_get_jmx_metrics_command() {

  # src/commands/get-jmx-metrics.sh
  IGNORE_CHECK_FOR_DOCKER_COMPOSE=true

  containers="${args[--container]}"
  domain="${args[--domain]}"
  open="${args[--open]}"

  # Convert space-separated string to array
  IFS=' ' read -ra container_array <<< "$containers"

  for container in "${container_array[@]}"
  do
  	case "${container}" in
  	zookeeper|broker|schema-registry|connect|connect2|connect3|controller)
  	;;
  	*)
  		logerror "❌ container name not valid ! Should be one of zookeeper, controller, broker, schema-registry, connect, connect2 or connect3"
  		exit 1
  	;;
  	esac

  	get_jmx_metrics "$container" "$domain" "$open"
  done

}

# :command.function
playground_container_get_properties_command() {

  # src/commands/container/get-properties.sh
  containers="${args[--container]}"

  # Convert space-separated string to array
  IFS=' ' read -ra container_array <<< "$containers"

  for container in "${container_array[@]}"
  do
  	log "📝 Displaying properties file for $container"

  docker exec -i "$container" sh << EOF
ps -ef | grep properties | grep java | grep -v grep | awk '{ print \$NF }' > /tmp/propertie_file
propertie_file=\$(cat /tmp/propertie_file)
if [ ! -f \$propertie_file ]
then
  logerror 'ERROR: Could not determine properties file!'
  exit 1
fi
cat \$propertie_file | grep -v None | grep .
EOF
  done

}

# :command.function
playground_container_recreate_command() {

  # src/commands/container/recreate.sh
  ignore_current_versions="${args[--ignore-current-versions]}"

  export IGNORE_CHECK_FOR_DOCKER_COMPOSE=true

  if [[ ! -n "$ignore_current_versions" ]]
  then
    # keep TAG and CP_CONNECT_TAG
    export TAG=$(docker inspect -f '{{.Config.Image}}' broker 2> /dev/null | cut -d ":" -f 2)
    export CP_CONNECT_TAG=$(docker inspect -f '{{.Config.Image}}' connect 2> /dev/null | cut -d ":" -f 2)
  fi

  export ORACLE_IMAGE=$(docker inspect -f '{{.Config.Image}}' oracle 2> /dev/null)

  docker_command=$(playground state get run.docker_command)
  if [ "$docker_command" == "" ]
  then
    logerror "docker_command retrieved from $root_folder/playground.ini is empty !"
    exit 1
  fi

  enable_flink=$(playground state get flags.ENABLE_FLINK)
  if [ "$enable_flink" != "1" ]
  then
    export flink_connectors=""
  fi

  get_environment_used
  if [[ "$environment" == "ccloud" ]]
  then
      get_kafka_docker_playground_dir
      DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

      if [ -f $DELTA_CONFIGS_ENV ]
      then
          source $DELTA_CONFIGS_ENV
      else
          logerror "❌ $DELTA_CONFIGS_ENV has not been generated"
          exit 1
      fi
  fi

  echo "$docker_command" > /tmp/playground-command
  log "💫 Recreate container(s)"
  bash /tmp/playground-command

  wait_container_ready
}

# :command.function
playground_container_get_ip_addresses_command() {

  # src/commands/container/get-ip-addresses.sh
  log "Get IP address of running containers"
  docker inspect -f '{{.Name}} - {{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' $(docker ps -aq)
}

# :command.function
playground_container_kill_all_command() {

  # src/commands/container/kill-all.sh
  log "💀 kill all docker containers"
  docker rm -f $(docker ps -qa) > /dev/null 2>&1
}

# :command.function
playground_container_logs_command() {

  # src/commands/container/logs.sh
  containers="${args[--container]}"
  open="${args[--open]}"
  log="${args[--wait-for-log]}"
  max_wait="${args[--max-wait]}"

  # Convert space-separated string to array
  IFS=' ' read -ra container_array <<< "$containers"

  for container in "${container_array[@]}"
  do
  	if [[ -n "$open" ]]
  	then
  		filename="/tmp/${container}-$(date '+%Y-%m-%d-%H-%M-%S').log"
  		docker container logs "$container" > "$filename" 2>&1
  		if [ $? -eq 0 ]
  		then
  			playground open --file "${filename}"
  		else
  			logerror "❌ failed to get logs using container logs $container"
  		fi
  	elif [[ -n "$log" ]]
  	then
  		wait_for_log "$log" "$container" "$max_wait"
  	else

  		# For multiple containers, run docker logs in parallel in background
  		if [ ${#container_array[@]} -gt 1 ]; then
  			# Add container prefix to distinguish logs from different containers
  			docker container logs --tail=200 -f "$container" 2>&1 | sed "s/^/[$container] /" &
  		else
  			# For single container, use normal behavior without prefix
  			docker container logs --tail=200 -f "$container"
  		fi
  	fi
  done

  # If multiple containers, wait for all background processes
  if [ ${#container_array[@]} -gt 1 ]; then
  	wait
  fi
}

# :command.function
playground_container_display_error_all_containers_command() {

  # src/commands/container/display-error-all-containers.sh
  set +e
  containers=$(docker ps --format="{{.Names}}")
  if [ -z "$containers" ]; then
      logwarn "💤 no running containers"
  else
      log "####################################################"
      log "🐳 docker ps"
      docker ps
      log "####################################################"

      while IFS= read -r container
      do
          log "####################################################"
          log "$container logs"
          docker container logs "$container" 2>&1 | grep -E "ERROR|FATAL"
          log "####################################################"
      done <<< "$containers"
  fi
}

# :command.function
playground_container_ssh_command() {

  # src/commands/container/ssh.sh
  containers="${args[--container]}"
  shell="${args[--shell]}"

  # Convert space-separated string to array
  IFS=' ' read -ra container_array <<< "$containers"

  for container in "${container_array[@]}"
  do
  	log "🛬 SSH into container: opening shell $shell on container $container"
      docker exec -it "$container" "$shell"
  done
}

# :command.function
playground_container_change_jdk_command() {

  # src/commands/container/change-jdk.sh
  containers="${args[--container]}"
  version="${args[--version]}"

  # Convert space-separated string to array
  IFS=' ' read -ra container_array <<< "$containers"

  for container in "${container_array[@]}"
  do
  	log "🤎 Installing Azul JDK ${version} on container ${container}" /usr/lib/jvm/java-11-zulu-openjdk/bin/java
  	playground container exec --container "${container}" --root --command "yum install -y https://cdn.azul.com/zulu/bin/zulu-repo-1.0.0-1.noarch.rpm ; yum -y install zulu${version}-jdk"
  	if [ $? -eq 0 ]
  	then
  		java_path=$(playground --output-level ERROR container exec --container "${container}" --root --command "update-alternatives --display java | grep \"java-${version}-zulu-openjdk\" | grep \"priority\" | head -1 | cut -d \" \" -f 1")
  		if [ -n "$java_path" ]
  		then
  			playground container exec --container "${container}" --root --command "update-alternatives --set java \"$java_path\""
  		else
  			logerror "could not find java ${version} in alternatives list"
  		fi
  		playground container restart --container "${container}"

  		sleep 5

  		playground container exec --container "${container}" --command "java -version"
  	else
  		logerror "❌ failed to install Azul JDK ${version}"
  	fi
  done
}

# :command.function
playground_container_exec_command() {

  # src/commands/container/exec.sh
  containers="${args[--container]}"
  command="${args[--command]}"
  root="${args[--root]}"
  shell="${args[--shell]}"

  # Convert space-separated string to array
  IFS=' ' read -ra container_array <<< "$containers"

  for container in "${container_array[@]}"
  do
  	if [[ -n "$root" ]]
  	then
  	log "🪄👑 Executing command as root in container $container with $shell"
  	docker exec --privileged --user root $container $shell -c "$command"
  	else
  	log "🪄 Executing command in container $container with $shell"
  	docker exec $container $shell -c "$command"
  	fi
  done
}

# :command.function
playground_container_restart_command() {

  # src/commands/container/restart.sh
  containers="${args[--container]}"

  # Convert space-separated string to array
  IFS=' ' read -ra container_array <<< "$containers"

  for container in "${container_array[@]}"
  do
  	log "🔁 Restarting docker container ${container}"
  	docker restart ${container}

  	if [[ ${container} == connect* ]]
  	then
  		wait_container_ready
  	fi
  done
}

# :command.function
playground_container_pause_command() {

  # src/commands/container/pause.sh
  containers="${args[--container]}"

  # Convert space-separated string to array
  IFS=' ' read -ra container_array <<< "$containers"

  for container in "${container_array[@]}"
  do
  	log "⏸️ Pausing docker container ${container}"
  	docker pause ${container}
  done
}

# :command.function
playground_container_resume_command() {

  # src/commands/container/resume.sh
  containers="${args[--container]}"

  # Convert space-separated string to array
  IFS=' ' read -ra container_array <<< "$containers"

  for container in "${container_array[@]}"
  do
  	log "⏯️ Resuming docker container ${container}"
  	docker unpause ${container}
  done
}

# :command.function
playground_container_kill_command() {

  # src/commands/container/kill.sh
  containers="${args[--container]}"

  # Convert space-separated string to array
  IFS=' ' read -ra container_array <<< "$containers"

  for container in "${container_array[@]}"
  do
      log "🔫 Killing docker container ${container}"
      docker kill ${container}
  done
}

# :command.function
playground_container_set_environment_variables_command() {

  # src/commands/container/set-environment-variables.sh
  containers="${args[--container]}"
  restore_original_values="${args[--restore-original-values]}"
  mount_jscissors_files="${args[--mount-jscissors-files]}"

  # Convert space-separated string to array
  IFS=' ' read -ra container_array <<< "$containers"

  # Convert the space delimited string to an array
  eval "env_array=(${args[--env]})"

  if [[ ! -n "$restore_original_values" ]]
  then
      # check if env_array is empty
      if [ ${#env_array[@]} -eq 0 ]
      then
          logerror "❌ No environment variables provided with --env option"
          exit 1
      fi
  fi

  # For ccloud case
  if [ -f $root_folder/.ccloud/env.delta ]
  then
       source $root_folder/.ccloud/env.delta
  fi

  # keep TAG, CONNECT TAG and ORACLE_IMAGE
  export TAG=$(docker inspect -f '{{.Config.Image}}' broker 2> /dev/null | cut -d ":" -f 2)
  export CP_CONNECT_TAG=$(docker inspect -f '{{.Config.Image}}' connect 2> /dev/null | cut -d ":" -f 2)
  export ORACLE_IMAGE=$(docker inspect -f '{{.Config.Image}}' oracle 2> /dev/null)

  docker_command=$(playground state get run.docker_command)
  if [ "$docker_command" == "" ]
  then
    logerror "docker_command retrieved from $root_folder/playground.ini is empty !"
    exit 1
  fi

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  if [[ ! -n "$restore_original_values" ]]
  then
      cat << EOF > $tmp_dir/docker-compose.override.java.env.yml
services:
EOF

      # Generate environment variables for each container
      for container in "${container_array[@]}"
      do
          cat << EOF >> $tmp_dir/docker-compose.override.java.env.yml
  $container:
    environment:
      DUMMY: $RANDOM
EOF

          for env_variable in "${env_array[@]}"
          do
              env_list="$env_list $env_variable"
              cat << EOF >> $tmp_dir/docker-compose.override.java.env.yml
      $env_variable
EOF
          done

          if [[ -n "$mount_jscissors_files" ]]
          then
              cat << EOF >> $tmp_dir/docker-compose.override.java.env.yml
    volumes:
      - ${root_folder}/scripts/cli/src/jscissors/jscissors-1.0-SNAPSHOT.jar:/tmp/jscissors-1.0-SNAPSHOT.jar
      - /tmp/:/tmp/
EOF
          fi
      done

      log "📦 enabling containers ${containers} with environment variables $env_list"
      echo "$docker_command" > $tmp_dir/playground-command-java-env
      sed -i -E -e "s|up -d --quiet-pull|-f $tmp_dir/docker-compose.override.java.env.yml up -d --quiet-pull|g" $tmp_dir/playground-command-java-env
      load_env_variables
      bash $tmp_dir/playground-command-java-env
  else
      log "🧽 restore back original values before any changes was made for containers ${containers}"
      echo "$docker_command" > $tmp_dir/playground-command
      load_env_variables
      bash $tmp_dir/playground-command
  fi
  wait_container_ready
}

# :command.function
playground_container_wait_for_connect_rest_api_ready_command() {

  # src/commands/container/wait-for-connect-rest-api-ready.sh
  max_wait="${args[--max-wait]}"

  get_connect_url_and_security
  cur_wait=0
  while ! handle_onprem_connect_rest_api "curl $security -s \"$connect_url\"" > /dev/null;
  do
    sleep 1
    cur_wait=$(( cur_wait+1 ))
    if [[ "$cur_wait" -gt "$max_wait" ]]
    then
      logerror "❌ the connect REST API is still not ready after $max_wait seconds, see output"
      handle_onprem_connect_rest_api "curl $security -s \"$connect_url\""
      return 1
    fi
  done
}

# :command.function
playground_topic_get_number_records_command() {

  # src/commands/topic/get-number-records.sh
  topic="${args[--topic]}"

  get_security_broker "--command-config"

  if [[ ! -n "$topic" ]]
  then
      log "✨ --topic flag was not provided, applying command to all topics"
      topic=$(playground get-topic-list --skip-connect-internal-topics)
      if [ "$topic" == "" ]
      then
          logerror "❌ No topic found !"
          exit 1
      fi
  fi

  get_environment_used

  items=($topic)
  for topic in ${items[@]}
  do
      log "💯 Get number of records in topic $topic"
      set +e
      playground topic describe --topic $topic > /tmp/result.log 2>/tmp/result.log
      grep "does not exist" /tmp/result.log > /dev/null 2>&1
      if [ $? == 0 ]
      then
          logwarn "topic $topic does not exist !"
          continue
      fi
      set +e
      if [[ "$environment" == "ccloud" ]]
      then
          get_sr_url_and_security

          value_type=""
          version=$(curl $sr_security -s "${sr_url}/subjects/${topic}-value/versions/1" | jq -r .version)
          if [ "$version" != "null" ]
          then
          schema_type=$(curl $sr_security -s "${sr_url}/subjects/${topic}-value/versions/1"  | jq -r .schemaType)
          case "${schema_type}" in
              JSON)
              value_type="json-schema"
              ;;
              PROTOBUF)
              value_type="protobuf"
              ;;
              AVRO|null)
              value_type="avro"
              ;;
          esac
          fi

          if [ ! -f $root_folder/.ccloud/librdkafka.delta ]
          then
              logerror "❌ $root_folder/.ccloud/librdkafka.delta has not been generated"
              exit 1
          fi
          tr -d '"' < $root_folder/.ccloud/librdkafka.delta > $root_folder/.ccloud/librdkafka_no_quotes_tmp.delta
          sr_url=$(grep "schema.registry.url=" $root_folder/.ccloud/librdkafka_no_quotes_tmp.delta | cut -d "=" -f2)
          sr_url_hostname=$(echo $sr_url | cut -d "/" -f 3)
          sr_auth=$(grep "basic.auth.user.info=" $root_folder/.ccloud/librdkafka_no_quotes_tmp.delta | cut -d "=" -f2)
          sr_username=$(echo $sr_auth | cut -d ":" -f 1)
          sr_password=$(echo $sr_auth | cut -d ":" -f 2)
          # sr_password_url_encoded=$(urlencode $sr_password)
          grep -v "basic.auth.user.info" $root_folder/.ccloud/librdkafka_no_quotes_tmp.delta > $root_folder/.ccloud/librdkafka_no_quotes.delta

          case "${value_type}" in
          avro)
          docker run -i --network=host \
                  -v $root_folder/.ccloud/librdkafka_no_quotes.delta:/tmp/configuration/ccloud.properties \
              confluentinc/cp-kcat:latest kcat \
                  -F /tmp/configuration/ccloud.properties \
                  -C -t $topic \
                  -s value=avro \
                  -r https://$sr_username:$sr_password@$sr_url_hostname \
                  -e -q > /tmp/result.log 2>/dev/null
              ;;
          *)
          docker run -i --network=host \
                  -v $root_folder/.ccloud/librdkafka_no_quotes.delta:/tmp/configuration/ccloud.properties \
              confluentinc/cp-kcat:latest kcat \
                  -F /tmp/configuration/ccloud.properties \
                  -C -t $topic \
                  -e -q > /tmp/result.log 2>/dev/null
          ;;
          esac
          wc -l /tmp/result.log | awk '{print $1}'
      else
          tag=$(docker ps --format '{{.Image}}' | grep -E 'confluentinc/cp-.*-connect-.*:' | awk -F':' '{print $2}')
          if [ $? != 0 ] || [ "$tag" == "" ]
          then
              logerror "Could not find current CP version from docker ps"
              exit 1
          fi
          get_broker_container
          if ! version_gt $tag "6.9.9" && [ "$security" != "" ]
          then
              # GetOffsetShell does not support security before 7.x
              get_security_broker "--consumer.config"

              set +e
              docker exec $container timeout 15 kafka-console-consumer --bootstrap-server $broker_container:9092 --topic $topic $security --from-beginning --timeout-ms 15000 2>/dev/null | wc -l | tr -d ' '
              set -e
          else
              class_name="kafka.tools.GetOffsetShell"
              if version_gt $tag "7.6.9"
              then
                  class_name="org.apache.kafka.tools.GetOffsetShell"
              fi
              parameter_for_list_broker="--bootstrap-server"
              if ! version_gt $tag "5.3.99"
              then
                  parameter_for_list_broker="--broker-list"
              fi
              docker exec $broker_container kafka-run-class $class_name $parameter_for_list_broker $broker_container:9092 $security --topic $topic --time -1 | grep -v "No configuration found" | awk -F ":" '{sum += $3} END {print sum}'
          fi
      fi
  done

}

# :command.function
playground_topic_display_consumer_offsets_command() {

  # src/commands/topic/display-consumer-offsets.sh
  get_security_broker "--consumer.config"
  get_environment_used
  verbose="${args[--verbose]}"

  log "Display content of __consumer_offsets topic, press crtl-c to stop..."
  if [[ "$environment" == "ccloud" ]]
  then
      logerror " __consumer_offsets topic is not readable in cloud"
      exit 1
  else
      if [[ -n "$verbose" ]]
      then
          log "🐞 CLI command used"
          echo "kafka-console-consumer --bootstrap-server $bootstrap_server --topic __consumer_offsets --from-beginning --formatter "kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter" $security"
      fi

  	tag=$(docker ps --format '{{.Image}}' | grep -E 'confluentinc/cp-server-.*:' | awk -F':' '{print $2}')
  	if [ $? != 0 ] || [ "$tag" == "" ]
  	then
  		logerror "Could not find current CP version from docker ps"
  		exit 1
  	fi

  	formatter="kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter"
  	if version_gt $tag "7.9.9"; then
  		formatter="org.apache.kafka.tools.consumer.OffsetsMessageFormatter"
  	fi

      docker exec -i $container kafka-console-consumer --bootstrap-server $bootstrap_server --topic __consumer_offsets --from-beginning --formatter "$formatter" $security | grep -v "_confluent-controlcenter"
  fi
}

# :command.function
playground_topic_list_command() {

  # src/commands/topic/list.sh
  log "🔘 List of topics (internal topics are excluded)"
  playground get-topic-list --skip-connect-internal-topics
}

# :command.function
playground_topic_describe_command() {

  # src/commands/topic/describe.sh
  topic="${args[--topic]}"
  verbose="${args[--verbose]}"

  get_security_broker "--command-config"

  if [[ ! -n "$topic" ]]
  then
      log "✨ --topic flag was not provided, applying command to all topics"
      topic=$(playground get-topic-list --skip-connect-internal-topics)
      if [ "$topic" == "" ]
      then
          logerror "❌ No topic found !"
          exit 1
      fi
  fi

  get_environment_used

  items=($topic)
  for topic in ${items[@]}
  do
      log "🔎 Describing topic $topic"
      if [[ "$environment" == "ccloud" ]]
      then
          get_kafka_docker_playground_dir
          DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

          if [ -f $DELTA_CONFIGS_ENV ]
          then
              source $DELTA_CONFIGS_ENV
          else
              logerror "❌ $DELTA_CONFIGS_ENV has not been generated"
              exit 1
          fi
          if [ ! -f $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta ]
          then
              logerror "❌ $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta has not been generated"
              exit 1
          fi
          if [[ -n "$verbose" ]]
          then
              log "🐞 CLI command used"
              echo "kafka-topics --describe --topic $topic --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties"
          fi
          get_connect_image
          docker run --quiet --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-topics --describe --topic $topic --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties
      else
          if [[ -n "$verbose" ]]
          then
              log "🐞 CLI command used"
              echo "kafka-topics --describe --topic $topic --bootstrap-server $bootstrap_server $security"
          fi
          docker exec $container kafka-topics --describe --topic $topic --bootstrap-server $bootstrap_server $security
      fi
  done
}

# :command.function
playground_topic_set_schema_compatibility_command() {

  # src/commands/topic/set-schema-compatibility.sh
  topic="${args[--topic]}"
  compatibility="${args[--compatibility]}"
  verbose="${args[--verbose]}"

  get_environment_used
  get_sr_url_and_security

  if [[ ! -n "$topic" ]]
  then
      logwarn "--topic flag was not provided, applying command to all topics"
      check_if_continue
      topic=$(playground get-topic-list --skip-connect-internal-topics)
      if [ "$topic" == "" ]
      then
          logerror "❌ No topic found !"
          exit 1
      fi
  fi

  items=($topic)
  for topic in ${items[@]}
  do
    log "🛡️ Set compatibility for subject ${topic}-value to $compatibility"
    if [[ -n "$verbose" ]]
    then
        log "🐞 curl command used"
        echo "curl $sr_security -X PUT -H "Content-Type: application/vnd.schemaregistry.v1+json" --data "{\"compatibility\": \"$compatibility\"}" "${sr_url}/config/${topic}-value""
    fi
    curl $sr_security -X PUT -H "Content-Type: application/vnd.schemaregistry.v1+json" --data "{\"compatibility\": \"$compatibility\"}" "${sr_url}/config/${topic}-value"
  done
}

# :command.function
playground_topic_consume_command() {

  # src/commands/topic/consume.sh
  topic="${args[--topic]}"
  verbose="${args[--verbose]}"
  max_messages="${args[--max-messages]}"
  grep_string="${args[--grep]}"
  min_expected_messages="${args[--min-expected-messages]}"
  timeout="${args[--timeout]}"
  tail="${args[--tail]}"
  timestamp_field="${args[--plot-latencies-timestamp-field]}"
  key_subject="${args[--key-subject]}"
  value_subject="${args[--value-subject]}"
  max_characters="${args[--max-characters]}"
  open="${args[--open]}"

  if [[ -n "$key_subject" ]]
  then
    original_key_subject=$key_subject
  fi

  if [[ -n "$value_subject" ]]
  then
    original_value_subject=$value_subject
  fi

  get_environment_used
  get_sr_url_and_security

  get_broker_container
  bootstrap_server="$broker_container:9092"
  get_connect_container
  container=$connect_container
  sr_url_cli="http://schema-registry:8081"
  security=""
  if [[ "$environment" == "kerberos" ]] || [[ "$environment" == "ssl_kerberos" ]]
  then
      container="client"
      security="--consumer.config /etc/kafka/consumer.properties"

      docker exec -i client kinit -k -t /var/lib/secret/kafka-connect.key connect
  elif [[ "$environment" == *"ssl"* ]]
  then
      sr_url_cli="https://schema-registry:8081"
      security="--property schema.registry.ssl.truststore.location=/etc/kafka/secrets/kafka.client.truststore.jks --property schema.registry.ssl.truststore.password=confluent --property schema.registry.ssl.keystore.location=/etc/kafka/secrets/kafka.client.keystore.jks --property schema.registry.ssl.keystore.password=confluent --consumer.config /etc/kafka/secrets/client_without_interceptors.config"
  elif [[ "$environment" == "rbac-sasl-plain" ]]
  then
      security="--property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info=clientAvroCli:clientAvroCli --consumer.config /etc/kafka/secrets/client_without_interceptors.config"
  elif [[ "$environment" == "ldap-authorizer-sasl-plain" ]]
  then
      security="--group test-consumer-group --consumer.config /service/kafka/users/client.properties"
  elif [[ "$environment" == "sasl-plain" ]] || [[ "$environment" == "sasl-scram" ]] || [[ "$environment" == "ldap-sasl-plain" ]]
  then
      security="--consumer.config /tmp/client.properties"

  elif [[ "$environment" == "ccloud" ]]
  then
    get_kafka_docker_playground_dir
    DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

    if [ -f $DELTA_CONFIGS_ENV ]
    then
        source $DELTA_CONFIGS_ENV
    else
        logerror "❌ $DELTA_CONFIGS_ENV has not been generated"
        exit 1
    fi
    if [ ! -f $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta ]
    then
        logerror "❌ $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta has not been generated"
        exit 1
    fi
  fi

  if [[ -n "$timeout" ]] && [ "$timeout" != "60" ]
  then
    if [[ ! -n "$min_expected_messages" ]] || [ "$min_expected_messages" == "0" ]
    then
      logerror "❌ --timeout was provided without specifying --min-expected-messages"
      exit 1
    fi
  fi

  if [[ ! -n "$topic" ]]
  then
      if [[ -n "$min_expected_messages" ]] && [ "$min_expected_messages" != "0" ]
      then
        logerror "--min-expected-messages was provided without specifying --topic"
        exit 1
      fi
      if [[ -n "$key_subject" ]]
      then
        logerror "--key-subject was provided without specifying --topic"
        exit 1
      fi
      if [[ -n "$value_subject" ]]
      then
        logerror "--value-subject was provided without specifying --topic"
        exit 1
      fi
      if [[ -n "$tail" ]]
      then
        logerror "--tail was provided without specifying --topic"
        exit 1
      fi
      if [[ -n "$timestamp_field" ]]
      then
        logerror "--plot-latencies-timestamp-field was provided without specifying --topic"
        exit 1
      fi
      log "✨ --topic flag was not provided, applying command to all topics"
      topic=$(playground get-topic-list --skip-connect-internal-topics)
      if [ "$topic" == "" ]
      then
          logerror "❌ no topic found !"
          exit 1
      fi
  fi

  get_connect_image
  if version_gt $CP_CONNECT_TAG "7.9.99"
  then
      tool_log4j_jvm_arg="-Dlog4j2.configurationFile=file:/etc/kafka/tools-log4j2.yaml"
  else
      tool_log4j_jvm_arg="-Dlog4j.configuration=file:/etc/kafka/tools-log4j.properties"
  fi

  items=($topic)
  for topic in ${items[@]}
  do
    key_subject=""
    value_subject=""
    if [ ! -n "$tail" ]
    then
      if [[ -n "$min_expected_messages" ]] && [ "$min_expected_messages" != "0" ]
      then

        start_time=$(date +%s)

        while true; do
          nb_messages=$(playground topic get-number-records -t $topic | tail -1)

          if [[ ! $nb_messages =~ ^[0-9]+$ ]]
          then
            echo $nb_messages | grep "does not exist" > /dev/null 2>&1
            if [ $? == 0 ]
            then
              logwarn "❌ topic $topic does not exist !"
            else
              logwarn "❌ problem while getting number of messages: $nb_messages"
            fi
            exit 1
          fi

          if [ $nb_messages -ge $min_expected_messages ]
          then
            break
          fi

          current_time=$(date +%s)
          elapsed_time=$((current_time - start_time))

          if [ $elapsed_time -ge $timeout ]
          then
            logerror "❌ overall timeout of $timeout seconds exceeded. --min-expected-messages is set with $min_expected_messages but topic $topic contains $nb_messages messages"
            exit 1
          fi

          sleep 1
        done
      else
        nb_messages=$(playground topic get-number-records -t $topic | tail -1)

        if [[ ! $nb_messages =~ ^[0-9]+$ ]]
        then
          echo $nb_messages | grep "does not exist" > /dev/null 2>&1
          if [ $? == 0 ]
          then
            logwarn "❌ topic $topic does not exist !"
          else
            logwarn "❌ problem while getting number of messages: $nb_messages"
          fi
          break
        fi
      fi
    fi

    if [[ -n "$open" ]]
    then
      filename="/tmp/dump-${topic}-$(date '+%Y-%m-%d-%H-%M-%S').log"

      log "📄 dumping topic content to $filename"
      playground topic consume --topic $topic --max-messages -1 > $filename
      if [ $? -eq 0 ]
      then
        playground open --file "${filename}"
      else
        logerror "❌ failed to dump topic $topic"
      fi
      exit 0
    fi

    if [ -n "$tail" ]
    then
      log "✨ Tailing content of topic $topic"
    elif [[ -n "$max_messages" ]] && [ $max_messages -eq -1 ] && [[ ! -n "$timestamp_field" ]]
    then
      log "✨ --max-messages is set to -1, display full content of topic $topic, it contains $nb_messages messages"
      max_messages=$nb_messages
    elif [[ -n "$max_messages" ]] && [ $nb_messages -ge $max_messages ] && [[ ! -n "$timestamp_field" ]]
    then
      log "✨ Display content of topic $topic, it contains $nb_messages messages, but displaying only --max-messages=$max_messages"
      nb_messages=$max_messages
    else
      log "✨ Display content of topic $topic, it contains $nb_messages messages"
    fi

    if [[ -n "$grep_string" ]]
    then
      logwarn "--grep is set so only matched results will be displayed !"
    fi

    if [[ -n "$timestamp_field" ]]
    then
      log "📈 plotting results.."
    fi
    key_type=""
    version=$(curl $sr_security -s "${sr_url}/subjects/${topic}-key/versions/latest" | jq -r .version)
    if [ "$version" != "null" ]
    then
      schema_type=$(curl $sr_security -s "${sr_url}/subjects/${topic}-key/versions/latest" | jq -r .schemaType)
      case "${schema_type}" in
        JSON)
          key_type="json-schema"
        ;;
        PROTOBUF)
          key_type="protobuf"
        ;;
        null)
          key_type="avro"
        ;;
      esac
    fi

    if [[ -n "$original_key_subject" ]]
    then
      log "📛 key subject is set with $original_key_subject"
      key_subject=$original_key_subject
    else
      key_subject="${topic}-key"
    fi

    key_type=""
    version=$(curl $sr_security -s "${sr_url}/subjects/${key_subject}/versions/latest" | jq -r .version)
    if [ "$version" != "null" ]
    then
      schema_type=$(curl $sr_security -s "${sr_url}/subjects/${key_subject}/versions/latest"  | jq -r .schemaType)
      case "${schema_type}" in
        JSON)
          key_type="json-schema"
        ;;
        PROTOBUF)
          key_type="protobuf"
        ;;
        null)
          key_type="avro"
        ;;
      esac
    fi

    if [ "$key_type" != "" ]
    then
      log "🔮🔰 topic is using $key_type for key"
      playground schema get --subject ${key_subject}
    else
      log "🔮🙅 topic is not using any schema for key"
    fi

    if [[ -n "$original_value_subject" ]]
    then
      log "📛 value subject is set with $original_value_subject"
      value_subject=$original_value_subject
    else
      value_subject="${topic}-value"
    fi

    value_type=""
    version=$(curl $sr_security -s "${sr_url}/subjects/${value_subject}/versions/latest" | jq -r .version)
    if [ "$version" != "null" ]
    then
      schema_type=$(curl $sr_security -s "${sr_url}/subjects/${value_subject}/versions/latest"  | jq -r .schemaType)
      case "${schema_type}" in
        JSON)
          value_type="json-schema"
        ;;
        PROTOBUF)
          value_type="protobuf"
        ;;
        AVRO|null)
          value_type="avro"
        ;;
      esac
    fi

    if [ "$value_type" != "" ]
    then
      log "🔮🔰 topic is using $value_type for value"
      playground schema get --subject ${value_subject}
    else
      log "🔮🙅 topic is not using any schema for value"
    fi

    type=""
    tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
    if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi
    fifo_path="$tmp_dir/kafka_output_fifo"
    mkfifo "$fifo_path"

    nottailing1=""
    nottailing2=""
    if [ ! -n "$tail" ]
    then
      nottailing1="--from-beginning --max-messages $nb_messages"
      if [[ ! -n "$timestamp_field" ]]
      then
        nottailing2="timeout $timeout"
      fi
    fi

    if [ "$max_messages" != "10" ]
    then
      nottailing2=""
    fi
    case "${value_type}" in
      avro|protobuf|json-schema)
          if [ "$key_type" == "avro" ] || [ "$key_type" == "protobuf" ] || [ "$key_type" == "json-schema" ]
          then
              if [[ "$environment" == "ccloud" ]]
              then
                if [[ -n "$verbose" ]]
                then
                  log "🐞 CLI command used to consume data"
                  echo "kafka-$value_type-console-consumer --bootstrap-server $BOOTSTRAP_SERVERS --topic $topic --consumer-property ssl.endpoint.identification.algorithm=https --consumer-property sasl.mechanism=PLAIN --consumer-property security.protocol=SASL_SSL --consumer-property sasl.jaas.config=\"$SASL_JAAS_CONFIG\" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info=\"$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO\" --property schema.registry.url=$SCHEMA_REGISTRY_URL --property print.schema.ids=true --property schema.id.separator=\"|\" --property print.partition=true --property print.offset=true --property print.headers=true --property headers.separator=, --property headers.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.timestamp=true --property print.key=true --property key.separator=\"|\" --skip-message-on-error $security $nottailing1"
                fi
                get_connect_image
                docker run -i --rm -e SCHEMA_REGISTRY_LOG4J_OPTS="$tool_log4j_jvm_arg" -e value_type=$value_type -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" -e SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} $nottailing2 kafka-$value_type-console-consumer --bootstrap-server $BOOTSTRAP_SERVERS --topic $topic --consumer-property ssl.endpoint.identification.algorithm=https --consumer-property sasl.mechanism=PLAIN --consumer-property security.protocol=SASL_SSL --consumer-property sasl.jaas.config="$SASL_JAAS_CONFIG" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" --property schema.registry.url=$SCHEMA_REGISTRY_URL --property print.schema.ids=true --property schema.id.separator="|" --property print.partition=true --property print.offset=true --property print.headers=true --property headers.separator=, --property headers.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.timestamp=true --property print.key=true --property key.separator="|" --skip-message-on-error $security $nottailing1 > "$fifo_path" 2>&1 &
              else
                if [[ -n "$verbose" ]]
                then
                  log "🐞 CLI command used to consume data"
                  echo "kafka-$value_type-console-consumer -bootstrap-server $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic  --property print.schema.ids=true --property schema.id.separator=\"|\" --property print.partition=true --property print.offset=true --property print.headers=true --property headers.separator=, --property headers.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.timestamp=true --property print.key=true --property key.separator=\"|\" --skip-message-on-error $security $nottailing1"
                fi
                docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS="$tool_log4j_jvm_arg" $container $nottailing2 kafka-$value_type-console-consumer -bootstrap-server $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic  --property print.schema.ids=true --property schema.id.separator="|" --property print.partition=true --property print.offset=true --property print.headers=true --property headers.separator=, --property headers.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.timestamp=true --property print.key=true --property key.separator="|" --skip-message-on-error $security $nottailing1 > "$fifo_path" 2>&1 &
              fi
          else
              if [[ "$environment" == "ccloud" ]]
              then
                if [[ -n "$verbose" ]]
                then
                  log "🐞 CLI command used to consume data"
                  echo "kafka-$value_type-console-consumer --bootstrap-server $BOOTSTRAP_SERVERS --topic $topic --consumer-property ssl.endpoint.identification.algorithm=https --consumer-property sasl.mechanism=PLAIN --consumer-property security.protocol=SASL_SSL --consumer-property sasl.jaas.config=\"$SASL_JAAS_CONFIG\" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info=\"$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO\" --property schema.registry.url=$SCHEMA_REGISTRY_URL --property print.schema.ids=true --property schema.id.separator=\"|\" --property print.partition=true --property print.offset=true --property print.headers=true --property headers.separator=, --property headers.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.timestamp=true --property print.key=true --property key.separator=\"|\" --property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer --skip-message-on-error $security $nottailing1"
                fi
                get_connect_image
                docker run -i --rm -e SCHEMA_REGISTRY_LOG4J_OPTS="$tool_log4j_jvm_arg" -e value_type=$value_type -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" -e SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} $nottailing2 kafka-$value_type-console-consumer --bootstrap-server $BOOTSTRAP_SERVERS --topic $topic --consumer-property ssl.endpoint.identification.algorithm=https --consumer-property sasl.mechanism=PLAIN --consumer-property security.protocol=SASL_SSL --consumer-property sasl.jaas.config="$SASL_JAAS_CONFIG" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" --property schema.registry.url=$SCHEMA_REGISTRY_URL --property print.schema.ids=true --property schema.id.separator="|" --property print.partition=true --property print.offset=true --property print.headers=true --property headers.separator=, --property headers.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.timestamp=true --property print.key=true --property key.separator="|" --property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer --skip-message-on-error $security $nottailing1 > "$fifo_path" 2>&1 &
              else
                if [[ -n "$verbose" ]]
                then
                  log "🐞 CLI command used to consume data"
                  echo "kafka-$value_type-console-consumer --bootstrap-server $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic --property print.partition=true  --property print.schema.ids=true --property schema.id.separator=\"|\" --property print.offset=true --property print.headers=true --property headers.separator=, --property headers.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.timestamp=true --property print.key=true --property key.separator=\"|\" --property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer --skip-message-on-error $security $nottailing1"
                fi
                docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS="$tool_log4j_jvm_arg" $container $nottailing2  kafka-$value_type-console-consumer --bootstrap-server $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic --property print.partition=true  --property print.schema.ids=true --property schema.id.separator="|" --property print.offset=true --property print.headers=true --property headers.separator=, --property headers.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.timestamp=true --property print.key=true --property key.separator="|" --property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer --skip-message-on-error $security $nottailing1 > "$fifo_path" 2>&1 &
              fi
          fi
          ;;
      *)
        if [[ "$environment" == "ccloud" ]]
        then
          if [[ -n "$verbose" ]]
          then
            log "🐞 CLI command used to consume data"
            echo "kafka-console-consumer --bootstrap-server $BOOTSTRAP_SERVERS --topic $topic --consumer.config /tmp/configuration/ccloud.properties --property print.partition=true --property print.offset=true --property print.headers=true --property headers.separator=, --property headers.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.timestamp=true --property print.key=true --property key.separator=\"|\" $security $nottailing1"
          fi
          get_connect_image
          docker run -i --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} $nottailing2 kafka-console-consumer --bootstrap-server $BOOTSTRAP_SERVERS --topic $topic --consumer.config /tmp/configuration/ccloud.properties --property print.partition=true --property print.offset=true --property print.headers=true --property headers.separator=, --property headers.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.timestamp=true --property print.key=true --property key.separator="|" $security $nottailing1 > "$fifo_path" 2>&1 &
        else
          if [[ -n "$verbose" ]]
          then
            log "🐞 CLI command used to consume data"
            echo "kafka-console-consumer --bootstrap-server $bootstrap_server --topic $topic --property print.partition=true --property print.offset=true --property print.headers=true --property headers.separator=, --property headers.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.timestamp=true --property print.key=true --property key.separator=\"|\" $security $nottailing1"
          fi
          docker exec $container $nottailing2 kafka-console-consumer --bootstrap-server $bootstrap_server --topic $topic --property print.partition=true --property print.offset=true --property print.headers=true --property headers.separator=, --property headers.deserializer=org.apache.kafka.common.serialization.StringDeserializer --property print.timestamp=true --property print.key=true --property key.separator="|" $security $nottailing1 > "$fifo_path" 2>&1  &
        fi
      ;;
    esac
    # Detect the platform (macOS or Linux) and set the date command accordingly
    if [[ "$(uname)" == "Darwin" ]]; then
      # macOS
      date_command="date -r "
    else
      # Linux
      date_command="date -d @"
    fi

    if [[ -n "$timestamp_field" ]]
    then
      rm -rf /tmp/latency
      mkdir -p /tmp/latency
      latency_csv="/tmp/latency/latency.csv"
      latency_png="/tmp/latency/latency.png"
    fi
    found=0
    first_record=1
    is_base64=0
    export LC_ALL=C
    # Loop through each line in the named pipe
    while read -r line
    do
      display_line=1
      if [[ $line =~ "CreateTime:" ]]
      then
        # Extract the timestamp from the line
        timestamp_ms=$(echo "$line" | cut -d ":" -f 2 | cut -d "|" -f 1)
        # Convert milliseconds to seconds
        timestamp_sec=$((timestamp_ms / 1000))
        milliseconds=$((timestamp_ms % 1000))
        readable_date="$(${date_command}${timestamp_sec} "+%Y-%m-%d %H:%M:%S.${milliseconds}")"
        line_with_date=$(echo "$line" | sed -E "s/CreateTime:[0-9]{13}/CreateTime:${readable_date}/")

        if [ $first_record -eq 1 ]
        then
          payload=$(echo "$line" | cut -d "|" -f 6)

          if [ ${#payload} -lt 1000 ]
          then
            # check if it is base64 encoded
            set +e
            base64=$(echo "$payload" | tr -d '"' | base64 -d 2>/dev/null)
            if [ $? -eq 0 ]
            then
              if [ "$base64" != "" ]
              then
                decoded=$(echo "$base64" | iconv -t UTF-8//IGNORE 2>/dev/null)
                if [ "$decoded" == "$base64" ]
                then
                  logwarn "🤖 Data is base64 encoded, payload will be decoded"
                  is_base64=1
                fi
              fi
            fi
            set -e
          fi

          first_record=0
        fi

        if [ $is_base64 -eq 1 ]
        then
          base64=$(echo "$payload" | tr -d '"' | base64 -d)
          line_with_date=$(echo "$line_with_date" | awk -v new_value="$base64" 'BEGIN {FS=OFS="|"} {$6=new_value}1')
        fi

        if [[ -n "$grep_string" ]]
        then
          if [[ $line =~ "$grep_string" ]]
          then
            log "✅ found $grep_string in topic $topic"
            found=1
          else
            display_line=0
          fi
        fi

        if [[ ! -n "$timestamp_field" ]]
        then
          if [ $display_line -eq 1 ]
          then
            payload=$(echo "$line_with_date" | cut -d "|" -f 6)
            if [ ${#payload} -lt $max_characters ]
            then
              if [ "$key_type" == "avro" ] || [ "$key_type" == "protobuf" ] || [ "$key_type" == "json-schema" ]
              then
                echo "$line_with_date" | awk 'BEGIN{FS=OFS="|"} {$4="Headers:"$4; $5="Key:"$5; $6="KeySchemaId:"$6; $7="Value:"$7; $8="ValueSchemaId:"$8} 1'
              else
                echo "$line_with_date" | awk 'BEGIN{FS=OFS="|"} {$4="Headers:"$4; $5="Key:"$5; $6="Value:"$6; $7="ValueSchemaId:"$7} 1'
              fi
            else
              if [ "$key_type" == "avro" ] || [ "$key_type" == "protobuf" ] || [ "$key_type" == "json-schema" ]
              then
                echo "$line_with_date" | awk 'BEGIN{FS=OFS="|"} {$4="Headers:"$4; $5="Key:"$5; $6="KeySchemaId:"$6; $7="Value:"$7; $8="ValueSchemaId:"$8} 1' | cut -c 1-$max_characters | awk "{print \$0 \"...<truncated, only showing first $max_characters characters, out of ${#payload}>...\"}"
              else
                echo "$line_with_date" | awk 'BEGIN{FS=OFS="|"} {$4="Headers:"$4; $5="Key:"$5; $6="Value:"$6; $7="ValueSchemaId:"$7} 1' | cut -c 1-$max_characters | awk "{print \$0 \"...<truncated, only showing first $max_characters characters, out of ${#payload}>...\"}"
              fi
            fi
          fi
        fi

        if [[ -n "$timestamp_field" ]]
        then
          payload=$(echo "$line" | cut -d "|" -f 6)
          # JSON is invalid
          if ! echo "$payload" | jq -e .  > /dev/null 2>&1
          then
              logerror "--plot-latencies-timestamp-field is set but value content is not in json representation"
              exit 1
          else
            timestamp_source=$(echo "$payload" | jq -r .${timestamp_field})
            echo "$readable_date,$timestamp_ms,$timestamp_source" >> $latency_csv
          fi
        fi
      elif [[ $line =~ "Unable to find FetchSessionHandler" ]]
      then
        continue
      elif [[ $line =~ "Processed a total of" ]]
      then
        continue
      elif [[ $line =~ "SLF4J" ]]
      then
        continue
      else
        if [[ -n "$grep_string" ]]
        then
          if [[ $line =~ "$grep_string" ]]
          then
            log "✅ found $grep_string in topic $topic"
            found=1
          else
            display_line=0
          fi
        fi

        if [ $display_line -eq 1 ]
        then
          payload=$(echo "$line" | cut -d "|" -f 6)
          if [ ${#payload} -lt $max_characters ]
          then
            echo "$line"
          else
            echo "$line" | cut -c 1-$max_characters | awk "{print \$0 \"...<truncated, only showing first $max_characters characters, out of ${#payload}>...\"}"
          fi
        fi
      fi
    done < "$fifo_path"

    if [[ -n "$grep_string" ]]
    then
      if [ $found != 1 ]
      then
        logerror "❌ could not find $grep_string in topic $topic"
        exit 1
      fi
    fi
  done

  if [[ -n "$timestamp_field" ]]
  then
    log "Plot data using gnuplot, see ${latency_png}"
    docker run --quiet --rm -i -v /tmp/latency:/work remuslazar/gnuplot -e \
    "
    set grid;
    set datafile separator ',';
    set timefmt \"%Y-%m-%d %H:%M:%S.%s\";
    set format x '%H:%M:%S';
    set term png size 1200,600;
    set output 'latency.png';
    set xdata time;
    set autoscale;
    set xlabel 'Time';
    set ylabel 'Latency in ms';
    plot 'latency.csv' using 1:(\$2-\$3) with points;"

    # open $latency_csv
    if [[ $(type -f open 2>&1) =~ "not found" ]]
    then
      :
    else
      open $latency_png
    fi
  fi
}

# :command.function
playground_topic_produce_command() {

  # src/commands/topic/produce.sh
  topic="${args[--topic]}"
  verbose="${args[--verbose]}"
  debug="${args[--debug]}"
  nb_messages="${args[--nb-messages]}"
  nb_partitions="${args[--nb-partitions]}"
  value="${args[--value]}"
  key="${args[--key]}"
  headers="${args[--headers]}"
  forced_key="${args[--forced-key]}"
  forced_value="${args[--forced-value]}"
  generate_only="${args[--generate-only]}"
  tombstone="${args[--tombstone]}"
  compatibility="${args[--compatibility]}"
  key_subject_name_strategy="${args[--key-subject-name-strategy]}"
  value_subject_name_strategy="${args[--value-subject-name-strategy]}"
  validate="${args[--validate]}"
  record_size="${args[--record-size]}"
  max_nb_messages_per_batch="${args[--max-nb-messages-per-batch]}"
  max_nb_messages_to_generate="${args[--max-nb-messages-to-generate]}"
  sleep_time_between_batch="${args[--sleep-time-between-batch]}"
  compression_codec="${args[--compression-codec]}"
  value_schema_id="${args[--value-schema-id]}"
  no_null="${args[--no-null]}"
  consume="${args[--consume]}"
  delete_topic="${args[--delete-topic]}"
  derive_key_schema_as="${args[--derive-key-schema-as]}"
  derive_value_schema_as="${args[--derive-value-schema-as]}"

  # Convert the space delimited string to an array
  eval "validate_config=(${args[--validate-config]})"
  eval "producer_property=(${args[--producer-property]})"
  eval "references=(${args[--reference]})"

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  # debug
  if [[ -n "$debug" ]]
  then
      log "🐞 debug mode is on"
      trap 'code $tmp_dir' EXIT
  fi

  ref_schema_file=$tmp_dir/ref_schema
  key_schema_file=$tmp_dir/key_schema
  value_schema_file=$tmp_dir/value_schema

  if [ "$value" = "-" ]
  then
      if [[ ! -n "$tombstone" ]]
      then
          # stdin
          if [ -t 0 ]
          then
              logerror "❌ stdin is empty you probably forgot to set --value !"
              exit 1
          else
              value_content=$(cat "$value")
              echo "$value_content" > $value_schema_file
          fi
      fi
  else
      if [[ $value == @* ]]
      then
          # this is a schema file
          argument_schema_file=$(echo "$value" | cut -d "@" -f 2)
          cp $argument_schema_file $value_schema_file
      elif [ -f "$value" ]
      then
          cp $value $value_schema_file
      else
          value_content=$value
          echo "$value_content" > $value_schema_file
      fi
  fi

  get_environment_used
  get_sr_url_and_security

  get_broker_container
  bootstrap_server="$broker_container:9092"
  get_connect_container
  container=$connect_container
  sr_url_cli="http://schema-registry:8081"
  security=""
  if [[ "$environment" == "kerberos" ]] || [[ "$environment" == "ssl_kerberos" ]]
  then
      container="client"
      security="--producer.config /etc/kafka/producer.properties"

      docker exec -i client kinit -k -t /var/lib/secret/kafka-connect.key connect
  elif [[ "$environment" == *"ssl"* ]]
  then
      sr_url_cli="https://schema-registry:8081"
      security="--property schema.registry.ssl.truststore.location=/etc/kafka/secrets/kafka.client.truststore.jks --property schema.registry.ssl.truststore.password=confluent --property schema.registry.ssl.keystore.location=/etc/kafka/secrets/kafka.client.keystore.jks --property schema.registry.ssl.keystore.password=confluent --producer.config /etc/kafka/secrets/client_without_interceptors.config"
  elif [[ "$environment" == "rbac-sasl-plain" ]]
  then
      security="--property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info=clientAvroCli:clientAvroCli --producer.config /etc/kafka/secrets/client_without_interceptors.config"
  elif [[ "$environment" == "ldap-authorizer-sasl-plain" ]]
  then
      security="--producer.config /service/kafka/users/client.properties"
  elif [[ "$environment" == "sasl-plain" ]] || [[ "$environment" == "sasl-scram" ]] || [[ "$environment" == "ldap-sasl-plain" ]]
  then
      security="--producer.config /tmp/client.properties"
  elif [[ "$environment" == "ccloud" ]]
  then
      get_kafka_docker_playground_dir
      DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

      if [ -f $DELTA_CONFIGS_ENV ]
      then
          source $DELTA_CONFIGS_ENV
      else
          logerror "❌ $DELTA_CONFIGS_ENV has not been generated"
          exit 1
      fi
      if [ ! -f $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta ]
      then
          logerror "❌ $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta has not been generated"
          exit 1
      fi
  fi

  if [[ -n "$delete_topic" ]]
  then
      if [[ ! -n "$generate_only" ]]
      then
          log "❌ --delete-topic is set, delete topic if applicable"
          playground topic delete --topic $topic
      fi
  fi

  if [[ -n "$tombstone" ]]
  then
      if [[ ! -n "$key" ]] && [[ ! -n "$forced_key" ]]
      then
          logwarn "--tombstone is set but neither --key or --forced-key are set, forcing key to NULL."
          key="NULL"
      fi
      get_connect_image
      if ! version_gt $CP_CONNECT_TAG "7.1.99"
      then
          logerror "❌ --tombstone is set but it can be produced only with CP 7.2+"
          exit 1
      fi
      if [[ -n "$forced_key" ]]
      then
          key=$forced_key
      fi
  fi

  if [[ -n "$headers" ]]
  then
      get_connect_image
      if ! version_gt $CP_CONNECT_TAG "7.1.99"
      then
          logerror "❌ --headers is set but it can be produced only with CP 7.2+"
          exit 1
      fi
  fi

  function identify_schema() {
      schema_file=$1
      type=$2

      if grep -q "proto3" $schema_file
      then
          log "🔮 $type schema was identified as protobuf"
          schema_type=protobuf
      elif grep -q "\"type\"\s*:\s*\"object\"" $schema_file
      then
          log "🔮 $type schema was identified as json schema"
          schema_type=json-schema
      elif grep -q "\"_meta" $schema_file
      then
          log "🔮 $type schema was identified as json"
          schema_type=json
      elif grep -q "CREATE TABLE" $schema_file
      then
          log "🔮 $type schema was identified as sql"
          schema_type=sql
      elif grep -q "\"type\"\s*:\s*\"record\"" $schema_file
      then
          log "🔮 $type schema was identified as avro"
          schema_type=avro
      elif grep -xq "\".*\"" $schema_file
      then
          log "🔮 $type schema was identified as avro (single line surrounded by double quotes)"
          schema_type=avro
      else
          log "📢 $type no known schema could be identified, payload will be sent as raw data"
          schema_type=raw
      fi
  }

  ref_array_schema_file=$tmp_dir/ref_array_schema
    if [ ${#references[@]} -ne 0 ]
    then
      declare -a array_ref_name=()
      i=0
      list_file=""
      for ref in "${references[@]}"
      do
          log "🖇️ ref is $ref"

          if [[ $ref == @* ]]
          then
              # this is a schema file
              argument_schema_file=$(echo "$ref" | cut -d "@" -f 2)
              cp $argument_schema_file $ref_schema_file
          elif [ -f "$ref" ]
          then
              cp $ref $ref_schema_file
          else
              echo "$ref" > "$ref_schema_file"
          fi

          cp $ref_schema_file $tmp_dir/schema_ref_$i
          list_file="$list_file $tmp_dir/schema_ref_$i"

          identify_schema "$ref_schema_file" "ref"
          ref_schema_type=$schema_type

          ref_name=$(cat $ref_schema_file | jq -r '.["$id"]')

          log "🔖 registering schema reference with subject $ref_name"
          playground schema register --subject "$ref_name" < "$ref_schema_file"

          array_ref_name+=("$ref_name")
          ((i=i+1))
      done

      jq -s '.' $list_file > $ref_array_schema_file

      json_new_file=$tmp_dir/json_new_file
      json="{\"schemaType\":\"JSON\"}"
      content=$(cat $value_schema_file | tr -d '\n' | tr -s ' ')
      json_new=$(echo $json | jq --arg content "$content" '. + { "schema": $content }')
      echo "$json_new" > $json_new_file
      references=""
      curl_tmp_ref_schema=$tmp_dir/curl_tmp_ref_schema
      curl_ref_array_schema_file=$tmp_dir/curl_ref_array_schema

      i=0
      list_file=""
      for ref_name in "${array_ref_name[@]}"
      do
          reference="{\"name\":\"$ref_name\",\"subject\":\"$ref_name\",\"version\":1}"
          echo "$reference" > $curl_tmp_ref_schema
          cp $curl_tmp_ref_schema $tmp_dir/ref_$i
          list_file="$list_file $tmp_dir/ref_$i"
          ((i=i+1))
      done

      jq -s '.' $list_file > $curl_ref_array_schema_file

      references=$(cat $curl_ref_array_schema_file | tr -d '\n' | tr -s ' ')

      register_ref_array_schema=$tmp_dir/register_ref_array_schema

      jq --argjson addition "$(cat $curl_ref_array_schema_file)" '. + {references: $addition}' $json_new_file > $register_ref_array_schema

      log "🔖 registering schema with subject $topic-value and reference"
      playground schema register --subject "${topic}-value" < $register_ref_array_schema

      value_schema_id=$(playground schema get --subject "${topic}-value" | grep "subject" | cut -d "(" -f 2 | cut -d " " -f 2 | cut -d ")" -f 1)

      if [[ "$value_schema_id" =~ ^-?[0-9]+$ ]]
      then
          :
      else
          logerror "❌ value schema id $value_schema_id is not valid"
          exit 1
      fi

  fi

  if [[ -n "$key" ]]
  then
      if [[ $key == @* ]]
      then
          # this is a schema file
          argument_schema_file=$(echo "$key" | cut -d "@" -f 2)
          cp $argument_schema_file $key_schema_file
      elif [ -f "$key" ]
      then
          cp $key $key_schema_file
      else
          echo "$key" > "$key_schema_file"
      fi

      if [[ -n "$derive_key_schema_as" ]]
      then
          log "🪄 --derive-key-schema-as $derive_key_schema_as is used"
          set +e
          output=$(playground --output-level ERROR  schema derive-schema --schema-type "${derive_key_schema_as}" < "$key_schema_file")
          if [ $? -ne 0 ]
          then
              logerror "❌ schema derivation failed"
              echo "$output"
              exit 1
          else
              log "🪄 generated $derive_key_schema_as schema:"
              echo "$output"
          fi
          set -e
          echo "$output" > $key_schema_file
      fi
      identify_schema "$key_schema_file" "key"
      key_schema_type=$schema_type
  fi

  if [[ ! -n "$tombstone" ]]
  then
      if [[ -n "$derive_value_schema_as" ]]
      then
          log "🪄 --derive-value-schema-as $derive_value_schema_as is used"
          set +e
          output=$(playground --output-level ERROR  schema derive-schema --schema-type "${derive_value_schema_as}" < "$value_schema_file")
          if [ $? -ne 0 ]
          then
              logerror "❌ schema derivation failed"
              echo "$output"
              exit 1
          else
              log "🪄 generated $derive_value_schema_as schema:"
              echo "$output"
          fi
          set -e
          echo "$output" > $value_schema_file
      fi
      identify_schema "$value_schema_file" "value"
      value_schema_type=$schema_type
  fi

  if [[ -n "$key" ]]
  then
      if ([ "$key_schema_type" = "avro" ] || [ "$key_schema_type" = "protobuf" ] || [ "$key_schema_type" = "json-schema" ]) &&

          ([ "$value_schema_type" = "avro" ] || [ "$value_schema_type" = "protobuf" ] || [ "$value_schema_type" = "json-schema" ])
      then
          if [ "$key_schema_type" != "$value_schema_type" ]
          then
              logerror "❌ both key and schemas are set with schema registry aware converters, but they are not the same"
              exit 1
          fi
      fi

      if ([ "$key_schema_type" = "avro" ] || [ "$key_schema_type" = "protobuf" ] || [ "$key_schema_type" = "json-schema" ]) &&

          ([ "$value_schema_type" = "raw" ] || [ "$value_schema_type" = "json" ] || [ "$value_schema_type" = "sql" ])
      then
          logerror "❌ key is set with schema registry aware converter, but not value"
          exit 1
      fi
  fi

  if [[ -n "$validate" ]]
  then
      if [ $nb_messages != 1 ]
      then
          logwarn "--validate is set, ignoring --nb-messages"
          nb_messages=1
      fi
  fi

  # https://stackoverflow.com/questions/22818814/repeat-a-file-content-until-reach-a-defined-line-count
  function repcat() {
      while cat "$1"
      do

          :
      done
  }

  function generate_data() {
      schema_type=$1
      schema_file=$2
      output_file=$3
      type="$4"
      input_file=""

      if [[ -n "$max_nb_messages_to_generate" ]]
      then
          log "🔨 --max-nb-messages-to-generate is set with $max_nb_messages_to_generate (it can be slow if number is high)"
          nb_max_messages_to_generate=$max_nb_messages_to_generate
      else

          if [ "$schema_type" == "protobuf" ]
          then
              nb_max_messages_to_generate=50
          else
              if [ "$record_size" != 0 ] && [ "$type" == "VALUE" ]
              then
                  nb_max_messages_to_generate=100
              else
                  nb_max_messages_to_generate=100000
              fi
          fi
          if [ $nb_messages = -1 ]
          then
              nb_messages_to_generate=1000
          fi
      fi
      if [ $nb_messages = -1 ]
      then
          nb_messages_to_generate=$nb_max_messages_to_generate
      elif [ $nb_messages -lt $nb_max_messages_to_generate ]
      then
          nb_messages_to_generate=$nb_messages
      else
          nb_messages_to_generate=$nb_max_messages_to_generate
      fi

      if [[ -n "$forced_value" ]] && [ "$type" == "VALUE" ]
      then
          log "☢️ --forced-value is set"
          echo "$forced_value" > $tmp_dir/out.json
      elif [[ -n "$forced_key" ]] && [ "$type" == "KEY" ]
      then
          log "☢️ --forced-key is set"
          echo "$forced_key" > $tmp_dir/out.json
      else
          if [[ -n "$no_null" ]]
          then
              no_null="true"
          else
              no_null="false"
          fi
          case "${schema_type}" in
              json|sql)
                  # https://github.com/MaterializeInc/datagen
                  set +e
                  docker run --quiet --rm -i -v $schema_file:/app/schema.$schema_type materialize/datagen -s schema.$schema_type -n $nb_messages_to_generate --dry-run > $tmp_dir/result.log

                  nb=$(grep -c "Payload: " $tmp_dir/result.log)
                  if [ $nb -eq 0 ]
                  then
                      logerror "❌ materialize/datagen failed to produce $schema_type "
                      cat $tmp_dir/result.log
                      exit 1
                  fi
                  set -e
                  cat $tmp_dir/result.log | grep "Payload: " | sed 's/  Payload: //' > $tmp_dir/out.json
              ;;
              avro)
                  schema_file_name="$(basename "${schema_file}")"
                  docker run --quiet --rm -v $tmp_dir:/tmp/ vdesabou/avro-tools random /tmp/out.avro --schema-file /tmp/$schema_file_name --count $nb_messages_to_generate --no-null "$no_null"
                  docker run --quiet --rm -v $tmp_dir:/tmp/ vdesabou/avro-tools tojson /tmp/out.avro > $tmp_dir/out.json
              ;;
              json-schema)
                  # https://github.com/json-schema-faker/json-schema-faker/tree/master/docs
                  schema_file_name="$(basename "${schema_file}")"
                  if [ -f $ref_array_schema_file ]
                  then
                      ref_array_schema_file_name="$(basename "${ref_array_schema_file}")"
                      docker run --quiet --rm -v $tmp_dir:/tmp/ -e NB_MESSAGES=$nb_messages_to_generate -e SCHEMA=/tmp/$schema_file_name -e REFS=/tmp/$ref_array_schema_file_name -e NO_NULL="$no_null" vdesabou/json-schema-faker > $tmp_dir/out.json
                  else
                      docker run --quiet --rm -v $tmp_dir:/tmp/ -e NB_MESSAGES=$nb_messages_to_generate -e SCHEMA=/tmp/$schema_file_name -e NO_NULL="$no_null" vdesabou/json-schema-faker > $tmp_dir/out.json
                  fi
              ;;
              protobuf)
                  # https://github.com/JasonkayZK/mock-protobuf.js
                  docker run -u0 --rm -v $tmp_dir:/tmp/ -v $schema_file:/app/schema.proto -e NB_MESSAGES=$nb_messages_to_generate vdesabou/protobuf-faker bash -c "bash /app/produce.sh && chown -R $(id -u $USER):$(id -g $USER) /tmp/" > $tmp_dir/out.json
              ;;
              raw)
                  if jq -e . >/dev/null 2>&1 <<< "$(head -1 "$schema_file")"
                  then
                      log "💫 payload is one json per line, one json record per line will be sent"
                      set +e
                      repcat "$schema_file" | head -n "$nb_messages_to_generate" > $tmp_dir/out.json
                      set -e
                  elif jq -e . >/dev/null 2>&1 <<< "$(cat "$schema_file")"
                  then
                      log "💫 payload is single json, it will be sent as one record"
                      jq -c . "$schema_file" > $tmp_dir/minified.json
                      set +e
                      repcat "$tmp_dir/minified.json" | head -n "$nb_messages_to_generate" > $tmp_dir/out.json
                      set -e
                  else
                      log "💫 payload is not single json, one record per line will be sent"
                      set +e
                      repcat "$schema_file" | head -n "$nb_messages_to_generate" > $tmp_dir/out.json
                      set -e
                  fi
              ;;
              *)
                  logerror "❌ schema_type name not valid ! Should be one of raw, json, avro, json-schema or protobuf"
                  exit 1
              ;;
          esac
      fi

      if [ "$input_file" = "" ]
      then
          input_file=$tmp_dir/out.json
      fi

      input2_file=$tmp_dir/input2.json
      if [ -f $input2_file ]
      then
          rm -f $input2_file
      fi
      record_size_temp_file_line=$tmp_dir/line.json
      record_size_temp_file_output=$tmp_dir/output.json
      lines_count=0
      counter=0

      while IFS= read -r line
      do
          if [ $record_size != 0 ] && [ "$type" == "VALUE" ]
          then
              if ! echo "$line" | jq -e .  > /dev/null 2>&1
              then
                  echo "${line}PLACEHOLDER" > $record_size_temp_file_output
              else
                  echo $line > $record_size_temp_file_line
                  new_value="PLACEHOLDER"

                  first_string_field=$(echo "$line" | jq -r 'path(.. | select(type == "string")) | .[-1]' | head -1)

                  if [ $lines_count -eq 0 ]
                  then
                      log "🔮 Replacing first string field $first_string_field value with long payload"
                  fi
                  jq -c --arg new_val "$new_value" ".${first_string_field} |= \$new_val" $record_size_temp_file_line > $record_size_temp_file_output
              fi

              # The size needed for the new_value
              size_with_placeholder=$(wc -c < $record_size_temp_file_output)

              # The size needed for the new_value
              new_value_size=$((record_size - size_with_placeholder))

              if [[ $new_value_size -gt 0 ]]
              then
                  # Create a string of '-' characters with length equivalent to new_value_size
                  new_value_string=$(LC_ALL=C tr -dc 'a-zA-Z0-9' < /dev/urandom | head -c$new_value_size)

                  echo -n "$new_value_string" > temp.txt

                  # Replace placeholder with the content of temp.txt file in $record_size_temp_file_output
                  # Perl can handle very large arguments and perform replacement effectively
                  perl -pi -e 'BEGIN{undef $/;} s/PLACEHOLDER/`cat temp.txt`/gse' $record_size_temp_file_output

                  cat $record_size_temp_file_output >> "$input2_file"
                  # Remove temp file
                  rm temp.txt
              else
                  log "❌ record-size is too small"
                  exit 1
              fi
          else
              echo "$line" >> "$input2_file"
          fi

          lines_count=$((lines_count+1))
          if [ $nb_messages != -1 ]
          then
              if [ $lines_count -ge $nb_messages ]
              then
                  break
              fi
          fi
          counter=$((counter+1))
      done < "$input_file"

      if [ $nb_messages -gt $max_nb_messages_per_batch ] || [ $nb_messages = -1 ]
      then
          set +e
          repcat "$input2_file" | head -n "$max_nb_messages_per_batch" > "$output_file"
          set -e
      elif [ $lines_count -lt $nb_messages ]
      then
          set +e
          repcat "$input2_file" | head -n "$nb_messages" > "$output_file"
          set -e
      else
          cp $input2_file $output_file
      fi
  }

  output_key_file=$tmp_dir/out_key_final.json
  output_value_file=$tmp_dir/out_value_final.json
  output_final_file=$tmp_dir/out_final.json
  SECONDS=0
  if [[ -n "$key" ]]
  then
      log "✨ generating key data..."
      generate_data "$key_schema_type" "$key_schema_file" "$output_key_file" "KEY"
  fi
  if [[ ! -n "$tombstone" ]]
  then
      log "✨ generating value data..."
      generate_data "$value_schema_type" "$value_schema_file" "$output_value_file" "VALUE"
      nb_generated_messages=$(wc -l < $output_value_file)
  else
      nb_generated_messages=$(wc -l < $output_key_file)
  fi
  nb_generated_messages=${nb_generated_messages// /}

  if [ "$nb_generated_messages" == "0" ]
  then
      logerror "❌ records could not be generated!"
      exit 1
  fi

  if [[ -n "$key" ]] && [ "$key_schema_type" = "raw" ]
  then
      if [[ $key =~ ^([^0-9]*)([0-9]+)([^0-9]*)$ ]]; then
          prefix="${BASH_REMATCH[1]}"
          number="${BASH_REMATCH[2]}"
          suffix="${BASH_REMATCH[3]}"

          log "🗝️ key $key is set with a number $number, it will be used as starting point"
          while read -r line
          do
              new_key="${prefix}${number}${suffix}"
              echo "${new_key}" >> "$tmp_dir/temp_value_file"
              number=$((number + 1))
          done < "$output_key_file"

          mv "$tmp_dir/temp_value_file" "$output_key_file"
      else
          counter=1
          log "🗝️ key is set with a string $key, it will be used for all records"
          while read -r line
          do
              echo "${key}" >> "$tmp_dir/temp_value_file"
          done < "$output_key_file"

          mv "$tmp_dir/temp_value_file" "$output_key_file"
      fi
  fi

  if [[ -n "$key" ]]
  then
      if [[ ! -n "$tombstone" ]]
      then
          # merging key and value files
          paste -d "|" $output_key_file $output_value_file > $output_final_file
      else
          touch "$output_value_file"
          while read -r line; do
              echo "NULL" >> "$output_value_file"
          done < "$output_key_file"
          # merging key and value files
          paste -d "|" $output_key_file $output_value_file > $output_final_file
      fi
  else
      cp $output_value_file $output_final_file
  fi

  # headers need to be set first
  if [[ -n "$headers" ]]
  then
      log "🚏 headers are set $headers"
      while read line
      do
          echo "${headers}|${line}" >> $tmp_dir/temp_headers_file
      done < $output_final_file

      mv $tmp_dir/temp_headers_file $output_final_file
  fi

  value_str=""
  if [[ -n "$forced_value" ]]
  then
      value_str=" based on --forced-value "
  fi

  ELAPSED="took: $((($SECONDS / 60) % 60))min $(($SECONDS % 60))sec"

  size_limit_to_show=3000
  if [ $record_size -gt $size_limit_to_show ]
  then
      log "✨ $nb_generated_messages records were generated$value_str (only showing first 1 as record size is $record_size), $ELAPSED"
      log "✨ only showing first $size_limit_to_show characters"
      head -n 1 "$output_final_file" | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | cut -c 1-${size_limit_to_show} | awk "{print \$0 \"...<truncated, only showing first $size_limit_to_show characters, out of $record_size>...\"}"
  else
      if (( nb_generated_messages < 10 ))
      then
          log "✨ $nb_generated_messages records were generated$value_str"
          cat "$output_final_file" | awk -v counter=1 '{gsub("%g", counter); counter++; print}'
      else
          log "✨ $nb_generated_messages records were generated$value_str (only showing first 10), $ELAPSED"
          head -n 10 "$output_final_file" | awk -v counter=1 '{gsub("%g", counter); counter++; print}'
      fi
  fi

  if [[ -n "$generate_only" ]]
  then
    log "🚪 --generate-only is set, exiting now."
    exit 0
  fi

  if [[ -n "$validate" ]]
  then
      log "✔️ --validate is set, validating schema now..."

      if [ "$value_schema_type" == "json-schema" ]
      then
          log "✨ also validating with https://raw.githubusercontent.com/conan-goldsmith/Python-Scripts/main/json_type_validator.py"
          curl -s -L https://raw.githubusercontent.com/conan-goldsmith/Python-Scripts/main/json_type_validator.py -o /tmp/json_type_validator.py
          docker run -i --rm -v "/tmp/json_type_validator.py:/tmp/json_type_validator.py" -v "$value_schema_file:/tmp/schema" python:3.7-slim python /tmp/json_type_validator.py -f /tmp/schema
      fi

      set +e
      tag=$(docker ps --format '{{.Image}}' | grep -E 'confluentinc/cp-.*-connect-.*:' | awk -F':' '{print $2}')
      if [ $? != 0 ] || [ "$tag" == "" ]
      then
          logerror "❌ Could not find current CP version from docker ps"
          exit 1
      fi
      log "🏗 Building jar for schema-validator"
      docker run -i --rm -e TAG=$tag -v "${root_folder}/scripts/cli/src/schema-validator":/usr/src/mymaven -v "$HOME/.m2":/root/.m2 -v "$root_folder/scripts/settings.xml:/tmp/settings.xml" -v "${root_folder}/scripts/cli/src/schema-validator/target:/usr/src/mymaven/target" -w /usr/src/mymaven maven:3.6.1-jdk-11 mvn -s /tmp/settings.xml -Dkafka.tag=$tag package > /tmp/result.log 2>&1
      if [ $? != 0 ]
      then
          logerror "❌ failed to build java component schema-validator"
          tail -500 /tmp/result.log
          exit 1
      fi
      set -e

      docker cp ${root_folder}/scripts/cli/src/schema-validator/target/schema-validator-1.0.0-jar-with-dependencies.jar connect:/tmp/schema-validator-1.0.0-jar-with-dependencies.jar > /dev/null 2>&1
      docker cp $value_schema_file connect:/tmp/schema > /dev/null 2>&1
      docker cp $output_value_file connect:/tmp/message.json > /dev/null 2>&1
      env_list=""
      for conf in "${validate_config[@]}"
      do
          case "${conf}" in

              "connect.meta.data=false")
                  env_list="$env_list -e KAFKA_CONNECT_META_DATA=false"
              ;;

              # avro specifics
              "scrub.invalid.names=true")
                  env_list="$env_list -e KAFKA_SCRUB_INVALID_NAMES=true"
              ;;
              "enhanced.avro.schema.support=true")
                  env_list="$env_list -e KAFKA_ENHANCED_AVRO_SCHEMA_SUPPORT=true"
              ;;

              # json-schema specifics
              "use.optional.for.nonrequired=true")
                  env_list="$env_list -e KAFKA_USE_OPTIONAL_FOR_NONREQUIRED=true"
              ;;
              "ignore.default.for.nullables=true")
                  env_list="$env_list -e KAFKA_IGNORE_DEFAULT_FOR_NULLABLES=true"
              ;;
              "generalized.sum.type.support=true")
                  env_list="$env_list -e KAFKA_GENERALIZED_SUM_TYPE_SUPPORT=true"
              ;;

              # protobuf specifics
              "enhanced.protobuf.schema.support=true")
                  env_list="$env_list -e KAFKA_ENHANCED_PROTOBUF_SCHEMA_SUPPORT=true"
              ;;
              "generate.index.for.unions=false")
                  env_list="$env_list -e KAFKA_GENERATE_INDEX_FOR_UNIONS=false"
              ;;
              "int.for.enums=true")
                  env_list="$env_list -e KAFKA_INT_FOR_ENUMS=true"
              ;;
              "optional.for.nullables=true")
                  env_list="$env_list -e KAFKA_OPTIONAL_FOR_NULLABLES=true"
              ;;
              "generate.struct.for.nulls=true")
                  env_list="$env_list -e KAFKA_GENERATE_STRUCT_FOR_NULLS=true"
              ;;
              "wrapper.for.nullables=true")
                  env_list="$env_list -e KAFKA_WRAPPER_FOR_NULLABLES=true"
              ;;
              "wrapper.for.raw.primitives=false")
                  env_list="$env_list -e KAFKA_WRAPPER_FOR_RAW_PRIMITIVES=false"
              ;;
              *)
                  logerror "default (none of above)"
              ;;
          esac
      done

      docker exec $env_list -e SCHEMA_TYPE=$value_schema_type connect bash -c "java -jar /tmp/schema-validator-1.0.0-jar-with-dependencies.jar" > $tmp_dir/result.log
      set +e
      nb=$(grep -c "ERROR" $tmp_dir/result.log)
      if [ $nb -ne 0 ]
      then
          logerror "❌ schema is not valid according to $value_schema_type converter"
          cat $tmp_dir/result.log
          exit 1
      else
          log "👌 schema is valid according to $value_schema_type converter"
      fi
      set -e
  fi

  set +e
  playground topic describe --topic $topic > /tmp/result.log 2>/tmp/result.log
  grep "does not exist" /tmp/result.log > /dev/null 2>&1
  if [ $? == 0 ]
  then
      log "✨ topic $topic does not exist, it will be created.."
      if [[ "$environment" == "ccloud" ]]
      then
          if [ "$nb_partitions" != "1" ]
          then
              log "⛅ creating topic in confluent cloud with $nb_partitions partitions"
              playground topic create --topic $topic --nb-partitions $nb_partitions
          else
              log "⛅ creating topic in confluent cloud"
              playground topic create --topic $topic --nb-partitions 1
          fi
      else
          if [ "$nb_partitions" != "1" ]
          then
              log "--nb-partitions is set, creating topic with $nb_partitions partitions"
              playground topic create --topic $topic --nb-partitions $nb_partitions
          else
              playground topic create --topic $topic
          fi
      fi
  else
      if [ "$nb_partitions" != "1" ]
      then
          nb=$(playground topic get-number-records -t $topic | tail -1)
          if [ $nb == 0 ]
          then
              log "--nb-partitions is set and topic is empty, re-creating it with $nb_partitions partitions..."
              playground topic delete --topic $topic
              playground topic create --topic $topic --nb-partitions $nb_partitions
          else
              logerror "--nb-partitions is set, but topic is not empty, delete it first and retry"
              echo "playground topic delete --topic $topic"
              exit 0
          fi
      fi
  fi

  if [ "$compatibility" != "" ]
  then
      playground topic set-schema-compatibility --topic $topic --compatibility $compatibility
  fi

  if [[ ! -n "$key" ]] && [[ -n "$key_subject_name_strategy" ]]
  then
      logerror "❌ --key-subject-name-strategy is set but not --key"
      exit 1

  fi

  if [ "$key_schema_type" != "" ]
  then
      case "${key_schema_type}" in
          avro|json-schema|protobuf)

          ;;
          *)
              if [[ -n "$validate" ]]
              then
                  logerror "❌ --validate is set but $key_schema_type is used. This is only valid for avro|json-schema|protobuf"
                  exit 1
              fi
              if [[ -n "$key_subject_name_strategy" ]]
              then
                  logerror "❌ --key-subject-name-strategy is set but $key_schema_type is used. This is only valid for avro|json-schema|protobuf"
                  exit 1

              fi
          ;;
      esac
  fi

  case "${value_schema_type}" in
      avro|json-schema|protobuf)

      ;;
      *)
          if [[ -n "$validate" ]]
          then
              logerror "❌ --validate is set but $value_schema_type is used. This is only valid for avro|json-schema|protobuf"
              exit 1
          fi
          if [[ -n "$value_subject_name_strategy" ]]
          then
              logerror "❌ --value-subject-name-strategy is set but $value_schema_type is used. This is only valid for avro|json-schema|protobuf"
              exit 1

          fi
      ;;
  esac

  compression=""
  producer_properties=""

  set -e
  SECONDS=0
  if [ $nb_messages = -1 ]
  then
      log "📤 producing infinite records to topic $topic (--nb-messages is set to -1)"
  else
      log "📤 producing $nb_messages records to topic $topic"
  fi
  sleep_msg=""
  if [[ $sleep_time_between_batch -gt 0 ]]
  then
      sleep_msg=" with $sleep_time_between_batch seconds between each batch"
  fi
  if [ $nb_messages -gt $max_nb_messages_per_batch ] || [ $nb_messages = -1 ]
  then
      log "✨ it will be done in batches of maximum $max_nb_messages_per_batch records$sleep_msg"

      log "✨ setting --producer-property linger.ms=100 and --producer-property batch.size=500000"
      producer_properties="$producer_properties --producer-property linger.ms=1000 --producer-property batch.size=500000"
  fi

  if [ $record_size -gt 1048576 ]
  then
      log "✨ record-size $record_size is greater than 1Mb (1048576), setting --producer-property max.request.size=$((record_size + 1000)) and --producer-property buffer.memory=67108864"
      producer_properties="$producer_properties --producer-property max.request.size=$((record_size + 1000)) --producer-property buffer.memory=67108864"
      log "✨ topic $topic max.message.bytes is also set to $((record_size + 1000))"
      playground topic alter --topic $topic --add-config max.message.bytes=$((record_size + 1000))
  fi

  for producer_prop in "${producer_property[@]}"
  do
      producer_properties="$producer_properties --producer-property $producer_prop"
  done

  if [ "$producer_properties" != "" ]
  then
      log "⚙️ following producer properties will be used: $producer_properties"
  fi

  if [[ -n "$compression_codec" ]]
  then
      log "🤐 --compression-codec $compression_codec will be used"
      compression="--compression-codec $compression_codec"
  fi

  if [[ -n "$tombstone" ]]
  then
      log "🧟 Sending tombstone(s)"
      tombstone="--property null.marker=NULL"
  fi

  function handle_signal {
    echo "Stopping..."
    stop=1
  }
  # Set the signal handler
  trap handle_signal SIGINT

  parameter_for_list_broker="--bootstrap-server"
  set +e
  tag=$(docker ps --format '{{.Image}}' | grep -E 'confluentinc/cp-.*-connect-.*:' | awk -F':' '{print $2}')
  if [ $? != 0 ] || [ "$tag" == "" ]
  then
      # default to --bootstrap-server
      parameter_for_list_broker="--bootstrap-server"
  fi
  set -e
  if [ "$tag" != "" ]
  then
      if ! version_gt $tag "5.4.99"
      then
          parameter_for_list_broker="--broker-list"
      fi
  fi

  nb_messages_sent=0
  nb_messages_to_send=0
  stop=0
  should_stop=0
  while [ $stop != 1 ]
  do
      if [ $nb_messages -eq -1 ]
      then
          nb_messages_to_send=$nb_generated_messages
      elif [ $((nb_messages_sent + nb_generated_messages)) -le $nb_messages ]
      then
          nb_messages_to_send=$nb_generated_messages
      else
          nb_messages_to_send=$((nb_messages - nb_messages_sent))
          should_stop=1
      fi
      if [ $nb_messages_to_send -eq 0 ]
      then
          stop=1
          continue
      fi
      if [ $nb_messages -gt $max_nb_messages_per_batch ] || [ $nb_messages = -1 ]
      then
          if [ $nb_messages -eq -1 ]
          then
              log "📤 producing a batch of $nb_messages_to_send records to topic $topic (press ctrl-c to stop)"
              log "💯 $nb_messages_sent records sent so far..."
          else
              log "📤 producing a batch of $nb_messages_to_send records to topic $topic"
              log "💯 $nb_messages_sent/$nb_messages records sent so far..."
          fi
      fi

      if [[ -n "$verbose" ]]
      then
          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' > /tmp/verbose_input_file.txt
      fi
      get_connect_image
      if version_gt $CP_CONNECT_TAG "7.9.99"
      then
          tool_log4j_jvm_arg="-Dlog4j2.configurationFile=file:/etc/kafka/tools-log4j2.yaml"
      else
          tool_log4j_jvm_arg="-Dlog4j.configuration=file:/etc/kafka/tools-log4j.properties"
      fi
      switch_schema_type=""
      if [[ -n "$tombstone" ]]
      then
          switch_schema_type="${key_schema_type}"
      else
          switch_schema_type="${value_schema_type}"
      fi
      case "${switch_schema_type}" in
          json|sql|raw)
              if [[ "$environment" == "ccloud" ]]
              then
                  if [[ -n "$key" ]]
                  then
                      if [[ -n "$headers" ]]
                      then
                          get_connect_image
                          if [[ -n "$verbose" ]]
                          then
                              log "🐞 CLI command used to produce data"
                              echo "cat /tmp/verbose_input_file.txt | docker run -i --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS=\"$BOOTSTRAP_SERVERS\" ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-console-producer $parameter_for_list_broker $BOOTSTRAP_SERVERS --topic $topic --producer.config /tmp/configuration/ccloud.properties $security $producer_properties $compression $tombstone --property parse.key=true --property key.separator=\"|\" --property parse.headers=true --property headers.delimiter=\"|\" --property headers.separator=\",\" --property headers.key.separator=\":\""
                          fi
                          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker run -i --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS=\"$BOOTSTRAP_SERVERS\" ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-console-producer $parameter_for_list_broker $BOOTSTRAP_SERVERS --topic $topic --producer.config /tmp/configuration/ccloud.properties $security $producer_properties $compression $tombstone --property parse.key=true --property key.separator="|" --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":"
                      else
                          get_connect_image
                          if [[ -n "$verbose" ]]
                          then
                              log "🐞 CLI command used to produce data"
                              echo "cat /tmp/verbose_input_file.txt | docker run -i --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS=\"$BOOTSTRAP_SERVERS\" ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-console-producer $parameter_for_list_broker $BOOTSTRAP_SERVERS --topic $topic --producer.config /tmp/configuration/ccloud.properties $security $producer_properties $compression $tombstone --property parse.key=true --property key.separator=\"|\" "
                          fi
                          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker run -i --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS=\"$BOOTSTRAP_SERVERS\" ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-console-producer $parameter_for_list_broker $BOOTSTRAP_SERVERS --topic $topic --producer.config /tmp/configuration/ccloud.properties $security $producer_properties $compression $tombstone --property parse.key=true --property key.separator="|"

                      fi
                  else
                      if [[ -n "$headers" ]]
                      then
                          get_connect_image
                          if [[ -n "$verbose" ]]
                          then
                              log "🐞 CLI command used to produce data"
                              echo "cat /tmp/verbose_input_file.txt | docker run -i --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS=\"$BOOTSTRAP_SERVERS\" ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-console-producer $parameter_for_list_broker $BOOTSTRAP_SERVERS --topic $topic --producer.config /tmp/configuration/ccloud.properties $security $producer_properties $compression $tombstone --property parse.headers=true --property headers.delimiter=\"|\" --property headers.separator=\",\" --property headers.key.separator=\":\""
                          fi
                          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker run -i --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS=\"$BOOTSTRAP_SERVERS\" ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-console-producer $parameter_for_list_broker $BOOTSTRAP_SERVERS --topic $topic --producer.config /tmp/configuration/ccloud.properties $security $producer_properties $compression $tombstone --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":"
                      else
                          get_connect_image
                          if [[ -n "$verbose" ]]
                          then
                              log "🐞 CLI command used to produce data"
                              echo "cat /tmp/verbose_input_file.txt | docker run -i --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS=\"$BOOTSTRAP_SERVERS\" ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-console-producer $parameter_for_list_broker $BOOTSTRAP_SERVERS --topic $topic --producer.config /tmp/configuration/ccloud.properties $security $producer_properties $compression $tombstone"
                          fi
                          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker run -i --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS=\"$BOOTSTRAP_SERVERS\" ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-console-producer $parameter_for_list_broker $BOOTSTRAP_SERVERS --topic $topic --producer.config /tmp/configuration/ccloud.properties $security $producer_properties $compression $tombstone
                      fi
                  fi
              else
                  if [[ -n "$key" ]]
                  then
                      if [[ -n "$headers" ]]
                      then
                          if [[ -n "$verbose" ]]
                          then
                              log "🐞 CLI command used to produce data"
                              echo "cat /tmp/verbose_input_file.txt | docker exec -i $container kafka-console-producer $parameter_for_list_broker $bootstrap_server --topic $topic $security $producer_properties $compression $tombstone --property parse.key=true --property key.separator=\"|\" --property parse.headers=true --property headers.delimiter=\"|\" --property headers.separator=\",\" --property headers.key.separator=\":\""
                          fi
                          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker exec -i $container kafka-console-producer $parameter_for_list_broker $bootstrap_server --topic $topic $security $producer_properties $compression $tombstone --property parse.key=true --property key.separator="|" --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":"
                      else
                          if [[ -n "$verbose" ]]
                          then
                              log "🐞 CLI command used to produce data"
                              echo "cat /tmp/verbose_input_file.txt | docker exec -i $container kafka-console-producer $parameter_for_list_broker $bootstrap_server --topic $topic $security $producer_properties $compression $tombstone --property parse.key=true --property key.separator=\"|\""
                          fi
                          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker exec -i $container kafka-console-producer $parameter_for_list_broker $bootstrap_server --topic $topic $security $producer_properties $compression $tombstone --property parse.key=true --property key.separator="|"
                      fi
                  else
                      if [[ -n "$headers" ]]
                      then
                          if [[ -n "$verbose" ]]
                          then
                              log "🐞 CLI command used to produce data"
                              echo "cat /tmp/verbose_input_file.txt | docker exec -i $container kafka-console-producer $parameter_for_list_broker $bootstrap_server --topic $topic $security $producer_properties $compression $tombstone --property parse.headers=true --property headers.delimiter=\"|\" --property headers.separator=\",\" --property headers.key.separator=\":\""
                          fi
                          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker exec -i $container kafka-console-producer $parameter_for_list_broker $bootstrap_server --topic $topic $security $producer_properties $compression $tombstone --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":"
                      else
                          if [[ -n "$verbose" ]]
                          then
                              log "🐞 CLI command used to produce data"
                              echo "cat /tmp/verbose_input_file.txt | docker exec -i $container kafka-console-producer $parameter_for_list_broker $bootstrap_server --topic $topic $security $producer_properties $compression $tombstone"
                          fi
                          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker exec -i $container kafka-console-producer $parameter_for_list_broker $bootstrap_server --topic $topic $security $producer_properties $compression $tombstone
                      fi
                  fi
              fi
          ;;
          *)
              force_schema_id=""
              if [[ -n "$value_schema_id" ]]
              then
                  log "🔰 --value-schema-id is set: adding --property value.schema.id=$value_schema_id --property auto.register=false --property use.latest.version=true"
                  force_schema_id="--property value.schema.id=$value_schema_id --property auto.register=false --property use.latest.version=true"
              fi

              key_subject_name_strategy_property=""
              if [[ -n "$key_subject_name_strategy" ]]
              then
                  key_subject_name_strategy_property="--property key.subject.name.strategy=io.confluent.kafka.serializers.subject.$key_subject_name_strategy"
              fi

              value_subject_name_strategy_property=""
              if [[ -n "$value_subject_name_strategy" ]]
              then
                  value_subject_name_strategy_property="--property value.subject.name.strategy=io.confluent.kafka.serializers.subject.$value_subject_name_strategy"
              fi

              avro_use_logical_type_converters_property=""
              if [ "${value_schema_type}" == "avro" ]
              then
                  avro_use_logical_type_converters_property=" --property avro.use.logical.type.converters=true"
              fi
              if [[ "$environment" == "ccloud" ]]
              then
                  if [ -f $key_schema_file ]
                  then
                      cp $key_schema_file /tmp/key_schema_file > /dev/null 2>&1
                  fi
                  if [ -f $value_schema_file ]
                  then
                      cp $value_schema_file /tmp/value_schema_file > /dev/null 2>&1
                  fi
                  if [[ -n "$key" ]]
                  then
                      if [[ -n "$headers" ]]
                      then
                          if [ "$key_schema_type" = "avro" ] || [ "$key_schema_type" = "protobuf" ] || [ "$key_schema_type" = "json-schema" ]
                          then
                              get_connect_image
                              if [[ -n "$verbose" ]]
                              then
                                  log "🐞 CLI command used to produce data"
                                  echo "cat /tmp/verbose_input_file.txt | docker run -i --rm -v /tmp:/tmp -e SCHEMA_REGISTRY_LOG4J_OPTS=\"$tool_log4j_jvm_arg\" -e key_schema_type=$key_schema_type -e BOOTSTRAP_SERVERS=\"$BOOTSTRAP_SERVERS\" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO=\"$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO\" -e SCHEMA_REGISTRY_URL=\"$SCHEMA_REGISTRY_URL\" ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-$key_schema_type-console-producer $parameter_for_list_broker $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config=\"$SASL_JAAS_CONFIG\" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info=\"$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO\" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema.file=/tmp/value_schema_file --property parse.key=true --property key.separator=\"|\" --property key.schema.file=\"/tmp/key_schema_file\" --property parse.headers=true --property headers.delimiter=\"|\" --property headers.separator=\",\" --property headers.key.separator=\":\" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression $tombstone"
                              fi
                              head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker run -i --rm -v /tmp:/tmp -e SCHEMA_REGISTRY_LOG4J_OPTS="$tool_log4j_jvm_arg" -e key_schema_type=$key_schema_type -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" -e SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-$key_schema_type-console-producer $parameter_for_list_broker $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config="$SASL_JAAS_CONFIG" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.key=true --property key.separator="|" --property key.schema.file="/tmp/key_schema_file" --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression $tombstone
                          else
                              get_connect_image
                              if [[ -n "$verbose" ]]
                              then
                                  log "🐞 CLI command used to produce data"
                                  echo "cat /tmp/verbose_input_file.txt | docker run -i --rm -v /tmp:/tmp -e SCHEMA_REGISTRY_LOG4J_OPTS=\"$tool_log4j_jvm_arg\" -e value_schema_type=$value_schema_type -e BOOTSTRAP_SERVERS=\"$BOOTSTRAP_SERVERS\" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO=\"$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO\" -e SCHEMA_REGISTRY_URL=\"$SCHEMA_REGISTRY_URL\" ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-$value_schema_type-console-producer $parameter_for_list_broker $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config=\"$SASL_JAAS_CONFIG\" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info=\"$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO\" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema.file=/tmp/value_schema_file --property parse.key=true --property key.separator=\"|\" --property key.serializer=org.apache.kafka.common.serialization.StringSerializer --property parse.headers=true --property headers.delimiter=\"|\" --property headers.separator=\",\" --property headers.key.separator=\":\" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression $tombstone"
                              fi
                              head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker run -i --rm -v /tmp:/tmp -e SCHEMA_REGISTRY_LOG4J_OPTS="$tool_log4j_jvm_arg" -e value_schema_type=$value_schema_type -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" -e SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-$value_schema_type-console-producer $parameter_for_list_broker $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config="$SASL_JAAS_CONFIG" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.key=true --property key.separator="|" --property key.serializer=org.apache.kafka.common.serialization.StringSerializer --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression $tombstone
                          fi
                      else
                          if [ "$key_schema_type" = "avro" ] || [ "$key_schema_type" = "protobuf" ] || [ "$key_schema_type" = "json-schema" ]
                          then
                              get_connect_image
                              if [[ -n "$verbose" ]]
                              then
                                  log "🐞 CLI command used to produce data"
                                  echo "cat /tmp/verbose_input_file.txt | docker run -i --rm -v /tmp:/tmp -e SCHEMA_REGISTRY_LOG4J_OPTS=\"$tool_log4j_jvm_arg\" -e key_schema_type=$key_schema_type -e BOOTSTRAP_SERVERS=\"$BOOTSTRAP_SERVERS\" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO=\"$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO\" -e SCHEMA_REGISTRY_URL=\"$SCHEMA_REGISTRY_URL\" ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-$key_schema_type-console-producer $parameter_for_list_broker $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config=\"$SASL_JAAS_CONFIG\" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info=\"$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO\" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema.file=/tmp/value_schema_file --property parse.key=true --property key.separator=\"|\" --property key.schema.file=\"/tmp/key_schema_file\" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression $tombstone"
                              fi
                              head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker run -i --rm -v /tmp:/tmp -e SCHEMA_REGISTRY_LOG4J_OPTS="$tool_log4j_jvm_arg" -e key_schema_type=$key_schema_type -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" -e SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-$key_schema_type-console-producer $parameter_for_list_broker $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config="$SASL_JAAS_CONFIG" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.key=true --property key.separator="|" --property key.schema.file="/tmp/key_schema_file" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression $tombstone
                          else

                              get_connect_image
                              if [[ -n "$verbose" ]]
                              then
                                  log "🐞 CLI command used to produce data"
                                  echo "cat /tmp/verbose_input_file.txt | docker run -i --rm -v /tmp:/tmp -e SCHEMA_REGISTRY_LOG4J_OPTS=\"$tool_log4j_jvm_arg\" -e value_schema_type=$value_schema_type -e BOOTSTRAP_SERVERS=\"$BOOTSTRAP_SERVERS\" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO=\"$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO\" -e SCHEMA_REGISTRY_URL=\"$SCHEMA_REGISTRY_URL\" ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-$value_schema_type-console-producer $parameter_for_list_broker $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config=\"$SASL_JAAS_CONFIG\" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info=\"$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO\" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema.file=/tmp/value_schema_file --property parse.key=true --property key.separator=\"|\" --property key.serializer=org.apache.kafka.common.serialization.StringSerializer $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression $tombstone"
                              fi
                              head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker run -i --rm -v /tmp:/tmp -e SCHEMA_REGISTRY_LOG4J_OPTS="$tool_log4j_jvm_arg" -e value_schema_type=$value_schema_type -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" -e SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-$value_schema_type-console-producer $parameter_for_list_broker $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config="$SASL_JAAS_CONFIG" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.key=true --property key.separator="|" --property key.serializer=org.apache.kafka.common.serialization.StringSerializer $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression $tombstone
                          fi
                      fi
                  else
                      if [[ -n "$headers" ]]
                      then
                          get_connect_image
                          if [[ -n "$verbose" ]]
                          then
                              log "🐞 CLI command used to produce data"
                              echo "cat /tmp/verbose_input_file.txt | docker run -i --rm -v /tmp:/tmp -e SCHEMA_REGISTRY_LOG4J_OPTS=\"$tool_log4j_jvm_arg\" -e value_schema_type=$value_schema_type -e BOOTSTRAP_SERVERS=\"$BOOTSTRAP_SERVERS\" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO=\"$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO\" -e SCHEMA_REGISTRY_URL=\"$SCHEMA_REGISTRY_URL\" ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-$value_schema_type-console-producer $parameter_for_list_broker $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config=\"$SASL_JAAS_CONFIG\" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info=\"$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO\" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema.file=/tmp/value_schema_file --property parse.headers=true --property headers.delimiter=\"|\" --property headers.separator=\",\" --property headers.key.separator=\":\" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression $tombstone"
                          fi
                          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker run -i --rm -v /tmp:/tmp -e SCHEMA_REGISTRY_LOG4J_OPTS="$tool_log4j_jvm_arg" -e value_schema_type=$value_schema_type -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" -e SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-$value_schema_type-console-producer $parameter_for_list_broker $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config="$SASL_JAAS_CONFIG" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression $tombstone
                      else
                          get_connect_image
                          if [[ -n "$verbose" ]]
                          then
                              log "🐞 CLI command used to produce data"
                              echo "cat /tmp/verbose_input_file.txt | docker run -i --rm -v /tmp:/tmp -e SCHEMA_REGISTRY_LOG4J_OPTS=\"$tool_log4j_jvm_arg\" -e value_schema_type=$value_schema_type -e BOOTSTRAP_SERVERS=\"$BOOTSTRAP_SERVERS\" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO=\"$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO\" -e SCHEMA_REGISTRY_URL=\"$SCHEMA_REGISTRY_URL\" ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-$value_schema_type-console-producer $parameter_for_list_broker $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config=\"$SASL_JAAS_CONFIG\" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info=\"$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO\" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema.file=/tmp/value_schema_file $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression $tombstone"
                          fi
                          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker run -i --rm -v /tmp:/tmp -e SCHEMA_REGISTRY_LOG4J_OPTS="$tool_log4j_jvm_arg" -e value_schema_type=$value_schema_type -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" -e SCHEMA_REGISTRY_URL="$SCHEMA_REGISTRY_URL" ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-$value_schema_type-console-producer $parameter_for_list_broker $BOOTSTRAP_SERVERS --producer-property ssl.endpoint.identification.algorithm=https --producer-property sasl.mechanism=PLAIN --producer-property security.protocol=SASL_SSL --producer-property sasl.jaas.config="$SASL_JAAS_CONFIG" --property basic.auth.credentials.source=USER_INFO --property schema.registry.basic.auth.user.info="$SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO" --property schema.registry.url=$SCHEMA_REGISTRY_URL --topic $topic $security --property value.schema.file="/tmp/value_schema_file" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression $tombstone
                      fi
                  fi
              else
                  # 🧠 remove SLF4J traces from topic produce #6254
                  playground --output-level ERROR container exec --command "rm -f /usr/share/java/schema-registry/slf4j-reload4j-1.7.36.jar > /dev/null 2>&1" --root
                  if [ -f $key_schema_file ]
                  then
                      docker cp $key_schema_file $container:/tmp/key_schema_file > /dev/null 2>&1
                  fi
                  if [ -f $value_schema_file ]
                  then
                      docker cp $value_schema_file $container:/tmp/value_schema_file > /dev/null 2>&1
                  fi
                  if [[ -n "$key" ]]
                  then
                      if [[ -n "$headers" ]]
                      then
                          if [ "$key_schema_type" = "avro" ] || [ "$key_schema_type" = "protobuf" ] || [ "$key_schema_type" = "json-schema" ]
                          then
                              if [[ -n "$verbose" ]]
                              then
                                  log "🐞 CLI command used to produce data"
                                  echo "cat /tmp/verbose_input_file.txt | docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS=\"$tool_log4j_jvm_arg\" -i $container kafka-$key_schema_type-console-producer $parameter_for_list_broker $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema.file=/tmp/value_schema_file --property parse.key=true --property key.separator=\"|\" --property key.schema.file=\"/tmp/key_schema_file\" --property parse.headers=true --property headers.delimiter=\"|\" --property headers.separator=\",\" --property headers.key.separator=\":\" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression $tombstone"
                              fi

                              head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS="$tool_log4j_jvm_arg" -i $container kafka-$key_schema_type-console-producer $parameter_for_list_broker $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.key=true --property key.separator="|" --property key.schema.file="/tmp/key_schema_file" --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression $tombstone
                          else
                              if [[ -n "$verbose" ]]
                              then
                                  log "🐞 CLI command used to produce data"
                                  echo "cat /tmp/verbose_input_file.txt | docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS=\"$tool_log4j_jvm_arg\" -i $container kafka-$value_schema_type-console-producer $parameter_for_list_broker $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema.file=/tmp/value_schema_file --property parse.key=true --property key.separator=\"|\" --property key.serializer=org.apache.kafka.common.serialization.StringSerializer --property parse.headers=true --property headers.delimiter=\"|\" --property headers.separator=\",\" --property headers.key.separator=\":\" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression $tombstone"
                              fi

                              head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS="$tool_log4j_jvm_arg" -i $container kafka-$value_schema_type-console-producer $parameter_for_list_broker $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.key=true --property key.separator="|" --property key.serializer=org.apache.kafka.common.serialization.StringSerializer --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression $tombstone
                          fi
                      else
                          if [ "$key_schema_type" = "avro" ] || [ "$key_schema_type" = "protobuf" ] || [ "$key_schema_type" = "json-schema" ]
                          then
                              if [[ -n "$verbose" ]]
                              then
                                  log "🐞 CLI command used to produce data"
                                  echo "cat /tmp/verbose_input_file.txt | docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS=\"$tool_log4j_jvm_arg\" -i $container kafka-$key_schema_type-console-producer $parameter_for_list_broker $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema.file=/tmp/value_schema_file --property parse.key=true --property key.separator=\"|\" --property key.schema.file=\"/tmp/key_schema_file\" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression $tombstone"
                              fi
                              head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS="$tool_log4j_jvm_arg" -i $container kafka-$key_schema_type-console-producer $parameter_for_list_broker $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.key=true --property key.separator="|" --property key.schema.file="/tmp/key_schema_file" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression $tombstone
                          else
                              if [[ -n "$verbose" ]]
                              then
                                  log "🐞 CLI command used to produce data"
                                  echo "cat /tmp/verbose_input_file.txt | docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS=\"$tool_log4j_jvm_arg\" -i $container kafka-$value_schema_type-console-producer $parameter_for_list_broker $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema.file=/tmp/value_schema_file --property parse.key=true --property key.separator=\"|\" --property key.serializer=org.apache.kafka.common.serialization.StringSerializer $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression $tombstone"
                              fi
                              head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS="$tool_log4j_jvm_arg" -i $container kafka-$value_schema_type-console-producer $parameter_for_list_broker $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.key=true --property key.separator="|" --property key.serializer=org.apache.kafka.common.serialization.StringSerializer $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression $tombstone
                          fi
                      fi
                  else
                      if [[ -n "$headers" ]]
                      then
                          if [[ -n "$verbose" ]]
                          then
                              log "🐞 CLI command used to produce data"
                              echo "cat /tmp/verbose_input_file.txt | docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS=\"$tool_log4j_jvm_arg\" -i $container kafka-$key_schema_type-console-producer $parameter_for_list_broker $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema.file=/tmp/value_schema_file --property parse.headers=true --property headers.delimiter=\"|\" --property headers.separator=\",\" --property headers.key.separator=\":\" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression $tombstone"
                          fi
                          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS="$tool_log4j_jvm_arg" -i $container kafka-$value_schema_type-console-producer $parameter_for_list_broker $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema.file="/tmp/value_schema_file" --property parse.headers=true --property headers.delimiter="|" --property headers.separator="," --property headers.key.separator=":" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression $tombstone
                      else
                          if [[ -n "$verbose" ]]
                          then
                              log "🐞 CLI command used to produce data"
                              echo "cat /tmp/verbose_input_file.txt | docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS=\"$tool_log4j_jvm_arg\" -i $container kafka-$value_schema_type-console-producer $parameter_for_list_broker $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema.file=/tmp/value_schema_file $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression $tombstone"
                          fi
                          head -n $nb_messages_to_send $output_final_file | awk -v counter=1 '{gsub("%g", counter); counter++; print}' | docker exec -e SCHEMA_REGISTRY_LOG4J_OPTS="$tool_log4j_jvm_arg" -i $container kafka-$value_schema_type-console-producer $parameter_for_list_broker $bootstrap_server --property schema.registry.url=$sr_url_cli --topic $topic $security --property value.schema.file="/tmp/value_schema_file" $force_schema_id $key_subject_name_strategy_property $value_subject_name_strategy_property $avro_use_logical_type_converters_property $producer_properties $compression $tombstone
                      fi
                  fi
              fi
          ;;
      esac
      # Increment the number of sent messages
      nb_messages_sent=$((nb_messages_sent + nb_messages_to_send))

      if [[ $sleep_time_between_batch -gt 0 ]]
      then
          sleep $sleep_time_between_batch
      fi
      if [ $nb_messages != -1 ] && [ $should_stop -eq 1 ]
      then
          stop=1
      fi
  done
  ELAPSED="took: $((($SECONDS / 60) % 60))min $(($SECONDS % 60))sec"
  log "📤 produced $nb_messages records to topic $topic, $ELAPSED"

  if [[ -n "$consume" ]]
  then
      log "📥 --consume is set, consuming topic $topic"
      playground topic consume --topic $topic
  fi
}

# :command.function
playground_topic_create_command() {

  # src/commands/topic/create.sh
  topic="${args[--topic]}"
  nb_partitions="${args[--nb-partitions]}"
  verbose="${args[--verbose]}"

  get_security_broker "--command-config"
  get_environment_used

  playground topic get-number-records --topic $topic > /tmp/result.log 2>/tmp/result.log
  set +e
  grep "does not exist" /tmp/result.log > /dev/null 2>&1
  if [ $? == 0 ]
  then
      set -e
      log "🆕 Creating topic $topic"
      if [[ "$environment" == "ccloud" ]]
      then
          get_kafka_docker_playground_dir
          DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

          if [ -f $DELTA_CONFIGS_ENV ]
          then
              source $DELTA_CONFIGS_ENV
          else
              logerror "❌ $DELTA_CONFIGS_ENV has not been generated"
              exit 1
          fi
          if [ ! -f $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta ]
          then
              logerror "❌ $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta has not been generated"
              exit 1
          fi
          if [[ -n "$verbose" ]]
          then
              log "🐞 CLI command used"
              echo "kafka-topics --create --topic $topic --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties --partitions $nb_partitions ${other_args[*]}"
          fi
          get_connect_image
          docker run --quiet --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-topics --create --topic $topic --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties --partitions $nb_partitions ${other_args[*]}
      else
          if [[ -n "$verbose" ]]
          then
              log "🐞 CLI command used"
              echo "kafka-topics --create --topic $topic --bootstrap-server $bootstrap_server --partitions $nb_partitions $security ${other_args[*]}"
          fi
          docker exec $container kafka-topics --create --topic $topic --bootstrap-server $bootstrap_server --partitions $nb_partitions $security ${other_args[*]}
      fi
  else
      logerror "❌ topic $topic already exist !"
      exit 1
  fi
}

# :command.function
playground_topic_delete_command() {

  # src/commands/topic/delete.sh
  topic="${args[--topic]}"
  verbose="${args[--verbose]}"
  skip_delete_schema="${args[--skip-delete-schema]}"

  get_security_broker "--command-config"
  get_environment_used

  # playground topic get-number-records --topic $topic > /tmp/result.log 2>/tmp/result.log
  # set +e
  # grep "does not exist" /tmp/result.log > /dev/null 2>&1
  # if [ $? == 0 ]
  # then
  #     log "❌ topic $topic does not exist !"
  #     exit 0
  # fi
  # set -e

  log "❌ Deleting topic $topic"
  if [[ "$environment" == "ccloud" ]]
  then
      get_kafka_docker_playground_dir
      DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

      if [ -f $DELTA_CONFIGS_ENV ]
      then
          source $DELTA_CONFIGS_ENV
      else
          logerror "❌ $DELTA_CONFIGS_ENV has not been generated"
          exit 1
      fi
      if [ ! -f $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta ]
      then
          logerror "❌ $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta has not been generated"
          exit 1
      fi
      if [[ -n "$verbose" ]]
      then
          log "🐞 CLI command used"
          echo "kafka-topics --delete --topic $topic --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties"
      fi
      get_connect_image
      docker run --quiet --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-topics --delete --topic $topic --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties
  else
      if [[ -n "$verbose" ]]
      then
          log "🐞 CLI command used"
          echo "kafka-topics --delete --topic $topic --bootstrap-server $bootstrap_server $security"
      fi
      docker exec $container kafka-topics --delete --topic $topic --bootstrap-server $bootstrap_server $security
  fi

  if [[ -n "$skip_delete_schema" ]]
  then
      log "🔰 Do not delete subject/schema as --skip-delete-schema is set"
  else
      set +e
      playground schema get --subject "$topic-key" > /dev/null 2>&1
      if [ $? -eq 0 ]
      then
          log "🔰 Delete subject $topic-key"
          playground schema delete --subject "$topic-key" --permanent
      fi

      playground schema get --subject "$topic-value" > /dev/null 2>&1
      if [ $? -eq 0 ]
      then
          log "🔰 Delete subject $topic-value"
          playground schema delete --subject "$topic-value" --permanent
      fi
  fi
}

# :command.function
playground_topic_alter_command() {

  # src/commands/topic/alter.sh
  topic="${args[--topic]}"

  get_security_broker "--command-config"
  get_environment_used

  playground topic get-number-records --topic $topic > /tmp/result.log 2>/tmp/result.log
  set +e
  grep "does not exist" /tmp/result.log > /dev/null 2>&1
  if [ $? == 0 ]
  then
      logwarn "🆕 topic $topic does not exist, creating it..."
      playground topic create --topic $topic

      playground topic alter --topic $topic ${other_args[*]}
  else
      log "🪛 Altering topic $topic"
      if [[ "$environment" == "ccloud" ]]
      then
          get_kafka_docker_playground_dir
          DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

          if [ -f $DELTA_CONFIGS_ENV ]
          then
              source $DELTA_CONFIGS_ENV
          else
              logerror "❌ $DELTA_CONFIGS_ENV has not been generated"
              exit 1
          fi
          if [ ! -f $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta ]
          then
              logerror "❌ $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta has not been generated"
              exit 1
          fi

          get_connect_image
          docker run --quiet --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-configs --alter --entity-type topics --entity-name $topic --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties ${other_args[*]}
      else
          docker exec $container kafka-configs --alter --entity-type topics --entity-name $topic --bootstrap-server $bootstrap_server $security ${other_args[*]}
      fi
  fi
  set -e

}

# :command.function
playground_connector_plugin_search_jar_command() {

  # src/commands/connector-plugin/search-jar.sh
  connector_plugin="${args[--connector-plugin]}"
  connector_tag="${args[--connector-tag]}"
  class="${args[--class]}"

  if [[ $connector_plugin == *"@"* ]]
  then
    connector_plugin=$(echo "$connector_plugin" | cut -d "@" -f 2)
  fi

  if [[ -n "$connector_tag" ]]
  then
      if [ "$connector_tag" == " " ]
      then
          ret=$(choose_connector_tag "$connector_plugin")
          connector_tag=$(echo "$ret" | cut -d ' ' -f 2 | sed 's/^v//')
      fi
  else
      connector_tag="latest"
  fi

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  get_connect_image
  log "🔌 Downloading connector plugin $connector_plugin:$connector_tag"
  docker run -u0 -i --rm -v $tmp_dir:/usr/share/confluent-hub-components ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} bash -c "confluent-hub install --no-prompt $connector_plugin:$connector_tag && chown -R $(id -u $USER):$(id -g $USER) /usr/share/confluent-hub-components" | grep "Downloading"

  log "🤎 Listing jar files"
  cd $tmp_dir/*/lib
  ls -1 | sort

  if [[ -n "$class" ]]
  then
    log "Searching for java class $class in all jars"
    find . -name '*.jar' -print | while read i;

    do

      set +e
      jar -tvf "$i" | grep -Hsi ${class} | awk '{print $10}' | sed 's/\.class$//' | tr '/' '.' | while read j
      do
        if [ $? -eq 0 ]
        then
          if [ "$j" != "" ]
          then
            log "👉 method signatures from $i jar for class $j"
            javap -classpath $i $j
          fi
        fi
      done
    done
  fi
}

# :command.function
playground_connector_plugin_versions_command() {

  # src/commands/connector-plugin/versions.sh
  connector_plugin="${args[--connector-plugin]}"
  last="${args[--last]}"
  force_refresh="${args[--force-refresh]}"

  if [[ $connector_plugin == *"@"* ]]
  then
    connector_plugin=$(echo "$connector_plugin" | cut -d "@" -f 2)
  fi

  owner=$(echo "$connector_plugin" | cut -d "/" -f 1)
  name=$(echo "$connector_plugin" | cut -d "/" -f 2)

  filename="/tmp/version_$owner_$name"
  if [[ -n "$force_refresh" ]]
  then
      if [ -f $filename ]
      then
          rm -f $filename
      fi
  fi

  if [[ -n "$last" ]]
  then
      if [ "$last" != "1" ]
      then
          log "💯 Listing last $last versions for connector plugin $connector_plugin"
      fi
  else
      log "💯 Listing all versions for connector plugin $connector_plugin"
  fi

  if [ ! -f $filename ]
  then
      curl_output=$(curl -s https://api.hub.confluent.io/api/plugins/$owner/$name/versions)
      ret=$?
      set -e
      if [ $ret -eq 0 ]
      then
          if ! echo "$curl_output" | jq -e .  > /dev/null 2>&1
          then
              set +e
              json_file=/tmp/json
              echo "$curl_output" > $json_file
              jq_output=$(jq . "$json_file" 2>&1)
              error_line=$(echo "$jq_output" | grep -oE 'parse error.*at line [0-9]+' | grep -oE '[0-9]+')

              if [[ -n "$error_line" ]]; then
                  logerror "❌ Invalid JSON at line $error_line"
              fi
              set -e

              if [ -z "$GITHUB_RUN_NUMBER" ]
              then
                  if [[ $(type -f bat 2>&1) =~ "not found" ]]
                  then
                      cat -n $json_file
                  else
                      bat $json_file --highlight-line $error_line
                  fi
              fi
              exit 1
          fi

          if [ "$curl_output" == "[]" ]
          then
              logwarn "❌ could not get versions for connector plugin $connector_plugin"
              exit 0
          fi

          if [[ "$(uname)" == "Darwin" ]]; then
              # macOS
              current_date=$(date -j -f "%Y-%m-%d" "$(date "+%Y-%m-%d")" "+%s")
          else
              # Linux
              current_date=$(date +%s)
          fi
          while IFS= read -r row; do
              IFS=$'\n'
              arr=($(echo "$row" | jq -r '.version, .manifest_url, .release_date'))
              version="${arr[0]}"
              manifest_url="${arr[1]}"
              release_date="${arr[2]}"
              if [ "$release_date" != "null" ]
              then
                  if [[ "$(uname)" == "Darwin" ]]; then
                      # macOS
                      release_date_sec=$(date -j -f "%Y-%m-%d" "$release_date" "+%s")
                  else
                      # Linux
                      release_date_sec=$(date -d "$release_date" "+%s")
                  fi

                  # Calculate the difference in days
                  diff=$(( (current_date - release_date_sec) / 60 / 60 / 24 ))
                  echo "🔢 v$version - 📅 release date: $release_date ($diff days ago)" >> $filename
              else
                  echo "🔢 v$version - 📅 release date: <unknown>" >> $filename
              fi
          done <<< "$(echo "$curl_output" | jq -c '.[]')"

          # documentation_url
          set +e
          curl_output=$(curl -s $manifest_url)
          ret=$?
          if [ $ret -eq 0 ]
          then
              documentation_url=$(echo "$curl_output" | jq -r '.documentation_url')
          fi
          set -e
          if [[ -n "$documentation_url" && "$documentation_url" != "null" ]]
          then
              echo "🌐 documentation: $documentation_url" >> $filename
          else
              echo "🌐 documentation: <not available>" >> $filename
          fi
      else
          logerror "❌ curl request failed with error code $ret!"
          exit 1
      fi

      if [ ! -f $filename ]
      then
          logerror "❌ could not get versions for connector plugin $connector_plugin"
          exit 1
      fi
  fi

  if [[ -n "$last" ]]
  then
      last=$((last + 1))
      tail -${last} $filename
  else
      cat $filename
  fi
}

# :command.function
playground_connector_plugin_display_last_updated_command() {

  # src/commands/connector-plugin/display-last-updated.sh
  days="${args[--days]}"
  vendor="${args[--vendor]}"

  if [ ! -f $root_folder/scripts/cli/confluent-hub-plugin-list.txt ]
  then
      log "file $root_folder/scripts/cli/confluent-hub-plugin-list.txt not found. Generating it now, it may take a while..."
      playground generate-connector-plugin-list
  fi

  if [ ! -f $root_folder/scripts/cli/confluent-hub-plugin-list.txt ]
  then
      logerror "file $root_folder/scripts/cli/confluent-hub-plugin-list.txt could not be generated"
      exit 1
  fi

  if [[ -n "$vendor" ]]
  then
      log "🆕 Listing last updated connector plugins (within $days days) for $vendor vendor"
  else
      log "🆕 Listing last updated connector plugins (within $days days) for all vendors"
  fi

  for plugin in $(cat $root_folder/scripts/cli/confluent-hub-plugin-list.txt | cut -d "|" -f 1)
  do
      if [[ -n "$vendor" && ! "$plugin" =~ $vendor ]]
      then
          continue
      fi
      if [[ "$vendor" == *"confluentinc"* ]] && [[ "$plugin" != *"-"* ]]
      then
          # fully managed connector, skipping
          continue
      fi
      output=$(playground connector-plugin versions --connector-plugin "$plugin" --force-refresh --last 1 | head -n 1)
      set +e
      if [[ -n "$days" ]]
      then
          last_updated=$(echo "$output" | grep -v "<unknown>" | cut -d "(" -f 2 | cut -d " " -f 1)
          if [[ -n "$last_updated" ]]
          then
              last_updated_days=$(echo $last_updated | tr -d '[:space:]')
              if [[ $last_updated_days -le $days ]]
              then
                  documentation_url=$(playground connector-plugin versions --connector-plugin "$plugin" --last 1 | tail -n 1)
                  echo "🔌 $plugin - $output - $documentation_url"
              fi
          fi
      fi
      set -e
  done
}

# :command.function
playground_connector_plugin_sourcecode_command() {

  # src/commands/connector-plugin/sourcecode.sh
  connector_plugin="${args[--connector-plugin]}"
  connector_tags="${args[--connector-tag]}"
  only_show_url="${args[--only-show-url]}"

  # Convert space-separated string to array
  IFS=' ' read -ra connector_tag_array <<< "$connector_tags"

  if [[ $connector_plugin == *"@"* ]]
  then
    connector_plugin=$(echo "$connector_plugin" | cut -d "@" -f 2)
  fi

  if [ ! -f $root_folder/scripts/cli/confluent-hub-plugin-list.txt ]
  then
      log "file $root_folder/scripts/cli/confluent-hub-plugin-list.txt not found. Generating it now, it may take a while..."
      playground generate-connector-plugin-list
  fi

  if [ ! -f $root_folder/scripts/cli/confluent-hub-plugin-list.txt ]
  then
      logerror "❌ file $root_folder/scripts/cli/confluent-hub-plugin-list.txt could not be generated"
      exit 1
  fi

  is_fully_managed=0
  if [[ "$connector_plugin" == *"confluentinc"* ]] && [[ "$connector_plugin" != *"-"* ]]
  then
      log "🌥️ connector was identified as fully managed connector"
      is_fully_managed=1
  fi

  set +e
  is_confluent_employee=0
  output=$(grep "CONFLUENT EMPLOYEE VERSION" $root_folder/scripts/cli/confluent-hub-plugin-list.txt)
  ret=$?
  if [ $ret -eq 0 ]
  then
      is_confluent_employee=1
  else
      logerror "❌ playground connector-plugin sourcecode is not working with fully managed connectors"
      logerror "❌ if you're a Confluent employee, make sure your aws creds are set and then run <playground generate-connector-plugin-list>"
      exit 1
  fi

  output=$(grep "^$connector_plugin|" $root_folder/scripts/cli/confluent-hub-plugin-list.txt)
  ret=$?
  set -e
  if [ $ret -ne 0 ]
  then
      logerror "❌ could not found $connector_plugin in $root_folder/scripts/cli/confluent-hub-plugin-list.txt"
      exit 1
  fi

  sourcecode_url=$(echo "$output" | cut -d "|" -f 2)
  if [ "$sourcecode_url" == "null" ] || [ "$sourcecode_url" == "" ]
  then
      logerror "❌ could not found sourcecode url for plugin $connector_plugin. It is probably proprietary"
      if [[ "$sourcecode_url" == *"confluentinc"* ]]
      then
          if [ $is_confluent_employee -eq 1 ]
          then
              logerror "❌ if you're a Confluent employee, make sure your aws creds are set and then run <playground generate-connector-plugin-list>"
              exit 1
          fi
      fi
      exit 1
  fi

  if [ $is_confluent_employee -eq 1 ] || [ $is_fully_managed -eq 1 ]
  then
      connector_name_cache_versions=$(echo "$output" | cut -d "|" -f 3)
  fi

  function get_latest_version_from_cc_docker_connect_cache_versions_env () {
      tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
      if [ -z "$PG_VERBOSE_MODE" ]
      then
          trap 'rm -rf $tmp_dir' EXIT
      else
          log "🐛📂 not deleting tmp dir $tmp_dir"
      fi
      # confluent only
      cd $tmp_dir > /dev/null
      get_3rdparty_file "cache-versions.env" > /dev/null
      cd - > /dev/null
      if [ -f $tmp_dir/cache-versions.env ]
      then
          last_version=$(grep "$connector_name_cache_versions" $tmp_dir/cache-versions.env  | cut -d "=" -f 2)
          if [ $ret -eq 0 ]
          then
              log "✨ --connector-tag was not set, using latest version on cc-docker-connect (cache-versions.env file https://github.com/confluentinc/cc-docker-connect/blob/master/cc-connect/cache-versions.env) which is $last_version"
              connector_tag="$last_version"
          else
              logerror "❌ could not find $connector_name_cache_versions in $tmp_dir/cache-versions.env"
              exit 1
          fi
      else
          logerror "❌ file cache-versions.env could not be downloaded from s3 bucket"
          exit 1
      fi
  }

  function get_latest_version_from_confluent_hub () {
      output=$(playground connector-plugin versions --connector-plugin "$connector_plugin" --last 1 | head -n 1)
      last_version=$(echo "$output" | grep -v "<unknown>" | cut -d " " -f 2 | cut -d "v" -f 2)
      if [[ -n "$last_version" ]]
      then
          log "✨ --connector-tag was not set, using latest version on hub $last_version"
          connector_tag="$last_version"
      else
          logwarn "could not find latest version using <playground connector-plugin versions --connector-plugin \"$connector_plugin\" --last 1>"
          logerror "❌ --connector-tag flag is set 2 times, but one of them is set to latest. Comparison between version can only works when providing versions"
          exit 1
      fi
  }

  comparison_mode_versions=""
  length=${#connector_tag_array[@]}
  if ((length > 1))
  then
      if ((length > 2))
      then
          logerror "❌ --connector-tag can only be set 2 times"
          exit 1
      fi
      if [[ "$sourcecode_url" != *"github.com"* ]]
      then
          logerror "❌ --connector-tag flag is set 2 times, but sourcecode is not hosted on github, comparison between version can only works with github"
          exit 1
      fi
      connector_tag1="${connector_tag_array[0]}"
      connector_tag2="${connector_tag_array[1]}"

      if [ "$connector_tag1" == "latest" ]
      then
          if [ $is_fully_managed -eq 1 ]
          then
              get_latest_version_from_cc_docker_connect_cache_versions_env
              connector_tag1=$connector_tag
          else
              get_latest_version_from_confluent_hub
              connector_tag1=$connector_tag
          fi
      fi
      if [ "$connector_tag2" == "latest" ]
      then
          if [ $is_fully_managed -eq 1 ]
          then
              get_latest_version_from_cc_docker_connect_cache_versions_env
              connector_tag2=$connector_tag
          else
              get_latest_version_from_confluent_hub
              connector_tag2=$connector_tag
          fi
      fi

      if [ "$connector_tag1" == "\\" ]
      then
          if [ $is_fully_managed -eq 1 ]
          then
              logerror "❌ --connector-tag set with \" \" cannot work when using fully managed connector plugin"
              exit 1
          fi
          ret=$(choose_connector_tag "$connector_plugin")
          connector_tag1=$(echo "$ret" | cut -d ' ' -f 2 | sed 's/^v//')
      fi

      if [ "$connector_tag2" == "\\" ]
      then
          if [ $is_fully_managed -eq 1 ]
          then
              logerror "❌ --connector-tag set with \" \" cannot work when using fully managed connector plugin"
              exit 1
          fi
          ret=$(choose_connector_tag "$connector_plugin")
          connector_tag2=$(echo "$ret" | cut -d ' ' -f 2 | sed 's/^v//')
      fi
      log "✨ --connector-tag flag is set 2 times, comparison mode will be opened with versions v$connector_tag1 and v$connector_tag2"
      comparison_mode_versions="v$connector_tag1...v$connector_tag2"
  else
      connector_tag="${connector_tag_array[0]}"
      if [[ -n "$connector_tag" ]]
      then
          if [ "$connector_tag" == "\\" ]
          then
              if [ $is_fully_managed -eq 1 ]
              then
                  logerror "❌ --connector-tag set with \" \" cannot work when using fully managed connector plugin"
                  exit 1
              fi
              ret=$(choose_connector_tag "$connector_plugin")
              connector_tag=$(echo "$ret" | cut -d ' ' -f 2 | sed 's/^v//')
          fi
      else
          if [ $is_fully_managed -eq 0 ]
          then
              output=$(playground connector-plugin versions --connector-plugin "$connector_plugin" --last 1 | head -n 1)
              last_version=$(echo "$output" | grep -v "<unknown>" | cut -d " " -f 2 | cut -d "v" -f 2)
              if [[ -n "$last_version" ]]
              then
                  log "✨ --connector-tag was not set, using latest version on hub $last_version"
                  connector_tag="$last_version"
              else
                  logwarn "could not find latest version using <playground connector-plugin versions --connector-plugin \"$connector_plugin\" --last 1>, using latest"
                  connector_tag="latest"
              fi
          else
              get_latest_version_from_cc_docker_connect_cache_versions_env
          fi
      fi
  fi

  if [ "$comparison_mode_versions" != "" ]
  then
      additional_text=", comparing v$connector_tag1 and v$connector_tag2"
      sourcecode_url="$sourcecode_url/compare/$comparison_mode_versions"
  else
      additional_text=" for $connector_tag version"
      if [ "$connector_tag" != "latest" ] && [[ "$sourcecode_url" == *"github.com"* ]]
      then
          sourcecode_url="$sourcecode_url/tree/v$connector_tag"
      fi
  fi

  if [[ -n "$only_show_url" ]] || [[ $(type -f open 2>&1) =~ "not found" ]]
  then
      log "🧑‍💻🌐 sourcecode for plugin $connector_plugin$additional_text is available at:"
      echo "$sourcecode_url"
  else
      log "🧑‍💻 Opening sourcecode url $sourcecode_url for plugin $connector_plugin in browser$additional_text"
      open "$sourcecode_url"
  fi
}

# :command.function
playground_connector_status_command() {

  # src/commands/connector/status.sh
  connector="${args[--connector]}"
  verbose="${args[--verbose]}"

  connector_type=$(playground state get run.connector_type)

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      set +e
      maybe_id=""
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          get_ccloud_connect
          handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/status\" --header \"authorization: Basic $authorization\""
          connectorId=$(get_ccloud_connector_lcc $connector)
          maybe_id=" ($connectorId)"

          log "🧩 Displaying status for $connector_type connector $connector${maybe_id}"

          printf "%-30s %-12s %-60s %-50s\n" "Name" "Status" "Tasks" "Stack Trace"
          echo "-------------------------------------------------------------------------------------------------------------"
          status=$(echo "$curl_output" | jq -r '.connector.state')

          if [ "$status" == "RUNNING" ]
          then
              status="✅ RUNNING"
          elif [ "$status" == "PAUSED" ]
          then
              status="⏸️  PAUSED"
          elif [ "$status" == "FAILED" ]
          then
              status="❌ FAILED"
          elif [ "$status" == "STOPPED" ]
          then
              status="🛑 STOPPED"
          elif [ "$status" == "PROVISIONING" ]
          then
              status="🏭 PROVISIONING"
          else
              status="🤔 UNKNOWN"
          fi

          tasks=$(echo "$curl_output" | jq -r '.tasks[] | "\(.id):\(.state)"' | tr '\n' ',' | sed 's/,$/\n/')

          if [[ "$tasks" == *"RUNNING"* ]]
          then
              tasks="${tasks//RUNNING/🟢 RUNNING}"
          elif [[ "$tasks" == *"PAUSED"* ]]
          then
              tasks="${tasks//PAUSED/⏸️  PAUSED}"
          elif [[ "$tasks" == *"STOPPED"* ]]
          then
              tasks="${tasks//STOPPED/🛑  STOPPED}"
          elif [[ "$tasks" == *"FAILED"* ]]
          then
              tasks="${tasks//FAILED/🛑 FAILED}"
          elif [[ "$tasks" == *"USER_ACTIONABLE_ERROR"* ]]
          then
              tasks="${tasks//USER_ACTIONABLE_ERROR/💪 USER_ACTIONABLE_ERROR}"
          else
              tasks="🤔 N/A"
          fi

          stacktrace_connector=$(echo "$curl_output" | jq -r '.connector.trace | select(length > 0)')
          errors_from_trace=$(echo "$curl_output" | jq -r '.errors_from_trace[0].error | select(length > 0)')
          validation_errors=$(echo "$curl_output" | jq -r '.validation_errors[0] | select(length > 0)')
          stacktrace=""
          if [ "$stacktrace_connector" != "" ]
          then
              stacktrace="connector: $stacktrace_connector"
          fi

          if [ "$errors_from_trace" != "" ]
          then
              stacktrace="$stacktrace errors_from_trace: $errors_from_trace"
          fi

          if [ "$validation_errors" != "" ]
          then
              stacktrace="$stacktrace validation_errors: $validation_errors"
          fi

          if [ -z "$stacktrace" ]
          then
              stacktrace="-"
          fi

          printf "%-30s %-12s %-30s %-50s\n" "$connector" "$status" "$tasks" "$stacktrace"
          echo "-------------------------------------------------------------------------------------------------------------"
      else
          log "🧩 Displaying status for $connector_type connector $connector"
          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl -s $security \"$connect_url/connectors/$connector/status\""

          printf "%-30s %-12s %-60s %-50s\n" "Name" "Status" "Tasks" "Stack Trace"
          echo "-------------------------------------------------------------------------------------------------------------"
          status=$(echo "$curl_output" | jq -r '.connector.state')

          if [ "$status" == "RUNNING" ]
          then
              status="✅ RUNNING"
          elif [ "$status" == "PAUSED" ]
          then
              status="⏸️  PAUSED"
          elif [ "$status" == "FAILED" ]
          then
              status="❌ FAILED"
          elif [ "$status" == "STOPPED" ]
          then
              status="🛑 STOPPED"
          else
              status="🤔 UNKNOWN"
          fi

          tasks=$(echo "$curl_output" | jq -r '.tasks[] | "\(.id):\(.state)[\(.worker_id)]"' | tr '\n' ',' | sed 's/,$/\n/' | sed 's/:8083//g' | sed 's/:8283//g' | sed 's/:8383//g')

          if [[ "$tasks" == *"RUNNING"* ]]
          then
              tasks="${tasks//RUNNING/🟢 RUNNING}"
          elif [[ "$tasks" == *"PAUSED"* ]]
          then
              tasks="${tasks//PAUSED/⏸️  PAUSED}"
          elif [[ "$tasks" == *"STOPPED"* ]]
          then
              tasks="${tasks//STOPPED/🛑  STOPPED}"
          elif [[ "$tasks" == *"FAILED"* ]]
          then
              tasks="${tasks//FAILED/🛑 FAILED}"
          else
              tasks="🤔 N/A"
          fi

          stacktrace_connector=$(echo "$curl_output" | jq -r '.connector.trace | select(length > 0)')
          stacktrace_tasks=$(echo "$curl_output" | jq -r '.tasks[].trace | select(length > 0)')
          stacktrace=""
          if [ "$stacktrace_connector" != "" ]
          then
              stacktrace="connector: $stacktrace_connector"
          fi

          if [ "$stacktrace_tasks" != "" ]
          then
              stacktrace="$stacktrace tasks: $stacktrace_tasks"
          fi

          if [ -z "$stacktrace" ]
          then
              stacktrace="-"
          fi

          printf "%-30s %-12s %-30s %-50s\n" "$connector" "$status" "$tasks" "$stacktrace"
          echo "-------------------------------------------------------------------------------------------------------------"
      fi
      set -e
  done
}

# :command.function
playground_connector_oracle_cdc_xstream_generate_report_command() {

  # src/commands/connector/oracle-cdc-xstream/generate-report.sh
  log "⚙️ Generate and open oracle cdc xstream connector diagnostics"
  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  cd $tmp_dir
  if [ ! -f orclcdc_diag.sql ]
  then
      wget -q https://docs.confluent.io/kafka-connectors/oracle-xstream-cdc-source/current/_downloads/6d672a473a3153a88f9c67de5e0b558f/orclcdc_diag.sql
  fi
  docker cp orclcdc_diag.sql oracle:/orclcdc_diag.sql > /dev/null 2>&1
  docker exec -i oracle bash -c "ORACLE_SID=ORCLCDB;export ORACLE_SID;sqlplus /nolog" << EOF
     CONNECT sys/Admin123 AS SYSDBA
     @/orclcdc_diag.sql C##CFLTADMIN C##CFLTUSER XOUT ''
END;
/
EOF
  playground container exec --container oracle --command "mv /home/oracle/orclcdc_diag_*.html /home/oracle/orclcdc_diag.html"
  docker cp oracle:/home/oracle/orclcdc_diag.html /tmp/ > /dev/null 2>&1
  if [ -f /tmp/orclcdc_diag.html ]
  then
      log "⚙️ oracle cdc xstream connector diagnostics report is available at /tmp/orclcdc_diag.html"
      if [[ $(type -f open 2>&1) =~ "not found" ]]
      then
          :
      else
          open "/tmp/orclcdc_diag.html"
      fi
  else
      logwarn "❌ oracle cdc xstream connector diagnostics report is not available"
  fi
}

# :command.function
playground_connector_oracle_cdc_xstream_debug_command() {

  # src/commands/connector/oracle-cdc-xstream/debug.sh
  log "Monitoring session information about XStream Out components"

  docker exec -i oracle bash -c "ORACLE_SID=ORCLCDB;export ORACLE_SID;sqlplus /nolog" << EOF
    CONNECT sys/Admin123 AS SYSDBA
    SELECT
    action "XStream Component",
    sid, SERIAL#,
    process "OS Process ID",
    SUBSTR(program,INSTR(program,'(')+1,4) "Component Name"
    FROM V\$SESSION
    WHERE module ='XStream';
EOF

  log "View the status of each capture process"
  docker exec -i oracle bash -c "ORACLE_SID=ORCLCDB;export ORACLE_SID;sqlplus /nolog" << EOF
    CONNECT sys/Admin123 AS SYSDBA
    SELECT
    state,
    total_messages_captured,
    total_messages_enqueued
    FROM V\$XSTREAM_CAPTURE;
EOF

  log "View the SCN values of each capture process"
  docker exec -i oracle bash -c "ORACLE_SID=ORCLCDB;export ORACLE_SID;sqlplus /nolog" << EOF
    CONNECT sys/Admin123 AS SYSDBA
    SELECT
    start_scn,captured_scn,
    last_enqueued_scn,required_checkpoint_scn
    FROM ALL_CAPTURE;
EOF

  log "View the latencies of each capture process"
  docker exec -i oracle bash -c "ORACLE_SID=ORCLCDB;export ORACLE_SID;sqlplus /nolog" << EOF
    CONNECT sys/Admin123 AS SYSDBA
    SELECT
    (capture_time - capture_message_create_time) * 86400 "Capture Latency Seconds",
    (enqueue_time - enqueue_message_create_time) * 86400 "Enqueue Latency Seconds"
    FROM V\$XSTREAM_CAPTURE;
EOF

  log "View redo log files required by each capture process"
  docker exec -i oracle bash -c "ORACLE_SID=ORCLCDB;export ORACLE_SID;sqlplus /nolog" << EOF
    CONNECT sys/Admin123 AS SYSDBA
    SELECT
    r.consumer_name "Capture Process Name",
    r.source_database "Source Database",
    r.sequence# "Sequence Number",
    r.name "Archived Redo Log File Name"
    FROM DBA_REGISTERED_ARCHIVED_LOG r,
    ALL_CAPTURE c
    WHERE r.consumer_name = c.capture_name AND
    r.next_scn >= c.required_checkpoint_scn;
EOF

  log 'Important Views'
  log 'V$XSTREAM_CAPTURE - displays information about each capture process that sends LCRs to an XStream outbound server (https://docs.oracle.com/en/database/oracle/oracle-database/19/refrn/V-XSTREAM_CAPTURE.html)'
  log 'ALL_CAPTURE - displays information about the capture processes that enqueue the captured changes into queues accessible to the current user (https://docs.oracle.com/en/database/oracle/oracle-database/19/refrn/ALL_CAPTURE.html).'

  log "View general information about outbound server"
  docker exec -i oracle bash -c "ORACLE_SID=ORCLCDB;export ORACLE_SID;sqlplus /nolog" << EOF
    CONNECT sys/Admin123 AS SYSDBA
    SELECT
    server_name "Outbound Server Name",
    capture_name "Capture Process Name",
    connect_user, capture_user,
    queue_owner, queue_name
    FROM ALL_XSTREAM_OUTBOUND;
EOF

  log "View information on outbound server current transaction"
  docker exec -i oracle bash -c "ORACLE_SID=ORCLCDB;export ORACLE_SID;sqlplus /nolog" << EOF
    CONNECT sys/Admin123 AS SYSDBA
    SELECT
    xidusn ||'.'|| xidslt ||'.'|| xidsqn "Transaction ID",
    commitscn, commit_position,
    last_sent_position,
    message_sequence
    FROM V\$XSTREAM_OUTBOUND_SERVER;
EOF

  log "View processed low position for an outbound server"
  docker exec -i oracle bash -c "ORACLE_SID=ORCLCDB;export ORACLE_SID;sqlplus /nolog" << EOF
    CONNECT sys/Admin123 AS SYSDBA
    SELECT
    processed_low_position,
    TO_CHAR(processed_low_time,'HH24:MI:SS MM/DD/YY') processed_low_time
    FROM ALL_XSTREAM_OUTBOUND_PROGRESS;
EOF

  log 'Important Views'
  log 'V$XSTREAM_OUTBOUND_SERVER - displays statistics about an outbound server (https://docs.oracle.com/en/database/oracle/oracle-database/19/refrn/V-XSTREAM_OUTBOUND_SERVER.html)'
  log 'ALL_XSTREAM_OUTBOUND - displays information about the XStream outbound servers (https://docs.oracle.com/en/database/oracle/oracle-database/19/refrn/ALL_XSTREAM_OUTBOUND.html)'
  log 'ALL_XSTREAM_OUTBOUND_PROGRESS - displays information about the progress made by the XStream outbound servers (https://docs.oracle.com/en/database/oracle/oracle-database/19/refrn/ALL_XSTREAM_OUTBOUND_PROGRESS.html)'

  log "View capture parameter settings"
  docker exec -i oracle bash -c "ORACLE_SID=ORCLCDB;export ORACLE_SID;sqlplus /nolog" << EOF
    CONNECT sys/Admin123 AS SYSDBA
    SELECT
    c.capture_name,
    parameter, value,
    set_by_user
    FROM ALL_CAPTURE_PARAMETERS c,
    ALL_XSTREAM_OUTBOUND o
    WHERE c.capture_name = o.capture_name
    ORDER BY parameter;
EOF

  log "View apply (outbound server) parameter settings"
  docker exec -i oracle bash -c "ORACLE_SID=ORCLCDB;export ORACLE_SID;sqlplus /nolog" << EOF
    CONNECT sys/Admin123 AS SYSDBA
    SELECT
    c.capture_name,
    parameter, value,
    set_by_user
    FROM ALL_CAPTURE_PARAMETERS c,
    ALL_XSTREAM_OUTBOUND o
    WHERE c.capture_name = o.capture_name

    ORDER BY parameter;
EOF

  log "View the rules used by XStream components"
  docker exec -i oracle bash -c "ORACLE_SID=ORCLCDB;export ORACLE_SID;sqlplus /nolog" << EOF
    CONNECT sys/Admin123 AS SYSDBA
    SELECT
    streams_name "XStream Component Name",
    streams_type "XStream Component Type",
    rule_name,
    rule_set_type,
    streams_rule_type,
    schema_name,
    object_name,
    rule_type
    FROM ALL_XSTREAM_RULES;
EOF
}

# :command.function
playground_connector_offsets_get_command() {

  # src/commands/connector/offsets/get.sh
  connector="${args[--connector]}"
  verbose="${args[--verbose]}"

  connector_type=$(playground state get run.connector_type)
  get_environment_used

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ] || [ "$environment" == "ccloud" ]
  then
    get_ccloud_connect
    get_kafka_docker_playground_dir
    DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

    if [ -f $DELTA_CONFIGS_ENV ]
    then
        source $DELTA_CONFIGS_ENV
    else
        logerror "❌ $DELTA_CONFIGS_ENV has not been generated"
        exit 1
    fi
    if [ ! -f $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta ]
    then
        logerror "❌ $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta has not been generated"
        exit 1
    fi
  else
    get_security_broker "--command-config"
  fi

  if [ "$connector_type" != "$CONNECTOR_TYPE_FULLY_MANAGED" ] && [ "$connector_type" != "$CONNECTOR_TYPE_CUSTOM" ]
  then
      tag=$(docker ps --format '{{.Image}}' | grep -E 'confluentinc/cp-.*-connect-.*:' | awk -F':' '{print $2}')
      if [ $? != 0 ] || [ "$tag" == "" ]
      then
          logerror "❌ could not find current CP version from docker ps"
          exit 1
      fi
  fi

  function handle_first_class_offset() {
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          get_ccloud_connect
          handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/offsets\" --header \"authorization: Basic $authorization\""
      else
          if ! version_gt $tag "7.4.99"
          then
              logerror "❌ command is available since CP 7.5 only"
              return
          fi

          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl $security -s -X GET \"$connect_url/connectors/$connector/offsets\""
      fi

      echo "$curl_output" | jq .
  }
  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      maybe_id=""
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          get_ccloud_connect
          handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/status\" --header \"authorization: Basic $authorization\""
          connectorId=$(get_ccloud_connector_lcc $connector)
          maybe_id=" ($connectorId)"
      else
          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl -s $security \"$connect_url/connectors/$connector/status\""
      fi
      log "🏹 Getting offsets for $connector_type $type connector $connector${maybe_id}"
      type=$(echo "$curl_output" | jq -r '.type')
      if [ "$type" == "source" ]
      then
          # SOURCE CONNECTOR
          handle_first_class_offset
          if [ $? != 0 ]
          then
              continue
          fi
      else
          # SINK CONNECTOR
          if [[ -n "$verbose" ]]
          then
              log "🐞 CLI command used"
              echo "kafka-consumer-groups --bootstrap-server $bootstrap_server --group connect-$connector --describe $security"
          fi
          get_environment_used
          if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ] || [[ "$environment" == "ccloud" ]]
          then
              handle_first_class_offset

          else
              if version_gt $tag "7.5.99"
              then
                  handle_first_class_offset
                  if [ $? != 0 ]
                  then
                      continue
                  fi
              else
                  docker exec $container kafka-consumer-groups --bootstrap-server $bootstrap_server --group connect-$connector --describe $security

              fi
          fi
      fi
  done
}

# :command.function
playground_connector_offsets_reset_command() {

  # src/commands/connector/offsets/reset.sh
  connector="${args[--connector]}"
  verbose="${args[--verbose]}"

  connector_type=$(playground state get run.connector_type)

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ] || [ "$environment" == "ccloud" ]
  then
    get_ccloud_connect
    get_kafka_docker_playground_dir
    DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

    if [ -f $DELTA_CONFIGS_ENV ]
    then
        source $DELTA_CONFIGS_ENV
    else
        logerror "❌ $DELTA_CONFIGS_ENV has not been generated"
        exit 1
    fi
    if [ ! -f $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta ]
    then
        logerror "❌ $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta has not been generated"
        exit 1
    fi
  else
    get_security_broker "--command-config"
  fi

  if [ "$connector_type" != "$CONNECTOR_TYPE_FULLY_MANAGED" ] && [ "$connector_type" != "$CONNECTOR_TYPE_CUSTOM" ]
  then
      tag=$(docker ps --format '{{.Image}}' | grep -E 'confluentinc/cp-.*-connect-.*:' | awk -F':' '{print $2}')
      if [ $? != 0 ] || [ "$tag" == "" ]
      then
          logerror "❌ could not find current CP version from docker ps"
          exit 1
      fi
  fi

  function handle_first_class_offset() {
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then

          echo '{"type":"DELETE"}' > /tmp/delete.json
          get_ccloud_connect
          handle_ccloud_connect_rest_api "curl -s --request POST -H \"Content-Type: application/json\" --data @/tmp/delete.json \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/offsets/request\" --header \"authorization: Basic $authorization\""
      else
          if ! version_gt $tag "7.5.99"; then
              logerror "❌ command is available since CP 7.6 only"
              return
          fi
          playground connector stop --connector $connector

          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl $security -s -X DELETE \"$connect_url/connectors/$connector/offsets\""

          echo "$curl_output" | jq .

          playground connector resume --connector $connector
      fi
  }

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      maybe_id=""
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          get_ccloud_connect
          handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/status\" --header \"authorization: Basic $authorization\""
          connectorId=$(get_ccloud_connector_lcc $connector)
          maybe_id=" ($connectorId)"
      else
          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl -s $security \"$connect_url/connectors/$connector/status\""
      fi
      log "🆕 Resetting offsets for $connector_type connector $connector"
      type=$(echo "$curl_output" | jq -r '.type')
      if [ "$type" == "source" ]
      then
          # SOURCE CONNECTOR
          handle_first_class_offset
          if [ $? != 0 ]
          then
              continue
          fi
          sleep 5
          playground connector offsets get-offsets-request-status --connector $connector
          sleep 20
          playground connector offsets get --connector $connector
      else
          if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
          then
              handle_first_class_offset
              if [ $? != 0 ]
              then
                  continue
              fi
              sleep 5
              playground connector offsets get-offsets-request-status --connector $connector
              sleep 20
              playground connector offsets get --connector $connector
              exit 0
          fi

          if version_gt $tag "7.5.99"
          then
              handle_first_class_offset
              if [ $? != 0 ]
              then
                  continue
              fi
              playground connector offsets get --connector $connector
          else
              docker exec $container kafka-consumer-groups --bootstrap-server $bootstrap_server --group connect-$connector --describe $security | grep -v PARTITION

              if version_gt $tag "7.4.99"
              then
                  playground connector stop --connector $connector
              else
                  playground --output-level ERROR connector show-config --connector $connector > "$tmp_dir/create-$connector-config.sh"
                  playground connector delete --connector $connector
              fi

              docker exec $container kafka-consumer-groups --bootstrap-server $bootstrap_server --group connect-$connector $security --to-earliest --reset-offsets --all-topics --execute

              if version_gt $tag "7.4.99"
              then
                  playground connector resume --connector $connector
              else
                  bash "$tmp_dir/create-$connector-config.sh"
              fi
              playground connector offsets get --connector $connector
          fi
      fi
  done
}

# :command.function
playground_connector_offsets_alter_command() {

  # src/commands/connector/offsets/alter.sh
  connector="${args[--connector]}"
  verbose="${args[--verbose]}"

  connector_type=$(playground state get run.connector_type)
  get_environment_used

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ] || [ "$environment" == "ccloud" ]
  then
    get_ccloud_connect
    get_kafka_docker_playground_dir
    DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

    if [ -f $DELTA_CONFIGS_ENV ]
    then
        source $DELTA_CONFIGS_ENV
    else
        logerror "❌ $DELTA_CONFIGS_ENV has not been generated"
        exit 1
    fi
    if [ ! -f $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta ]
    then
        logerror "❌ $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta has not been generated"
        exit 1
    fi
  else
    get_security_broker "--command-config"
  fi

  if [ "$connector_type" != "$CONNECTOR_TYPE_FULLY_MANAGED" ] && [ "$connector_type" != "$CONNECTOR_TYPE_CUSTOM" ]
  then
      tag=$(docker ps --format '{{.Image}}' | grep -E 'confluentinc/cp-.*-connect-.*:' | awk -F':' '{print $2}')
      if [ $? != 0 ] || [ "$tag" == "" ]
      then
          logerror "❌ could not find current CP version from docker ps"
          exit 1
      fi
  fi

  function handle_first_class_offset() {
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then

          file=$tmp_dir/offsets-$connector.json
          file_tmp=$tmp_dir/tmp.json

          playground --output-level ERROR connector offsets get --connector $connector > $file

          # add mandatory name field
          new_json_content=$(cat $file | jq ". + {\"type\": \"PATCH\"}")
          echo "$new_json_content" > $file

          jq 'del(.id)' $file > $file_tmp
          cp $file_tmp $file
          jq 'del(.name)' $file > $file_tmp
          cp $file_tmp $file
          jq 'del(.metadata)' $file > $file_tmp
          cp $file_tmp $file

          log "✨ Update the connector offsets as per your needs, save and close the file to continue"
          playground open --file "${file}" --wait

          handle_ccloud_connect_rest_api "curl -s --request POST -H \"Content-Type: application/json\" --data @$file \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/offsets/request\" --header \"authorization: Basic $authorization\""
      else
          if ! version_gt $tag "7.5.99"; then
              logerror "❌ command is available since CP 7.6 only"
              return
          fi

          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl $security -s -X GET \"$connect_url/connectors/$connector/offsets\""

          file=$tmp_dir/offsets-$connector.json
          echo "$curl_output" | jq . > $file

          log "✨ Update the connector offsets as per your needs, save and close the file to continue"
          playground open --file "${file}" --wait

          playground connector stop --connector $connector

          handle_onprem_connect_rest_api "curl $security -s -X PATCH -H \"Content-Type: application/json\" --data @$file \"$connect_url/connectors/$connector/offsets\""

          echo "$curl_output" | jq .

          playground connector resume --connector $connector
      fi
  }

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      maybe_id=""
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          get_ccloud_connect
          handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/status\" --header \"authorization: Basic $authorization\""
          connectorId=$(get_ccloud_connector_lcc $connector)
          maybe_id=" ($connectorId)"
      else
          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl -s $security \"$connect_url/connectors/$connector/status\""
      fi

      type=$(echo "$curl_output" | jq -r '.type')
      log "⛏️ Altering offsets for $connector_type connector $connector${maybe_id}"

      if [ "$type" == "source" ]
      then
          # SOURCE CONNECTOR
          handle_first_class_offset
          if [ $? != 0 ]
          then
              continue
          fi
          sleep 5
          playground connector offsets get-offsets-request-status --connector $connector
          sleep 20
          playground connector offsets get --connector $connector
      else
          # SINK CONNECTOR
          if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
          then
              handle_first_class_offset
              if [ $? != 0 ]
              then
                  continue
              fi
              sleep 5
              playground connector offsets get-offsets-request-status --connector $connector
              sleep 20
              playground connector offsets get --connector $connector
          else
              if version_gt $tag "7.5.99"
              then
                  handle_first_class_offset
                  if [ $? != 0 ]
                  then
                      continue
                  fi
                  playground connector offsets get --connector $connector
              else
                  # if [[ -n "$verbose" ]]
                  # then
                  #     log "🐞 CLI command used"
                  #     echo "kafka-consumer-groups --bootstrap-server $bootstrap_server --group connect-$connector --describe $security"
                  # fi
                  get_environment_used
                  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ] || [[ "$environment" == "ccloud" ]]
                  then
                      logwarn "command is not available with $connector_type $type connector"
                      continue
                  else
                      file=$tmp_dir/offsets-$connector.csv

                      if version_gt $tag "7.4.99"
                      then
                          playground connector stop --connector $connector
                      else
                          playground --output-level ERROR connector show-config --connector $connector > "$tmp_dir/create-$connector-config.sh"
                          playground connector delete --connector $connector
                      fi

                      echo "topic,partition,current-offset" > $file
                      docker exec $container kafka-consumer-groups --bootstrap-server $bootstrap_server --group connect-$connector $security --export --reset-offsets --to-current --all-topics --dry-run >> $file

                      log "✨ Update the connector offsets as per your needs, save and close the file to continue"
                      playground open --file "${file}" --wait

                      # remove any empty lines and header
                      grep -v '^$' "$file" > $tmp_dir/tmp && mv $tmp_dir/tmp "$file"
                      grep -v 'current-offset' "$file" > $tmp_dir/tmp && mv $tmp_dir/tmp "$file"

                      docker cp $file $container:/tmp/offsets.csv > /dev/null 2>&1
                      docker exec $container kafka-consumer-groups --bootstrap-server $bootstrap_server --group connect-$connector $security --reset-offsets --from-file /tmp/offsets.csv --execute

                      if version_gt $tag "7.4.99"
                      then
                          playground connector resume --connector $connector
                      else
                          bash "$tmp_dir/create-$connector-config.sh"
                      fi
                  fi
                  playground connector offsets get --connector $connector
              fi
          fi
      fi
  done
}

# :command.function
playground_connector_offsets_get_offsets_request_status_command() {

  # src/commands/connector/offsets/get-offsets-request-status.sh
  connector="${args[--connector]}"
  verbose="${args[--verbose]}"

  connector_type=$(playground state get run.connector_type)

  if [ "$connector_type" != "$CONNECTOR_TYPE_FULLY_MANAGED" ] && [ "$connector_type" != "$CONNECTOR_TYPE_CUSTOM" ]
  then
      log "connector offset get-offsets-request-status command is not supported with $connector_type connector"
      exit 0
  fi

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
    get_ccloud_connect
    get_kafka_docker_playground_dir
    DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

    if [ -f $DELTA_CONFIGS_ENV ]
    then
        source $DELTA_CONFIGS_ENV
    else
        logerror "❌ $DELTA_CONFIGS_ENV has not been generated"
        exit 1
    fi
    if [ ! -f $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta ]
    then
        logerror "❌ $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta has not been generated"
        exit 1
    fi
  fi

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      maybe_id=""
      connectorId=$(get_ccloud_connector_lcc $connector)
      maybe_id=" ($connectorId)"
      log "👁️‍🗨️ Getting status of the previous offset request for $connector_type connector $connector${maybe_id}"
      get_ccloud_connect
      handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/offsets/request/status\" --header \"authorization: Basic $authorization\""
      echo "$curl_output" | jq .
  done
}

# :command.function
playground_connector_plugins_command() {

  # src/commands/connector/plugins.sh
  all="${args[--all]}"
  verbose="${args[--verbose]}"

  connector_type=$(playground state get run.connector_type)

  log "🎨 Displaying all connector plugins installed"
  if [[ -n "$all" ]]
  then
      log "🌕 Displaying also transforms, converters, predicates available"
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          logerror "❌ --all is set but not supported with $connector_type connector"
          exit 1
      else
          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl $security -s -X GET -H \"Content-Type: application/json\" \"$connect_url/connector-plugins?connectorsOnly=false\""
      fi

      echo "$curl_output" | jq -r '.[] | [.class , .version , .type] | @tsv' | column -t

  else
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          get_ccloud_connect
          handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connector-plugins\" --header \"authorization: Basic $authorization\""
      else
          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl $security -s -X GET -H \"Content-Type: application/json\" \"$connect_url/connector-plugins\""
      fi

      echo "$curl_output" | jq -r '.[] | [.class , .version , .type] | @tsv' | column -t
  fi

}

# :command.function
playground_connector_pause_command() {

  # src/commands/connector/pause.sh
  connector="${args[--connector]}"
  verbose="${args[--verbose]}"

  connector_type=$(playground state get run.connector_type)

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      log "⏸️ Pausing $connector_type connector $connector"
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          get_ccloud_connect
          handle_ccloud_connect_rest_api "curl -s --request PUT \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/pause\" --header \"authorization: Basic $authorization\""
      else
          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl $security -s -X PUT -H \"Content-Type: application/json\" \"$connect_url/connectors/$connector/pause\""
      fi

      log "⏸️ $connector_type connector $connector has been paused successfully"

      sleep 1
      playground connector status --connector $connector
  done
}

# :command.function
playground_connector_versions_command() {

  # src/commands/connector/versions.sh
  test_file=$(playground state get run.test_file)

  connector_type=$(playground state get run.connector_type)
  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
      log "connector versions command is not supported with $connector_type connector"
      exit 0
  fi

  if [ ! -f $test_file ]
  then

      logerror "File $test_file retrieved from $root_folder/playground.ini does not exist!"
      exit 1
  fi
  get_connector_paths
  if [ "$connector_paths" == "" ]
  then
      logwarn "❌ skipping as it is not an example with connector, but --connector-tag is set"
      exit 1
  else
      current_tag=$(docker inspect -f '{{.Config.Image}}' connect 2> /dev/null | cut -d ":" -f 2)
      log "🎯 Version currently used for confluent platform"
      echo "$current_tag"

      for connector_path in ${connector_paths//,/ }
      do
          full_connector_name=$(basename "$connector_path")
          owner=$(echo "$full_connector_name" | cut -d'-' -f1)
          name=$(echo "$full_connector_name" | cut -d'-' -f2-)

          if [ "$owner" == "java" ] || [ "$name" == "hub-components" ] || [ "$owner" == "filestream" ]
          then
              # happens when plugin is not coming from confluent hub
              # logwarn "skipping as plugin $owner/$name does not appear to be coming from confluent hub"
              continue
          fi

          playground connector-plugin versions --connector-plugin $owner/$name --last 5

          # latest
          latest=$(playground connector-plugin versions --connector-plugin $owner/$name --last 1)
          latest_to_compare=$(echo "$latest" | head -n 1 | sed 's/ ([0-9]* days ago)//')

          manifest_file="$root_folder/confluent-hub/$full_connector_name/manifest.json"
          if [ -f $manifest_file ]
          then
              version=$(cat $manifest_file | jq -r '.version')
              release_date=$(cat $manifest_file | jq -r '.release_date')
          else
              logwarn "file $manifest_file does not exist, could not retrieve version"
              exit 0
          fi

          current="🔢 v$version - 📅 release date: $release_date"
          if [ "$current" == "$latest_to_compare" ]
          then
              log "👻 Version currently used for $owner/$name is latest"
              echo "$current"
          else
              log "🗯️ Version currently used for $owner/$name is not latest"
              log "Current"
              echo "$current"
              log "Latest on Hub"
              echo "$latest"
          fi

      done
  fi
}

# :command.function
playground_connector_sourcecode_command() {

  # src/commands/connector/sourcecode.sh
  connector_tags="${args[--connector-tag]}"
  only_show_url="${args[--only-show-url]}"

  # Convert space-separated string to array
  IFS=' ' read -ra connector_tag_array <<< "$connector_tags"

  test_file=$(playground state get run.test_file)

  connector_type=$(playground state get run.connector_type)
  if [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
      log "connector versions command is not supported with $connector_type connector"
      exit 0
  fi

  if [ ! -f $test_file ]
  then

      logerror "File $test_file retrieved from $root_folder/playground.ini does not exist!"
      exit 1
  fi

  maybe_only_show_url=""
  if [[ -n "$only_show_url" ]]
  then
      maybe_only_show_url="--only-show-url"
  fi
  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ]
  then
      owner="confluentinc"
      name=$(grep "connector.class" $test_file | head -1 | cut -d '"' -f4)

      length=${#connector_tag_array[@]}
      if ((length > 1))
      then
          if ((length > 2))
          then
              logerror "❌ --connector-tag can only be set 2 times"
              exit 1
          fi
          connector_tag1="${connector_tag_array[0]}"
          connector_tag2="${connector_tag_array[1]}"
          playground connector-plugin sourcecode --connector-plugin "$owner/$name" --connector-tag "$connector_tag1" --connector-tag "$connector_tag2" $maybe_only_show_url
      else
          if ((length == 1))
          then
              connector_tag="${connector_tag_array[0]}"
              playground connector-plugin sourcecode --connector-plugin "$owner/$name" --connector-tag "$connector_tag" $maybe_only_show_url
          else
              playground connector-plugin sourcecode --connector-plugin "$owner/$name" $maybe_only_show_url
          fi
      fi
      exit 0
  fi

  get_connector_paths
  if [ "$connector_paths" == "" ]
  then
      logwarn "❌ skipping as it is not an example with connector, but --connector-tag is set"
      exit 1
  else
      for connector_path in ${connector_paths//,/ }
      do
          full_connector_name=$(basename "$connector_path")
          owner=$(echo "$full_connector_name" | cut -d'-' -f1)
          name=$(echo "$full_connector_name" | cut -d'-' -f2-)

          if [ "$owner" == "java" ] || [ "$name" == "hub-components" ] || [ "$owner" == "filestream" ]
          then
              # happens when plugin is not coming from confluent hub
              # logwarn "skipping as plugin $owner/$name does not appear to be coming from confluent hub"
              continue
          fi

          # # latest
          # latest=$(playground connector-plugin versions --connector-plugin $owner/$name --last 1)
          # latest_to_compare=$(echo "$latest" | head -n 1 | sed 's/ ([0-9]* days ago)//')

          length=${#connector_tag_array[@]}
          if ((length > 1))
          then
              if ((length > 2))
              then
                  logerror "❌ --connector-tag can only be set 2 times"
                  exit 1
              fi
              connector_tag1="${connector_tag_array[0]}"
              if [ "$connector_tag1" == "\\" ]
              then
                  connector_tag1=" "
              fi
              connector_tag2="${connector_tag_array[1]}"
              if [ "$connector_tag2" == "\\" ]
              then
                  connector_tag2=" "
              fi
              playground connector-plugin sourcecode --connector-plugin "$owner/$name" --connector-tag "$connector_tag1" --connector-tag "$connector_tag2" $maybe_only_show_url
          else
              if ((length == 1))
              then
                  connector_tag="${connector_tag_array[0]}"
                  if [ "$connector_tag" == "\\" ]
                  then
                      connector_tag=" "
                  fi
                  playground connector-plugin sourcecode --connector-plugin "$owner/$name" --connector-tag "$connector_tag" $maybe_only_show_url
              else
                  manifest_file="$root_folder/confluent-hub/$full_connector_name/manifest.json"
                  if [ -f $manifest_file ]
                  then
                      version=$(cat $manifest_file | jq -r '.version')
                      playground connector-plugin sourcecode --connector-plugin "$owner/$name" --connector-tag "$version" $maybe_only_show_url
                  else
                      logwarn "file $manifest_file does not exist, could not retrieve version"
                      exit 0
                  fi
              fi
          fi
      done
  fi
}

# :command.function
playground_connector_restart_command() {

  # src/commands/connector/restart.sh
  connector="${args[--connector]}"
  verbose="${args[--verbose]}"
  task_id="${args[--task-id]}"

  connector_type=$(playground state get run.connector_type)

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  if [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
      log "connector restart command is not supported with $connector_type connector"
      exit 0
  fi

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      if [[ -n "$task_id" ]]; then
          log "🔄 Restarting $connector_type connector $connector task $task_id"
      else
          log "🔄 Restarting $connector_type connector $connector"
      fi

      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] #|| [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          get_ccloud_connect
          if [[ -n "$task_id" ]]; then
              handle_ccloud_connect_rest_api "curl -s --request POST \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/tasks/$task_id/restart\" --header \"authorization: Basic $authorization\""
          else
              handle_ccloud_connect_rest_api "curl -s --request POST \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/restart\" --header \"authorization: Basic $authorization\""
          fi
      else
              tag=$(docker ps --format '{{.Image}}' | grep -E 'confluentinc/cp-.*-connect-.*:' | awk -F':' '{print $2}')
              if [ $? != 0 ] || [ "$tag" == "" ]
              then
                  logerror "Could not find current CP version from docker ps"
                  exit 1
              fi
          get_connect_url_and_security

          if [[ -n "$task_id" ]]; then
              # Restart specific task
              log "🤹‍♂️ Restart task $task_id"
              handle_onprem_connect_rest_api "curl $security -s -X POST -H \"Content-Type: application/json\" \"$connect_url/connectors/$connector/tasks/$task_id/restart\""
          elif ! version_gt $tag "6.9.9"
          then
              # For older versions, restart all tasks individually
              handle_onprem_connect_rest_api "curl $security -s -X GET \"$connect_url/connectors/$connector/tasks"

              task_ids=$(echo "$curl_output" | jq -r '.[].id.task')

              for task_id_loop in $task_ids
              do
                  log "🤹‍♂️ Restart task $task_id_loop"
                  handle_onprem_connect_rest_api "curl $security -s -X POST -H \"Content-Type: application/json\" \"$connect_url/connectors/$connector/tasks/$task_id_loop/restart\""
              done
          else
              # For newer versions, restart entire connector
              handle_onprem_connect_rest_api "curl $security -s -X POST -H \"Content-Type: application/json\" \"$connect_url/connectors/$connector/restart?includeTasks=true&onlyFailed=false\""
          fi
      fi

      if [[ -n "$task_id" ]]; then
          log "🔄 $connector_type connector $connector task $task_id has been restarted successfully"
      else
          log "🔄 $connector_type connector $connector has been restarted successfully"
      fi
  done
  sleep 3
  for connector in "${items[@]}"
  do
  	playground connector status --connector $connector
  done
}

# :command.function
playground_connector_stop_command() {

  # src/commands/connector/stop.sh
  connector="${args[--connector]}"
  verbose="${args[--verbose]}"

  connector_type=$(playground state get run.connector_type)

  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
      log "connector stop command is not available with $connector_type connector"
      exit 0
  fi

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  tag=$(docker ps --format '{{.Image}}' | grep -E 'confluentinc/cp-.*-connect-.*:' | awk -F':' '{print $2}')
  if [ $? != 0 ] || [ "$tag" == "" ]
  then
      logerror "❌ could not find current CP version from docker ps"
      exit 1
  fi

  if ! version_gt $tag "7.4.99"; then
      logerror "❌ stop connector is available since CP 7.5 only"
      exit 1
  fi

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      log "🛑 Stopping $connector_type connector $connector"
      get_connect_url_and_security
      handle_onprem_connect_rest_api "curl $security -s -X PUT -H \"Content-Type: application/json\" \"$connect_url/connectors/$connector/stop\""

      log "🛑 $connector_type connector $connector has been stopped successfully"

      sleep 1
      playground connector status --connector $connector
  done
}

# :command.function
playground_connector_resume_command() {

  # src/commands/connector/resume.sh
  connector="${args[--connector]}"
  verbose="${args[--verbose]}"

  connector_type=$(playground state get run.connector_type)

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      log "⏯️ Resuming $connector_type connector $connector"
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          get_ccloud_connect
          handle_ccloud_connect_rest_api "curl -s --request PUT \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/resume\" --header \"authorization: Basic $authorization\""
      else
          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl $security -s -X PUT -H \"Content-Type: application/json\" \"$connect_url/connectors/$connector/resume\""
      fi

      log "⏯️ $connector_type connector $connector has been resumed successfully"

      sleep 1
      playground connector status --connector $connector
  done
}

# :command.function
playground_connector_delete_command() {

  # src/commands/connector/delete.sh
  verbose="${args[--verbose]}"
  connector="${args[--connector]}"

  connector_type=$(playground state get run.connector_type)

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
      check_if_continue
  fi
  for connector in "${items[@]}"
  do
      log "❌ Deleting $connector_type connector $connector"
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          get_ccloud_connect
          handle_ccloud_connect_rest_api "curl -s --request DELETE \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector\" --header \"authorization: Basic $authorization\""
      else
          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl $security -s -X DELETE \"$connect_url/connectors/$connector\""
      fi

      log "❌ $connector_type connector $connector has been deleted successfully"
  done
}

# :command.function
playground_connector_show_lag_command() {

  # src/commands/connector/show-lag.sh
  connector="${args[--connector]}"
  verbose="${args[--verbose]}"
  interval="${args[--interval]}"
  max_wait="${args[--max-wait]}"

  connector_type=$(playground state get run.connector_type)
  get_environment_used

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ] || [ "$environment" == "ccloud" ]
  then
    get_ccloud_connect
    get_kafka_docker_playground_dir
    DELTA_CONFIGS_ENV=$KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/env.delta

    if [ -f $DELTA_CONFIGS_ENV ]
    then
        source $DELTA_CONFIGS_ENV
    else
        logerror "❌ $DELTA_CONFIGS_ENV has not been generated"
        exit 1
    fi
    if [ ! -f $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta ]
    then
        logerror "❌ $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta has not been generated"
        exit 1
    fi
  else
    get_security_broker "--command-config"
  fi

  declare -A prev_lags
  prev_lags=()

  function show_output () {
    prev_topic=""
    while read line; do
      arr=($line)
      topic=${arr[1]}
      partition=${arr[2]}
      current_offset=${arr[3]}
      end_offset=${arr[4]}
      lag=${arr[5]}
      prev_lag=${prev_lags["${topic}_${partition}"]}
      compare_line=""
      compare_action=""

      if [ "$topic" != "$prev_topic" ] && [ "$prev_topic" != "" ]
      then
        echo "---"
      fi

      if [[ "$total_lag" =~ ^[0-9]+$ ]]
      then
        if [[ "$prev_lag" =~ ^[0-9]+$ ]] && [[ "$lag" =~ ^[0-9]+$ ]]
        then
          if [ $lag -lt $prev_lag ]
          then
            compare_line="🔻 $(($prev_lag - $lag))"
            compare_action="up"
          elif [ $lag -eq $prev_lag ]
          then
            compare_line="🔸"
            compare_action="same"
          else
            compare_line="🔺 $(($lag - $prev_lag))"
            compare_action="down"
          fi
        fi
      fi

      if [ $lag == 0 ]
      then
        compare_line="🏁"
      fi

      if [[ "$end_offset" =~ ^[0-9]+$ ]] && [[ "$end_offset" =~ ^[0-9]+$ ]] && [ $end_offset != 0 ] && [[ "$lag" =~ ^[0-9]+$ ]]
      then
        # calculate the percentage of lag
        percentage=$((100 * lag / end_offset))
        inverse_percentage=$((100 - percentage))

        # create the progress bar
        bar_length=20
        filled_length=$((percentage * bar_length / 100))
        empty_length=$((bar_length - filled_length))
        bar=$(printf "%${empty_length}s" | tr ' ' '🔹')
        bar+=$(printf "%${filled_length}s" | tr ' ' '💠')
      fi

      prev_lags["${topic}_${partition}"]=$lag
      if [ "$compare_line" != "" ]
      then
        case "${compare_action}" in
          up)
            printf "\033[32mtopic: %-10s partition: %-3s current-offset: %-10s end-offset: %-10s lag: %-10s [%s] %3d%% %s\033[0m\n" "$topic" "$partition" "$current_offset" "$end_offset" "$lag" "$bar" "$inverse_percentage" "$compare_line"
          ;;
          down)
            printf "\033[31mtopic: %-10s partition: %-3s current-offset: %-10s end-offset: %-10s lag: %-10s [%s] %3d%% %s\033[0m\n" "$topic" "$partition" "$current_offset" "$end_offset" "$lag" "$bar" "$inverse_percentage" "$compare_line"
          ;;
          *)
            printf "topic: %-10s partition: %-3s current-offset: %-10s end-offset: %-10s lag: %-10s [%s] %3d%% %s\n" "$topic" "$partition" "$current_offset" "$end_offset" "$lag" "$bar" "$inverse_percentage" "$compare_line"
          ;;
        esac
      else
        printf "topic: %-10s partition: %-3s current-offset: %-10s end-offset: %-10s lag: %-10s [%s] %3d%%\n" "$topic" "$partition" "$current_offset" "$end_offset" "$lag" "$bar" "$inverse_percentage"
      fi
      prev_topic="$topic"
    done < <(cat "$lag_output" | grep -v PARTITION | sed '/^$/d' | sort -k2n)
  }

  function log_down() {
    GREEN='\033[0;32m'
    NC='\033[0m' # No Color
    echo -e "$GREEN$(date +"%H:%M:%S") 🔻$@$NC"
  }

  function log_up() {
    RED='\033[0;31m'
    NC='\033[0m' # No Color
    echo -e "$RED$(date +"%H:%M:%S") 🔺$@$NC"
  }

  function log_same() {
    ORANGE='\033[0;33m'
    NC='\033[0m' # No Color
    echo -e "$ORANGE$(date +"%H:%M:%S") 🔸$@$NC"
  }

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi
  lag_output=$tmp_dir/lag_output

  function handle_signal {
    echo "Stopping..."
    stop=1
  }
  # Set the signal handler
  trap handle_signal SIGINT

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
    maybe_id=""
    if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
    then
        get_ccloud_connect
        handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/status\" --header \"authorization: Basic $authorization\""
        connectorId=$(get_ccloud_connector_lcc $connector)
        maybe_id=" ($connectorId)"
    else
        get_connect_url_and_security
        handle_onprem_connect_rest_api "curl -s $security \"$connect_url/connectors/$connector/status\""
    fi

    type=$(echo "$curl_output" | jq -r '.type')
    if [ "$type" != "sink" ]
    then
      logwarn "⏭️ Skipping $type $connector_type connector ${connector}${maybe_id}, it must be a sink to show the lag"
      continue

    fi

    playground connector status --connector $connector  > $tmp_dir/result.log  2>&1
    if [ $(grep -c "✅" $tmp_dir/result.log) -ne 1 ]
    then
        logerror "❌ $connector_type connector ${connector}${maybe_id} instance is not in ✅ RUNNING state"
        exit 1
    fi

    if [ $(grep -c "🟢" $tmp_dir/result.log) -lt 1 ]
    then
        logerror "❌ $connector_type connector ${connector}${maybe_id} does not have 🟢 task in RUNNING state"
        exit 1
    fi

    if [[ -n "$verbose" ]]
    then
        log "🐞 CLI command used"
        echo "kafka-consumer-groups --bootstrap-server $bootstrap_server --group connect-$connector --describe $security"
    fi

    SECONDS=0
    prev_lag=0
    stop=0
    cur_wait=0

    get_environment_used
    while [ $stop != 1 ]
    do
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ] || [[ "$environment" == "ccloud" ]]
      then
        get_ccloud_connect
        get_connect_image

        if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]

        then
          consumer_group="connect-$connectorId"
        else
          consumer_group="connect-$connector"
        fi
        docker run --quiet --rm -v $KAFKA_DOCKER_PLAYGROUND_DIR/.ccloud/ak-tools-ccloud.delta:/tmp/configuration/ccloud.properties -e BOOTSTRAP_SERVERS="$BOOTSTRAP_SERVERS" -e SASL_JAAS_CONFIG="$SASL_JAAS_CONFIG" ${CP_CONNECT_IMAGE}:${CP_CONNECT_TAG} kafka-consumer-groups --bootstrap-server $BOOTSTRAP_SERVERS --command-config /tmp/configuration/ccloud.properties --group $consumer_group --describe | grep -v PARTITION | sed '/^$/d' &> $lag_output
      else
        docker exec $container kafka-consumer-groups --bootstrap-server $bootstrap_server --group connect-$connector --describe $security | grep -v PARTITION | sed '/^$/d' &> $lag_output
      fi

      if grep -q "Warning" $lag_output
      then
        logwarn "🐢 consumer group for $connector_type connector ${connector}${maybe_id} is rebalancing"
        cat $lag_output
        sleep $interval
        cur_wait=$(( cur_wait+interval ))
        if [ "$max_wait" != "0" ] && [[ "$cur_wait" -gt "$max_wait" ]]
        then
          log "🐢 the consumer lag is still not 0 after $max_wait seconds."
          exit 0
        fi
        continue
      fi

      set +e
      lag_not_set=$(cat "$lag_output" | awk -F" " '{ print $6 }' | grep "-")

      if [ ! -z "$lag_not_set" ]
      then
        logwarn "🐢 consumer lag for $connector_type connector ${connector}${maybe_id} is not available"
        show_output
        sleep $interval
        cur_wait=$(( cur_wait+interval ))
        if [ "$max_wait" != "0" ] && [[ "$cur_wait" -gt "$max_wait" ]]
        then
          log "🐢 the consumer lag is still not 0 after $max_wait seconds."
          exit 0
        fi
      else
        total_lag=$(cat "$lag_output" | grep -v "PARTITION" | awk -F" " '{sum+=$6;} END{print sum;}')

        if [[ "$total_lag" =~ ^[0-9]+$ ]]
        then
          if [ $total_lag -ne 0 ]
          then
            compare=""
            compare_action=""
            if [[ "$prev_lag" =~ ^[0-9]+$ ]]
            then
              if [ $prev_lag != 0 ]
              then
                if [ $total_lag -lt $prev_lag ]
                then
                  compare="🔻 $(($prev_lag - $total_lag))"
                  compare_action="down"
                elif [ $total_lag -eq $prev_lag ]
                then
                  compare="🔸"
                  compare_action="same"
                else
                  compare="🔺 $(($total_lag - $prev_lag))"
                  compare_action="up"
                fi
              fi
            fi
            if [ "$compare" != "" ]
            then
              case "${compare_action}" in
                up)
                  log_up "🔥 total consumer lag for $connector_type connector ${connector}${maybe_id} has increased to $total_lag $compare (press ctrl-c to stop)"
                ;;
                down)
                  log_down "🚀 consumer lag for $connector_type connector ${connector}${maybe_id} has decreased to $total_lag $compare (press ctrl-c to stop)"
                ;;
                *)
                  log_same "🐌 consumer lag for $connector_type connector ${connector}${maybe_id} is still $total_lag $compare (press ctrl-c to stop)"
                ;;
              esac
            else
              log "🐢 consumer lag for $connector_type connector ${connector}${maybe_id} is $total_lag"
            fi
            show_output
            prev_lag=$total_lag
            sleep $interval
            cur_wait=$(( cur_wait+interval ))
            if [ "$max_wait" != "0" ] && [[ "$cur_wait" -gt "$max_wait" ]]
            then
              log "🐢 the consumer lag is still not 0 after $max_wait seconds."
              exit 0
            fi
          else
            ELAPSED="took: $((($SECONDS / 60) % 60))min $(($SECONDS % 60))sec"
            log "🏁 consumer lag for $connector_type connector ${connector}${maybe_id} is 0 ! $ELAPSED"
            stop=1
            show_output
            break
          fi
        fi
      fi
    done
  done
}

# :command.function
playground_connector_show_config_command() {

  # src/commands/connector/show-config.sh
  connector="${args[--connector]}"
  force_rest_endpoint="${args[--force-rest-endpoint]}"
  verbose="${args[--verbose]}"
  no_clipboard="${args[--no-clipboard]}"

  connector_type=$(playground state get run.connector_type)

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  ci_ok=0
  if [ ! -z "$GITHUB_RUN_NUMBER" ] && [[ -n "$no_clipboard" ]]
  then
      ci_ok=1
  fi
  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      if [ -f "/tmp/config-$connector" ] && [ ${ci_ok} -eq 1 ] && [[ ! -n "$force_rest_endpoint" ]]
      then
          log "🧰 Current config for $connector_type connector $connector"
          if [[ -n "$no_clipboard" ]]
          then
              echo "playground connector create-or-update --connector $connector --no-clipboard << EOF"
        else
            echo "playground connector create-or-update --connector $connector << EOF"
        fi
        cat "/tmp/config-$connector" | jq -S . | sed 's/\$/\\$/g'
        echo "EOF"

        if [[ "$OSTYPE" == "darwin"* ]]
        then
            clipboard=$(playground config get clipboard)
            if [ "$clipboard" == "" ]
            then
                playground config set clipboard true
            fi

            if ( [ "$clipboard" == "true" ] || [ "$clipboard" == "" ] ) && [[ ! -n "$no_clipboard" ]]
            then
                tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
                if [ -z "$PG_VERBOSE_MODE" ]
                then
                    trap 'rm -rf $tmp_dir' EXIT
                else
                    log "🐛📂 not deleting tmp dir $tmp_dir"
                fi
                echo "playground connector create-or-update --connector $connector << EOF" > $tmp_dir/tmp
                cat "/tmp/config-$connector" | jq -S . | sed 's/\$/\\$/g' >> $tmp_dir/tmp
                echo "EOF" >> $tmp_dir/tmp

                cat $tmp_dir/tmp | pbcopy
                log "📋 $connector_type connector config has been copied to the clipboard (disable with 'playground config clipboard false')"
            fi
        fi
    else
        log "🧰 Current config for $connector_type connector $connector (using REST API /config endpoint)"

        if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
        then
            get_ccloud_connect
            handle_ccloud_connect_rest_api "curl $security -s -X GET -H \"Content-Type: application/json\" \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/config\" --header \"authorization: Basic $authorization\""
        else
            get_connect_url_and_security
            handle_onprem_connect_rest_api "curl $security -s -X GET -H \"Content-Type: application/json\" \"$connect_url/connectors/$connector/config\""
        fi

        if [[ -n "$no_clipboard" ]]
        then
            echo "playground connector create-or-update --connector $connector --no-clipboard << EOF"
        else
            echo "playground connector create-or-update --connector $connector << EOF"
        fi
        echo "$curl_output" | jq -S . | sed 's/\$/\\$/g'
        echo "EOF"

        if [[ "$OSTYPE" == "darwin"* ]]
        then
            clipboard=$(playground config get clipboard)
            if [ "$clipboard" == "" ]
            then
                playground config set clipboard true
            fi

            if ( [ "$clipboard" == "true" ] || [ "$clipboard" == "" ] ) && [[ ! -n "$no_clipboard" ]]
            then
                tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
                if [ -z "$PG_VERBOSE_MODE" ]
                then
                    trap 'rm -rf $tmp_dir' EXIT
                else
                    log "🐛📂 not deleting tmp dir $tmp_dir"
                fi
                echo "playground connector create-or-update --connector $connector << EOF" > $tmp_dir/tmp
                echo "$curl_output" | jq -S . | sed 's/\$/\\$/g' >> $tmp_dir/tmp
                echo "EOF" >> $tmp_dir/tmp

                cat $tmp_dir/tmp | pbcopy
                log "📋 $connector_type connector config has been copied to the clipboard (disable with 'playground config clipboard false')"
            fi
        fi
    fi
done
}

# :command.function
playground_connector_show_config_parameters_command() {

  # src/commands/connector/show-config-parameters.sh
  connector="${args[--connector]}"
  open="${args[--open]}"
  force_refresh="${args[--force-refresh]}"
  only_show_file_path="${args[--only-show-file-path]}"
  only_show_json="${args[--only-show-json]}"
  only_show_json_file_path="${args[--only-show-json-file-path]}"
  verbose="${args[--verbose]}"

  connector_type=$(playground state get run.connector_type)

  if [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
      log "connector show-config-parameters command is not supported with $connector_type connector"
      exit 0
  fi

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi
  json_file=$tmp_dir/connector.json

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          get_ccloud_connect
          handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/config\" --header \"authorization: Basic $authorization\""
      else
          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl $security -s -X GET -H \"Content-Type: application/json\" \"$connect_url/connectors/$connector/config\""
      fi

      echo "$curl_output" > $json_file

      connector_class=$(echo "$curl_output" | jq -r '."connector.class"')
      class=$(echo $connector_class | rev | cut -d '.' -f 1 | rev)

      version="unknown"
      if [ "$connector_type" == "$CONNECTOR_TYPE_ONPREM" ] || [ "$connector_type" == "$CONNECTOR_TYPE_SELF_MANAGED" ]
      then
          get_connect_url_and_security
          handle_onprem_connect_rest_api "curl $security -s -X GET -H \"Content-Type: application/json\" $connect_url/connector-plugins/"
          for row in $(echo "$curl_output" | jq -r '.[] | @base64'); do
              _jq() {
                  echo ${row} | base64 -d | jq -r ${1}
              }

              class=$(_jq '.class')

              if [ "$class" == "$connector_class" ]
              then
                  version=$(_jq '.version')
                  break
              fi
          done
      fi

  	if [ -z "$GITHUB_RUN_NUMBER" ]
  	then
  		mkdir -p $root_folder/.connector_config
  		filename="$root_folder/.connector_config/config-$connector_class-$version.txt"
  		json_filename="$root_folder/.connector_config/config-$connector_class-$version.json"
  	else
  		test_file=$(playground state get run.test_file)
  		if [ ! -f $test_file ]
  		then

  			logerror "File $test_file retrieved from $root_folder/playground.ini does not exist!"
  			exit 1
  		fi

  		folder_of_test_file=$(dirname "$test_file")
  		filename="$folder_of_test_file/config-$connector_class.txt"
  		json_filename="$folder_of_test_file/config-$connector_class.json"
  	fi

      if [[ ! -n "$only_show_json_file_path" ]]
      then
          if [[ -n "$only_show_json" ]]
          then
              log "🔩 list of all available parameters for $connector_type connector $connector ($class) and version $version (with default value when applicable)"
          else
              log "🔩 getting parameters for $connector_type connector $connector ($class) and version $version"
          fi
      fi

      if [[ -n "$force_refresh" ]] || [ ! -z "$GITHUB_RUN_NUMBER" ]
      then
          if [ -f $filename ]
          then
              rm -f $filename
          fi
          if [ -f $json_filename ]
          then
              rm -f $json_filename
          fi
      fi
      if [ ! -f $filename ] || [ ! -f $json_filename ]
      then
          if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
          then
              get_ccloud_connect
              handle_ccloud_connect_rest_api "curl -s --request PUT -H \"Content-Type: application/json\" --data @$json_file \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connector-plugins/$connector_class/config/validate\" --header \"authorization: Basic $authorization\""
          else
              get_connect_url_and_security
              handle_onprem_connect_rest_api "curl $security -s -X PUT -H \"Content-Type: application/json\" --data @$json_file $connect_url/connector-plugins/$connector_class/config/validate"
          fi

          if ! echo "$curl_output" | jq -e .  > /dev/null 2>&1
          then
              set +e
              json_file=/tmp/json
              echo "$curl_output" > $json_file
              jq_output=$(jq . "$json_file" 2>&1)
              error_line=$(echo "$jq_output" | grep -oE 'parse error.*at line [0-9]+' | grep -oE '[0-9]+')

              if [[ -n "$error_line" ]]; then
                  logerror "❌ Invalid JSON at line $error_line"
              fi
              set -e

              if [ -z "$GITHUB_RUN_NUMBER" ]
              then
                  if [[ $(type -f bat 2>&1) =~ "not found" ]]
                  then
                      cat -n $json_file
                  else
                      bat $json_file --highlight-line $error_line
                  fi
              fi

              exit 1
          fi

          current_group=""
          configs=$(echo "$curl_output" | jq -r '.configs')
          while IFS= read -r row; do

              IFS=$'\n'
              arr=($(echo "$row" | jq -r '.definition.group, .definition.name, .definition.default_value, .definition.type, .definition.required, .definition.importance, .definition.documentation'))
              group="${arr[0]}"
                                  set +x
              if [[ "$group" == "Common" || "$group" == "Transforms" || "$group" == "Error Handling" || "$group" == "Topic Creation" || "$group" == "offsets.topic" || "$group" == "Exactly Once Support" || "$group" == "Predicates" || "$group" == "Confluent Licensing" ]] ; then
                  continue
              fi

              if [ "$group" != "$current_group" ]
              then
                  echo -e "==========================" >> "$filename"
                  echo -e "$group"                     >> "$filename"
                  echo -e "==========================" >> "$filename"
                  current_group=$group
              fi

              param="${arr[1]}"
              default="${arr[2]}"
              type="${arr[3]}"
              required="${arr[4]}"
              importance="${arr[5]}"
              description="${arr[6]}"

              echo -e "🔘 $param" >> "$filename"
              echo -e "" >> "$filename"
              echo -e "$description" >> "$filename"
              echo -e "" >> "$filename"
              echo -e "\t - Type: $type" >> "$filename"
              echo -e "\t - Default: $default" >> "$filename"
              echo -e "\t - Importance: $importance" >> "$filename"
              echo -e "\t - Required: $required" >> "$filename"
              echo -e "" >> "$filename"

              if [ "$default" == "null" ]
              then
                  default=""
              fi
              echo -e "    \"$param\": \"$default\"," >> "$json_filename"
              sort "$json_filename" -o /tmp/tmp
              # fix unwanted commits like this one #7231
              cat /tmp/tmp | sed -E 's/[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}Z/YYYY-MM-DDTHH:mm:ss/g' | sed -E 's/[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}/YYYY-MM-DD HH:mm/g' | sed -E 's/[0-9]{4}-[0-9]{2}-[0-9]{2}/YYYY-MM-DD/g' > /tmp/tmp2
              mv /tmp/tmp2 "$json_filename"
          done <<< "$(echo "$configs" | jq -c '.[]')"
      fi

      if [ ! -f $filename ]
      then
          logwarn "❌ there was no specific config for this $connector_type connector"
          exit 0
      fi

      if [[ -n "$open" ]]
      then
          if [[ -n "$only_show_json" ]]
          then
              filename=$json_filename
          else
              # fix unwanted commits like this one #7231
              cat $filename | sed -E 's/[0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}:[0-9]{2}:[0-9]{2}Z/YYYY-MM-DDTHH:mm:ss/g' | sed -E 's/[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}/YYYY-MM-DD HH:mm/g' | sed -E 's/[0-9]{4}-[0-9]{2}-[0-9]{2}/YYYY-MM-DD/g' > /tmp/tmp
              mv /tmp/tmp "$filename"
              cat $filename > "/tmp/config-$connector_class-$version.txt"
              filename="/tmp/config-$connector_class-$version.txt"
              cat $json_filename >> $filename
              echo "🔩 list of all available parameters for connector $connector ($class) and version $version (with default value when applicable)" >> $filename
          fi

          playground open --file "${filename}"
      else
          if [[ -n "$only_show_json" ]] || [[ -n "$only_show_json_file_path" ]]
          then
              if [[ -n "$only_show_json_file_path" ]]
              then
                  echo "$json_filename"
              else
                  cat $json_filename
              fi
              return
          fi

          if [[ -n "$only_show_file_path" ]]
          then
              echo "$filename"
          else
              cat $filename
              log "🔩 list of all available parameters for $connector_type connector $connector ($class) and version $version (with default value when applicable)"
              cat $json_filename
          fi
      fi
  done
}

# :command.function
playground_connector_select_config_command() {

  # src/commands/connector/select-config.sh
  connector="${args[--connector]}"

  connector_type=$(playground state get run.connector_type)

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  log "🗜️ Easily select config from all possible configuration parameters"
  log "🎓 Tip: use <tab> to select multiple config at once !"

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      json_file=$(playground connector show-config-parameters --only-show-json --only-show-json-file-path --connector $connector)
      if [ ! -f "$json_file" ]
      then
          logwarn "❌ file <$json_file> does not exist, could not retrieve json config file for connector $connector."
          exit 1
      fi

      fzf_version=$(get_fzf_version)
      if version_gt $fzf_version "0.38"
      then
          fzf_option_wrap="--preview-window=40%,wrap"
          fzf_option_pointer="--pointer=👉"
          fzf_option_rounded="--border=rounded"
      else
          fzf_options=""
          fzf_option_pointer=""
          fzf_option_rounded=""
      fi

      res=$(cat $json_file | fzf --multi --margin=1%,1%,1%,1% $fzf_option_rounded --info=inline --cycle --prompt="🗜️" --header="ctrl-c or esc to quit" --color="bg:-1,bg+:-1,info:#BDBB72,border:#FFFFFF,spinner:0,hl:#beb665,fg:#00f7f7,header:#5CC9F5,fg+:#beb665,pointer:#E12672,marker:#5CC9F5,prompt:#98BEDE" $fzf_option_wrap $fzf_option_pointer)

      log "🗜️ selected config parameter(s) for connector $connector"
      echo "$res"

      if [[ "$OSTYPE" == "darwin"* ]]
      then
          clipboard=$(playground config get clipboard)
          if [ "$clipboard" == "" ]
          then
              playground config set clipboard true
          fi

          if [ "$clipboard" == "true" ] || [ "$clipboard" == "" ]
          then
              tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
              if [ -z "$PG_VERBOSE_MODE" ]
              then
                  trap 'rm -rf $tmp_dir' EXIT
              else
                  log "🐛📂 not deleting tmp dir $tmp_dir"
              fi
              echo "$res" > $tmp_dir/tmp

              cat $tmp_dir/tmp | pbcopy
              log "📋 config has been copied to the clipboard (disable with 'playground config clipboard false')"
          fi
      fi
  done
}

# :command.function
playground_connector_snippets_command() {

  # src/commands/connector/snippets.sh
  converter=${args[--converter]}
  dlq=${args[--dlq]}

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  if [[ ! -n "$converter" ]] && [[ ! -n "$dlq" ]]
  then
      logerror "❌ neither --converter or --dlq were provided"
      exit 1
  fi

  if [[ -n "$dlq" ]]
  then
      dlq_file=$tmp_dir/dlq
      echo -e "    \"errors.tolerance\": \"all\"," >> $dlq_file
      echo -e "    \"errors.deadletterqueue.topic.name\": \"dlq\"," >> $dlq_file
      echo -e "    \"errors.deadletterqueue.topic.replication.factor\": \"1\"," >> $dlq_file
      echo -e "    \"errors.deadletterqueue.context.headers.enable\": \"true\"," >> $dlq_file
      echo -e "    \"errors.log.enable\": \"true\"," >> $dlq_file
      echo -e "    \"errors.log.include.messages\": \"true\"," >> $dlq_file
  fi

  if [[ -n "$converter" ]]
  then
      converter_file=$tmp_dir/converter
      case "${converter}" in
          string)
              echo -e "    \"key.converter\": \"org.apache.kafka.connect.storage.StringConverter\"," >> $converter_file
              echo -e "    \"value.converter\": \"org.apache.kafka.connect.storage.StringConverter\"," >> $converter_file
          ;;
          bytearray)
              echo -e "    \"key.converter\": \"org.apache.kafka.connect.converters.ByteArrayConverter\"," >> $converter_file
              echo -e "    \"value.converter\": \"org.apache.kafka.connect.converters.ByteArrayConverter\"," >> $converter_file
          ;;
          json)
              echo -e "    \"key.converter\": \"org.apache.kafka.connect.json.JsonConverter\"," >> $converter_file
              echo -e "    \"key.converter.schemas.enable\": \"false\"," >> $converter_file
              echo -e "    \"value.converter\": \"org.apache.kafka.connect.json.JsonConverter\"," >> $converter_file
              echo -e "    \"value.converter.schemas.enable\": \"false\"," >> $converter_file
          ;;
          json-schema-enabled)
              echo -e "    \"key.converter\": \"org.apache.kafka.connect.json.JsonConverter\"," >> $converter_file
              echo -e "    \"value.converter\": \"org.apache.kafka.connect.json.JsonConverter\"," >> $converter_file
          ;;
          avro|json-schema|protobuf)

              case "${converter}" in
                  avro)
                      converter_class="io.confluent.connect.avro.AvroConverter"
                  ;;
                  json-schema)
                      converter_class="io.confluent.connect.json.JsonSchemaConverter"
                  ;;
                  protobuf)
                      converter_class="io.confluent.connect.protobuf.ProtobufConverter"
                  ;;
              esac

              environment=$(playground state get run.environment_before_switch)
              if [ "$environment" = "" ]
              then
                  environment=$(playground state get run.environment)
              fi

              if [ "$environment" = "" ]
              then
                  environment="plaintext"
              fi

              case "${environment}" in
              plaintext|sasl-plain|ldap-authorizer-sasl-plain|ldap-sasl-plain|sasl-scram|kerberos|ssl_kerberos)
                  echo -e "    \"key.converter\": \"$converter_class\"," >> $converter_file
                  echo -e "    \"key.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $converter_file
                  echo -e "    \"value.converter\": \"$converter_class\"," >> $converter_file
                  echo -e "    \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $converter_file
              ;;
              ccloud)
                  if [ -f $root_folder/.ccloud/env.delta ]
                  then
                      source $root_folder/.ccloud/env.delta
                  else
                      logerror "❌ $root_folder/.ccloud/env.delta has not been generated"
                      exit 1
                  fi
                  echo -e "    \"key.converter\": \"$converter_class\"," >> $converter_file
                  echo -e "    \"key.converter.schema.registry.url\": \"$SCHEMA_REGISTRY_URL\"," >> $converter_file
                  echo -e "    \"key.converter.basic.auth.credentials.source\": \"USER_INFO\"," >> $converter_file
                  echo -e "    \"key.converter.basic.auth.user.info\": \"\${file:/datacloud:schema.registry.basic.auth.user.info}\"," >> $converter_file
                  echo -e "    \"value.converter\": \"$converter_class\"," >> $converter_file
                  echo -e "    \"value.converter.schema.registry.url\": \"$SCHEMA_REGISTRY_URL\"," >> $converter_file
                  echo -e "    \"value.converter.basic.auth.credentials.source\": \"USER_INFO\"," >> $converter_file
                  echo -e "    \"value.converter.basic.auth.user.info\": \"\${file:/datacloud:schema.registry.basic.auth.user.info}\"," >> $converter_file
                  ;;

              sasl-ssl|2way-ssl)
                  echo -e "    \"key.converter\": \"$converter_class\"," >> $converter_file
                  echo -e "    \"key.converter.schema.registry.url\": \"https://schema-registry:8081\"," >> $converter_file
                  echo -e "    \"key.converter.schema.registry.ssl.truststore.location\": \"/etc/kafka/secrets/kafka.connect.truststore.jks\"," >> $converter_file
                  echo -e "    \"key.converter.schema.registry.ssl.truststore.password\": \"confluent\"," >> $converter_file
                  echo -e "    \"key.converter.schema.registry.ssl.keystore.location\": \"/etc/kafka/secrets/kafka.connect.keystore.jks\"," >> $converter_file
                  echo -e "    \"key.converter.schema.registry.ssl.keystore.password\": \"confluent\"," >> $converter_file
                  echo -e "    \"key.converter.schema.registry.ssl.key.password\": \"confluent\"," >> $converter_file
                  echo -e "    \"value.converter\": \"$converter_class\"," >> $converter_file
                  echo -e "    \"value.converter.schema.registry.url\": \"https://schema-registry:8081\"," >> $converter_file
                  echo -e "    \"value.converter.schema.registry.ssl.truststore.location\": \"/etc/kafka/secrets/kafka.connect.truststore.jks\"," >> $converter_file
                  echo -e "    \"value.converter.schema.registry.ssl.truststore.password\": \"confluent\"," >> $converter_file
                  echo -e "    \"value.converter.schema.registry.ssl.keystore.location\": \"/etc/kafka/secrets/kafka.connect.keystore.jks\"," >> $converter_file
                  echo -e "    \"value.converter.schema.registry.ssl.keystore.password\": \"confluent\"," >> $converter_file
                  echo -e "    \"value.converter.schema.registry.ssl.key.password\": \"confluent\"," >> $converter_file
                  ;;

              rbac-sasl-plain)
                  echo -e "    \"key.converter\": \"$converter_class\"," >> $converter_file
                  echo -e "    \"key.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $converter_file
                  echo -e "    \"key.converter.basic.auth.credentials.source\": \"USER_INFO\"," >> $converter_file
                  echo -e "    \"key.converter.basic.auth.user.info\": \"connectorSA:connectorSA\"," >> $converter_file
                  echo -e "    \"value.converter\": \"$converter_class\"," >> $converter_file
                  echo -e "    \"value.converter.schema.registry.url\": \"http://schema-registry:8081\"," >> $converter_file
                  echo -e "    \"value.converter.basic.auth.credentials.source\": \"USER_INFO\"," >> $converter_file
                  echo -e "    \"value.converter.basic.auth.user.info\": \"connectorSA:connectorSA\"," >> $converter_file
                  ;;
              *)
                  return
              ;;
              esac
          ;;
      esac
  fi

  clipboard_file=$tmp_dir/clipboard
  if [ -f "$dlq_file" ]
  then
      log "💀 add this for getting dead letter queue"
      cat $dlq_file

      cat $dlq_file >> $clipboard_file
  fi

  if [ -f "$converter_file" ]
  then
      log "🔌 converter config for $converter"
      cat $converter_file

      cat $converter_file >> $clipboard_file
  fi

  if [[ "$OSTYPE" == "darwin"* ]]
  then
      clipboard=$(playground config get clipboard)
      if [ "$clipboard" == "" ]
      then
          playground config set clipboard true
      fi

      if [ -f "$clipboard_file" ]
      then
          if [ "$clipboard" == "true" ] || [ "$clipboard" == "" ]
          then
              cat $clipboard_file | pbcopy
              log "📋 config has been copied to the clipboard (disable with 'playground config clipboard false')"
          fi
      fi
  fi

}

# :command.function
playground_connector_open_docs_command() {

  # src/commands/connector/open-docs.sh
  test_file=$(playground state get run.test_file)
  only_show_url="${args[--only-show-url]}"

  connector_type=$(playground state get run.connector_type)

  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
      log "connector open-docs command is not supported with $connector_type connector"
      exit 0
  fi

  if [ ! -f $test_file ]
  then

      logerror "❌ File $test_file retrieved from $root_folder/playground.ini does not exist!"
      exit 1
  fi

  get_connector_paths
  if [ "$connector_paths" == "" ]
  then
      logwarn "❌ skipping as it is not an example with connector, but --connector-tag is set"
      exit 1
  else
      doc_available=1
      doc_links=""
      for connector_path in ${connector_paths//,/ }
      do
          full_connector_name=$(basename "$connector_path")

          manifest_file="$root_folder/confluent-hub/$full_connector_name/manifest.json"
          if [ -f $manifest_file ]
          then
              url=$(cat $manifest_file | jq -r '.documentation_url')
              name=$(cat $manifest_file | jq -r '.name')
              url=${url//)/}

              if [[ $url =~ "http" ]]
              then
                  short_url=$(echo $url | cut -d '#' -f 1)
                  if [[ -n "$only_show_url" ]] || [[ $(type -f open 2>&1) =~ "not found" ]]
                  then
                      log "🌐 documentation for $connector_type connector $name is available at:"
                      echo "$short_url"
                      doc_links="${doc_links}|$name@$short_url"
                  else
                      log "🌐 opening documentation for $connector_type connector $name $short_url"
                      open "$short_url"
                  fi
              else
                  doc_available=0
              fi
          else
              doc_available=0
          fi
      done
      if [ $doc_available -eq 0 ]
      then
          log "🌐 documentation could not be retrieved"

      else
          doc_links="${doc_links#|}"
          doc_links=$(echo "${doc_links}" | tr -d '${}')
          playground state set run.connector_docs_links "$doc_links"
      fi
  fi
}

# :command.function
playground_connector_log_level_command() {

  # src/commands/connector/log-level.sh
  level="${args[--level]}"
  connector="${args[--connector]}"

  connector_type=$(playground state get run.connector_type)

  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
      log "connector log-level command is not supported with $connector_type connector"
      exit 0
  fi

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  log "🔰 also setting io.confluent.kafka.schemaregistry.client.rest.RestService (to see schema registry rest requests) to $level"
  playground debug log-level set -p "io.confluent.kafka.schemaregistry.client.rest.RestService" -l $level
  log "🔗 also setting org.apache.kafka.connect.runtime.TransformationChain (to see records before and after SMTs) to $level"
  playground debug log-level set -p "org.apache.kafka.connect.runtime.TransformationChain" -l $level

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      get_connect_url_and_security
      handle_onprem_connect_rest_api "curl -s $security \"$connect_url/connectors/$connector\""

      tmp=$(echo "$curl_output" | jq -r '.config."connector.class"')
      package="${tmp%.*}"

      type=$(echo "$curl_output" | jq -r '.type')
      if [ "$type" == "sink" ]
      then
          log "🔗 also setting org.apache.kafka.connect.runtime.WorkerSinkTask to $level"
          playground debug log-level set -p "org.apache.kafka.connect.runtime.WorkerSinkTask" -l $level
      else
          log "🔗 also setting org.apache.kafka.connect.runtime.WorkerSourceTask to $level"
          playground debug log-level set -p "org.apache.kafka.connect.runtime.WorkerSourceTask" -l $level
      fi
      # log "🧬 Set log level for connector $connector to $level"
      playground debug log-level set -p "$package" -l "$level"
  done
}

# :command.function
playground_connector_logs_command() {

  # src/commands/connector/logs.sh
  open="${args[--open]}"
  log="${args[--wait-for-log]}"
  connector="${args[--connector]}"
  verbose="${args[--verbose]}"

  connector_type=$(playground state get run.connector_type)

  if [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
      logerror "🚨 This command is not supported for custom connectors"
      exit 1
  fi

  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ]
  then

      if [[ ! -n "$connector" ]]
      then
          connector=$(playground get-connector-list)
          if [ "$connector" == "" ]
          then
              log "💤 No $connector_type connector is running !"
              exit 1
          fi
      fi

      items=($connector)
      length=${#items[@]}
      if ((length > 1))
      then
          log "✨ --connector flag was not provided, applying command to all connectors"
      fi
      # macOS (BSD date) vs Linux (GNU date) compatibility
      if [[ "$OSTYPE" == "darwin"* ]]; then
          start_time=$(date -u -v-71H +"%Y-%m-%dT%H:%M:%SZ")
      else
          start_time=$(date -u -d "71 hours ago" +"%Y-%m-%dT%H:%M:%SZ")
      fi
      end_time=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
      for connector in "${items[@]}"
      do
          connectorId=$(get_ccloud_connector_lcc $connector)
          if [[ -n "$open" ]]
          then
              filename="/tmp/${connector}-$(date '+%Y-%m-%d-%H-%M-%S').log"
          fi
          if [[ -n "$log" ]]
          then
              if [[ -n "$verbose" ]]
              then
                  log "🐞 CLI command used"
                  echo "confluent connect logs \"$connectorId\" --level \"ERROR|WARN|INFO\" --start-time \"$start_time\" --end-time \"$end_time\" --search-text \"$log\""
              fi
              confluent connect logs "$connectorId" --level "ERROR|WARN|INFO" --start-time "$start_time" --end-time "$end_time" --search-text "$log"
          else
              if [[ -n "$verbose" ]]
              then
                  log "🐞 CLI command used"
                  echo "confluent connect logs \"$connectorId\" --level \"ERROR|WARN|INFO\" --start-time \"$start_time\" --end-time \"$end_time\" --next"
              fi

              log "📄 Fetching connector logs for $connector (this may take a while for large log sets)..."
              page_num=1
              while true; do
                  log "📖 Fetching page $page_num..."
                  output=$(confluent connect logs "$connectorId" --level "ERROR|WARN|INFO" --start-time "$start_time" --end-time "$end_time" --next 2>&1)

                  # Check if no logs found
                  if echo "$output" | grep -q "No logs found for the current query"; then
                      log "✅ Finished fetching all log pages (total pages: $((page_num-1)))"
                      break
                  fi

                  if [[ -n "$open" ]]
                  then
                      # Save the logs to a file
                      echo "$output" >> "$filename"
                  else
                      # Display the logs
                      echo "$output"
                  fi

                  # Check if there are more pages by looking for log entries
                  if [ -z "$(echo "$output" | grep -E '\[INFO\]|\[WARN\]|\[ERROR\]')" ]; then
                      log "✅ No more log entries found (total pages: $page_num)"
                      break
                  fi

                  page_num=$((page_num + 1))

                  # Safety limit to prevent infinite loops
                  if [ $page_num -gt 100 ]; then
                      logwarn "⚠️  Reached maximum page limit (100), stopping pagination"
                      break
                  fi

                  sleep 1  # Small delay between requests
              done
          fi
          if [[ -n "$open" ]]
          then
              playground open --file "${filename}"
          fi
      done
  else
      if [[ -n "$open" ]]
      then
          playground container logs --open --container connect
      elif [[ -n "$log" ]]
      then
          playground container logs --container connect --wait-for-log "$log"
      else

          playground container logs --container connect
      fi
  fi
}

# :command.function
playground_connector_open_ccloud_connector_in_browser_command() {

  # src/commands/connector/open-ccloud-connector-in-browser.sh
  connector="${args[--connector]}"
  browser="${args[--browser]}"

  connector_type=$(playground state get run.connector_type)

  if [ "$connector_type" != "$CONNECTOR_TYPE_FULLY_MANAGED" ] && [ "$connector_type" != "$CONNECTOR_TYPE_CUSTOM" ]
  then
      log "connector open-ccloud-connector-in-browser command is not supported with $connector_type connector"
      exit 0
  fi

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
      check_if_continue
  fi
  for connector in "${items[@]}"
  do
      get_ccloud_connect
      handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/status\" --header \"authorization: Basic $authorization\""
      connectorId=$(get_ccloud_connector_lcc $connector)

      type=$(echo "$curl_output" | jq -r '.type')
      TYPE=""
      if [ "$type" == "sink" ]
      then
          TYPE="sinks"
      else
          TYPE="sources"
      fi

      if [[ $(type -f open 2>&1) =~ "not found" ]]
      then
          log "🔗 Cannot open browser, use url:"
          echo "https://confluent.cloud/environments/$environment/clusters/$cluster/connectors/$TYPE/$connector?granularity=PT1M&interval=3600000&label=Last%20hour"
      else
          if [[ -n "$browser" ]]
          then
              log "🤖 Open $connector_type connector $connector ($connectorId) in Confluent Cloud dashboard with browser $browser"
              open -a "$browser" "https://confluent.cloud/environments/$environment/clusters/$cluster/connectors/$TYPE/$connector?granularity=PT1M&interval=3600000&label=Last%20hour"
          else
              log "🤖 Open $connector_type connector $connector ($connectorId) in Confluent Cloud dashboard"
              open "https://confluent.cloud/environments/$environment/clusters/$cluster/connectors/$TYPE/$connector?granularity=PT1M&interval=3600000&label=Last%20hour"
          fi
      fi
  done
}

# :command.function
playground_connector_connect_migration_utility_discovery_command() {

  # src/commands/connector/connect-migration-utility/discovery.sh
  verbose=${args[--verbose]}

  get_connect_url_and_security

  log "👨‍🔬 Discover connectors in the local connect cluster and export their configurations to files"
  log "🛠️ It is using Connector Migration Utility (see https://github.com/confluentinc/connect-migration-utility/) on running connect cluster"

  log "🔌 boostrapping ccloud environment"
  bootstrap_ccloud_environment "" "" "true"

  get_ccloud_connect

  discovery_output_dir="$root_folder/connect-migration-utility-discovery-output"
  rm -rf "$discovery_output_dir"

  set +e
  docker pull vdesabou/docker-connect-migration-utility:latest > /dev/null 2>&1
  docker run -i --rm --network=host -v "$discovery_output_dir:/discovery_output_dir" vdesabou/docker-connect-migration-utility:latest bash -c "python src/discovery_script.py --worker-urls 'http://localhost:8083' --output-dir /discovery_output_dir --disable-ssl-verify --redact --environment-id $environment --cluster-id $cluster" > /tmp/output.log 2>&1
  ret=$?
  set -e

  if [[ -n "$verbose" ]]
  then
    log "🐞 --verbose is set, full output of the discovery process:"
    cat /tmp/output.log
  fi

  if [ $ret -ne 0 ]
  then
      logerror "❌ Failed to Run Kafka Connector Migration Utility, check output below:"
      cat /tmp/output.log
      exit 1
  fi

  if [ ! -f "$discovery_output_dir/summary.txt" ]
  then
      logerror "❌ File "$discovery_output_dir/summary.txt" does not exist"
      exit 1
  fi

  log "📝 Summary of the discovery process:"
  cat "$discovery_output_dir/summary.txt"

  echo ""

  json_count=$(find "$discovery_output_dir/discovered_configs/successful_configs/fm_configs" -name "*.json" -type f | wc -l)
  if [ "$json_count" -eq 0 ]
  then
      logerror "❌ No connector was discovered that can be migrated to fully managed"
      exit 1
  else
      log "📁 Found $json_count connector configuration(s) that can be migrated to fully managed:"
      # Display the directory structure
      if command -v tree >/dev/null 2>&1; then
          tree "$discovery_output_dir/discovered_configs/successful_configs/fm_configs"
      else
          find "$discovery_output_dir/discovered_configs/successful_configs/fm_configs" -type f -name "*.json" | sort
      fi

      echo ""

      # Display each JSON file with its connector name
      for json_file in "$discovery_output_dir/discovered_configs/successful_configs/fm_configs"/*.json
      do
          if [ -f "$json_file" ]
          then
              log "📄 $(basename "$json_file")"
              # if [[ $(type -f bat 2>&1) =~ "not found" ]]
              # then
              # 	cat $json_file
              # else
              # 	bat $json_file
              # fi
              cat $json_file
          fi
      done

      log "✅ Now you can run 'playground connector connect-migration-utility migrate' to migrate these connectors to fully managed"
  fi
}

# :command.function
playground_connector_connect_migration_utility_migrate_command() {

  # src/commands/connector/connect-migration-utility/migrate.sh
  migration_mode=${args[--migration-mode]}

  get_connect_url_and_security

  discovery_output_dir="$root_folder/connect-migration-utility-discovery-output"
  if [ ! -d "$discovery_output_dir" ]
  then
  	logerror "❌ $discovery_output_dir does not exist, please run playground connect-migration-utility discovery first !"
  	exit 1
  fi

  log "🪄 Migrate discovered local connectors in $discovery_output_dir as fully managed connectors"

  get_environment_used
  if [ "$migration_mode" == "stop_create_latest_offset" ] ||  [ "$migration_mode" == "create_latest_offset" ]
  then
  	if [ "$environment" != "ccloud" ]
  	then
  		logerror "❌ --migration-mode $migration_mode is only supported with --environment ccloud"
  		exit 1
  	fi
  fi

  log "🔌 boostrapping ccloud environment"
  bootstrap_ccloud_environment "" "" "true"

  get_ccloud_connect

  for json_file in "$discovery_output_dir/discovered_configs/successful_configs/fm_configs"/*.json
  do
  	if [ -f "$json_file" ]
  	then
  		log "📄 $(basename "$json_file")"
  		log "✨ Update the connector config file $(basename "$json_file") as per your needs, save and close the file to continue"
  		playground open --file "$json_file" --wait
  	fi
  done

  set +e
  docker run -i --rm --network=host -v "$discovery_output_dir:/discovery_output_dir" vdesabou/docker-connect-migration-utility:latest bash -c "python src/migrate_connector_script.py --worker-urls 'http://localhost:8083' --disable-ssl-verify --environment-id $environment --cluster-id $cluster --bearer-token $CLOUD_API_KEY:$CLOUD_API_SECRET --kafka-auth-mode KAFKA_API_KEY --kafka-api-key $CLOUD_KEY --kafka-api-secret $CLOUD_SECRET --fm-config-dir /discovery_output_dir/discovered_configs/successful_configs/fm_configs --migration-mode $migration_mode" > /tmp/output.log 2>&1
  ret=$?
  set -e
  if [ $ret -ne 0 ]
  then
  	logerror "❌ Failed to Migrate Kafka Connectors, check output below"
  	cat /tmp/output.log
  	exit 1
  else
  	set +e
  	grep "ERROR" /tmp/output.log > /dev/null 2>&1
  	if [ $? -eq 0 ]
  	then
  		logerror "❌ Found ERROR in the output of the migration process, please check output below"
  		grep "ERROR" /tmp/output.log
  		exit 1
  	fi
  	set -e
  	log "✅ Migrate Kafka Connectors was successful!"
  	playground switch-ccloud

  	playground connector status

  	if [ -z "$GITHUB_RUN_NUMBER" ]
  	then
  		# not running with CI
  		log "Do you want to see the connector in your browser ?"
  		check_if_continue
  		playground connector open-ccloud-connector-in-browser
  	fi
  fi
}

# :command.function
playground_connector_create_or_update_command() {

  # src/commands/connector/create-or-update.sh
  connector="${args[--connector]}"
  json=${args[json]}
  level=${args[--level]}
  package=${args[--package]}
  validate=${args[--validate]}
  wait_for_zero_lag=${args[--wait-for-zero-lag]}
  skip_automatic_connector_config=${args[--skip-automatic-connector-config]}
  verbose="${args[--verbose]}"
  no_clipboard="${args[--no-clipboard]}"
  offsets=${args[--offsets]}
  initial_state=${args[--initial-state]}

  connector_type=$(playground state get run.connector_type)

  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
      if [[ -n "$level" ]]
      then
          logerror "❌ --level is set but not supported with $connector_type connector"
          exit 1
      fi

      if [[ -n "$package" ]]
      then
          logerror "❌ --package is set but not supported with $connector_type connector"
          exit 1
      fi
  fi

  if [[ -n "$initial_state" ]]
  then
      tag=$(docker ps --format '{{.Image}}' | grep -E 'confluentinc/cp-.*-connect-.*:' | awk -F':' '{print $2}')
      if [ $? != 0 ] || [ "$tag" == "" ]
      then
          logerror "❌ could not find current CP version from docker ps"
          exit 1
      fi

      if ! version_gt $tag "7.6.99"; then
          logerror "❌ --initial-state is available since CP 7.7 only"
          exit 1
      fi
  fi

  environment=$(playground state get run.environment_before_switch)
  if [ "$environment" = "" ]
  then
      environment=$(playground state get run.environment)
  fi

  if [ "$environment" = "" ]
  then
      environment="plaintext"
  fi

  if [ "$json" = "-" ]
  then
      # stdin
      json_content=$(cat "$json")
  else
      json_content=$json
  fi

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi
  json_file=$tmp_dir/connector.json
  new_json_file=$tmp_dir/connector_new.json
  connector_with_offsets_file=$tmp_dir/connector_with_offsets.json
  connector_with_initial_state_file=$tmp_dir/connector_with_initial_state.json
  json_validate_file=$tmp_dir/json_validate_file

  echo "$json_content" > $json_file

  # JSON is invalid
  if ! echo "$json_content" | jq -e .  > /dev/null 2>&1
  then
      set +e
      jq_output=$(jq . "$json_file" 2>&1)
      error_line=$(echo "$jq_output" | grep -oE 'parse error.*at line [0-9]+' | grep -oE '[0-9]+')

      if [[ -n "$error_line" ]]; then
          logerror "❌ Invalid JSON at line $error_line"
      fi
      set -e

      if [ -z "$GITHUB_RUN_NUMBER" ]
      then
          if [[ $(type -f bat 2>&1) =~ "not found" ]]
          then
              cat -n $json_file
          else
              bat $json_file --highlight-line $error_line
          fi
      fi
      exit 1
  fi

  is_create=1
  set +e
  connectors=$(playground get-connector-list)
  ret=$?
  if [ $ret -ne 0 ]
  then
      logerror "❌ Failed to get list of connectors"
      playground get-connector-list
      exit 1
  fi
  set -e
  items=($connectors)
  for con in ${items[@]}
  do
      if [[ "$con" == "$connector" ]]
      then
          is_create=0
      fi
  done

  if [[ -n "$validate" ]]
  then
      log "✅ --validate is set"
      set +e
      connector_class=$(echo "$json_content" | jq -r '."connector.class"')

      if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
      then
          get_ccloud_connect
          handle_ccloud_connect_rest_api "curl $security -s -X PUT -H \"Content-Type: application/json\" -H \"authorization: Basic $authorization\" --data @$json_file https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connector-plugins/$connector_class/config/validate"
      else
          get_connect_url_and_security
          if [[ -n "$skip_automatic_connector_config" ]]
          then
              log "🤖 --skip-automatic-connector-config is set"
          else
              add_connector_config_based_on_environment "$environment" "$json_content"
          fi
          # add mandatory name field
          new_json_content=$(echo "$json_content" | jq ". + {\"name\": \"$connector\"}")

          echo "$new_json_content" > $new_json_file
          handle_onprem_connect_rest_api "curl $security -s -X PUT -H \"Content-Type: application/json\" --data @$new_json_file $connect_url/connector-plugins/$connector_class/config/validate"
      fi
      set -e
      if ! echo "$curl_output" | jq -e .  > /dev/null 2>&1
      then
          set +e
          echo "$curl_output" > $json_validate_file
          jq_output=$(jq . "$json_validate_file" 2>&1)
          error_line=$(echo "$jq_output" | grep -oE 'parse error.*at line [0-9]+' | grep -oE '[0-9]+')

          if [[ -n "$error_line" ]]; then
              logerror "❌ Invalid JSON at line $error_line"
          fi
          set -e

          if [ -z "$GITHUB_RUN_NUMBER" ]
          then
              if [[ $(type -f bat 2>&1) =~ "not found" ]]
              then
                  cat -n $json_validate_file
              else
                  bat $json_validate_file --highlight-line $error_line
              fi
          fi

          exit 1
      fi

      # Check if there were any errors
      has_errors=$(echo "$curl_output" | jq '.configs[] | select(.value.errors | length > 0) | length' | tr -d '\n')

      if [[ "$has_errors" -gt 0 ]]
      then
          output=$(echo "$curl_output" | jq -r '.configs[] | select(.value.errors | length > 0) | .value.name + " ->> " + (.value.errors | to_entries | map("\(.value|tostring)") | join(", "))')
          logerror "❌ Validation errors found in connector config\n$output"

          exit 1
      else
          log "✅ $connector_type connector config is valid !"
      fi
  fi

  if [ $is_create == 1 ]
  then
      log "🛠️ Creating $connector_type connector $connector"
  else
      log "🔄 Updating $connector_type connector $connector"
  fi

  if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
  then
      if [[ -n "$offsets" ]] && [ $is_create == 0 ]
      then
          logerror "❌ --offsets is set but $connector_type connector $connector already exists"
          exit 1
      fi

      if [[ -n "$initial_state" ]]
      then
          logerror "❌ --initial-state is set but not supported with $connector_type connector"
          exit 1
      fi

      get_ccloud_connect
      if [[ -n "$offsets" ]]
      then
          log "📍 creating $connector_type connector $connector with offsets: $offsets"

          # add mandatory name field
          new_json_content=$(echo "$json_content" | jq -c ". + {\"name\": \"$connector\"}")

          sed -e "s|:CONNECTOR_NAME:|$connector|g" \
              -e "s|:CONNECTOR_CONFIG:|$new_json_content|g" \
              -e "s|:CONNECTOR_OFFSETS:|$offsets|g" \
              $root_folder/scripts/cli/src/create-connector-post-template.json > ${connector_with_offsets_file}

          handle_ccloud_connect_rest_api "curl $security -s -X POST -H \"Content-Type: application/json\" -H \"authorization: Basic $authorization\" --data @$connector_with_offsets_file https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors"
      else
          handle_ccloud_connect_rest_api "curl $security -s -X PUT -H \"Content-Type: application/json\" -H \"authorization: Basic $authorization\" --data @$json_file https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/config"
      fi
  else
      if [[ -n "$offsets" ]]
      then
          logerror "❌ --offsets is set but not supported with $connector_type connector"
          exit 1
      fi
      if [[ -n "$initial_state" ]] && [ $is_create == 0 ]
      then
          logerror "❌ --initial-state is set but $connector_type connector $connector already exists"
          exit 1
      fi
      get_connect_url_and_security
      if [[ -n "$skip_automatic_connector_config" ]]
      then
          log "🤖 --skip-automatic-connector-config is set"
      else
          add_connector_config_based_on_environment "$environment" "$json_content"
      fi

      if [[ -n "$initial_state" ]]
      then
          log "🪵 creating $connector_type connector $connector with --initial-state: $initial_state"

          # add mandatory name field
          new_json_content=$(echo "$json_content" | sed 's/&/:AMPERSAND:/g' | jq -c ". + {\"name\": \"$connector\"}")

          sed -e "s|:CONNECTOR_NAME:|$connector|g" \
              -e "s|:CONNECTOR_CONFIG:|$new_json_content|g" \
              -e "s|:CONNECTOR_INITIAL_STATE:|$initial_state|g" \
              $root_folder/scripts/cli/src/create-connector-post-template-initial-state.json > /tmp/connector_with_initial_state_file.json

          sed -e "s|:AMPERSAND:|\&|g" /tmp/connector_with_initial_state_file.json > ${connector_with_initial_state_file}

          handle_onprem_connect_rest_api "curl $security -s -X POST -H \"Content-Type: application/json\" --data @$connector_with_initial_state_file $connect_url/connectors"
      else
          echo "$json_content" > $new_json_file
          handle_onprem_connect_rest_api "curl $security -s -X PUT -H \"Content-Type: application/json\" --data @$new_json_file $connect_url/connectors/$connector/config"
      fi
  fi

  echo "$json_content" > "/tmp/config-$connector"

  if [ -z "$GITHUB_RUN_NUMBER" ]
  then
      if [[ "$OSTYPE" == "darwin"* ]]
      then
          clipboard=$(playground config get clipboard)
          if [ "$clipboard" == "" ]
          then
              playground config set clipboard true
          fi

          if ( [ "$clipboard" == "true" ] || [ "$clipboard" == "" ] ) && [[ ! -n "$no_clipboard" ]]
          then
              tmp_dir_clipboard=$(mktemp -d -t pg-XXXXXXXXXX)
              if [ -z "$PG_VERBOSE_MODE" ]
              then
                  trap 'rm -rf $tmp_dir_clipboard' EXIT
              else
                  log "🐛📂 not deleting tmp dir $tmp_dir_clipboard"
              fi
              echo "playground connector create-or-update --connector $connector << EOF" > $tmp_dir_clipboard/tmp
            cat "/tmp/config-$connector" | jq -S . | sed 's/\$/\\$/g' >> $tmp_dir_clipboard/tmp
            echo "EOF" >> $tmp_dir_clipboard/tmp

            cat $tmp_dir_clipboard/tmp | pbcopy
            log "📋 $connector_type connector config has been copied to the clipboard (disable with 'playground config clipboard false')"
        fi
    fi
fi

if [[ -n "$level" ]]
then
    if [[ -n "$package" ]]
    then
        playground debug log-level set --level $level --package $package
    else
        playground connector log-level --connector $connector --level $level
    fi
fi
if [ $is_create == 1 ]
then
    log "✅ $connector_type connector $connector was successfully created"
else
    log "✅ $connector_type connector $connector was successfully updated"
fi
if [ -z "$GITHUB_RUN_NUMBER" ]
then
    playground connector show-config --connector "$connector" --no-clipboard
fi

playground connector show-config-parameters --connector "$connector" --only-show-json
log "🥁 Waiting a few seconds to get new status"
sleep 5
set +e
playground connector status --connector $connector
if [ "$connector_type" == "$CONNECTOR_TYPE_ONPREM" ] || [ "$connector_type" == "$CONNECTOR_TYPE_SELF_MANAGED" ]
then
    playground connector open-docs --only-show-url
fi
set -e

if [[ -n "$wait_for_zero_lag" ]]
then
    maybe_id=""
    if [ "$connector_type" == "$CONNECTOR_TYPE_FULLY_MANAGED" ] || [ "$connector_type" == "$CONNECTOR_TYPE_CUSTOM" ]
    then
        handle_ccloud_connect_rest_api "curl -s --request GET \"https://api.confluent.cloud/connect/v1/environments/$environment/clusters/$cluster/connectors/$connector/status\" --header \"authorization: Basic $authorization\""
        connectorId=$(get_ccloud_connector_lcc $connector)
        maybe_id=" ($connectorId)"
    else
        handle_onprem_connect_rest_api "curl -s $security \"$connect_url/connectors/$connector/status\""
    fi

    type=$(echo "$curl_output" | jq -r '.type')
    if [ "$type" != "sink" ]
    then
        logwarn "⏭️ --wait-for-zero-lag is set but $connector_type connector ${connector}${maybe_id} is not a sink"
    fi
    playground connector show-lag --connector $connector
fi

}

# :command.function
playground_connector_update_command() {

  # src/commands/connector/update.sh
  connector="${args[--connector]}"

  connector_type=$(playground state get run.connector_type)

  if [[ ! -n "$connector" ]]
  then
      connector=$(playground get-connector-list)
      if [ "$connector" == "" ]
      then
          log "💤 No $connector_type connector is running !"
          exit 1
      fi
  fi

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  items=($connector)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --connector flag was not provided, applying command to all connectors"
  fi
  for connector in "${items[@]}"
  do
      log "🛠️ Updating $connector_type connector $connector"
      file=$tmp_dir/config-$connector.sh

      set +e
      echo "#!/bin/bash" > $file
      echo -e "" >> $file
      echo -e "##########################" >> $file
      echo "# this is the part to edit" >> $file
      playground connector show-config --connector "$connector" --no-clipboard | grep -v "Current config for" >> $file
      if [ $? -ne 0 ]
      then
          logerror "❌ playground connector show-config --connector $connector failed with:"
          cat $file
          exit 1
      fi
      set -e
      echo "# end of part to edit" >> $file
      echo -e "##########################" >> $file
      echo -e "" >> $file
      echo "exit 0" >> $file

      echo -e "" >> $file
      docs_links=$(playground state get run.connector_docs_links)
      if [ "$docs_links" != "" ]
      then
          for docs_link in $(echo "${docs_links}" | tr '|' ' ')
          do
              name=$(echo "$docs_link" | cut -d "@" -f 1)
              url=$(echo "$docs_link" | cut -d "@" -f 2)
              echo "🌐⚡ documentation for $connector_type connector $name is available at:" >> $file
              echo "$url" >> $file
          done
      else
          playground connector open-docs --only-show-url | sed -r "s/\x1B\[([0-9]{1,2}(;[0-9]{1,2})?)?[mGK]//g" >> $file
      fi

      echo -e "" >> $file
      playground connector show-config-parameters --connector $connector  | sed -r "s/\x1B\[([0-9]{1,2}(;[0-9]{1,2})?)?[mGK]//g" >> $file

      log "✨ Update the connector config as per your needs, save and close the file to continue"
      playground open --file "${file}" --wait
      bash $file
  done

}

# :command.function
playground_ec2_create_command() {

  # src/commands/ec2/create.sh
  suffix="${args[--suffix]}"
  instance_type="${args[--instance-type]}"
  ec2_size="${args[--size]}"

  username=$(whoami)
  if [[ -n "$suffix" ]]
  then
      suffix_kebab="${suffix// /-}"
      suffix_kebab=$(echo "$suffix_kebab" | tr '[:upper:]' '[:lower:]')
  else
      suffix_kebab=$(LC_ALL=C tr -dc 'a-z0-9' < /dev/urandom | fold -w 6 | head -n 1)
  fi
  name="pg-${username}-${suffix_kebab}"
  pem_file="$root_folder/$name.pem"

  if [ -z "$AWS_REGION" ]
  then
      AWS_REGION=$(aws configure get region | tr '\r' '\n')
      if [ "$AWS_REGION" == "" ]
      then
          logerror "❌ either the file $HOME/.aws/config is not present or environment variables AWS_REGION is not set!"
          exit 1
      fi
  fi

  # check if instance already exists
  res=$(playground ec2 status --instance "$name" --all)
  if [ "$res" != "" ]
  then
      logerror "❌ ec2 instance $name already exists"
      logerror "use playground ec2 delete --instance $name to delete it"
      exit 1
  fi

  log "🔐 creating pem file $pem_file (make sure to create backup)"
  aws ec2 create-key-pair --key-name "$name" --key-type rsa --key-format pem --query "KeyMaterial" --output text > $pem_file

  if ! grep "BEGIN RSA PRIVATE KEY" $pem_file > /dev/null
  then
      logerror "❌ failed to create pem file $pem_file"
      cat $pem_file
      exit 1
  fi
  chmod 400 $pem_file

  cloud_formation_yml_file="$root_folder/cloudformation/kafka-docker-playground.yml"
  myip=$(dig @resolver4.opendns.com myip.opendns.com +short)
  key_name=$(basename $pem_file .pem)

  tmp_dir=$(mktemp -d -t pg-XXXXXXXXXX)
  if [ -z "$PG_VERBOSE_MODE" ]
  then
      trap 'rm -rf $tmp_dir' EXIT
  else
      log "🐛📂 not deleting tmp dir $tmp_dir"
  fi

  cd $tmp_dir
  cp "$cloud_formation_yml_file" tmp.yml

  log "👷 creating ${instance_type} instance $name in $AWS_REGION region (${ec2_size} Gb)"
  log "🌀 cloud formation file used: $cloud_formation_yml_file"
  log "🔐 ec2 pem file used: $pem_file"
  aws cloudformation create-stack \
      --stack-name $name \
      --template-body "file://tmp.yml" \
      --region ${AWS_REGION} \
      --parameters ParameterKey=InstanceType,ParameterValue=${instance_type} \
                   ParameterKey=Ec2RootVolumeSize,ParameterValue=${ec2_size} \
                   ParameterKey=KeyName,ParameterValue=${key_name} \
                   ParameterKey=InstanceName,ParameterValue=$name \
                   ParameterKey=IPAddressRange,ParameterValue=${myip}/32 \
                   ParameterKey=SecretsEncryptionPassword,ParameterValue="${SECRETS_ENCRYPTION_PASSWORD}" \
                   ParameterKey=LinuxUserName,ParameterValue="${username}" \
      --tags Key=cflt_managed_by,Value=user \
             Key=cflt_managed_id,Value="${USER}"
  cd - > /dev/null

  wait_for_ec2_instance_to_be_running "$name"

  instance="$(playground ec2 status --instance "$name" --all)"
  if [ $? != 0 ] || [ -z "$instance" ]
  then
      logerror "❌ failed to get instance with name $name"
      playground ec2 status --instance "$name" --all
      exit 1
  fi
  log "👷 ec2 instance $name is created and accesible via SSH, it will be opened with visual studio code in 3 minutes..."
  log "🌀 cloud formation is still in progress (installing docker, etc...) and can be reverted after 10 minutes (i.e removing ec2 instance) in case of issue. You can check progress by checking log file output.log in root folder of ec2 instance"
  sleep 180
  playground ec2 open --instance "$instance"

  wait_for_ec2_cloudformation_to_be_completed "$name"

  playground ec2 sync-repro-folder local-to-ec2 --instance "$instance" > /dev/null
  log "🎉 ec2 instance $name is ready!"
  log "🐚 make sure to use zsh in order to have everything working out of the box"
}

# :command.function
playground_ec2_delete_command() {

  # src/commands/ec2/delete.sh
  instance="${args[--instance]}"

  if [[ $instance == *"@"* ]]
  then
      instance=$(echo "$instance" | cut -d "@" -f 2)
  fi

  if [[ ! -n "$instance" ]]
  then
      instance=$(playground --output-level WARN ec2 list)
      if [ "$instance" == "" ]
      then
          log "💤 No ec2 instance was found !"
          exit 1
      fi
  fi

  items=($instance)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --instance flag was not provided, applying command to all ec2 instances"
      check_if_continue
  fi
  for instance in "${items[@]}"
  do
      name=$(echo "${instance}" | cut -d "/" -f 1)
      state=$(echo "${instance}" | cut -d "/" -f 2)

      log "❌ deleting ec2 cloudformation $name in state $state"
      aws cloudformation delete-stack --stack-name $name
      remove_ec2_instance_from_running_list "$name"

      pem_file="$root_folder/$name.pem"

      if [ -f "$pem_file" ]
      then
          log "🔐 deleting pem file $pem_file"
          rm -f "$pem_file"
          log "🔐 deleting pem $name on aws"
          aws ec2 delete-key-pair --key-name "$name"
      fi
  done
}

# :command.function
playground_ec2_open_command() {

  # src/commands/ec2/open.sh
  instance="${args[--instance]}"
  enable_sync_repro_folder="${args[--enable-sync-repro-folder]}"

  if [[ $(type code 2>&1) =~ "not found" ]]
  then
      logerror "❌ code command is not found - this command requires vscode to be installed"
      exit 1
  fi

  if [[ $instance == *"@"* ]]
  then
      instance=$(echo "$instance" | cut -d "@" -f 2)
  fi

  if [[ ! -n "$instance" ]]
  then
      instance=$(playground --output-level WARN ec2 list)
      if [ "$instance" == "" ]
      then
          log "💤 No ec2 instance was found !"
          exit 1
      fi
  fi

  username=$(whoami)
  items=($instance)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --instance flag was not provided, applying command to all ec2 instances"
  fi
  for instance in "${items[@]}"
  do
      name=$(echo "${instance}" | cut -d "/" -f 1)
      state=$(echo "${instance}" | cut -d "/" -f 2)

      if [ "$state" != "$EC2_INSTANCE_STATE_STOPPED" ] && [ "$state" != "$EC2_INSTANCE_STATE_RUNNING" ]
      then
          log "ec2 instance $name is in state $state (not stopped and not running), skipping it"
          continue
      fi

      playground ec2 allow-my-ip --instance "$instance"

      if [[ -n "$enable_sync_repro_folder" ]]
      then
          instance="$(playground ec2 status --instance "$name" --all)"
          playground ec2 sync-repro-folder local-to-ec2 --instance "$instance"

      fi

      log "👨‍💻 Open EC2 instance $name using Visual Studio code"
      log "🐚 make sure to use zsh in order to have everything working out of the box"
      code --folder-uri "vscode-remote://ssh-remote+$name/home/$username"
  done
}

# :command.function
playground_ec2_allow_my_ip_command() {

  # src/commands/ec2/allow-my-ip.sh
  instance="${args[--instance]}"

  if [[ $instance == *"@"* ]]
  then
      instance=$(echo "$instance" | cut -d "@" -f 2)
  fi

  if [[ ! -n "$instance" ]]
  then
      instance=$(playground --output-level WARN ec2 list)
      if [ "$instance" == "" ]
      then
          log "💤 No ec2 instance was found !"
          exit 1
      fi
  fi

  items=($instance)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --instance flag was not provided, applying command to all ec2 instances"
  fi
  for instance in "${items[@]}"
  do
      name=$(echo "${instance}" | cut -d "/" -f 1)
      state=$(echo "${instance}" | cut -d "/" -f 2)
      ip=$(echo "${instance}" | cut -d "/" -f 3)
      id=$(echo "${instance}" | cut -d "/" -f 4)

      pem_file="$root_folder/$name.pem"

      if [ ! -f "$pem_file" ]
      then
          logerror "❌ aws ec2 pem file $pem_file file does not exist"
          exit 1
      fi

      group=$(aws ec2 describe-instances --instance-id "$id" --output=json | jq '.Reservations[] | .Instances[] | {SecurityGroups: .SecurityGroups}' | jq -r '.SecurityGroups[0] | .GroupName')

      # delete all rules
      aws ec2 revoke-security-group-ingress --group-name "$group" \
      --ip-permissions \
      "$(aws ec2 describe-security-groups --output json --group-name "$group" --query "SecurityGroups[0].IpPermissions")" > /dev/null

      myip=$(dig @resolver4.opendns.com myip.opendns.com +short)
      aws ec2 authorize-security-group-ingress --group-name "$group" --protocol tcp --port 22 --cidr "$myip/32" > /dev/null 2>&1 &
      if [ "$state" = "$EC2_INSTANCE_STATE_STOPPED" ]
      then
          log "🟢 starting the ec2 instance $name"
          aws ec2 start-instances --instance-ids "$id"
          wait_for_ec2_instance_to_be_running "$name"
          ip=$(aws ec2 describe-instances --instance-ids "$id" | jq ".Reservations[0].Instances[0].PublicDnsName" | tr -d '"')
      fi

      mkdir -p $HOME/.ssh
      username=$(whoami)
      ssh_config_file=$HOME/.ssh/config

      if [ -f "$ssh_config_file" ]
      then
          if grep "Host $name" -A 1 "$ssh_config_file" | grep "$ip" > /dev/null
          then
              log "🛂 ip $myip is now allowed to connect to ec2 instance $name"
              continue
          fi
      fi

      set +e
      grep "$name" "$ssh_config_file" > /dev/null
      if [ $? = 0 ]
      then
          old_ip=$(grep -w $name -A 1 ${ssh_config_file} | awk '/HostName/ {print $2}')
          sed -e "s/$old_ip/$ip/g" ${ssh_config_file} > /tmp/tmp_file
          mv /tmp/tmp_file "${ssh_config_file}"
      else
      cat << EOF >> "${ssh_config_file}"

    Host $name
    HostName $ip
    IdentityFile $pem_file
    User $username
    StrictHostKeyChecking no
EOF

      fi
      set -e

      log "🛂 ip $myip is now allowed to connect to ec2 instance $name"
      add_ec2_instance_to_running_list "$name"
  done
}

# :command.function
playground_ec2_list_command() {

  # src/commands/ec2/list.sh
  log "🔘 listing all your ec2 instances"
  ec2_instance_list
}

# :command.function
playground_ec2_stop_command() {

  # src/commands/ec2/stop.sh
  instance="${args[--instance]}"

  if [[ $instance == *"@"* ]]
  then
      instance=$(echo "$instance" | cut -d "@" -f 2)
  fi

  if [[ ! -n "$instance" ]]
  then
      instance=$(playground --output-level WARN ec2 list)
      if [ "$instance" == "" ]
      then
          log "💤 No ec2 instance was found !"
          exit 1
      fi
  fi

  items=($instance)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --instance flag was not provided, applying command to all ec2 instances"
  fi
  for instance in "${items[@]}"
  do
      name=$(echo "${instance}" | cut -d "/" -f 1)
      state=$(echo "${instance}" | cut -d "/" -f 2)
      id=$(echo "${instance}" | cut -d "/" -f 4)

      if [ "$state" != "$EC2_INSTANCE_STATE_STOPPED" ] && [ "$state" != "$EC2_INSTANCE_STATE_RUNNING" ]
      then
          log "ec2 instance $name is in state $state (not stopped and not running), skipping it"
          continue
      fi

      if [ "$state" != "$EC2_INSTANCE_STATE_STOPPED" ]
      then
          log "🔴 stopping ec2 instance $name"
          aws ec2 stop-instances --instance-ids "$id"
          remove_ec2_instance_from_running_list "$name"
      else
          log "ec2 instance $name is already stopped"
      fi
  done
}

# :command.function
playground_ec2_start_command() {

  # src/commands/ec2/start.sh
  instance="${args[--instance]}"

  if [[ $instance == *"@"* ]]
  then
      instance=$(echo "$instance" | cut -d "@" -f 2)
  fi

  if [[ ! -n "$instance" ]]
  then
      instance=$(playground --output-level WARN ec2 list)
      if [ "$instance" == "" ]
      then
          log "💤 No ec2 instance was found !"
          exit 1
      fi
  fi

  items=($instance)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --instance flag was not provided, applying command to all ec2 instances"
  fi
  for instance in "${items[@]}"
  do
      name=$(echo "${instance}" | cut -d "/" -f 1)
      state=$(echo "${instance}" | cut -d "/" -f 2)

      if [ "$state" != "$EC2_INSTANCE_STATE_STOPPED" ] && [ "$state" != "$EC2_INSTANCE_STATE_RUNNING" ]
      then
          log "ec2 instance $name is in state $state (not stopped and not running), skipping it"
          continue
      fi

      if [ "$state" != "$EC2_INSTANCE_STATE_RUNNING" ]
      then
          playground ec2 allow-my-ip --instance "$instance"
      else
          log "ec2 instance $name is already running"
      fi
  done
}

# :command.function
playground_ec2_status_command() {

  # src/commands/ec2/status.sh
  instance_name="${args[--instance]}"
  all="${args[--all]}"

  for instance in $(ec2_instance_list)
  do
      name=$(echo "${instance}" | cut -d "/" -f 1)
      state=$(echo "${instance}" | cut -d "/" -f 2)
      ip=$(echo "${instance}" | cut -d "/" -f 3)
      id=$(echo "${instance}" | cut -d "/" -f 4)

      if [ "$name" = "$instance_name" ]
      then
          if [[ -n "$all" ]]
          then
              echo "$name/$state/$ip/$id"
          else
              echo "$state"
          fi
      fi
  done
}

# :command.function
playground_ec2_sync_repro_folder_local_to_ec2_command() {

  # src/commands/ec2/sync-repro-folder/local-to-ec2.sh
  instance="${args[--instance]}"

  if [[ $instance == *"@"* ]]
  then
      instance=$(echo "$instance" | cut -d "@" -f 2)
  fi

  if [[ ! -n "$instance" ]]
  then
      instance=$(playground --output-level WARN ec2 list)
      if [ "$instance" == "" ]
      then
          log "💤 No ec2 instance was found !"
          exit 1
      fi
  fi

  items=($instance)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --instance flag was not provided, applying command to all ec2 instances"
  fi
  for instance in "${items[@]}"
  do
      name=$(echo "${instance}" | cut -d "/" -f 1)
      state=$(echo "${instance}" | cut -d "/" -f 2)
      ip=$(echo "${instance}" | cut -d "/" -f 3)

      pem_file="$root_folder/$name.pem"
      username=$(whoami)

      if [ ! -f "$pem_file" ]
      then
          logerror "❌ aws ec2 pem file $pem_file file does not exist"
          exit 1
      fi

      if [ "$state" != "$EC2_INSTANCE_STATE_STOPPED" ] && [ "$state" != "$EC2_INSTANCE_STATE_RUNNING" ]
      then
          log "ec2 instance $name is in state $state (not stopped and not running), skipping it"
          continue
      fi

      playground ec2 allow-my-ip --instance "$instance"
      instance="$(playground ec2 status --instance "$name" --all)"
      ip=$(echo "${instance}" | cut -d "/" -f 3)

      log "👉 Sync local reproduction-models folder to ec2 instance $name"
      rsync -cauv --exclude '.git' --filter=':- .gitignore' -e "ssh -i $pem_file -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null" "$root_folder/reproduction-models" "$username@$ip:/home/$username/kafka-docker-playground"
  done
}

# :command.function
playground_ec2_sync_repro_folder_ec2_to_local_command() {

  # src/commands/ec2/sync-repro-folder/ec2-to-local.sh
  instance="${args[--instance]}"

  if [[ $instance == *"@"* ]]
  then
      instance=$(echo "$instance" | cut -d "@" -f 2)
  fi

  if [[ ! -n "$instance" ]]
  then
      instance=$(playground --output-level WARN ec2 list)
      if [ "$instance" == "" ]
      then
          log "💤 No ec2 instance was found !"
          exit 1
      fi
  fi

  items=($instance)
  length=${#items[@]}
  if ((length > 1))
  then
      log "✨ --instance flag was not provided, applying command to all ec2 instances"
  fi
  for instance in "${items[@]}"
  do
      name=$(echo "${instance}" | cut -d "/" -f 1)
      state=$(echo "${instance}" | cut -d "/" -f 2)
      ip=$(echo "${instance}" | cut -d "/" -f 3)

      pem_file="$root_folder/$name.pem"
      username=$(whoami)

      if [ ! -f "$pem_file" ]
      then
          logerror "❌ aws ec2 pem file $pem_file file does not exist"
          exit 1
      fi

      if [ "$state" != "$EC2_INSTANCE_STATE_STOPPED" ] && [ "$state" != "$EC2_INSTANCE_STATE_RUNNING" ]
      then
          log "ec2 instance $name is in state $state (not stopped and not running), skipping it"
          continue
      fi

      playground ec2 allow-my-ip --instance "$instance"
      instance="$(playground ec2 status --instance "$name" --all)"
      ip=$(echo "${instance}" | cut -d "/" -f 3)

      log "👈 Sync ec2 instance $name reproduction-models folder to local"
      rsync -cauv --exclude '.git' --filter=':- .gitignore' -e "ssh -i $pem_file -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null" "$username@$ip:/home/$username/kafka-docker-playground/reproduction-models" "$root_folder"
  done
}

# :command.parse_requirements
parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --version)
        version_command
        exit
        ;;

      --help | -h)
        long_usage=yes
        playground_usage
        exit
        ;;

      # :flag.case
      --vvv | -v)

        # :flag.case_no_arg
        args['--vvv']=1
        shift
        ;;

      # :flag.case
      --output-level | -o)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--output-level']="$2"
          shift
          shift
        else
          printf "%s\n" "--output-level requires an argument: --output-level, -o LEVEL" >&2
          exit 1
        fi
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  missing_deps=
  # :dependency.filter
  if ! command -v docker >/dev/null 2>&1; then
    printf "missing dependency: docker\n" >&2
    printf "%s\n\n" "visit https://docs.docker.com/get-docker to install" >&2
    missing_deps=1
  else
    deps['docker']="$(command -v docker | head -n1)"
  fi

  if [[ -n $missing_deps ]]; then
    exit 1
  fi

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    help)
      action="help"
      shift
      playground_help_parse_requirements "$@"
      shift $#
      ;;

    status)
      action="status"
      shift
      playground_status_parse_requirements "$@"
      shift $#
      ;;

    get-docker-ports)
      action="get-docker-ports"
      shift
      playground_get_docker_ports_parse_requirements "$@"
      shift $#
      ;;

    get-connector-list)
      action="get-connector-list"
      shift
      playground_get_connector_list_parse_requirements "$@"
      shift $#
      ;;

    get-ec2-instance-list)
      action="get-ec2-instance-list"
      shift
      playground_get_ec2_instance_list_parse_requirements "$@"
      shift $#
      ;;

    get-ec2-cloudformation-list)
      action="get-ec2-cloudformation-list"
      shift
      playground_get_ec2_cloudformation_list_parse_requirements "$@"
      shift $#
      ;;

    get-zazkia-connection-list)
      action="get-zazkia-connection-list"
      shift
      playground_get_zazkia_connection_list_parse_requirements "$@"
      shift $#
      ;;

    generate-fzf-find-files)
      action="generate-fzf-find-files"
      shift
      playground_generate_fzf_find_files_parse_requirements "$@"
      shift $#
      ;;

    generate-tag-list)
      action="generate-tag-list"
      shift
      playground_generate_tag_list_parse_requirements "$@"
      shift $#
      ;;

    generate-connector-plugin-list)
      action="generate-connector-plugin-list"
      shift
      playground_generate_connector_plugin_list_parse_requirements "$@"
      shift $#
      ;;

    generate-kafka-region-list)
      action="generate-kafka-region-list"
      shift
      playground_generate_kafka_region_list_parse_requirements "$@"
      shift $#
      ;;

    get-connector-plugin)
      action="get-connector-plugin"
      shift
      playground_get_connector_plugin_parse_requirements "$@"
      shift $#
      ;;

    get-ccloud-environment-list)
      action="get-ccloud-environment-list"
      shift
      playground_get_ccloud_environment_list_parse_requirements "$@"
      shift $#
      ;;

    get-ccloud-cluster-list)
      action="get-ccloud-cluster-list"
      shift
      playground_get_ccloud_cluster_list_parse_requirements "$@"
      shift $#
      ;;

    get-tag-list)
      action="get-tag-list"
      shift
      playground_get_tag_list_parse_requirements "$@"
      shift $#
      ;;

    get-kafka-region-list)
      action="get-kafka-region-list"
      shift
      playground_get_kafka_region_list_parse_requirements "$@"
      shift $#
      ;;

    get-topic-list)
      action="get-topic-list"
      shift
      playground_get_topic_list_parse_requirements "$@"
      shift $#
      ;;

    get-subject-list)
      action="get-subject-list"
      shift
      playground_get_subject_list_parse_requirements "$@"
      shift $#
      ;;

    get-examples-list-with-fzf)
      action="get-examples-list-with-fzf"
      shift
      playground_get_examples_list_with_fzf_parse_requirements "$@"
      shift $#
      ;;

    get-zip-or-jar-with-fzf)
      action="get-zip-or-jar-with-fzf"
      shift
      playground_get_zip_or_jar_with_fzf_parse_requirements "$@"
      shift $#
      ;;

    get-specific-file-extension)
      action="get-specific-file-extension"
      shift
      playground_get_specific_file_extension_parse_requirements "$@"
      shift $#
      ;;

    get-any-file-with-fzf)
      action="get-any-file-with-fzf"
      shift
      playground_get_any_file_with_fzf_parse_requirements "$@"
      shift $#
      ;;

    get-playground-repro-export-with-fzf)
      action="get-playground-repro-export-with-fzf"
      shift
      playground_get_playground_repro_export_with_fzf_parse_requirements "$@"
      shift $#
      ;;

    get-predefined-schemas)
      action="get-predefined-schemas"
      shift
      playground_get_predefined_schemas_parse_requirements "$@"
      shift $#
      ;;

    update-cache-versions)
      action="update-cache-versions"
      shift
      playground_update_cache_versions_parse_requirements "$@"
      shift $#
      ;;

    update-readme)
      action="update-readme"
      shift
      playground_update_readme_parse_requirements "$@"
      shift $#
      ;;

    force-ci)
      action="force-ci"
      shift
      playground_force_ci_parse_requirements "$@"
      shift $#
      ;;

    update-docs)
      action="update-docs"
      shift
      playground_update_docs_parse_requirements "$@"
      shift $#
      ;;

    bashly-reload)
      action="bashly-reload"
      shift
      playground_bashly_reload_parse_requirements "$@"
      shift $#
      ;;

    state)
      action="state"
      shift
      playground_state_parse_requirements "$@"
      shift $#
      ;;

    config)
      action="config"
      shift
      playground_config_parse_requirements "$@"
      shift $#
      ;;

    ai)
      action="ai"
      shift
      playground_ai_parse_requirements "$@"
      shift $#
      ;;

    ccloud-costs)
      action="ccloud-costs"
      shift
      playground_ccloud_costs_parse_requirements "$@"
      shift $#
      ;;

    ccloud-costs-history)
      action="ccloud-costs-history"
      shift
      playground_ccloud_costs_history_parse_requirements "$@"
      shift $#
      ;;

    run)
      action="run"
      shift
      playground_run_parse_requirements "$@"
      shift $#
      ;;

    re-run)
      action="re-run"
      shift
      playground_re_run_parse_requirements "$@"
      shift $#
      ;;

    get-ci-result)
      action="get-ci-result"
      shift
      playground_get_ci_result_parse_requirements "$@"
      shift $#
      ;;

    history)
      action="history"
      shift
      playground_history_parse_requirements "$@"
      shift $#
      ;;

    start-environment)
      action="start-environment"
      shift
      playground_start_environment_parse_requirements "$@"
      shift $#
      ;;

    switch-ccloud)
      action="switch-ccloud"
      shift
      playground_switch_ccloud_parse_requirements "$@"
      shift $#
      ;;

    switch-back)
      action="switch-back"
      shift
      playground_switch_back_parse_requirements "$@"
      shift $#
      ;;

    update-version)
      action="update-version"
      shift
      playground_update_version_parse_requirements "$@"
      shift $#
      ;;

    open)
      action="open"
      shift
      playground_open_parse_requirements "$@"
      shift $#
      ;;

    stop)
      action="stop"
      shift
      playground_stop_parse_requirements "$@"
      shift $#
      ;;

    remove-all-docker-images)
      action="remove-all-docker-images"
      shift
      playground_remove_all_docker_images_parse_requirements "$@"
      shift $#
      ;;

    remove-cp-docker-images)
      action="remove-cp-docker-images"
      shift
      playground_remove_cp_docker_images_parse_requirements "$@"
      shift $#
      ;;

    refresh-cp-docker-images)
      action="refresh-cp-docker-images"
      shift
      playground_refresh_cp_docker_images_parse_requirements "$@"
      shift $#
      ;;

    cleanup-cloud-details)
      action="cleanup-cloud-details"
      shift
      playground_cleanup_cloud_details_parse_requirements "$@"
      shift $#
      ;;

    open-docs)
      action="open-docs"
      shift
      playground_open_docs_parse_requirements "$@"
      shift $#
      ;;

    open-changelog)
      action="open-changelog"
      shift
      playground_open_changelog_parse_requirements "$@"
      shift $#
      ;;

    cleanup-cloud-resources)
      action="cleanup-cloud-resources"
      shift
      playground_cleanup_cloud_resources_parse_requirements "$@"
      shift $#
      ;;

    repro)
      action="repro"
      shift
      playground_repro_parse_requirements "$@"
      shift $#
      ;;

    get-docker-compose)
      action="get-docker-compose"
      shift
      playground_get_docker_compose_parse_requirements "$@"
      shift $#
      ;;

    schema)
      action="schema"
      shift
      playground_schema_parse_requirements "$@"
      shift $#
      ;;

    tcp-proxy)
      action="tcp-proxy"
      shift
      playground_tcp_proxy_parse_requirements "$@"
      shift $#
      ;;

    tools)
      action="tools"
      shift
      playground_tools_parse_requirements "$@"
      shift $#
      ;;

    debug)
      action="debug"
      shift
      playground_debug_parse_requirements "$@"
      shift $#
      ;;

    get-jmx-metrics)
      action="get-jmx-metrics"
      shift
      playground_get_jmx_metrics_parse_requirements "$@"
      shift $#
      ;;

    container)
      action="container"
      shift
      playground_container_parse_requirements "$@"
      shift $#
      ;;

    topic)
      action="topic"
      shift
      playground_topic_parse_requirements "$@"
      shift $#
      ;;

    connector-plugin)
      action="connector-plugin"
      shift
      playground_connector_plugin_parse_requirements "$@"
      shift $#
      ;;

    connector)
      action="connector"
      shift
      playground_connector_parse_requirements "$@"
      shift $#
      ;;

    ec2)
      action="ec2"
      shift
      playground_ec2_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.whitelist_filter
  if [[ ${args['--output-level']:-} ]] && [[ ! ${args['--output-level']:-} =~ ^(INFO|WARN|ERROR)$ ]]; then
    printf "%s\n" "--output-level must be one of: INFO, WARN, ERROR" >&2
    exit 1
  fi

  # :command.user_filter
  filter_error=$(filter_docker_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_help_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_help_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="help"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['command']+x} ]]; then
          args['command']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_status_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_status_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="status"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_docker_ports_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_get_docker_ports_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-docker-ports"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_connector_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_get_connector_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-connector-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_ec2_instance_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_get_ec2_instance_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-ec2-instance-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['cur']+x} ]]; then
          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_ec2_cloudformation_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_get_ec2_cloudformation_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-ec2-cloudformation-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['cur']+x} ]]; then
          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_zazkia_connection_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_get_zazkia_connection_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-zazkia-connection-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_generate_fzf_find_files_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_generate_fzf_find_files_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="generate-fzf-find-files"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_generate_tag_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_generate_tag_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="generate-tag-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_generate_connector_plugin_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_generate_connector_plugin_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="generate-connector-plugin-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_generate_kafka_region_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_generate_kafka_region_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  missing_deps=
  # :dependency.filter
  if ! command -v confluent >/dev/null 2>&1; then
    printf "missing dependency: confluent\n" >&2
    printf "%s\n\n" "visit https://docs.confluent.io/confluent-cli/current/overview.html to install" >&2
    missing_deps=1
  else
    deps['confluent']="$(command -v confluent | head -n1)"
  fi

  if [[ -n $missing_deps ]]; then
    exit 1
  fi

  # :command.command_filter
  action="generate-kafka-region-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_connector_plugin_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_get_connector_plugin_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-connector-plugin"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['cur']+x} ]]; then
          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_ccloud_environment_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_get_ccloud_environment_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-ccloud-environment-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['cur']+x} ]]; then
          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_ccloud_cluster_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_get_ccloud_cluster_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-ccloud-cluster-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['cur']+x} ]]; then
          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_tag_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_get_tag_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-tag-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connect-only)

        # :flag.case_no_arg
        args['--connect-only']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['cur']+x} ]]; then
          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_kafka_region_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_get_kafka_region_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  missing_deps=
  # :dependency.filter
  if ! command -v confluent >/dev/null 2>&1; then
    printf "missing dependency: confluent\n" >&2
    printf "%s\n\n" "visit https://docs.confluent.io/confluent-cli/current/overview.html to install" >&2
    missing_deps=1
  else
    deps['confluent']="$(command -v confluent | head -n1)"
  fi

  if [[ -n $missing_deps ]]; then
    exit 1
  fi

  # :command.command_filter
  action="get-kafka-region-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['cur']+x} ]]; then
          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_topic_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_get_topic_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-topic-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --skip-connect-internal-topics)

        # :flag.case_no_arg
        args['--skip-connect-internal-topics']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_subject_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_get_subject_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-subject-list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --deleted)

        # :flag.case_no_arg
        args['--deleted']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_examples_list_with_fzf_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_get_examples_list_with_fzf_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-examples-list-with-fzf"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --without-repro)

        # :flag.case_no_arg
        args['--without-repro']=1
        shift
        ;;

      # :flag.case
      --sink-only)

        # :flag.case_no_arg
        args['--sink-only']=1
        shift
        ;;

      # :flag.case
      --ccloud-only)

        # :flag.case_no_arg
        args['--ccloud-only']=1
        shift
        ;;

      # :flag.case
      --connector-only)

        # :flag.case_no_arg
        args['--connector-only']=1
        shift
        ;;

      # :flag.case
      --repro-only)

        # :flag.case_no_arg
        args['--repro-only']=1
        shift
        ;;

      # :flag.case
      --environment-only)

        # :flag.case_no_arg
        args['--environment-only']=1
        shift
        ;;

      # :flag.case
      --fully-managed-connector-only)

        # :flag.case_no_arg
        args['--fully-managed-connector-only']=1
        shift
        ;;

      # :flag.case
      --ksql-only)

        # :flag.case_no_arg
        args['--ksql-only']=1
        shift
        ;;

      # :flag.case
      --schema-registry-only)

        # :flag.case_no_arg
        args['--schema-registry-only']=1
        shift
        ;;

      # :flag.case
      --rest-proxy-only)

        # :flag.case_no_arg
        args['--rest-proxy-only']=1
        shift
        ;;

      # :flag.case
      --academy-only)

        # :flag.case_no_arg
        args['--academy-only']=1
        shift
        ;;

      # :flag.case
      --other-playgrounds-only)

        # :flag.case_no_arg
        args['--other-playgrounds-only']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['cur']+x} ]]; then
          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_zip_or_jar_with_fzf_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_get_zip_or_jar_with_fzf_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-zip-or-jar-with-fzf"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --type)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--type']="$2"
          shift
          shift
        else
          printf "%s\n" "--type requires an argument: --type TYPE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['cur']+x} ]]; then
          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.whitelist_filter
  if [[ ${args['--type']:-} ]] && [[ ! ${args['--type']:-} =~ ^(zip|jar)$ ]]; then
    printf "%s\n" "--type must be one of: zip, jar" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_get_specific_file_extension_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_get_specific_file_extension_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-specific-file-extension"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --extension)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--extension']="$2"
          shift
          shift
        else
          printf "%s\n" "--extension requires an argument: --extension EXTENSION" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['cur']+x} ]]; then
          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_any_file_with_fzf_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_get_any_file_with_fzf_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-any-file-with-fzf"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['cur']+x} ]]; then
          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_playground_repro_export_with_fzf_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_get_playground_repro_export_with_fzf_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-playground-repro-export-with-fzf"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['cur']+x} ]]; then
          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_predefined_schemas_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_get_predefined_schemas_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-predefined-schemas"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['cur']+x} ]]; then
          args['cur']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_update_cache_versions_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_update_cache_versions_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.environment_variables_filter

  env_var_names+=("GH_TOKEN")

  # :command.command_filter
  action="update-cache-versions"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_update_readme_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_update_readme_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.environment_variables_filter

  env_var_names+=("GH_TOKEN")

  # :command.command_filter
  action="update-readme"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --tags)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--tags']="$2"
          shift
          shift
        else
          printf "%s\n" "--tags requires an argument: --tags TAGS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --generate-for-kb)

        # :flag.case_no_arg
        args['--generate-for-kb']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--tags'] ]]; then
    validation_output="$(validate_not_empty "${args['--tags']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--tags TAGS" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_force_ci_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_force_ci_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="force-ci"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --all)

        # :flag.case_no_arg
        args['--all']=1
        shift
        ;;

      # :flag.case
      --force)

        # :flag.case_no_arg
        args['--force']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['filename']+x} ]]; then
          args['filename']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

}

# :command.parse_requirements
playground_update_docs_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_update_docs_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="update-docs"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_bashly_reload_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_bashly_reload_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  missing_deps=
  # :dependency.filter
  if ! command -v bashly >/dev/null 2>&1; then
    printf "missing dependency: bashly\n" >&2
    printf "%s\n\n" "visit https://bashly.dannyb.co/installation/ to install" >&2
    missing_deps=1
  else
    deps['bashly']="$(command -v bashly | head -n1)"
  fi

  if [[ -n $missing_deps ]]; then
    exit 1
  fi

  # :command.command_filter
  action="bashly-reload"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_state_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_state_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    show)
      action="show"
      shift
      playground_state_show_parse_requirements "$@"
      shift $#
      ;;

    get)
      action="get"
      shift
      playground_state_get_parse_requirements "$@"
      shift $#
      ;;

    set)
      action="set"
      shift
      playground_state_set_parse_requirements "$@"
      shift $#
      ;;

    del)
      action="del"
      shift
      playground_state_del_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_state_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_state_show_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_state_show_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="state show"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_state_get_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_state_get_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="state get"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['key']+x} ]]; then
          args['key']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.required_args_filter
  if [[ -z ${args['key']+x} ]]; then
    printf "missing required argument: KEY\nusage: playground state get KEY\n" >&2
    # :command.examples_on_error
    printf "examples:\n" >&2
    printf "  playground state get hello\n" >&2
    printf "  playground state get user.name\n" >&2

    exit 1
  fi

}

# :command.parse_requirements
playground_state_set_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_state_set_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="state set"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['key']+x} ]]; then
          args['key']=$1
          shift
        # :argument.case
        elif [[ -z ${args['value']+x} ]]; then
          args['value']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.required_args_filter
  if [[ -z ${args['key']+x} ]]; then
    printf "missing required argument: KEY\nusage: playground state set KEY VALUE\n" >&2
    # :command.examples_on_error
    printf "examples:\n" >&2
    printf "  playground state set hello world\n" >&2
    printf "  playground state set user.email me@example.com\n" >&2

    exit 1
  fi

  if [[ -z ${args['value']+x} ]]; then
    printf "missing required argument: VALUE\nusage: playground state set KEY VALUE\n" >&2
    # :command.examples_on_error
    printf "examples:\n" >&2
    printf "  playground state set hello world\n" >&2
    printf "  playground state set user.email me@example.com\n" >&2

    exit 1
  fi

}

# :command.parse_requirements
playground_state_del_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_state_del_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="state del"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['key']+x} ]]; then
          args['key']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.required_args_filter
  if [[ -z ${args['key']+x} ]]; then
    printf "missing required argument: KEY\nusage: playground state del KEY\n" >&2
    # :command.examples_on_error
    printf "examples:\n" >&2
    printf "  playground state del hello\n" >&2
    printf "  playground state del user.name\n" >&2

    exit 1
  fi

}

# :command.parse_requirements
playground_config_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_config_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    show)
      action="show"
      shift
      playground_config_show_parse_requirements "$@"
      shift $#
      ;;

    get)
      action="get"
      shift
      playground_config_get_parse_requirements "$@"
      shift $#
      ;;

    set)
      action="set"
      shift
      playground_config_set_parse_requirements "$@"
      shift $#
      ;;

    editor)
      action="editor"
      shift
      playground_config_editor_parse_requirements "$@"
      shift $#
      ;;

    folder_zip_or_jar)
      action="folder_zip_or_jar"
      shift
      playground_config_folder_zip_or_jar_parse_requirements "$@"
      shift $#
      ;;

    clipboard)
      action="clipboard"
      shift
      playground_config_clipboard_parse_requirements "$@"
      shift $#
      ;;

    open-ccloud-connector-in-browser)
      action="open-ccloud-connector-in-browser"
      shift
      playground_config_open_ccloud_connector_in_browser_parse_requirements "$@"
      shift $#
      ;;

    open-grafana-in-browser)
      action="open-grafana-in-browser"
      shift
      playground_config_open_grafana_in_browser_parse_requirements "$@"
      shift $#
      ;;

    container-kill-all-before-run)
      action="container-kill-all-before-run"
      shift
      playground_config_container_kill_all_before_run_parse_requirements "$@"
      shift $#
      ;;

    check-and-update-repo-version)
      action="check-and-update-repo-version"
      shift
      playground_config_check_and_update_repo_version_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_config_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_config_show_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_config_show_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="config show"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_config_get_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_config_get_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="config get"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['key']+x} ]]; then
          args['key']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.required_args_filter
  if [[ -z ${args['key']+x} ]]; then
    printf "missing required argument: KEY\nusage: playground config get KEY\n" >&2
    # :command.examples_on_error
    printf "examples:\n" >&2
    printf "  playground config get hello\n" >&2
    printf "  playground config get user.name\n" >&2

    exit 1
  fi

}

# :command.parse_requirements
playground_config_set_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_config_set_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="config set"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['key']+x} ]]; then
          args['key']=$1
          shift
        # :argument.case
        elif [[ -z ${args['value']+x} ]]; then
          args['value']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.required_args_filter
  if [[ -z ${args['key']+x} ]]; then
    printf "missing required argument: KEY\nusage: playground config set KEY VALUE\n" >&2
    # :command.examples_on_error
    printf "examples:\n" >&2
    printf "  playground config set hello world\n" >&2
    printf "  playground config set user.email me@example.com\n" >&2

    exit 1
  fi

  if [[ -z ${args['value']+x} ]]; then
    printf "missing required argument: VALUE\nusage: playground config set KEY VALUE\n" >&2
    # :command.examples_on_error
    printf "examples:\n" >&2
    printf "  playground config set hello world\n" >&2
    printf "  playground config set user.email me@example.com\n" >&2

    exit 1
  fi

}

# :command.parse_requirements
playground_config_editor_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_config_editor_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="config editor"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['editor']+x} ]]; then
          args['editor']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.required_args_filter
  if [[ -z ${args['editor']+x} ]]; then
    printf "missing required argument: EDITOR\nusage: playground config editor EDITOR\n" >&2
    # :command.examples_on_error
    printf "examples:\n" >&2
    printf "  playground config editor vi\n" >&2
    printf "  playground config editor code\n" >&2

    exit 1
  fi

  # :command.validations
  # :argument.validations
  validation_output="$(validate_editor_exists "${args['editor']:-}")"
  if [[ -v args['editor'] && -n "$validation_output" ]]; then
    printf "validation error in %s:\n%s\n" "EDITOR" "$validation_output" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_config_folder_zip_or_jar_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_config_folder_zip_or_jar_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="config folder_zip_or_jar"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_repeatable
        # :argument.case_repeatable
        escaped="$(printf '%q' "$1")"
        if [[ -z ${args['folder']+x} ]]; then
          args['folder']="$escaped"
          unique_lookup["folder:$escaped"]=1
        elif [[ -z "${unique_lookup["folder:$escaped"]:-}" ]]; then
          args['folder']="${args['folder']} $escaped"
          unique_lookup["folder:$escaped"]=1

        fi
        shift

        ;;

    esac
  done

  # :command.required_args_filter
  if [[ -z ${args['folder']+x} ]]; then
    printf "missing required argument: FOLDER\nusage: playground config folder_zip_or_jar FOLDER...\n" >&2
    # :command.examples_on_error
    printf "examples:\n" >&2
    printf "  playground config folder_zip_or_jar ~/Downloads\n  ~/Documents/github/kafka-connect-*\n" >&2
    printf "  playground config folder_zip_or_jar ~/Downloads\n" >&2

    exit 1
  fi

  # :command.validations
  # :argument.validations
  if [[ -v args['folder'] ]]; then
    values=''
    eval "values=(${args['folder']})"
    for value in "${values[@]}"; do
      validation_output="$(validate_dir_exists "$value")"
      if [[ -n "$validation_output" ]]; then
        printf "validation error in %s:\n%s\n" "FOLDER" "$validation_output" >&2
        exit 1
      fi
    done
  fi

}

# :command.parse_requirements
playground_config_clipboard_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_config_clipboard_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="config clipboard"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['enabled']+x} ]]; then
          args['enabled']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['enabled']:-} ]] || args['enabled']="true"

}

# :command.parse_requirements
playground_config_open_ccloud_connector_in_browser_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_config_open_ccloud_connector_in_browser_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    automatically)
      action="automatically"
      shift
      playground_config_open_ccloud_connector_in_browser_automatically_parse_requirements "$@"
      shift $#
      ;;

    browser)
      action="browser"
      shift
      playground_config_open_ccloud_connector_in_browser_browser_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_config_open_ccloud_connector_in_browser_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_config_open_ccloud_connector_in_browser_automatically_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_config_open_ccloud_connector_in_browser_automatically_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="config open-ccloud-connector-in-browser automatically"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['automatically']+x} ]]; then
          args['automatically']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['automatically']:-} ]] || args['automatically']="true"

}

# :command.parse_requirements
playground_config_open_ccloud_connector_in_browser_browser_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_config_open_ccloud_connector_in_browser_browser_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="config open-ccloud-connector-in-browser browser"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['browser']+x} ]]; then
          args['browser']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['browser']:-} ]] || args['browser']=""

}

# :command.parse_requirements
playground_config_open_grafana_in_browser_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_config_open_grafana_in_browser_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    automatically)
      action="automatically"
      shift
      playground_config_open_grafana_in_browser_automatically_parse_requirements "$@"
      shift $#
      ;;

    browser)
      action="browser"
      shift
      playground_config_open_grafana_in_browser_browser_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_config_open_grafana_in_browser_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_config_open_grafana_in_browser_automatically_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_config_open_grafana_in_browser_automatically_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="config open-grafana-in-browser automatically"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['automatically']+x} ]]; then
          args['automatically']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['automatically']:-} ]] || args['automatically']="true"

}

# :command.parse_requirements
playground_config_open_grafana_in_browser_browser_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_config_open_grafana_in_browser_browser_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="config open-grafana-in-browser browser"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['browser']+x} ]]; then
          args['browser']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['browser']:-} ]] || args['browser']=""

}

# :command.parse_requirements
playground_config_container_kill_all_before_run_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_config_container_kill_all_before_run_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="config container-kill-all-before-run"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['enabled']+x} ]]; then
          args['enabled']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['enabled']:-} ]] || args['enabled']="false"

}

# :command.parse_requirements
playground_config_check_and_update_repo_version_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_config_check_and_update_repo_version_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="config check-and-update-repo-version"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['enabled']+x} ]]; then
          args['enabled']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['enabled']:-} ]] || args['enabled']="true"

}

# :command.parse_requirements
playground_ai_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_ai_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  missing_deps=
  # :dependency.filter
  if ! command -v gemini >/dev/null 2>&1; then
    printf "missing dependency: gemini\n" >&2
    printf "%s\n\n" "visit https://github.com/google-gemini/gemini-cli/tree/main?tab=readme-ov-file#-installation to install" >&2
    missing_deps=1
  else
    deps['gemini']="$(command -v gemini | head -n1)"
  fi

  # :dependency.filter
  if ! command -v kafka-mcp-server >/dev/null 2>&1; then
    printf "missing dependency: kafka-mcp-server\n" >&2
    printf "%s\n\n" "visit https://docs.tuannvm.com/kafka-mcp-server#installation to install" >&2
    missing_deps=1
  else
    deps['kafka-mcp-server']="$(command -v kafka-mcp-server | head -n1)"
  fi

  if [[ -n $missing_deps ]]; then
    exit 1
  fi

  # :command.command_filter
  action="ai"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      --)
        shift
        other_args+=("$@")
        break
        ;;

      -?*)
        other_args+=("$1")
        shift
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_catch_all
        other_args+=("$1")
        shift

        ;;

    esac
  done

}

# :command.parse_requirements
playground_ccloud_costs_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_ccloud_costs_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  missing_deps=
  # :dependency.filter
  if ! command -v confluent >/dev/null 2>&1; then
    printf "missing dependency: confluent\n" >&2
    printf "%s\n\n" "visit https://docs.confluent.io/confluent-cli/current/overview.html to install" >&2
    missing_deps=1
  else
    deps['confluent']="$(command -v confluent | head -n1)"
  fi

  if [[ -n $missing_deps ]]; then
    exit 1
  fi

  # :command.command_filter
  action="ccloud-costs"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --start-date)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--start-date']="$2"
          shift
          shift
        else
          printf "%s\n" "--start-date requires an argument: --start-date START_DATE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --end-date)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--end-date']="$2"
          shift
          shift
        else
          printf "%s\n" "--end-date requires an argument: --end-date END_DATE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --display-only-total-cost)

        # :flag.case_no_arg
        args['--display-only-total-cost']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--start-date'] ]]; then
    validation_output="$(validate_date_format "${args['--start-date']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--start-date START_DATE" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--end-date'] ]]; then
    validation_output="$(validate_date_format "${args['--end-date']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--end-date END_DATE" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_ccloud_costs_history_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_ccloud_costs_history_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  missing_deps=
  # :dependency.filter
  if ! command -v confluent >/dev/null 2>&1; then
    printf "missing dependency: confluent\n" >&2
    printf "%s\n\n" "visit https://docs.confluent.io/confluent-cli/current/overview.html to install" >&2
    missing_deps=1
  else
    deps['confluent']="$(command -v confluent | head -n1)"
  fi

  if [[ -n $missing_deps ]]; then
    exit 1
  fi

  # :command.command_filter
  action="ccloud-costs-history"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --detailed)

        # :flag.case_no_arg
        args['--detailed']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_run_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_run_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  missing_deps=
  # :dependency.filter
  if ! command -v fzf >/dev/null 2>&1; then
    printf "missing dependency: fzf\n" >&2
    printf "%s\n\n" "visit https://github.com/junegunn/fzf#installation to install" >&2
    missing_deps=1
  else
    deps['fzf']="$(command -v fzf | head -n1)"
  fi

  if [[ -n $missing_deps ]]; then
    exit 1
  fi

  # :command.command_filter
  action="run"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --environment)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--environment']="$2"
          shift
          shift
        else
          printf "%s\n" "--environment requires an argument: --environment ENVIRONMENT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --file | -f)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--file']="$2"
          shift
          shift
        else
          printf "%s\n" "--file requires an argument: --file, -f FILE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --open | -o)

        # :flag.case_no_arg
        args['--open']=1
        shift
        ;;

      # :flag.case
      --tag)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--tag requires an argument: --tag TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connect-tag)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connect-tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--connect-tag requires an argument: --connect-tag CONNECT_TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-tag)
        # :flag.conflicts
        if [[ -n "${args['--connector-zip']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-zip" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector-tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-tag requires an argument: --connector-tag CONNECTOR_TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-zip)
        # :flag.conflicts
        if [[ -n "${args['--connector-tag']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-tag" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector-zip']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-zip requires an argument: --connector-zip CONNECTOR_ZIP" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-jar)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector-jar']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-jar requires an argument: --connector-jar CONNECTOR_JAR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --enable-ksqldb)

        # :flag.case_no_arg
        args['--enable-ksqldb']=1
        shift
        ;;

      # :flag.case
      --enable-rest-proxy)

        # :flag.case_no_arg
        args['--enable-rest-proxy']=1
        shift
        ;;

      # :flag.case
      --enable-control-center)

        # :flag.case_no_arg
        args['--enable-control-center']=1
        shift
        ;;

      # :flag.case
      --enable-flink)

        # :flag.case_no_arg
        args['--enable-flink']=1
        shift
        ;;

      # :flag.case
      --enable-conduktor)

        # :flag.case_no_arg
        args['--enable-conduktor']=1
        shift
        ;;

      # :flag.case
      --enable-multiple-brokers)

        # :flag.case_no_arg
        args['--enable-multiple-brokers']=1
        shift
        ;;

      # :flag.case
      --enable-multiple-connect-workers)

        # :flag.case_no_arg
        args['--enable-multiple-connect-workers']=1
        shift
        ;;

      # :flag.case
      --enable-jmx-grafana)

        # :flag.case_no_arg
        args['--enable-jmx-grafana']=1
        shift
        ;;

      # :flag.case
      --enable-kcat)

        # :flag.case_no_arg
        args['--enable-kcat']=1
        shift
        ;;

      # :flag.case
      --enable-sql-datagen)

        # :flag.case_no_arg
        args['--enable-sql-datagen']=1
        shift
        ;;

      # :flag.case
      --cluster-cloud)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--cluster-cloud']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-cloud requires an argument: --cluster-cloud CLUSTER-CLOUD" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-type)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--cluster-type']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-type requires an argument: --cluster-type CLUSTER-TYPE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-region)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--cluster-region']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-region requires an argument: --cluster-region CLUSTER-REGION" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-environment)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--cluster-environment']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-environment requires an argument: --cluster-environment CLUSTER-ENVIRONMENT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-name)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--cluster-name']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-name requires an argument: --cluster-name CLUSTER-NAME" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-creds)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--cluster-creds']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-creds requires an argument: --cluster-creds CLUSTER-CREDS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --cluster-schema-registry-creds)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--cluster-schema-registry-creds']="$2"
          shift
          shift
        else
          printf "%s\n" "--cluster-schema-registry-creds requires an argument: --cluster-schema-registry-creds CLUSTER-SCHEMA-REGISTRY-CREDS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --force-interactive-re-run)

        # :flag.case_no_arg
        args['--force-interactive-re-run']=1
        shift
        ;;

      # :flag.case
      --force-interactive-repro)

        # :flag.case_no_arg
        args['--force-interactive-repro']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--environment']:-} ]] || args['--environment']="plaintext"

  # :command.validations
  # :flag.validations
  if [[ -v args['--file'] ]]; then
    validation_output="$(validate_file_exists_with_trick "${args['--file']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--file, -f FILE" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--connector-zip'] ]]; then
    validation_output="$(validate_file_exists_with_trick "${args['--connector-zip']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--connector-zip CONNECTOR_ZIP" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--connector-jar'] ]]; then
    validation_output="$(validate_file_exists_with_trick "${args['--connector-jar']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--connector-jar CONNECTOR_JAR" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--cluster-environment'] ]]; then
    validation_output="$(validate_not_empty "${args['--cluster-environment']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--cluster-environment CLUSTER-ENVIRONMENT" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--cluster-name'] ]]; then
    validation_output="$(validate_not_empty "${args['--cluster-name']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--cluster-name CLUSTER-NAME" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--cluster-creds'] ]]; then
    validation_output="$(validate_not_empty "${args['--cluster-creds']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--cluster-creds CLUSTER-CREDS" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--cluster-schema-registry-creds'] ]]; then
    validation_output="$(validate_not_empty "${args['--cluster-schema-registry-creds']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--cluster-schema-registry-creds CLUSTER-SCHEMA-REGISTRY-CREDS" "$validation_output" >&2
      exit 1
    fi
  fi

  # :command.whitelist_filter
  if [[ ${args['--environment']:-} ]] && [[ ! ${args['--environment']:-} =~ ^(ccloud|plaintext|sasl-ssl|sasl-plain|2way-ssl|sasl-scram|kerberos|ssl_kerberos|ldap-authorizer-sasl-plain|ldap-sasl-plain|rbac-sasl-plain)$ ]]; then
    printf "%s\n" "--environment must be one of: ccloud, plaintext, sasl-ssl, sasl-plain, 2way-ssl, sasl-scram, kerberos, ssl_kerberos, ldap-authorizer-sasl-plain, ldap-sasl-plain, rbac-sasl-plain" >&2
    exit 1
  fi
  if [[ ${args['--cluster-cloud']:-} ]] && [[ ! ${args['--cluster-cloud']:-} =~ ^(aws|gcp|azure)$ ]]; then
    printf "%s\n" "--cluster-cloud must be one of: aws, gcp, azure" >&2
    exit 1
  fi
  if [[ ${args['--cluster-type']:-} ]] && [[ ! ${args['--cluster-type']:-} =~ ^(basic|standard|dedicated)$ ]]; then
    printf "%s\n" "--cluster-type must be one of: basic, standard, dedicated" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_re_run_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_re_run_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  missing_deps=
  # :dependency.filter
  if ! command -v fzf >/dev/null 2>&1; then
    printf "missing dependency: fzf\n" >&2
    printf "%s\n\n" "visit https://github.com/junegunn/fzf#installation to install" >&2
    missing_deps=1
  else
    deps['fzf']="$(command -v fzf | head -n1)"
  fi

  if [[ -n $missing_deps ]]; then
    exit 1
  fi

  # :command.command_filter
  action="re-run"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_get_ci_result_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_get_ci_result_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-ci-result"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_history_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_history_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  missing_deps=
  # :dependency.filter
  if ! command -v fzf >/dev/null 2>&1; then
    printf "missing dependency: fzf\n" >&2
    printf "%s\n\n" "visit https://github.com/junegunn/fzf#installation to install" >&2
    missing_deps=1
  else
    deps['fzf']="$(command -v fzf | head -n1)"
  fi

  if [[ -n $missing_deps ]]; then
    exit 1
  fi

  # :command.command_filter
  action="history"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_start_environment_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_start_environment_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="start-environment"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --environment)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--environment']="$2"
          shift
          shift
        else
          printf "%s\n" "--environment requires an argument: --environment ENVIRONMENT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --wait-for-control-center)

        # :flag.case_no_arg
        args['--wait-for-control-center']=1
        shift
        ;;

      # :flag.case
      --docker-compose-override-file | -f)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--docker-compose-override-file']="$2"
          shift
          shift
        else
          printf "%s\n" "--docker-compose-override-file requires an argument: --docker-compose-override-file, -f DOCKER-COMPOSE-OVERRIDE-FILE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--environment']:-} ]] || args['--environment']="plaintext"

  # :command.validations
  # :flag.validations
  if [[ -v args['--docker-compose-override-file'] ]]; then
    validation_output="$(validate_file_exists "${args['--docker-compose-override-file']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--docker-compose-override-file, -f DOCKER-COMPOSE-OVERRIDE-FILE" "$validation_output" >&2
      exit 1
    fi
  fi

  # :command.whitelist_filter
  if [[ ${args['--environment']:-} ]] && [[ ! ${args['--environment']:-} =~ ^(ccloud|2way-ssl|kerberos|ldap-authorizer-sasl-plain|ldap-sasl-plain|mdc-kerberos|mdc-plaintext|mdc-sasl-plain|plaintext|rbac-sasl-plain|sasl-plain|sasl-scram|sasl-ssl|ssl_kerberos)$ ]]; then
    printf "%s\n" "--environment must be one of: ccloud, 2way-ssl, kerberos, ldap-authorizer-sasl-plain, ldap-sasl-plain, mdc-kerberos, mdc-plaintext, mdc-sasl-plain, plaintext, rbac-sasl-plain, sasl-plain, sasl-scram, sasl-ssl, ssl_kerberos" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_switch_ccloud_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_switch_ccloud_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  missing_deps=
  # :dependency.filter
  if ! command -v confluent >/dev/null 2>&1; then
    printf "missing dependency: confluent\n" >&2
    printf "%s\n\n" "visit https://docs.confluent.io/confluent-cli/current/overview.html to install" >&2
    missing_deps=1
  else
    deps['confluent']="$(command -v confluent | head -n1)"
  fi

  if [[ -n $missing_deps ]]; then
    exit 1
  fi

  # :command.command_filter
  action="switch-ccloud"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_switch_back_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_switch_back_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="switch-back"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_update_version_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_update_version_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="update-version"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --tag)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--tag requires an argument: --tag TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connect-tag)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connect-tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--connect-tag requires an argument: --connect-tag CONNECT_TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-tag)
        # :flag.conflicts
        if [[ -n "${args['--connector-zip']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-zip" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector-tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-tag requires an argument: --connector-tag CONNECTOR_TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-zip)
        # :flag.conflicts
        if [[ -n "${args['--connector-tag']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-tag" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector-zip']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-zip requires an argument: --connector-zip CONNECTOR_ZIP" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-jar)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector-jar']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-jar requires an argument: --connector-jar CONNECTOR_JAR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--connector-zip'] ]]; then
    validation_output="$(validate_file_exists_with_trick "${args['--connector-zip']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--connector-zip CONNECTOR_ZIP" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--connector-jar'] ]]; then
    validation_output="$(validate_file_exists_with_trick "${args['--connector-jar']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--connector-jar CONNECTOR_JAR" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_open_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_open_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  missing_deps=
  # :dependency.filter
  if ! command -v fzf >/dev/null 2>&1; then
    printf "missing dependency: fzf\n" >&2
    printf "%s\n\n" "visit https://github.com/junegunn/fzf#installation to install" >&2
    missing_deps=1
  else
    deps['fzf']="$(command -v fzf | head -n1)"
  fi

  if [[ -n $missing_deps ]]; then
    exit 1
  fi

  # :command.command_filter
  action="open"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --file | -f)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--file']="$2"
          shift
          shift
        else
          printf "%s\n" "--file requires an argument: --file, -f FILE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --open-docker-compose)

        # :flag.case_no_arg
        args['--open-docker-compose']=1
        shift
        ;;

      # :flag.case
      --wait)

        # :flag.case_no_arg
        args['--wait']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--file'] ]]; then
    validation_output="$(validate_file_exists_with_trick "${args['--file']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--file, -f FILE" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_stop_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_stop_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="stop"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_remove_all_docker_images_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_remove_all_docker_images_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="remove-all-docker-images"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_remove_cp_docker_images_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_remove_cp_docker_images_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="remove-cp-docker-images"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --version)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--version']="$2"
          shift
          shift
        else
          printf "%s\n" "--version requires an argument: --version VERSION" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_refresh_cp_docker_images_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_refresh_cp_docker_images_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="refresh-cp-docker-images"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --version)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--version']="$2"
          shift
          shift
        else
          printf "%s\n" "--version requires an argument: --version VERSION" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--version']+x} ]]; then
    printf "missing required flag: --version VERSION\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_cleanup_cloud_details_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_cleanup_cloud_details_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="cleanup-cloud-details"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_open_docs_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_open_docs_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="open-docs"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --only-show-url)

        # :flag.case_no_arg
        args['--only-show-url']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_open_changelog_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_open_changelog_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="open-changelog"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --only-show-url)

        # :flag.case_no_arg
        args['--only-show-url']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_cleanup_cloud_resources_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_cleanup_cloud_resources_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.environment_variables_filter

  env_var_names+=("AZ_USER")
  env_var_names+=("AZ_PASS")
  env_var_names+=("GCP_PROJECT")
  env_var_names+=("AWS_ACCESS_KEY_ID")
  env_var_names+=("AWS_SECRET_ACCESS_KEY")
  env_var_names+=("GCP_KEYFILE_CONTENT")

  # :command.dependencies_filter
  missing_deps=
  # :dependency.filter
  if ! command -v confluent >/dev/null 2>&1; then
    printf "missing dependency: confluent\n" >&2
    printf "%s\n\n" "visit https://docs.confluent.io/confluent-cli/current/overview.html to install" >&2
    missing_deps=1
  else
    deps['confluent']="$(command -v confluent | head -n1)"
  fi

  if [[ -n $missing_deps ]]; then
    exit 1
  fi

  # :command.command_filter
  action="cleanup-cloud-resources"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --force)

        # :flag.case_no_arg
        args['--force']=1
        shift
        ;;

      # :flag.case
      --user)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--user']="$2"
          shift
          shift
        else
          printf "%s\n" "--user requires an argument: --user USER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --resource)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--resource']+x} ]]; then
            args['--resource']="$escaped"
          elif [[ -z "${unique_lookup["--resource:${escaped}"]:-}" ]]; then
            args['--resource']="${args['--resource']} $escaped"
          fi
          unique_lookup["--resource:${escaped}"]=1
          shift
          shift
        else
          printf "%s\n" "--resource requires an argument: --resource RESOURCE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--resource']:-} ]] || args['--resource']="aws gcp azure ccloud salesforce"

  # :command.whitelist_filter
  input_array=''
  eval "input_array=(${args[--resource]})"
  for i in "${input_array[@]}"; do
    if [[ ! $i =~ ^(aws|gcp|azure|ccloud|salesforce)$ ]]; then
      printf "%s\n" "--resource must be one of: aws, gcp, azure, ccloud, salesforce" >&2
      exit 1
    fi
  done

}

# :command.parse_requirements
playground_repro_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_repro_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.environment_variables_filter
  # :command.environment_variables_default
  export OUTPUT_FOLDER="${OUTPUT_FOLDER:-reproduction-models}"

  env_var_names+=("OUTPUT_FOLDER")

  # :command.dependencies_filter
  missing_deps=
  # :dependency.filter
  if ! command -v fzf >/dev/null 2>&1; then
    printf "missing dependency: fzf\n" >&2
    printf "%s\n\n" "visit https://github.com/junegunn/fzf#installation to install" >&2
    missing_deps=1
  else
    deps['fzf']="$(command -v fzf | head -n1)"
  fi

  if [[ -n $missing_deps ]]; then
    exit 1
  fi

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    export)
      action="export"
      shift
      playground_repro_export_parse_requirements "$@"
      shift $#
      ;;

    import)
      action="import"
      shift
      playground_repro_import_parse_requirements "$@"
      shift $#
      ;;

    bootstrap)
      action="bootstrap"
      shift
      playground_repro_bootstrap_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_repro_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_repro_export_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_repro_export_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  missing_deps=
  # :dependency.filter
  if ! command -v git >/dev/null 2>&1; then
    printf "missing dependency: git\n" >&2
    printf "%s\n\n" "visit https://git-scm.com/downloads to install" >&2
    missing_deps=1
  else
    deps['git']="$(command -v git | head -n1)"
  fi

  if [[ -n $missing_deps ]]; then
    exit 1
  fi

  # :command.command_filter
  action="repro export"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --all)

        # :flag.case_no_arg
        args['--all']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_repro_import_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_repro_import_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="repro import"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --file | -f)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--file']="$2"
          shift
          shift
        else
          printf "%s\n" "--file requires an argument: --file, -f FILE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--file'] ]]; then
    validation_output="$(validate_file_exists_with_trick "${args['--file']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--file, -f FILE" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_repro_bootstrap_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_repro_bootstrap_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="repro bootstrap"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --file | -f)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--file']="$2"
          shift
          shift
        else
          printf "%s\n" "--file requires an argument: --file, -f FILE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --description | -d)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--description']="$2"
          shift
          shift
        else
          printf "%s\n" "--description requires an argument: --description, -d DESCRIPTION" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --producer | -p)
        # :flag.conflicts
        if [[ -n "${args['--pipeline']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--pipeline" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--producer']="$2"
          shift
          shift
        else
          printf "%s\n" "--producer requires an argument: --producer, -p PRODUCER-TYPE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --nb-producers | -n)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--nb-producers']="$2"
          shift
          shift
        else
          printf "%s\n" "--nb-producers requires an argument: --nb-producers, -n NB-PRODUCERS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --producer-schema-key)

        # :flag.case_no_arg
        args['--producer-schema-key']=1
        shift
        ;;

      # :flag.case
      --producer-schema-value)

        # :flag.case_no_arg
        args['--producer-schema-value']=1
        shift
        ;;

      # :flag.case
      --custom-smt)

        # :flag.case_no_arg
        args['--custom-smt']=1
        shift
        ;;

      # :flag.case
      --pipeline)
        # :flag.conflicts
        if [[ -n "${args['--producer']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--producer" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--pipeline']+x} ]]; then
            args['--pipeline']="$escaped"
          else
            args['--pipeline']="${args['--pipeline']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--pipeline requires an argument: --pipeline SINK_FILE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--producer']:-} ]] || args['--producer']="none"

  # :command.validations
  # :flag.validations
  if [[ -v args['--file'] ]]; then
    validation_output="$(validate_file_exists_with_trick "${args['--file']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--file, -f FILE" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--description'] ]]; then
    validation_output="$(validate_not_empty "${args['--description']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--description, -d DESCRIPTION" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--pipeline'] ]]; then
    values=''
    eval "values=(${args['--pipeline']})"
    for value in "${values[@]}"; do
      validation_output="$(validate_file_exists_with_trick "$value")"
      if [[ -n "$validation_output" ]]; then
        printf "validation error in %s:\n%s\n" "--pipeline SINK_FILE" "$validation_output" >&2
        exit 1
      fi
    done
  fi

  # :command.whitelist_filter
  if [[ ${args['--producer']:-} ]] && [[ ! ${args['--producer']:-} =~ ^(none|avro|avro-with-key|protobuf|protobuf-with-key|json-schema|json-schema-with-key)$ ]]; then
    printf "%s\n" "--producer must be one of: none, avro, avro-with-key, protobuf, protobuf-with-key, json-schema, json-schema-with-key" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_get_docker_compose_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_get_docker_compose_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="get-docker-compose"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_schema_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_schema_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    get)
      action="get"
      shift
      playground_schema_get_parse_requirements "$@"
      shift $#
      ;;

    register)
      action="register"
      shift
      playground_schema_register_parse_requirements "$@"
      shift $#
      ;;

    get-compatibility)
      action="get-compatibility"
      shift
      playground_schema_get_compatibility_parse_requirements "$@"
      shift $#
      ;;

    set-compatibility)
      action="set-compatibility"
      shift
      playground_schema_set_compatibility_parse_requirements "$@"
      shift $#
      ;;

    get-mode)
      action="get-mode"
      shift
      playground_schema_get_mode_parse_requirements "$@"
      shift $#
      ;;

    set-mode)
      action="set-mode"
      shift
      playground_schema_set_mode_parse_requirements "$@"
      shift $#
      ;;

    set-normalize)
      action="set-normalize"
      shift
      playground_schema_set_normalize_parse_requirements "$@"
      shift $#
      ;;

    delete)
      action="delete"
      shift
      playground_schema_delete_parse_requirements "$@"
      shift $#
      ;;

    derive-schema)
      action="derive-schema"
      shift
      playground_schema_derive_schema_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_schema_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_schema_get_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_schema_get_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="schema get"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --subject)
        # :flag.conflicts
        if [[ -n "${args['id']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "id" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--subject requires an argument: --subject SUBJECT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --id)
        # :flag.conflicts
        for conflict in subject deleted; do
          if [[ -n "${args[$conflict]:-}" ]]; then
            printf "conflicting options: %s cannot be used with %s\n" "$key" "$conflict" >&2
            exit 1
          fi
        done

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--id']="$2"
          shift
          shift
        else
          printf "%s\n" "--id requires an argument: --id ID" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --deleted)
        # :flag.conflicts
        if [[ -n "${args['id']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "id" >&2
          exit 1
        fi

        # :flag.case_no_arg
        args['--deleted']=1
        shift
        ;;

      # :flag.case
      --store-in-tmp)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--store-in-tmp']="$2"
          shift
          shift
        else
          printf "%s\n" "--store-in-tmp requires an argument: --store-in-tmp FOLDER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--id'] ]]; then
    validation_output="$(validate_integer "${args['--id']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--id ID" "$validation_output" >&2
      exit 1
    fi
  fi

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_schema_register_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_schema_register_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="schema register"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --subject)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--subject requires an argument: --subject SUBJECT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --schema)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--schema']="$2"
          shift
          shift
        else
          printf "%s\n" "--schema requires an argument: --schema SCHEMA" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --id)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--id']="$2"
          shift
          shift
        else
          printf "%s\n" "--id requires an argument: --id ID" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --metadata-property)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--metadata-property']+x} ]]; then
            args['--metadata-property']="$escaped"
          else
            args['--metadata-property']="${args['--metadata-property']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--metadata-property requires an argument: --metadata-property METADATA-PROPERTY" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--subject']+x} ]]; then
    printf "missing required flag: --subject SUBJECT\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--schema']:-} ]] || args['--schema']="-"

  # :command.validations
  # :flag.validations
  if [[ -v args['--id'] ]]; then
    validation_output="$(validate_integer "${args['--id']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--id ID" "$validation_output" >&2
      exit 1
    fi
  fi

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_schema_get_compatibility_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_schema_get_compatibility_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="schema get-compatibility"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --subject)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--subject requires an argument: --subject SUBJECT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--subject']+x} ]]; then
    printf "missing required flag: --subject SUBJECT\n" >&2
    exit 1
  fi

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_schema_set_compatibility_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_schema_set_compatibility_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="schema set-compatibility"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --subject)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--subject requires an argument: --subject SUBJECT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --compatibility)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--compatibility']="$2"
          shift
          shift
        else
          printf "%s\n" "--compatibility requires an argument: --compatibility COMPATIBILITY" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--subject']+x} ]]; then
    printf "missing required flag: --subject SUBJECT\n" >&2
    exit 1
  fi
  if [[ -z ${args['--compatibility']+x} ]]; then
    printf "missing required flag: --compatibility COMPATIBILITY\n" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--compatibility']:-} ]] && [[ ! ${args['--compatibility']:-} =~ ^(BACKWARD|BACKWARD_TRANSITIVE|FORWARD|FORWARD_TRANSITIVE|FULL|FULL_TRANSITIVE|NONE)$ ]]; then
    printf "%s\n" "--compatibility must be one of: BACKWARD, BACKWARD_TRANSITIVE, FORWARD, FORWARD_TRANSITIVE, FULL, FULL_TRANSITIVE, NONE" >&2
    exit 1
  fi

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_schema_get_mode_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_schema_get_mode_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="schema get-mode"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --subject)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--subject requires an argument: --subject SUBJECT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--subject']+x} ]]; then
    printf "missing required flag: --subject SUBJECT\n" >&2
    exit 1
  fi

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_schema_set_mode_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_schema_set_mode_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="schema set-mode"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --subject)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--subject requires an argument: --subject SUBJECT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --mode)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--mode']="$2"
          shift
          shift
        else
          printf "%s\n" "--mode requires an argument: --mode MODE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--subject']+x} ]]; then
    printf "missing required flag: --subject SUBJECT\n" >&2
    exit 1
  fi
  if [[ -z ${args['--mode']+x} ]]; then
    printf "missing required flag: --mode MODE\n" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--mode']:-} ]] && [[ ! ${args['--mode']:-} =~ ^(IMPORT|READONLY|READWRITE)$ ]]; then
    printf "%s\n" "--mode must be one of: IMPORT, READONLY, READWRITE" >&2
    exit 1
  fi

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_schema_set_normalize_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_schema_set_normalize_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="schema set-normalize"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --value)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--value']="$2"
          shift
          shift
        else
          printf "%s\n" "--value requires an argument: --value VALUE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--value']+x} ]]; then
    printf "missing required flag: --value VALUE\n" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--value']:-} ]] && [[ ! ${args['--value']:-} =~ ^(true|false)$ ]]; then
    printf "%s\n" "--value must be one of: true, false" >&2
    exit 1
  fi

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_schema_delete_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_schema_delete_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="schema delete"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --subject)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--subject requires an argument: --subject SUBJECT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --version)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--version']="$2"
          shift
          shift
        else
          printf "%s\n" "--version requires an argument: --version VERSION" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --permanent)

        # :flag.case_no_arg
        args['--permanent']=1
        shift
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--version'] ]]; then
    validation_output="$(validate_integer "${args['--version']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--version VERSION" "$validation_output" >&2
      exit 1
    fi
  fi

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_schema_derive_schema_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_schema_derive_schema_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="schema derive-schema"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --payload)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--payload']="$2"
          shift
          shift
        else
          printf "%s\n" "--payload requires an argument: --payload PAYLOAD" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --schema-type)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--schema-type']="$2"
          shift
          shift
        else
          printf "%s\n" "--schema-type requires an argument: --schema-type SCHEMA-TYPE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--payload']:-} ]] || args['--payload']="-"
  [[ -n ${args['--schema-type']:-} ]] || args['--schema-type']="AVRO"

  # :command.whitelist_filter
  if [[ ${args['--schema-type']:-} ]] && [[ ! ${args['--schema-type']:-} =~ ^(AVRO|JSON|PROTOBUF)$ ]]; then
    printf "%s\n" "--schema-type must be one of: AVRO, JSON, PROTOBUF" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_tcp_proxy_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_tcp_proxy_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    start)
      action="start"
      shift
      playground_tcp_proxy_start_parse_requirements "$@"
      shift $#
      ;;

    get-connections)
      action="get-connections"
      shift
      playground_tcp_proxy_get_connections_parse_requirements "$@"
      shift $#
      ;;

    delay)
      action="delay"
      shift
      playground_tcp_proxy_delay_parse_requirements "$@"
      shift $#
      ;;

    break)
      action="break"
      shift
      playground_tcp_proxy_break_parse_requirements "$@"
      shift $#
      ;;

    close-connection)
      action="close-connection"
      shift
      playground_tcp_proxy_close_connection_parse_requirements "$@"
      shift $#
      ;;

    close-all-connection-with-error)
      action="close-all-connection-with-error"
      shift
      playground_tcp_proxy_close_all_connection_with_error_parse_requirements "$@"
      shift $#
      ;;

    toggle-accept-connections)
      action="toggle-accept-connections"
      shift
      playground_tcp_proxy_toggle_accept_connections_parse_requirements "$@"
      shift $#
      ;;

    toggle-reads-client)
      action="toggle-reads-client"
      shift
      playground_tcp_proxy_toggle_reads_client_parse_requirements "$@"
      shift $#
      ;;

    toggle-reads-service)
      action="toggle-reads-service"
      shift
      playground_tcp_proxy_toggle_reads_service_parse_requirements "$@"
      shift $#
      ;;

    toggle-writes-client)
      action="toggle-writes-client"
      shift
      playground_tcp_proxy_toggle_writes_client_parse_requirements "$@"
      shift $#
      ;;

    toggle-writes-service)
      action="toggle-writes-service"
      shift
      playground_tcp_proxy_toggle_writes_service_parse_requirements "$@"
      shift $#
      ;;

    open-ui)
      action="open-ui"
      shift
      playground_tcp_proxy_open_ui_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_tcp_proxy_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_tcp_proxy_start_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_tcp_proxy_start_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="tcp-proxy start"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --hostname)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--hostname']="$2"
          shift
          shift
        else
          printf "%s\n" "--hostname requires an argument: --hostname HOSTNAME" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --port)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--port']="$2"
          shift
          shift
        else
          printf "%s\n" "--port requires an argument: --port PORT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --throttle-service-response)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--throttle-service-response']="$2"
          shift
          shift
        else
          printf "%s\n" "--throttle-service-response requires an argument: --throttle-service-response THROTTLE-SERVICE-RESPONSE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --delay-service-response)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--delay-service-response']="$2"
          shift
          shift
        else
          printf "%s\n" "--delay-service-response requires an argument: --delay-service-response DELAY-SERVICE-RESPONSE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --break-service-response)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--break-service-response']="$2"
          shift
          shift
        else
          printf "%s\n" "--break-service-response requires an argument: --break-service-response BREAK-SERVICE-RESPONSE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --service-response-corrupt)

        # :flag.case_no_arg
        args['--service-response-corrupt']=1
        shift
        ;;

      # :flag.case
      --skip-automatic-connector-config)

        # :flag.case_no_arg
        args['--skip-automatic-connector-config']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--hostname']+x} ]]; then
    printf "missing required flag: --hostname HOSTNAME\n" >&2
    exit 1
  fi
  if [[ -z ${args['--port']+x} ]]; then
    printf "missing required flag: --port PORT\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--throttle-service-response']:-} ]] || args['--throttle-service-response']="0"
  [[ -n ${args['--delay-service-response']:-} ]] || args['--delay-service-response']="0"
  [[ -n ${args['--break-service-response']:-} ]] || args['--break-service-response']="0"

  # :command.validations
  # :flag.validations
  if [[ -v args['--port'] ]]; then
    validation_output="$(validate_integer "${args['--port']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--port PORT" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--throttle-service-response'] ]]; then
    validation_output="$(validate_integer "${args['--throttle-service-response']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--throttle-service-response THROTTLE-SERVICE-RESPONSE" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--delay-service-response'] ]]; then
    validation_output="$(validate_integer "${args['--delay-service-response']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--delay-service-response DELAY-SERVICE-RESPONSE" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--break-service-response'] ]]; then
    validation_output="$(validate_percentage "${args['--break-service-response']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--break-service-response BREAK-SERVICE-RESPONSE" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_tcp_proxy_get_connections_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_tcp_proxy_get_connections_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="tcp-proxy get-connections"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connection-id)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connection-id']="$2"
          shift
          shift
        else
          printf "%s\n" "--connection-id requires an argument: --connection-id CONNECTION-ID" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--connection-id'] ]]; then
    validation_output="$(validate_integer "${args['--connection-id']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--connection-id CONNECTION-ID" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_tcp_proxy_delay_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_tcp_proxy_delay_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="tcp-proxy delay"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --delay-service-response)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--delay-service-response']="$2"
          shift
          shift
        else
          printf "%s\n" "--delay-service-response requires an argument: --delay-service-response DELAY-SERVICE-RESPONSE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connection-id)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connection-id']="$2"
          shift
          shift
        else
          printf "%s\n" "--connection-id requires an argument: --connection-id CONNECTION-ID" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--delay-service-response']+x} ]]; then
    printf "missing required flag: --delay-service-response DELAY-SERVICE-RESPONSE\n" >&2
    exit 1
  fi

  # :command.validations
  # :flag.validations
  if [[ -v args['--delay-service-response'] ]]; then
    validation_output="$(validate_integer "${args['--delay-service-response']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--delay-service-response DELAY-SERVICE-RESPONSE" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--connection-id'] ]]; then
    validation_output="$(validate_integer "${args['--connection-id']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--connection-id CONNECTION-ID" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_tcp_proxy_break_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_tcp_proxy_break_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="tcp-proxy break"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --break-service-response)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--break-service-response']="$2"
          shift
          shift
        else
          printf "%s\n" "--break-service-response requires an argument: --break-service-response BREAK-SERVICE-RESPONSE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connection-id)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connection-id']="$2"
          shift
          shift
        else
          printf "%s\n" "--connection-id requires an argument: --connection-id CONNECTION-ID" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--break-service-response']+x} ]]; then
    printf "missing required flag: --break-service-response BREAK-SERVICE-RESPONSE\n" >&2
    exit 1
  fi

  # :command.validations
  # :flag.validations
  if [[ -v args['--break-service-response'] ]]; then
    validation_output="$(validate_percentage "${args['--break-service-response']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--break-service-response BREAK-SERVICE-RESPONSE" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--connection-id'] ]]; then
    validation_output="$(validate_integer "${args['--connection-id']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--connection-id CONNECTION-ID" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_tcp_proxy_close_connection_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_tcp_proxy_close_connection_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="tcp-proxy close-connection"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connection-id)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connection-id']="$2"
          shift
          shift
        else
          printf "%s\n" "--connection-id requires an argument: --connection-id CONNECTION-ID" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--connection-id'] ]]; then
    validation_output="$(validate_integer "${args['--connection-id']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--connection-id CONNECTION-ID" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_tcp_proxy_close_all_connection_with_error_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_tcp_proxy_close_all_connection_with_error_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="tcp-proxy close-all-connection-with-error"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_tcp_proxy_toggle_accept_connections_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_tcp_proxy_toggle_accept_connections_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="tcp-proxy toggle-accept-connections"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_tcp_proxy_toggle_reads_client_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_tcp_proxy_toggle_reads_client_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="tcp-proxy toggle-reads-client"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connection-id)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connection-id']="$2"
          shift
          shift
        else
          printf "%s\n" "--connection-id requires an argument: --connection-id CONNECTION-ID" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--connection-id'] ]]; then
    validation_output="$(validate_integer "${args['--connection-id']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--connection-id CONNECTION-ID" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_tcp_proxy_toggle_reads_service_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_tcp_proxy_toggle_reads_service_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="tcp-proxy toggle-reads-service"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connection-id)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connection-id']="$2"
          shift
          shift
        else
          printf "%s\n" "--connection-id requires an argument: --connection-id CONNECTION-ID" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--connection-id'] ]]; then
    validation_output="$(validate_integer "${args['--connection-id']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--connection-id CONNECTION-ID" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_tcp_proxy_toggle_writes_client_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_tcp_proxy_toggle_writes_client_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="tcp-proxy toggle-writes-client"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connection-id)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connection-id']="$2"
          shift
          shift
        else
          printf "%s\n" "--connection-id requires an argument: --connection-id CONNECTION-ID" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--connection-id'] ]]; then
    validation_output="$(validate_integer "${args['--connection-id']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--connection-id CONNECTION-ID" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_tcp_proxy_toggle_writes_service_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_tcp_proxy_toggle_writes_service_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="tcp-proxy toggle-writes-service"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connection-id)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connection-id']="$2"
          shift
          shift
        else
          printf "%s\n" "--connection-id requires an argument: --connection-id CONNECTION-ID" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--connection-id'] ]]; then
    validation_output="$(validate_integer "${args['--connection-id']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--connection-id CONNECTION-ID" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_tcp_proxy_open_ui_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_tcp_proxy_open_ui_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="tcp-proxy open-ui"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_tools_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_tools_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    install-vscode-extension)
      action="install-vscode-extension"
      shift
      playground_tools_install_vscode_extension_parse_requirements "$@"
      shift $#
      ;;

    read-avro-file)
      action="read-avro-file"
      shift
      playground_tools_read_avro_file_parse_requirements "$@"
      shift $#
      ;;

    read-parquet-file)
      action="read-parquet-file"
      shift
      playground_tools_read_parquet_file_parse_requirements "$@"
      shift $#
      ;;

    certs-create)
      action="certs-create"
      shift
      playground_tools_certs_create_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_tools_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_tools_install_vscode_extension_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_tools_install_vscode_extension_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  missing_deps=
  # :dependency.filter
  if ! command -v code >/dev/null 2>&1; then
    printf "missing dependency: code\n" >&2
    printf "%s\n\n" "visit https://code.visualstudio.com/docs/setup/mac#_launching-from-the-command-line to install" >&2
    missing_deps=1
  else
    deps['code']="$(command -v code | head -n1)"
  fi

  if [[ -n $missing_deps ]]; then
    exit 1
  fi

  # :command.command_filter
  action="tools install-vscode-extension"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_tools_read_avro_file_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_tools_read_avro_file_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="tools read-avro-file"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --file | -f)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--file']="$2"
          shift
          shift
        else
          printf "%s\n" "--file requires an argument: --file, -f FILE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--file'] ]]; then
    validation_output="$(validate_file_exists_and_avro "${args['--file']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--file, -f FILE" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_tools_read_parquet_file_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_tools_read_parquet_file_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="tools read-parquet-file"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --file | -f)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--file']="$2"
          shift
          shift
        else
          printf "%s\n" "--file requires an argument: --file, -f FILE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--file'] ]]; then
    validation_output="$(validate_file_exists_and_parquet "${args['--file']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--file, -f FILE" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_tools_certs_create_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_tools_certs_create_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="tools certs-create"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--container']+x} ]]; then
            args['--container']="$escaped"
          elif [[ -z "${unique_lookup["--container:${escaped}"]:-}" ]]; then
            args['--container']="${args['--container']} $escaped"
          fi
          unique_lookup["--container:${escaped}"]=1
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --output-folder)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--output-folder']="$2"
          shift
          shift
        else
          printf "%s\n" "--output-folder requires an argument: --output-folder FOLDER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--output-folder']+x} ]]; then
    printf "missing required flag: --output-folder FOLDER\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="broker broker2 broker3 client schema-registry restproxy connect connect2 connect3 control-center clientrestproxy ksqldb-server conduktor"

}

# :command.parse_requirements
playground_debug_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_debug_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    enable-remote-debugging)
      action="enable-remote-debugging"
      shift
      playground_debug_enable_remote_debugging_parse_requirements "$@"
      shift $#
      ;;

    testssl)
      action="testssl"
      shift
      playground_debug_testssl_parse_requirements "$@"
      shift $#
      ;;

    generate-diagnostics)
      action="generate-diagnostics"
      shift
      playground_debug_generate_diagnostics_parse_requirements "$@"
      shift $#
      ;;

    thread-dump)
      action="thread-dump"
      shift
      playground_debug_thread_dump_parse_requirements "$@"
      shift $#
      ;;

    heap-dump)
      action="heap-dump"
      shift
      playground_debug_heap_dump_parse_requirements "$@"
      shift $#
      ;;

    tcp-dump)
      action="tcp-dump"
      shift
      playground_debug_tcp_dump_parse_requirements "$@"
      shift $#
      ;;

    block-traffic)
      action="block-traffic"
      shift
      playground_debug_block_traffic_parse_requirements "$@"
      shift $#
      ;;

    java-debug)
      action="java-debug"
      shift
      playground_debug_java_debug_parse_requirements "$@"
      shift $#
      ;;

    jscissors)
      action="jscissors"
      shift
      playground_debug_jscissors_parse_requirements "$@"
      shift $#
      ;;

    flight-recorder)
      action="flight-recorder"
      shift
      playground_debug_flight_recorder_parse_requirements "$@"
      shift $#
      ;;

    log-level)
      action="log-level"
      shift
      playground_debug_log_level_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_debug_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_debug_enable_remote_debugging_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_debug_enable_remote_debugging_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug enable-remote-debugging"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--container']+x} ]]; then
            args['--container']="$escaped"
          else
            args['--container']="${args['--container']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_debug_testssl_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_debug_testssl_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug testssl"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --uri)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--uri']="$2"
          shift
          shift
        else
          printf "%s\n" "--uri requires an argument: --uri URI" >&2
          exit 1
        fi
        ;;

      --)
        shift
        other_args+=("$@")
        break
        ;;

      -?*)
        other_args+=("$1")
        shift
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_catch_all
        other_args+=("$1")
        shift

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--uri']+x} ]]; then
    printf "missing required flag: --uri URI\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_debug_generate_diagnostics_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_debug_generate_diagnostics_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug generate-diagnostics"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--container']+x} ]]; then
            args['--container']="$escaped"
          else
            args['--container']="${args['--container']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_debug_thread_dump_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_debug_thread_dump_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug thread-dump"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--container']+x} ]]; then
            args['--container']="$escaped"
          else
            args['--container']="${args['--container']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_debug_heap_dump_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_debug_heap_dump_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug heap-dump"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--container']+x} ]]; then
            args['--container']="$escaped"
          else
            args['--container']="${args['--container']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --live)

        # :flag.case_no_arg
        args['--live']=1
        shift
        ;;

      # :flag.case
      --histo)

        # :flag.case_no_arg
        args['--histo']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_debug_tcp_dump_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_debug_tcp_dump_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug tcp-dump"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--container']+x} ]]; then
            args['--container']="$escaped"
          else
            args['--container']="${args['--container']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --port)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--port']="$2"
          shift
          shift
        else
          printf "%s\n" "--port requires an argument: --port PORT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --duration)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--duration']="$2"
          shift
          shift
        else
          printf "%s\n" "--duration requires an argument: --duration DURATION" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"
  [[ -n ${args['--duration']:-} ]] || args['--duration']="30"

  # :command.validations
  # :flag.validations
  if [[ -v args['--port'] ]]; then
    validation_output="$(validate_integer "${args['--port']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--port PORT" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--duration'] ]]; then
    validation_output="$(validate_integer "${args['--duration']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--duration DURATION" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_debug_block_traffic_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_debug_block_traffic_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug block-traffic"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--container']+x} ]]; then
            args['--container']="$escaped"
          else
            args['--container']="${args['--container']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --destination)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--destination']="$2"
          shift
          shift
        else
          printf "%s\n" "--destination requires an argument: --destination DESTINATION" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --port)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--port']="$2"
          shift
          shift
        else
          printf "%s\n" "--port requires an argument: --port PORT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --action)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--action']="$2"
          shift
          shift
        else
          printf "%s\n" "--action requires an argument: --action ACTION" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--destination']+x} ]]; then
    printf "missing required flag: --destination DESTINATION\n" >&2
    exit 1
  fi
  if [[ -z ${args['--action']+x} ]]; then
    printf "missing required flag: --action ACTION\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

  # :command.validations
  # :flag.validations
  if [[ -v args['--port'] ]]; then
    validation_output="$(validate_integer "${args['--port']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--port PORT" "$validation_output" >&2
      exit 1
    fi
  fi

  # :command.whitelist_filter
  if [[ ${args['--action']:-} ]] && [[ ! ${args['--action']:-} =~ ^(start|stop)$ ]]; then
    printf "%s\n" "--action must be one of: start, stop" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_debug_java_debug_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_debug_java_debug_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug java-debug"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--container']+x} ]]; then
            args['--container']="$escaped"
          else
            args['--container']="${args['--container']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --type)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--type']="$2"
          shift
          shift
        else
          printf "%s\n" "--type requires an argument: --type TYPE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --action)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--action']="$2"
          shift
          shift
        else
          printf "%s\n" "--action requires an argument: --action ACTION" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--type']+x} ]]; then
    printf "missing required flag: --type TYPE\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"
  [[ -n ${args['--action']:-} ]] || args['--action']="enable"

  # :command.whitelist_filter
  if [[ ${args['--type']:-} ]] && [[ ! ${args['--type']:-} =~ ^(ssl_all|ssl_handshake|class_loading|kerberos)$ ]]; then
    printf "%s\n" "--type must be one of: ssl_all, ssl_handshake, class_loading, kerberos" >&2
    exit 1
  fi
  if [[ ${args['--action']:-} ]] && [[ ! ${args['--action']:-} =~ ^(enable|disable)$ ]]; then
    printf "%s\n" "--action must be one of: enable, disable" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_debug_jscissors_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_debug_jscissors_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug jscissors"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--container']+x} ]]; then
            args['--container']="$escaped"
          else
            args['--container']="${args['--container']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --operation)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--operation']+x} ]]; then
            args['--operation']="$escaped"
          elif [[ -z "${unique_lookup["--operation:${escaped}"]:-}" ]]; then
            args['--operation']="${args['--operation']} $escaped"
          fi
          unique_lookup["--operation:${escaped}"]=1
          shift
          shift
        else
          printf "%s\n" "--operation requires an argument: --operation OPERATION" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --class)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--class']="$2"
          shift
          shift
        else
          printf "%s\n" "--class requires an argument: --class CLASS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --method)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--method']="$2"
          shift
          shift
        else
          printf "%s\n" "--method requires an argument: --method METHOD" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --action)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--action']="$2"
          shift
          shift
        else
          printf "%s\n" "--action requires an argument: --action ACTION" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--class']+x} ]]; then
    printf "missing required flag: --class CLASS\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"
  [[ -n ${args['--operation']:-} ]] || args['--operation']="VALUES RETURN_VALUE DELAY STACK"
  [[ -n ${args['--method']:-} ]] || args['--method']=".*"
  [[ -n ${args['--action']:-} ]] || args['--action']="enable"

  # :command.whitelist_filter
  input_array=''
  eval "input_array=(${args[--operation]})"
  for i in "${input_array[@]}"; do
    if [[ ! $i =~ ^(VALUES|RETURN_VALUE|THREADS|HEAP|STACK|EXCEPTION_HEAP|DELAY)$ ]]; then
      printf "%s\n" "--operation must be one of: VALUES, RETURN_VALUE, THREADS, HEAP, STACK, EXCEPTION_HEAP, DELAY" >&2
      exit 1
    fi
  done
  if [[ ${args['--action']:-} ]] && [[ ! ${args['--action']:-} =~ ^(enable|disable)$ ]]; then
    printf "%s\n" "--action must be one of: enable, disable" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_debug_flight_recorder_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_debug_flight_recorder_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug flight-recorder"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--container']+x} ]]; then
            args['--container']="$escaped"
          else
            args['--container']="${args['--container']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --action)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--action']="$2"
          shift
          shift
        else
          printf "%s\n" "--action requires an argument: --action ACTION" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"
  [[ -n ${args['--action']:-} ]] || args['--action']="enable"

  # :command.whitelist_filter
  if [[ ${args['--action']:-} ]] && [[ ! ${args['--action']:-} =~ ^(enable|disable)$ ]]; then
    printf "%s\n" "--action must be one of: enable, disable" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_debug_log_level_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_debug_log_level_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    get)
      action="get"
      shift
      playground_debug_log_level_get_parse_requirements "$@"
      shift $#
      ;;

    set)
      action="set"
      shift
      playground_debug_log_level_set_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_debug_log_level_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.user_filter
  filter_error=$(filter_connect_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_debug_log_level_get_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_debug_log_level_get_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug log-level get"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --package | -p)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--package']="$2"
          shift
          shift
        else
          printf "%s\n" "--package requires an argument: --package, -p PACKAGE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--package'] ]]; then
    validation_output="$(validate_not_empty "${args['--package']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--package, -p PACKAGE" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_debug_log_level_set_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_debug_log_level_set_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="debug log-level set"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --package | -p)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--package']="$2"
          shift
          shift
        else
          printf "%s\n" "--package requires an argument: --package, -p PACKAGE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --level | -l)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--level']="$2"
          shift
          shift
        else
          printf "%s\n" "--level requires an argument: --level, -l LEVEL" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--package']+x} ]]; then
    printf "missing required flag: --package, -p PACKAGE\n" >&2
    exit 1
  fi
  if [[ -z ${args['--level']+x} ]]; then
    printf "missing required flag: --level, -l LEVEL\n" >&2
    exit 1
  fi

  # :command.validations
  # :flag.validations
  if [[ -v args['--package'] ]]; then
    validation_output="$(validate_not_empty "${args['--package']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--package, -p PACKAGE" "$validation_output" >&2
      exit 1
    fi
  fi

  # :command.whitelist_filter
  if [[ ${args['--level']:-} ]] && [[ ! ${args['--level']:-} =~ ^(INFO|WARN|DEBUG|TRACE)$ ]]; then
    printf "%s\n" "--level must be one of: INFO, WARN, DEBUG, TRACE" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_get_jmx_metrics_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_get_jmx_metrics_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  missing_deps=
  # :dependency.filter
  if ! command -v java >/dev/null 2>&1; then
    printf "missing dependency: java\n" >&2
    printf "%s\n\n" "visit https://openjdk.org/install/ to install" >&2
    missing_deps=1
  else
    deps['java']="$(command -v java | head -n1)"
  fi

  if [[ -n $missing_deps ]]; then
    exit 1
  fi

  # :command.command_filter
  action="get-jmx-metrics"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--container']+x} ]]; then
            args['--container']="$escaped"
          else
            args['--container']="${args['--container']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --open | -o)

        # :flag.case_no_arg
        args['--open']=1
        shift
        ;;

      # :flag.case
      --domain | -d)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--domain']="$2"
          shift
          shift
        else
          printf "%s\n" "--domain requires an argument: --domain, -d DOMAIN" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_container_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_container_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    get-properties)
      action="get-properties"
      shift
      playground_container_get_properties_parse_requirements "$@"
      shift $#
      ;;

    recreate)
      action="recreate"
      shift
      playground_container_recreate_parse_requirements "$@"
      shift $#
      ;;

    get-ip-addresses)
      action="get-ip-addresses"
      shift
      playground_container_get_ip_addresses_parse_requirements "$@"
      shift $#
      ;;

    kill-all)
      action="kill-all"
      shift
      playground_container_kill_all_parse_requirements "$@"
      shift $#
      ;;

    logs)
      action="logs"
      shift
      playground_container_logs_parse_requirements "$@"
      shift $#
      ;;

    display-error-all-containers)
      action="display-error-all-containers"
      shift
      playground_container_display_error_all_containers_parse_requirements "$@"
      shift $#
      ;;

    ssh)
      action="ssh"
      shift
      playground_container_ssh_parse_requirements "$@"
      shift $#
      ;;

    change-jdk)
      action="change-jdk"
      shift
      playground_container_change_jdk_parse_requirements "$@"
      shift $#
      ;;

    exec)
      action="exec"
      shift
      playground_container_exec_parse_requirements "$@"
      shift $#
      ;;

    restart)
      action="restart"
      shift
      playground_container_restart_parse_requirements "$@"
      shift $#
      ;;

    pause)
      action="pause"
      shift
      playground_container_pause_parse_requirements "$@"
      shift $#
      ;;

    resume | unpause)
      action="resume"
      shift
      playground_container_resume_parse_requirements "$@"
      shift $#
      ;;

    kill)
      action="kill"
      shift
      playground_container_kill_parse_requirements "$@"
      shift $#
      ;;

    set-environment-variables)
      action="set-environment-variables"
      shift
      playground_container_set_environment_variables_parse_requirements "$@"
      shift $#
      ;;

    wait-for-connect-rest-api-ready)
      action="wait-for-connect-rest-api-ready"
      shift
      playground_container_wait_for_connect_rest_api_ready_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_container_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_container_get_properties_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_container_get_properties_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container get-properties"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--container']+x} ]]; then
            args['--container']="$escaped"
          else
            args['--container']="${args['--container']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_container_recreate_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_container_recreate_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container recreate"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --ignore-current-versions)

        # :flag.case_no_arg
        args['--ignore-current-versions']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_container_get_ip_addresses_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_container_get_ip_addresses_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container get-ip-addresses"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_container_kill_all_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_container_kill_all_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container kill-all"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_container_logs_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_container_logs_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container logs"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--container']+x} ]]; then
            args['--container']="$escaped"
          else
            args['--container']="${args['--container']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --open | -o)
        # :flag.conflicts
        if [[ -n "${args['--wait-for-log']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--wait-for-log" >&2
          exit 1
        fi

        # :flag.case_no_arg
        args['--open']=1
        shift
        ;;

      # :flag.case
      --wait-for-log | -w)
        # :flag.conflicts
        if [[ -n "${args['--open']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--open" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--wait-for-log']="$2"
          shift
          shift
        else
          printf "%s\n" "--wait-for-log requires an argument: --wait-for-log, -w LOG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --max-wait | -m)
        # :flag.conflicts
        if [[ -n "${args['--open']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--open" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--max-wait']="$2"
          shift
          shift
        else
          printf "%s\n" "--max-wait requires an argument: --max-wait, -m MAX_WAIT" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"
  [[ -n ${args['--max-wait']:-} ]] || args['--max-wait']="600"

  # :command.validations
  # :flag.validations
  if [[ -v args['--wait-for-log'] ]]; then
    validation_output="$(validate_not_empty "${args['--wait-for-log']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--wait-for-log, -w LOG" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--max-wait'] ]]; then
    validation_output="$(validate_integer "${args['--max-wait']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--max-wait, -m MAX_WAIT" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_container_display_error_all_containers_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_container_display_error_all_containers_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container display-error-all-containers"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_container_ssh_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_container_ssh_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container ssh"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--container']+x} ]]; then
            args['--container']="$escaped"
          else
            args['--container']="${args['--container']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --shell | -s)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--shell']="$2"
          shift
          shift
        else
          printf "%s\n" "--shell requires an argument: --shell, -s SHELL" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"
  [[ -n ${args['--shell']:-} ]] || args['--shell']="bash"

  # :command.whitelist_filter
  if [[ ${args['--shell']:-} ]] && [[ ! ${args['--shell']:-} =~ ^(bash|sh|ksh|zsh)$ ]]; then
    printf "%s\n" "--shell must be one of: bash, sh, ksh, zsh" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_container_change_jdk_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_container_change_jdk_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container change-jdk"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--container']+x} ]]; then
            args['--container']="$escaped"
          else
            args['--container']="${args['--container']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --version)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--version']="$2"
          shift
          shift
        else
          printf "%s\n" "--version requires an argument: --version VERSION" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--version']+x} ]]; then
    printf "missing required flag: --version VERSION\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

  # :command.whitelist_filter
  if [[ ${args['--version']:-} ]] && [[ ! ${args['--version']:-} =~ ^(8|11|17|21|22)$ ]]; then
    printf "%s\n" "--version must be one of: 8, 11, 17, 21, 22" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_container_exec_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_container_exec_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container exec"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--container']+x} ]]; then
            args['--container']="$escaped"
          else
            args['--container']="${args['--container']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --command)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--command']="$2"
          shift
          shift
        else
          printf "%s\n" "--command requires an argument: --command COMMAND" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --root)

        # :flag.case_no_arg
        args['--root']=1
        shift
        ;;

      # :flag.case
      --shell)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--shell']="$2"
          shift
          shift
        else
          printf "%s\n" "--shell requires an argument: --shell SHELL" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--command']+x} ]]; then
    printf "missing required flag: --command COMMAND\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"
  [[ -n ${args['--shell']:-} ]] || args['--shell']="bash"

  # :command.validations
  # :flag.validations
  if [[ -v args['--command'] ]]; then
    validation_output="$(validate_not_empty "${args['--command']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--command COMMAND" "$validation_output" >&2
      exit 1
    fi
  fi

  # :command.whitelist_filter
  if [[ ${args['--shell']:-} ]] && [[ ! ${args['--shell']:-} =~ ^(bash|sh|ksh|zsh)$ ]]; then
    printf "%s\n" "--shell must be one of: bash, sh, ksh, zsh" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_container_restart_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_container_restart_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container restart"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--container']+x} ]]; then
            args['--container']="$escaped"
          else
            args['--container']="${args['--container']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_container_pause_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_container_pause_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container pause"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--container']+x} ]]; then
            args['--container']="$escaped"
          else
            args['--container']="${args['--container']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_container_resume_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_container_resume_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container resume"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--container']+x} ]]; then
            args['--container']="$escaped"
          else
            args['--container']="${args['--container']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_container_kill_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_container_kill_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container kill"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--container']+x} ]]; then
            args['--container']="$escaped"
          else
            args['--container']="${args['--container']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_container_set_environment_variables_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_container_set_environment_variables_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container set-environment-variables"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --container | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--container']+x} ]]; then
            args['--container']="$escaped"
          else
            args['--container']="${args['--container']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--container requires an argument: --container, -c CONTAINER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --env)
        # :flag.conflicts
        if [[ -n "${args['--restore-original-values']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--restore-original-values" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--env']+x} ]]; then
            args['--env']="$escaped"
          else
            args['--env']="${args['--env']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--env requires an argument: --env ENV" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --restore-original-values)
        # :flag.conflicts
        if [[ -n "${args['--env']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--env" >&2
          exit 1
        fi

        # :flag.case_no_arg
        args['--restore-original-values']=1
        shift
        ;;

      # :flag.case
      --mount-jscissors-files)

        # :flag.case_no_arg
        args['--mount-jscissors-files']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--container']:-} ]] || args['--container']="connect"

}

# :command.parse_requirements
playground_container_wait_for_connect_rest_api_ready_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_container_wait_for_connect_rest_api_ready_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="container wait-for-connect-rest-api-ready"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --max-wait)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--max-wait']="$2"
          shift
          shift
        else
          printf "%s\n" "--max-wait requires an argument: --max-wait MAX_WAIT" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--max-wait']:-} ]] || args['--max-wait']="300"

  # :command.validations
  # :flag.validations
  if [[ -v args['--max-wait'] ]]; then
    validation_output="$(validate_integer "${args['--max-wait']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--max-wait MAX_WAIT" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_topic_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_topic_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    get-number-records)
      action="get-number-records"
      shift
      playground_topic_get_number_records_parse_requirements "$@"
      shift $#
      ;;

    display-consumer-offsets)
      action="display-consumer-offsets"
      shift
      playground_topic_display_consumer_offsets_parse_requirements "$@"
      shift $#
      ;;

    list)
      action="list"
      shift
      playground_topic_list_parse_requirements "$@"
      shift $#
      ;;

    describe)
      action="describe"
      shift
      playground_topic_describe_parse_requirements "$@"
      shift $#
      ;;

    set-schema-compatibility)
      action="set-schema-compatibility"
      shift
      playground_topic_set_schema_compatibility_parse_requirements "$@"
      shift $#
      ;;

    consume)
      action="consume"
      shift
      playground_topic_consume_parse_requirements "$@"
      shift $#
      ;;

    produce)
      action="produce"
      shift
      playground_topic_produce_parse_requirements "$@"
      shift $#
      ;;

    create)
      action="create"
      shift
      playground_topic_create_parse_requirements "$@"
      shift $#
      ;;

    delete)
      action="delete"
      shift
      playground_topic_delete_parse_requirements "$@"
      shift $#
      ;;

    alter)
      action="alter"
      shift
      playground_topic_alter_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_topic_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_topic_get_number_records_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_topic_get_number_records_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic get-number-records"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_topic_display_consumer_offsets_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_topic_display_consumer_offsets_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic display-consumer-offsets"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_topic_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_topic_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_topic_describe_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_topic_describe_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic describe"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_topic_set_schema_compatibility_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_topic_set_schema_compatibility_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic set-schema-compatibility"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --compatibility)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--compatibility']="$2"
          shift
          shift
        else
          printf "%s\n" "--compatibility requires an argument: --compatibility COMPATIBILITY" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--compatibility']+x} ]]; then
    printf "missing required flag: --compatibility COMPATIBILITY\n" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--compatibility']:-} ]] && [[ ! ${args['--compatibility']:-} =~ ^(BACKWARD|BACKWARD_TRANSITIVE|FORWARD|FORWARD_TRANSITIVE|FULL|FULL_TRANSITIVE|NONE)$ ]]; then
    printf "%s\n" "--compatibility must be one of: BACKWARD, BACKWARD_TRANSITIVE, FORWARD, FORWARD_TRANSITIVE, FULL, FULL_TRANSITIVE, NONE" >&2
    exit 1
  fi

  # :command.user_filter
  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_topic_consume_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_topic_consume_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic consume"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --max-messages)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--max-messages']="$2"
          shift
          shift
        else
          printf "%s\n" "--max-messages requires an argument: --max-messages MAX-MESSAGES" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --min-expected-messages)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--min-expected-messages']="$2"
          shift
          shift
        else
          printf "%s\n" "--min-expected-messages requires an argument: --min-expected-messages MIN-EXPECTED-MESSAGES" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --grep)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--grep']="$2"
          shift
          shift
        else
          printf "%s\n" "--grep requires an argument: --grep GREP" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --timeout)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--timeout']="$2"
          shift
          shift
        else
          printf "%s\n" "--timeout requires an argument: --timeout TIMEOUT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --tail)
        # :flag.conflicts
        for conflict in --min-expected-messages --max-messages --open; do
          if [[ -n "${args[$conflict]:-}" ]]; then
            printf "conflicting options: %s cannot be used with %s\n" "$key" "$conflict" >&2
            exit 1
          fi
        done

        # :flag.case_no_arg
        args['--tail']=1
        shift
        ;;

      # :flag.case
      --plot-latencies-timestamp-field)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--plot-latencies-timestamp-field']="$2"
          shift
          shift
        else
          printf "%s\n" "--plot-latencies-timestamp-field requires an argument: --plot-latencies-timestamp-field TIMESTAMP" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --key-subject)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--key-subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--key-subject requires an argument: --key-subject KEY-SUBJECT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --value-subject)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--value-subject']="$2"
          shift
          shift
        else
          printf "%s\n" "--value-subject requires an argument: --value-subject VALUE-SUBJECT" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --max-characters)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--max-characters']="$2"
          shift
          shift
        else
          printf "%s\n" "--max-characters requires an argument: --max-characters MAX-CHARACTERS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --open | -o)
        # :flag.conflicts
        for conflict in --max-characters --tail --min-expected-messages; do
          if [[ -n "${args[$conflict]:-}" ]]; then
            printf "conflicting options: %s cannot be used with %s\n" "$key" "$conflict" >&2
            exit 1
          fi
        done

        # :flag.case_no_arg
        args['--open']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--max-messages']:-} ]] || args['--max-messages']="100"
  [[ -n ${args['--min-expected-messages']:-} ]] || args['--min-expected-messages']="0"
  [[ -n ${args['--grep']:-} ]] || args['--grep']=""
  [[ -n ${args['--timeout']:-} ]] || args['--timeout']="60"
  [[ -n ${args['--max-characters']:-} ]] || args['--max-characters']="3000"

  # :command.validations
  # :flag.validations
  if [[ -v args['--max-messages'] ]]; then
    validation_output="$(validate_integer "${args['--max-messages']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--max-messages MAX-MESSAGES" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--min-expected-messages'] ]]; then
    validation_output="$(validate_integer "${args['--min-expected-messages']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--min-expected-messages MIN-EXPECTED-MESSAGES" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--timeout'] ]]; then
    validation_output="$(validate_integer "${args['--timeout']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--timeout TIMEOUT" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--max-characters'] ]]; then
    validation_output="$(validate_integer "${args['--max-characters']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--max-characters MAX-CHARACTERS" "$validation_output" >&2
      exit 1
    fi
  fi

  # :command.user_filter
  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_topic_produce_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_topic_produce_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic produce"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --key)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--key']="$2"
          shift
          shift
        else
          printf "%s\n" "--key requires an argument: --key KEY" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --value)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--value']="$2"
          shift
          shift
        else
          printf "%s\n" "--value requires an argument: --value VALUE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --debug | -d)

        # :flag.case_no_arg
        args['--debug']=1
        shift
        ;;

      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --nb-messages)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--nb-messages']="$2"
          shift
          shift
        else
          printf "%s\n" "--nb-messages requires an argument: --nb-messages NB-MESSAGES" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --max-nb-messages-per-batch)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--max-nb-messages-per-batch']="$2"
          shift
          shift
        else
          printf "%s\n" "--max-nb-messages-per-batch requires an argument: --max-nb-messages-per-batch MAX-NB-MESSAGES-PER-BATCH" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --max-nb-messages-to-generate)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--max-nb-messages-to-generate']="$2"
          shift
          shift
        else
          printf "%s\n" "--max-nb-messages-to-generate requires an argument: --max-nb-messages-to-generate MAX-NB-MESSAGES-TO-GENERATE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --sleep-time-between-batch)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--sleep-time-between-batch']="$2"
          shift
          shift
        else
          printf "%s\n" "--sleep-time-between-batch requires an argument: --sleep-time-between-batch SLEEP-TIME-BETWEEN-BATCH" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --nb-partitions)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--nb-partitions']="$2"
          shift
          shift
        else
          printf "%s\n" "--nb-partitions requires an argument: --nb-partitions NB-PARTITIONS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --compression-codec)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--compression-codec']="$2"
          shift
          shift
        else
          printf "%s\n" "--compression-codec requires an argument: --compression-codec COMPRESSION-CODEC" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --compatibility)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--compatibility']="$2"
          shift
          shift
        else
          printf "%s\n" "--compatibility requires an argument: --compatibility COMPATIBILITY" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --key-subject-name-strategy)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--key-subject-name-strategy']="$2"
          shift
          shift
        else
          printf "%s\n" "--key-subject-name-strategy requires an argument: --key-subject-name-strategy KEY-SUBJECT-NAME-STRATEGY" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --value-subject-name-strategy)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--value-subject-name-strategy']="$2"
          shift
          shift
        else
          printf "%s\n" "--value-subject-name-strategy requires an argument: --value-subject-name-strategy VALUE-SUBJECT-NAME-STRATEGY" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --headers)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--headers']="$2"
          shift
          shift
        else
          printf "%s\n" "--headers requires an argument: --headers HEADERS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --forced-key)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--forced-key']="$2"
          shift
          shift
        else
          printf "%s\n" "--forced-key requires an argument: --forced-key FORCED-KEY" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --forced-value)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--forced-value']="$2"
          shift
          shift
        else
          printf "%s\n" "--forced-value requires an argument: --forced-value FORCED-VALUE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --generate-only)

        # :flag.case_no_arg
        args['--generate-only']=1
        shift
        ;;

      # :flag.case
      --tombstone)

        # :flag.case_no_arg
        args['--tombstone']=1
        shift
        ;;

      # :flag.case
      --validate)

        # :flag.case_no_arg
        args['--validate']=1
        shift
        ;;

      # :flag.case
      --derive-key-schema-as)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--derive-key-schema-as']="$2"
          shift
          shift
        else
          printf "%s\n" "--derive-key-schema-as requires an argument: --derive-key-schema-as DERIVE-KEY-SCHEMA-AS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --derive-value-schema-as)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--derive-value-schema-as']="$2"
          shift
          shift
        else
          printf "%s\n" "--derive-value-schema-as requires an argument: --derive-value-schema-as DERIVE-VALUE-SCHEMA-AS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --no-null)

        # :flag.case_no_arg
        args['--no-null']=1
        shift
        ;;

      # :flag.case
      --consume)

        # :flag.case_no_arg
        args['--consume']=1
        shift
        ;;

      # :flag.case
      --delete-topic)

        # :flag.case_no_arg
        args['--delete-topic']=1
        shift
        ;;

      # :flag.case
      --reference)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--reference']+x} ]]; then
            args['--reference']="$escaped"
          else
            args['--reference']="${args['--reference']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--reference requires an argument: --reference REFERENCE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --validate-config)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--validate-config']+x} ]]; then
            args['--validate-config']="$escaped"
          else
            args['--validate-config']="${args['--validate-config']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--validate-config requires an argument: --validate-config VALIDATE-CONFIG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --producer-property)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--producer-property']+x} ]]; then
            args['--producer-property']="$escaped"
          else
            args['--producer-property']="${args['--producer-property']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--producer-property requires an argument: --producer-property PRODUCER-PROPERTY" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --record-size)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--record-size']="$2"
          shift
          shift
        else
          printf "%s\n" "--record-size requires an argument: --record-size RECORD-SIZE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --value-schema-id)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--value-schema-id']="$2"
          shift
          shift
        else
          printf "%s\n" "--value-schema-id requires an argument: --value-schema-id VALUE-SCHEMA-ID" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--topic']+x} ]]; then
    printf "missing required flag: --topic, -t TOPIC\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--value']:-} ]] || args['--value']="-"
  [[ -n ${args['--nb-messages']:-} ]] || args['--nb-messages']="1"
  [[ -n ${args['--max-nb-messages-per-batch']:-} ]] || args['--max-nb-messages-per-batch']="300000"
  [[ -n ${args['--sleep-time-between-batch']:-} ]] || args['--sleep-time-between-batch']="0"
  [[ -n ${args['--nb-partitions']:-} ]] || args['--nb-partitions']="1"
  [[ -n ${args['--record-size']:-} ]] || args['--record-size']="0"

  # :command.validations
  # :flag.validations
  if [[ -v args['--nb-messages'] ]]; then
    validation_output="$(validate_integer "${args['--nb-messages']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--nb-messages NB-MESSAGES" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--max-nb-messages-per-batch'] ]]; then
    validation_output="$(validate_integer "${args['--max-nb-messages-per-batch']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--max-nb-messages-per-batch MAX-NB-MESSAGES-PER-BATCH" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--max-nb-messages-to-generate'] ]]; then
    validation_output="$(validate_integer "${args['--max-nb-messages-to-generate']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--max-nb-messages-to-generate MAX-NB-MESSAGES-TO-GENERATE" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--sleep-time-between-batch'] ]]; then
    validation_output="$(validate_integer "${args['--sleep-time-between-batch']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--sleep-time-between-batch SLEEP-TIME-BETWEEN-BATCH" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--nb-partitions'] ]]; then
    validation_output="$(validate_integer "${args['--nb-partitions']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--nb-partitions NB-PARTITIONS" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--record-size'] ]]; then
    validation_output="$(validate_integer "${args['--record-size']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--record-size RECORD-SIZE" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--value-schema-id'] ]]; then
    validation_output="$(validate_integer "${args['--value-schema-id']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--value-schema-id VALUE-SCHEMA-ID" "$validation_output" >&2
      exit 1
    fi
  fi

  # :command.whitelist_filter
  if [[ ${args['--compression-codec']:-} ]] && [[ ! ${args['--compression-codec']:-} =~ ^(gzip|snappy|lz4|zstd)$ ]]; then
    printf "%s\n" "--compression-codec must be one of: gzip, snappy, lz4, zstd" >&2
    exit 1
  fi
  if [[ ${args['--compatibility']:-} ]] && [[ ! ${args['--compatibility']:-} =~ ^(BACKWARD|BACKWARD_TRANSITIVE|FORWARD|FORWARD_TRANSITIVE|FULL|FULL_TRANSITIVE|NONE)$ ]]; then
    printf "%s\n" "--compatibility must be one of: BACKWARD, BACKWARD_TRANSITIVE, FORWARD, FORWARD_TRANSITIVE, FULL, FULL_TRANSITIVE, NONE" >&2
    exit 1
  fi
  if [[ ${args['--key-subject-name-strategy']:-} ]] && [[ ! ${args['--key-subject-name-strategy']:-} =~ ^(TopicNameStrategy|RecordNameStrategy|TopicRecordNameStrategy)$ ]]; then
    printf "%s\n" "--key-subject-name-strategy must be one of: TopicNameStrategy, RecordNameStrategy, TopicRecordNameStrategy" >&2
    exit 1
  fi
  if [[ ${args['--value-subject-name-strategy']:-} ]] && [[ ! ${args['--value-subject-name-strategy']:-} =~ ^(TopicNameStrategy|RecordNameStrategy|TopicRecordNameStrategy)$ ]]; then
    printf "%s\n" "--value-subject-name-strategy must be one of: TopicNameStrategy, RecordNameStrategy, TopicRecordNameStrategy" >&2
    exit 1
  fi
  if [[ ${args['--derive-key-schema-as']:-} ]] && [[ ! ${args['--derive-key-schema-as']:-} =~ ^(AVRO|JSON|PROTOBUF)$ ]]; then
    printf "%s\n" "--derive-key-schema-as must be one of: AVRO, JSON, PROTOBUF" >&2
    exit 1
  fi
  if [[ ${args['--derive-value-schema-as']:-} ]] && [[ ! ${args['--derive-value-schema-as']:-} =~ ^(AVRO|JSON|PROTOBUF)$ ]]; then
    printf "%s\n" "--derive-value-schema-as must be one of: AVRO, JSON, PROTOBUF" >&2
    exit 1
  fi
  input_array=''
  eval "input_array=(${args[--validate-config]})"
  for i in "${input_array[@]}"; do
    if [[ ! $i =~ ^(scrub.invalid.names=true|enhanced.avro.schema.support=true|connect.meta.data=false|object.additional.properties=false|use.optional.for.nonrequired=true|ignore.default.for.nullables=true|generalized.sum.type.support=true|enhanced.protobuf.schema.support=true|generate.index.for.unions=false|int.for.enums=true|optional.for.nullables=true|generate.struct.for.nulls=true|wrapper.for.nullables=true|wrapper.for.raw.primitives=false)$ ]]; then
      printf "%s\n" "--validate-config must be one of: scrub.invalid.names=true, enhanced.avro.schema.support=true, connect.meta.data=false, object.additional.properties=false, use.optional.for.nonrequired=true, ignore.default.for.nullables=true, generalized.sum.type.support=true, enhanced.protobuf.schema.support=true, generate.index.for.unions=false, int.for.enums=true, optional.for.nullables=true, generate.struct.for.nulls=true, wrapper.for.nullables=true, wrapper.for.raw.primitives=false" >&2
      exit 1
    fi
  done

  # :command.user_filter
  filter_error=$(filter_schema_registry_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_topic_create_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_topic_create_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic create"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --nb-partitions)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--nb-partitions']="$2"
          shift
          shift
        else
          printf "%s\n" "--nb-partitions requires an argument: --nb-partitions NB-PARTITIONS" >&2
          exit 1
        fi
        ;;

      --)
        shift
        other_args+=("$@")
        break
        ;;

      -?*)
        other_args+=("$1")
        shift
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_catch_all
        other_args+=("$1")
        shift

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--topic']+x} ]]; then
    printf "missing required flag: --topic, -t TOPIC\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['--nb-partitions']:-} ]] || args['--nb-partitions']="1"

  # :command.validations
  # :flag.validations
  if [[ -v args['--nb-partitions'] ]]; then
    validation_output="$(validate_integer "${args['--nb-partitions']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--nb-partitions NB-PARTITIONS" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_topic_delete_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_topic_delete_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic delete"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --skip-delete-schema)

        # :flag.case_no_arg
        args['--skip-delete-schema']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--topic']+x} ]]; then
    printf "missing required flag: --topic, -t TOPIC\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_topic_alter_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_topic_alter_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="topic alter"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --topic | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--topic']="$2"
          shift
          shift
        else
          printf "%s\n" "--topic requires an argument: --topic, -t TOPIC" >&2
          exit 1
        fi
        ;;

      --)
        shift
        other_args+=("$@")
        break
        ;;

      -?*)
        other_args+=("$1")
        shift
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_catch_all
        other_args+=("$1")
        shift

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--topic']+x} ]]; then
    printf "missing required flag: --topic, -t TOPIC\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_plugin_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_plugin_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    search-jar)
      action="search-jar"
      shift
      playground_connector_plugin_search_jar_parse_requirements "$@"
      shift $#
      ;;

    versions)
      action="versions"
      shift
      playground_connector_plugin_versions_parse_requirements "$@"
      shift $#
      ;;

    display-last-updated)
      action="display-last-updated"
      shift
      playground_connector_plugin_display_last_updated_parse_requirements "$@"
      shift $#
      ;;

    sourcecode)
      action="sourcecode"
      shift
      playground_connector_plugin_sourcecode_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_connector_plugin_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_plugin_search_jar_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_plugin_search_jar_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  missing_deps=
  # :dependency.filter
  if ! command -v javap >/dev/null 2>&1; then
    printf "missing dependency: javap\n" >&2
    printf "%s\n\n" "visit https://openjdk.org/install/ to install" >&2
    missing_deps=1
  else
    deps['javap']="$(command -v javap | head -n1)"
  fi

  if [[ -n $missing_deps ]]; then
    exit 1
  fi

  # :command.command_filter
  action="connector-plugin search-jar"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector-plugin | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector-plugin']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-plugin requires an argument: --connector-plugin, -c CONNECTOR-PLUGIN" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --connector-tag)
        # :flag.conflicts
        if [[ -n "${args['--connector-zip']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--connector-zip" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector-tag']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-tag requires an argument: --connector-tag CONNECTOR_TAG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --class)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--class']="$2"
          shift
          shift
        else
          printf "%s\n" "--class requires an argument: --class CLASS" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--connector-plugin']+x} ]]; then
    printf "missing required flag: --connector-plugin, -c CONNECTOR-PLUGIN\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_plugin_versions_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_plugin_versions_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector-plugin versions"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector-plugin | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector-plugin']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-plugin requires an argument: --connector-plugin, -c CONNECTOR-PLUGIN" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --force-refresh)

        # :flag.case_no_arg
        args['--force-refresh']=1
        shift
        ;;

      # :flag.case
      --last)
        # :flag.conflicts
        if [[ -n "${args['--all']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--all" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--last']="$2"
          shift
          shift
        else
          printf "%s\n" "--last requires an argument: --last LAST" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--connector-plugin']+x} ]]; then
    printf "missing required flag: --connector-plugin, -c CONNECTOR-PLUGIN\n" >&2
    exit 1
  fi

  # :command.validations
  # :flag.validations
  if [[ -v args['--last'] ]]; then
    validation_output="$(validate_integer "${args['--last']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--last LAST" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_connector_plugin_display_last_updated_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_plugin_display_last_updated_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector-plugin display-last-updated"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --days)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--days']="$2"
          shift
          shift
        else
          printf "%s\n" "--days requires an argument: --days DAYS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --vendor)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--vendor']="$2"
          shift
          shift
        else
          printf "%s\n" "--vendor requires an argument: --vendor VENDOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--days']:-} ]] || args['--days']="3"

  # :command.validations
  # :flag.validations
  if [[ -v args['--days'] ]]; then
    validation_output="$(validate_integer "${args['--days']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--days DAYS" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--vendor'] ]]; then
    validation_output="$(validate_not_empty "${args['--vendor']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--vendor VENDOR" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_connector_plugin_sourcecode_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_plugin_sourcecode_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector-plugin sourcecode"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector-plugin | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector-plugin']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector-plugin requires an argument: --connector-plugin, -c CONNECTOR-PLUGIN" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --only-show-url)

        # :flag.case_no_arg
        args['--only-show-url']=1
        shift
        ;;

      # :flag.case
      --connector-tag)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--connector-tag']+x} ]]; then
            args['--connector-tag']="$escaped"
          else
            args['--connector-tag']="${args['--connector-tag']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--connector-tag requires an argument: --connector-tag CONNECTOR_TAG" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--connector-plugin']+x} ]]; then
    printf "missing required flag: --connector-plugin, -c CONNECTOR-PLUGIN\n" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    status)
      action="status"
      shift
      playground_connector_status_parse_requirements "$@"
      shift $#
      ;;

    oracle-cdc-xstream)
      action="oracle-cdc-xstream"
      shift
      playground_connector_oracle_cdc_xstream_parse_requirements "$@"
      shift $#
      ;;

    offsets)
      action="offsets"
      shift
      playground_connector_offsets_parse_requirements "$@"
      shift $#
      ;;

    plugins)
      action="plugins"
      shift
      playground_connector_plugins_parse_requirements "$@"
      shift $#
      ;;

    pause)
      action="pause"
      shift
      playground_connector_pause_parse_requirements "$@"
      shift $#
      ;;

    versions)
      action="versions"
      shift
      playground_connector_versions_parse_requirements "$@"
      shift $#
      ;;

    sourcecode)
      action="sourcecode"
      shift
      playground_connector_sourcecode_parse_requirements "$@"
      shift $#
      ;;

    restart)
      action="restart"
      shift
      playground_connector_restart_parse_requirements "$@"
      shift $#
      ;;

    stop)
      action="stop"
      shift
      playground_connector_stop_parse_requirements "$@"
      shift $#
      ;;

    resume | unpause)
      action="resume"
      shift
      playground_connector_resume_parse_requirements "$@"
      shift $#
      ;;

    delete)
      action="delete"
      shift
      playground_connector_delete_parse_requirements "$@"
      shift $#
      ;;

    show-lag)
      action="show-lag"
      shift
      playground_connector_show_lag_parse_requirements "$@"
      shift $#
      ;;

    show-config)
      action="show-config"
      shift
      playground_connector_show_config_parse_requirements "$@"
      shift $#
      ;;

    show-config-parameters)
      action="show-config-parameters"
      shift
      playground_connector_show_config_parameters_parse_requirements "$@"
      shift $#
      ;;

    select-config)
      action="select-config"
      shift
      playground_connector_select_config_parse_requirements "$@"
      shift $#
      ;;

    snippets)
      action="snippets"
      shift
      playground_connector_snippets_parse_requirements "$@"
      shift $#
      ;;

    open-docs)
      action="open-docs"
      shift
      playground_connector_open_docs_parse_requirements "$@"
      shift $#
      ;;

    log-level)
      action="log-level"
      shift
      playground_connector_log_level_parse_requirements "$@"
      shift $#
      ;;

    logs)
      action="logs"
      shift
      playground_connector_logs_parse_requirements "$@"
      shift $#
      ;;

    open-ccloud-connector-in-browser)
      action="open-ccloud-connector-in-browser"
      shift
      playground_connector_open_ccloud_connector_in_browser_parse_requirements "$@"
      shift $#
      ;;

    connect-migration-utility)
      action="connect-migration-utility"
      shift
      playground_connector_connect_migration_utility_parse_requirements "$@"
      shift $#
      ;;

    create-or-update)
      action="create-or-update"
      shift
      playground_connector_create_or_update_parse_requirements "$@"
      shift $#
      ;;

    update)
      action="update"
      shift
      playground_connector_update_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_connector_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.user_filter
  filter_error=$(filter_not_mdc_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_status_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_status_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector status"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_oracle_cdc_xstream_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_oracle_cdc_xstream_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    generate-report)
      action="generate-report"
      shift
      playground_connector_oracle_cdc_xstream_generate_report_parse_requirements "$@"
      shift $#
      ;;

    debug)
      action="debug"
      shift
      playground_connector_oracle_cdc_xstream_debug_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_connector_oracle_cdc_xstream_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.user_filter
  filter_error=$(filter_oracle_running)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_oracle_cdc_xstream_generate_report_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_oracle_cdc_xstream_generate_report_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector oracle-cdc-xstream generate-report"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_oracle_cdc_xstream_debug_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_oracle_cdc_xstream_debug_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector oracle-cdc-xstream debug"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_offsets_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_offsets_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    get)
      action="get"
      shift
      playground_connector_offsets_get_parse_requirements "$@"
      shift $#
      ;;

    reset)
      action="reset"
      shift
      playground_connector_offsets_reset_parse_requirements "$@"
      shift $#
      ;;

    alter)
      action="alter"
      shift
      playground_connector_offsets_alter_parse_requirements "$@"
      shift $#
      ;;

    get-offsets-request-status)
      action="get-offsets-request-status"
      shift
      playground_connector_offsets_get_offsets_request_status_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_connector_offsets_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_offsets_get_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_offsets_get_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector offsets get"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_offsets_reset_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_offsets_reset_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector offsets reset"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_offsets_alter_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_offsets_alter_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector offsets alter"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_offsets_get_offsets_request_status_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_offsets_get_offsets_request_status_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector offsets get-offsets-request-status"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_plugins_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_plugins_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector plugins"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --all)

        # :flag.case_no_arg
        args['--all']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_pause_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_pause_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector pause"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_versions_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_versions_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector versions"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_sourcecode_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_sourcecode_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector sourcecode"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --only-show-url)

        # :flag.case_no_arg
        args['--only-show-url']=1
        shift
        ;;

      # :flag.case
      --connector-tag)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          escaped="$(printf '%q' "$2")"
          if [[ -z ${args['--connector-tag']+x} ]]; then
            args['--connector-tag']="$escaped"
          else
            args['--connector-tag']="${args['--connector-tag']} $escaped"
          fi
          shift
          shift
        else
          printf "%s\n" "--connector-tag requires an argument: --connector-tag CONNECTOR_TAG" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_restart_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_restart_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector restart"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --task-id | -t)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--task-id']="$2"
          shift
          shift
        else
          printf "%s\n" "--task-id requires an argument: --task-id, -t TASK_ID" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--task-id'] ]]; then
    validation_output="$(validate_integer "${args['--task-id']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--task-id, -t TASK_ID" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_connector_stop_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_stop_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector stop"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_resume_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_resume_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector resume"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_delete_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_delete_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector delete"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_show_lag_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_show_lag_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector show-lag"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --interval)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--interval']="$2"
          shift
          shift
        else
          printf "%s\n" "--interval requires an argument: --interval INTERVAL" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --max-wait)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--max-wait']="$2"
          shift
          shift
        else
          printf "%s\n" "--max-wait requires an argument: --max-wait MAX_WAIT" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--interval']:-} ]] || args['--interval']="20"
  [[ -n ${args['--max-wait']:-} ]] || args['--max-wait']="0"

  # :command.validations
  # :flag.validations
  if [[ -v args['--interval'] ]]; then
    validation_output="$(validate_integer "${args['--interval']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--interval INTERVAL" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--max-wait'] ]]; then
    validation_output="$(validate_integer "${args['--max-wait']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--max-wait MAX_WAIT" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_connector_show_config_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_show_config_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector show-config"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --no-clipboard)

        # :flag.case_no_arg
        args['--no-clipboard']=1
        shift
        ;;

      # :flag.case
      --force-rest-endpoint)

        # :flag.case_no_arg
        args['--force-rest-endpoint']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_show_config_parameters_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_show_config_parameters_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector show-config-parameters"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --open | -o)

        # :flag.case_no_arg
        args['--open']=1
        shift
        ;;

      # :flag.case
      --force-refresh)

        # :flag.case_no_arg
        args['--force-refresh']=1
        shift
        ;;

      # :flag.case
      --only-show-file-path)

        # :flag.case_no_arg
        args['--only-show-file-path']=1
        shift
        ;;

      # :flag.case
      --only-show-json)

        # :flag.case_no_arg
        args['--only-show-json']=1
        shift
        ;;

      # :flag.case
      --only-show-json-file-path)

        # :flag.case_no_arg
        args['--only-show-json-file-path']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_select_config_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_select_config_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  missing_deps=
  # :dependency.filter
  if ! command -v fzf >/dev/null 2>&1; then
    printf "missing dependency: fzf\n" >&2
    printf "%s\n\n" "visit https://github.com/junegunn/fzf#installation to install" >&2
    missing_deps=1
  else
    deps['fzf']="$(command -v fzf | head -n1)"
  fi

  if [[ -n $missing_deps ]]; then
    exit 1
  fi

  # :command.command_filter
  action="connector select-config"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_snippets_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_snippets_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector snippets"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --converter)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--converter']="$2"
          shift
          shift
        else
          printf "%s\n" "--converter requires an argument: --converter CONVERTER" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --dlq)

        # :flag.case_no_arg
        args['--dlq']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.whitelist_filter
  if [[ ${args['--converter']:-} ]] && [[ ! ${args['--converter']:-} =~ ^(avro|protobuf|json-schema|json|json-schema-enabled|string|bytearray)$ ]]; then
    printf "%s\n" "--converter must be one of: avro, protobuf, json-schema, json, json-schema-enabled, string, bytearray" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_open_docs_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_open_docs_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector open-docs"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --only-show-url)

        # :flag.case_no_arg
        args['--only-show-url']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_log_level_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_log_level_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector log-level"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --level | -l)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--level']="$2"
          shift
          shift
        else
          printf "%s\n" "--level requires an argument: --level, -l LEVEL" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--level']+x} ]]; then
    printf "missing required flag: --level, -l LEVEL\n" >&2
    exit 1
  fi

  # :command.whitelist_filter
  if [[ ${args['--level']:-} ]] && [[ ! ${args['--level']:-} =~ ^(INFO|WARN|DEBUG|TRACE)$ ]]; then
    printf "%s\n" "--level must be one of: INFO, WARN, DEBUG, TRACE" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_logs_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_logs_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector logs"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --open | -o)
        # :flag.conflicts
        if [[ -n "${args['--wait-for-log']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--wait-for-log" >&2
          exit 1
        fi

        # :flag.case_no_arg
        args['--open']=1
        shift
        ;;

      # :flag.case
      --wait-for-log | -w)
        # :flag.conflicts
        if [[ -n "${args['--open']:-}" ]]; then
          printf "conflicting options: %s cannot be used with %s\n" "$key" "--open" >&2
          exit 1
        fi

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--wait-for-log']="$2"
          shift
          shift
        else
          printf "%s\n" "--wait-for-log requires an argument: --wait-for-log, -w LOG" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--wait-for-log'] ]]; then
    validation_output="$(validate_not_empty "${args['--wait-for-log']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--wait-for-log, -w LOG" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_connector_open_ccloud_connector_in_browser_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_open_ccloud_connector_in_browser_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector open-ccloud-connector-in-browser"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --browser)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--browser']="$2"
          shift
          shift
        else
          printf "%s\n" "--browser requires an argument: --browser BROWSER" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_connect_migration_utility_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_connect_migration_utility_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  missing_deps=
  # :dependency.filter
  if ! command -v confluent >/dev/null 2>&1; then
    printf "missing dependency: confluent\n" >&2
    printf "%s\n\n" "visit https://docs.confluent.io/confluent-cli/current/overview.html to install" >&2
    missing_deps=1
  else
    deps['confluent']="$(command -v confluent | head -n1)"
  fi

  if [[ -n $missing_deps ]]; then
    exit 1
  fi

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    discovery)
      action="discovery"
      shift
      playground_connector_connect_migration_utility_discovery_parse_requirements "$@"
      shift $#
      ;;

    migrate)
      action="migrate"
      shift
      playground_connector_connect_migration_utility_migrate_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_connector_connect_migration_utility_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.user_filter
  filter_error=$(filter_ccloud_environment)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_connect_migration_utility_discovery_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_connect_migration_utility_discovery_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector connect-migration-utility discovery"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_connector_connect_migration_utility_migrate_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_connect_migration_utility_migrate_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector connect-migration-utility migrate"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --migration-mode)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--migration-mode']="$2"
          shift
          shift
        else
          printf "%s\n" "--migration-mode requires an argument: --migration-mode MIGRATION-MODE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--migration-mode']:-} ]] || args['--migration-mode']="create"

  # :command.whitelist_filter
  if [[ ${args['--migration-mode']:-} ]] && [[ ! ${args['--migration-mode']:-} =~ ^(stop_create_latest_offset|create|create_latest_offset)$ ]]; then
    printf "%s\n" "--migration-mode must be one of: stop_create_latest_offset, create, create_latest_offset" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_create_or_update_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_create_or_update_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector create-or-update"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --verbose | -v)

        # :flag.case_no_arg
        args['--verbose']=1
        shift
        ;;

      # :flag.case
      --no-clipboard)

        # :flag.case_no_arg
        args['--no-clipboard']=1
        shift
        ;;

      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --level | -l)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--level']="$2"
          shift
          shift
        else
          printf "%s\n" "--level requires an argument: --level, -l LEVEL" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --package | -p)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--package']="$2"
          shift
          shift
        else
          printf "%s\n" "--package requires an argument: --package, -p PACKAGE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --wait-for-zero-lag)

        # :flag.case_no_arg
        args['--wait-for-zero-lag']=1
        shift
        ;;

      # :flag.case
      --validate)

        # :flag.case_no_arg
        args['--validate']=1
        shift
        ;;

      # :flag.case
      --skip-automatic-connector-config)

        # :flag.case_no_arg
        args['--skip-automatic-connector-config']=1
        shift
        ;;

      # :flag.case
      --offsets)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--offsets']="$2"
          shift
          shift
        else
          printf "%s\n" "--offsets requires an argument: --offsets OFFSETS" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --initial-state)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--initial-state']="$2"
          shift
          shift
        else
          printf "%s\n" "--initial-state requires an argument: --initial-state INITIAL-STATE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        # :argument.case
        if [[ -z ${args['json']+x} ]]; then
          args['json']=$1
          shift
        else
          printf "invalid argument: %s\n" "$key" >&2
          exit 1
        fi

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--connector']+x} ]]; then
    printf "missing required flag: --connector, -c CONNECTOR\n" >&2
    exit 1
  fi

  # :command.default_assignments
  [[ -n ${args['json']:-} ]] || args['json']="-"

  # :command.validations
  # :flag.validations
  if [[ -v args['--package'] ]]; then
    validation_output="$(validate_not_empty "${args['--package']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--package, -p PACKAGE" "$validation_output" >&2
      exit 1
    fi
  fi

  # :flag.validations
  if [[ -v args['--offsets'] ]]; then
    validation_output="$(validate_json "${args['--offsets']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--offsets OFFSETS" "$validation_output" >&2
      exit 1
    fi
  fi

  # :command.whitelist_filter
  if [[ ${args['--level']:-} ]] && [[ ! ${args['--level']:-} =~ ^(INFO|WARN|DEBUG|TRACE)$ ]]; then
    printf "%s\n" "--level must be one of: INFO, WARN, DEBUG, TRACE" >&2
    exit 1
  fi
  if [[ ${args['--initial-state']:-} ]] && [[ ! ${args['--initial-state']:-} =~ ^(RUNNING|PAUSED|STOPPED)$ ]]; then
    printf "%s\n" "--initial-state must be one of: RUNNING, PAUSED, STOPPED" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_connector_update_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_connector_update_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="connector update"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --connector | -c)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--connector']="$2"
          shift
          shift
        else
          printf "%s\n" "--connector requires an argument: --connector, -c CONNECTOR" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_ec2_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_ec2_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    create)
      action="create"
      shift
      playground_ec2_create_parse_requirements "$@"
      shift $#
      ;;

    delete)
      action="delete"
      shift
      playground_ec2_delete_parse_requirements "$@"
      shift $#
      ;;

    open)
      action="open"
      shift
      playground_ec2_open_parse_requirements "$@"
      shift $#
      ;;

    allow-my-ip)
      action="allow-my-ip"
      shift
      playground_ec2_allow_my_ip_parse_requirements "$@"
      shift $#
      ;;

    list)
      action="list"
      shift
      playground_ec2_list_parse_requirements "$@"
      shift $#
      ;;

    stop)
      action="stop"
      shift
      playground_ec2_stop_parse_requirements "$@"
      shift $#
      ;;

    start)
      action="start"
      shift
      playground_ec2_start_parse_requirements "$@"
      shift $#
      ;;

    status)
      action="status"
      shift
      playground_ec2_status_parse_requirements "$@"
      shift $#
      ;;

    sync-repro-folder)
      action="sync-repro-folder"
      shift
      playground_ec2_sync_repro_folder_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_ec2_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.user_filter
  filter_error=$(filter_aws_ec2_permissions)
  if [[ -n $filter_error ]]; then
    echo "$filter_error" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_ec2_create_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_ec2_create_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="ec2 create"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --instance-type)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--instance-type']="$2"
          shift
          shift
        else
          printf "%s\n" "--instance-type requires an argument: --instance-type INSTANCE-TYPE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --size)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--size']="$2"
          shift
          shift
        else
          printf "%s\n" "--size requires an argument: --size SIZE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --suffix)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--suffix']="$2"
          shift
          shift
        else
          printf "%s\n" "--suffix requires an argument: --suffix SUFFIX" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.default_assignments
  [[ -n ${args['--instance-type']:-} ]] || args['--instance-type']="t3.2xlarge"
  [[ -n ${args['--size']:-} ]] || args['--size']="1000"

  # :command.validations
  # :flag.validations
  if [[ -v args['--size'] ]]; then
    validation_output="$(validate_integer "${args['--size']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--size SIZE" "$validation_output" >&2
      exit 1
    fi
  fi

  # :command.whitelist_filter
  if [[ ${args['--instance-type']:-} ]] && [[ ! ${args['--instance-type']:-} =~ ^(c1.medium|c1.xlarge|c3.2xlarge|c3.4xlarge|c3.8xlarge|c3.large|c3.xlarge|c4.2xlarge|c4.4xlarge|c4.large|c4.xlarge|m1.large|m1.medium|m1.small|m1.xlarge|m2.2xlarge|m2.4xlarge|m2.xlarge|m3.2xlarge|m3.large|m3.medium|m3.xlarge|m4.10xlarge|m4.2xlarge|m4.4xlarge|m4.large|m4.xlarge|t1.micro|t2.large|t2.medium|t2.micro|t2.nano|t2.small|t3.2xlarge)$ ]]; then
    printf "%s\n" "--instance-type must be one of: c1.medium, c1.xlarge, c3.2xlarge, c3.4xlarge, c3.8xlarge, c3.large, c3.xlarge, c4.2xlarge, c4.4xlarge, c4.large, c4.xlarge, m1.large, m1.medium, m1.small, m1.xlarge, m2.2xlarge, m2.4xlarge, m2.xlarge, m3.2xlarge, m3.large, m3.medium, m3.xlarge, m4.10xlarge, m4.2xlarge, m4.4xlarge, m4.large, m4.xlarge, t1.micro, t2.large, t2.medium, t2.micro, t2.nano, t2.small, t3.2xlarge" >&2
    exit 1
  fi

}

# :command.parse_requirements
playground_ec2_delete_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_ec2_delete_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="ec2 delete"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --instance | -i)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--instance']="$2"
          shift
          shift
        else
          printf "%s\n" "--instance requires an argument: --instance, -i INSTANCE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--instance'] ]]; then
    validation_output="$(validate_not_empty "${args['--instance']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--instance, -i INSTANCE" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_ec2_open_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_ec2_open_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="ec2 open"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --instance | -i)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--instance']="$2"
          shift
          shift
        else
          printf "%s\n" "--instance requires an argument: --instance, -i INSTANCE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --enable-sync-repro-folder)

        # :flag.case_no_arg
        args['--enable-sync-repro-folder']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--instance'] ]]; then
    validation_output="$(validate_not_empty "${args['--instance']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--instance, -i INSTANCE" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_ec2_allow_my_ip_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_ec2_allow_my_ip_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="ec2 allow-my-ip"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --instance | -i)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--instance']="$2"
          shift
          shift
        else
          printf "%s\n" "--instance requires an argument: --instance, -i INSTANCE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--instance'] ]]; then
    validation_output="$(validate_not_empty "${args['--instance']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--instance, -i INSTANCE" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_ec2_list_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_ec2_list_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="ec2 list"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_ec2_stop_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_ec2_stop_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="ec2 stop"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --instance | -i)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--instance']="$2"
          shift
          shift
        else
          printf "%s\n" "--instance requires an argument: --instance, -i INSTANCE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--instance'] ]]; then
    validation_output="$(validate_not_empty "${args['--instance']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--instance, -i INSTANCE" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_ec2_start_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_ec2_start_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="ec2 start"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --instance | -i)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--instance']="$2"
          shift
          shift
        else
          printf "%s\n" "--instance requires an argument: --instance, -i INSTANCE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--instance'] ]]; then
    validation_output="$(validate_not_empty "${args['--instance']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--instance, -i INSTANCE" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_ec2_status_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_ec2_status_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="ec2 status"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --instance | -i)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--instance']="$2"
          shift
          shift
        else
          printf "%s\n" "--instance requires an argument: --instance, -i INSTANCE" >&2
          exit 1
        fi
        ;;

      # :flag.case
      --all)

        # :flag.case_no_arg
        args['--all']=1
        shift
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.required_flags_filter
  if [[ -z ${args['--instance']+x} ]]; then
    printf "missing required flag: --instance, -i INSTANCE\n" >&2
    exit 1
  fi

  # :command.validations
  # :flag.validations
  if [[ -v args['--instance'] ]]; then
    validation_output="$(validate_not_empty "${args['--instance']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--instance, -i INSTANCE" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_ec2_sync_repro_folder_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_ec2_sync_repro_folder_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.dependencies_filter
  missing_deps=
  # :dependency.filter
  if ! command -v rsync >/dev/null 2>&1; then
    printf "missing dependency: rsync\n" >&2
    printf "%s\n\n" "rsync needs to be installed" >&2
    missing_deps=1
  else
    deps['rsync']="$(command -v rsync | head -n1)"
  fi

  if [[ -n $missing_deps ]]; then
    exit 1
  fi

  # :command.command_filter
  action=${1:-}

  case $action in
    -*) ;;

    local-to-ec2)
      action="local-to-ec2"
      shift
      playground_ec2_sync_repro_folder_local_to_ec2_parse_requirements "$@"
      shift $#
      ;;

    ec2-to-local)
      action="ec2-to-local"
      shift
      playground_ec2_sync_repro_folder_ec2_to_local_parse_requirements "$@"
      shift $#
      ;;

    # :command.command_fallback
    "")
      playground_ec2_sync_repro_folder_usage >&2
      exit 1
      ;;

    *)
      printf "invalid command: %s\n" "$action" >&2
      exit 1
      ;;

  esac

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

}

# :command.parse_requirements
playground_ec2_sync_repro_folder_local_to_ec2_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_ec2_sync_repro_folder_local_to_ec2_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="ec2 sync-repro-folder local-to-ec2"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --instance | -i)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--instance']="$2"
          shift
          shift
        else
          printf "%s\n" "--instance requires an argument: --instance, -i INSTANCE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--instance'] ]]; then
    validation_output="$(validate_not_empty "${args['--instance']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--instance, -i INSTANCE" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.parse_requirements
playground_ec2_sync_repro_folder_ec2_to_local_parse_requirements() {
  # :command.fixed_flags_filter
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      --help | -h)
        long_usage=yes
        playground_ec2_sync_repro_folder_ec2_to_local_usage
        exit
        ;;

      *)
        break
        ;;

    esac
  done

  # :command.command_filter
  action="ec2 sync-repro-folder ec2-to-local"

  # :command.parse_requirements_while
  while [[ $# -gt 0 ]]; do
    key="$1"
    case "$key" in
      # :flag.case
      --instance | -i)

        # :flag.case_arg
        if [[ -n ${2+x} ]]; then
          args['--instance']="$2"
          shift
          shift
        else
          printf "%s\n" "--instance requires an argument: --instance, -i INSTANCE" >&2
          exit 1
        fi
        ;;

      -?*)
        printf "invalid option: %s\n" "$key" >&2
        exit 1
        ;;

      *)
        # :command.parse_requirements_case
        # :command.parse_requirements_case_simple
        printf "invalid argument: %s\n" "$key" >&2
        exit 1

        ;;

    esac
  done

  # :command.validations
  # :flag.validations
  if [[ -v args['--instance'] ]]; then
    validation_output="$(validate_not_empty "${args['--instance']:-}")"
    if [[ -n "${validation_output}" ]]; then
      printf "validation error in %s:\n%s\n" "--instance, -i INSTANCE" "$validation_output" >&2
      exit 1
    fi
  fi

}

# :command.user_hooks
before_hook() {
  # src/before.sh

  DIR_CLI="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"
  dir1=$(echo ${DIR_CLI%/*})
  root_folder=$(echo ${dir1%/*})

  vvv="${args[--vvv]}"
  level="${args[--output-level]}"

  if [[ -n "$vvv" ]]
  then
      if [ -z "$GITHUB_RUN_NUMBER" ]
      then
          log "🐛 --vvv is set"
          export PS4='\[\033[0;36m\]🐞$(date "+%H:%M:%S")[$(basename $0):${LINENO}] \[\033[0m\]'
          set -x
          export PG_VERBOSE_MODE=true
      fi
  fi

  if [[ -n "$level" ]]
  then
      export PG_LOG_LEVEL="$level"
      log "🔖 --output-level is set with $level"
  fi
}

# :command.initialize
initialize() {
  declare -g version="1.0.0"
  set -e

}

# :command.run
run() {
  # :command.globals
  declare -g long_usage=''
  declare -g -A args=()
  declare -g -a other_args=()
  declare -g -A deps=()
  declare -g -a env_var_names=()
  declare -g -a input=()
  declare -g -A unique_lookup=()

  normalize_input "$@"
  parse_requirements "${input[@]}"
  before_hook

  case "$action" in
    "help") playground_help_command ;;
    "status") playground_status_command ;;
    "get-docker-ports") playground_get_docker_ports_command ;;
    "get-connector-list") playground_get_connector_list_command ;;
    "get-ec2-instance-list") playground_get_ec2_instance_list_command ;;
    "get-ec2-cloudformation-list") playground_get_ec2_cloudformation_list_command ;;
    "get-zazkia-connection-list") playground_get_zazkia_connection_list_command ;;
    "generate-fzf-find-files") playground_generate_fzf_find_files_command ;;
    "generate-tag-list") playground_generate_tag_list_command ;;
    "generate-connector-plugin-list") playground_generate_connector_plugin_list_command ;;
    "generate-kafka-region-list") playground_generate_kafka_region_list_command ;;
    "get-connector-plugin") playground_get_connector_plugin_command ;;
    "get-ccloud-environment-list") playground_get_ccloud_environment_list_command ;;
    "get-ccloud-cluster-list") playground_get_ccloud_cluster_list_command ;;
    "get-tag-list") playground_get_tag_list_command ;;
    "get-kafka-region-list") playground_get_kafka_region_list_command ;;
    "get-topic-list") playground_get_topic_list_command ;;
    "get-subject-list") playground_get_subject_list_command ;;
    "get-examples-list-with-fzf") playground_get_examples_list_with_fzf_command ;;
    "get-zip-or-jar-with-fzf") playground_get_zip_or_jar_with_fzf_command ;;
    "get-specific-file-extension") playground_get_specific_file_extension_command ;;
    "get-any-file-with-fzf") playground_get_any_file_with_fzf_command ;;
    "get-playground-repro-export-with-fzf") playground_get_playground_repro_export_with_fzf_command ;;
    "get-predefined-schemas") playground_get_predefined_schemas_command ;;
    "update-cache-versions") playground_update_cache_versions_command ;;
    "update-readme") playground_update_readme_command ;;
    "force-ci") playground_force_ci_command ;;
    "update-docs") playground_update_docs_command ;;
    "bashly-reload") playground_bashly_reload_command ;;
    "state") playground_state_command ;;
    "state show") playground_state_show_command ;;
    "state get") playground_state_get_command ;;
    "state set") playground_state_set_command ;;
    "state del") playground_state_del_command ;;
    "config") playground_config_command ;;
    "config show") playground_config_show_command ;;
    "config get") playground_config_get_command ;;
    "config set") playground_config_set_command ;;
    "config editor") playground_config_editor_command ;;
    "config folder_zip_or_jar") playground_config_folder_zip_or_jar_command ;;
    "config clipboard") playground_config_clipboard_command ;;
    "config open-ccloud-connector-in-browser") playground_config_open_ccloud_connector_in_browser_command ;;
    "config open-ccloud-connector-in-browser automatically") playground_config_open_ccloud_connector_in_browser_automatically_command ;;
    "config open-ccloud-connector-in-browser browser") playground_config_open_ccloud_connector_in_browser_browser_command ;;
    "config open-grafana-in-browser") playground_config_open_grafana_in_browser_command ;;
    "config open-grafana-in-browser automatically") playground_config_open_grafana_in_browser_automatically_command ;;
    "config open-grafana-in-browser browser") playground_config_open_grafana_in_browser_browser_command ;;
    "config container-kill-all-before-run") playground_config_container_kill_all_before_run_command ;;
    "config check-and-update-repo-version") playground_config_check_and_update_repo_version_command ;;
    "ai") playground_ai_command ;;
    "ccloud-costs") playground_ccloud_costs_command ;;
    "ccloud-costs-history") playground_ccloud_costs_history_command ;;
    "run") playground_run_command ;;
    "re-run") playground_re_run_command ;;
    "get-ci-result") playground_get_ci_result_command ;;
    "history") playground_history_command ;;
    "start-environment") playground_start_environment_command ;;
    "switch-ccloud") playground_switch_ccloud_command ;;
    "switch-back") playground_switch_back_command ;;
    "update-version") playground_update_version_command ;;
    "open") playground_open_command ;;
    "stop") playground_stop_command ;;
    "remove-all-docker-images") playground_remove_all_docker_images_command ;;
    "remove-cp-docker-images") playground_remove_cp_docker_images_command ;;
    "refresh-cp-docker-images") playground_refresh_cp_docker_images_command ;;
    "cleanup-cloud-details") playground_cleanup_cloud_details_command ;;
    "open-docs") playground_open_docs_command ;;
    "open-changelog") playground_open_changelog_command ;;
    "cleanup-cloud-resources") playground_cleanup_cloud_resources_command ;;
    "repro") playground_repro_command ;;
    "repro export") playground_repro_export_command ;;
    "repro import") playground_repro_import_command ;;
    "repro bootstrap") playground_repro_bootstrap_command ;;
    "get-docker-compose") playground_get_docker_compose_command ;;
    "schema") playground_schema_command ;;
    "schema get") playground_schema_get_command ;;
    "schema register") playground_schema_register_command ;;
    "schema get-compatibility") playground_schema_get_compatibility_command ;;
    "schema set-compatibility") playground_schema_set_compatibility_command ;;
    "schema get-mode") playground_schema_get_mode_command ;;
    "schema set-mode") playground_schema_set_mode_command ;;
    "schema set-normalize") playground_schema_set_normalize_command ;;
    "schema delete") playground_schema_delete_command ;;
    "schema derive-schema") playground_schema_derive_schema_command ;;
    "tcp-proxy") playground_tcp_proxy_command ;;
    "tcp-proxy start") playground_tcp_proxy_start_command ;;
    "tcp-proxy get-connections") playground_tcp_proxy_get_connections_command ;;
    "tcp-proxy delay") playground_tcp_proxy_delay_command ;;
    "tcp-proxy break") playground_tcp_proxy_break_command ;;
    "tcp-proxy close-connection") playground_tcp_proxy_close_connection_command ;;
    "tcp-proxy close-all-connection-with-error") playground_tcp_proxy_close_all_connection_with_error_command ;;
    "tcp-proxy toggle-accept-connections") playground_tcp_proxy_toggle_accept_connections_command ;;
    "tcp-proxy toggle-reads-client") playground_tcp_proxy_toggle_reads_client_command ;;
    "tcp-proxy toggle-reads-service") playground_tcp_proxy_toggle_reads_service_command ;;
    "tcp-proxy toggle-writes-client") playground_tcp_proxy_toggle_writes_client_command ;;
    "tcp-proxy toggle-writes-service") playground_tcp_proxy_toggle_writes_service_command ;;
    "tcp-proxy open-ui") playground_tcp_proxy_open_ui_command ;;
    "tools") playground_tools_command ;;
    "tools install-vscode-extension") playground_tools_install_vscode_extension_command ;;
    "tools read-avro-file") playground_tools_read_avro_file_command ;;
    "tools read-parquet-file") playground_tools_read_parquet_file_command ;;
    "tools certs-create") playground_tools_certs_create_command ;;
    "debug") playground_debug_command ;;
    "debug enable-remote-debugging") playground_debug_enable_remote_debugging_command ;;
    "debug testssl") playground_debug_testssl_command ;;
    "debug generate-diagnostics") playground_debug_generate_diagnostics_command ;;
    "debug thread-dump") playground_debug_thread_dump_command ;;
    "debug heap-dump") playground_debug_heap_dump_command ;;
    "debug tcp-dump") playground_debug_tcp_dump_command ;;
    "debug block-traffic") playground_debug_block_traffic_command ;;
    "debug java-debug") playground_debug_java_debug_command ;;
    "debug jscissors") playground_debug_jscissors_command ;;
    "debug flight-recorder") playground_debug_flight_recorder_command ;;
    "debug log-level") playground_debug_log_level_command ;;
    "debug log-level get") playground_debug_log_level_get_command ;;
    "debug log-level set") playground_debug_log_level_set_command ;;
    "get-jmx-metrics") playground_get_jmx_metrics_command ;;
    "container") playground_container_command ;;
    "container get-properties") playground_container_get_properties_command ;;
    "container recreate") playground_container_recreate_command ;;
    "container get-ip-addresses") playground_container_get_ip_addresses_command ;;
    "container kill-all") playground_container_kill_all_command ;;
    "container logs") playground_container_logs_command ;;
    "container display-error-all-containers") playground_container_display_error_all_containers_command ;;
    "container ssh") playground_container_ssh_command ;;
    "container change-jdk") playground_container_change_jdk_command ;;
    "container exec") playground_container_exec_command ;;
    "container restart") playground_container_restart_command ;;
    "container pause") playground_container_pause_command ;;
    "container resume") playground_container_resume_command ;;
    "container kill") playground_container_kill_command ;;
    "container set-environment-variables") playground_container_set_environment_variables_command ;;
    "container wait-for-connect-rest-api-ready") playground_container_wait_for_connect_rest_api_ready_command ;;
    "topic") playground_topic_command ;;
    "topic get-number-records") playground_topic_get_number_records_command ;;
    "topic display-consumer-offsets") playground_topic_display_consumer_offsets_command ;;
    "topic list") playground_topic_list_command ;;
    "topic describe") playground_topic_describe_command ;;
    "topic set-schema-compatibility") playground_topic_set_schema_compatibility_command ;;
    "topic consume") playground_topic_consume_command ;;
    "topic produce") playground_topic_produce_command ;;
    "topic create") playground_topic_create_command ;;
    "topic delete") playground_topic_delete_command ;;
    "topic alter") playground_topic_alter_command ;;
    "connector-plugin") playground_connector_plugin_command ;;
    "connector-plugin search-jar") playground_connector_plugin_search_jar_command ;;
    "connector-plugin versions") playground_connector_plugin_versions_command ;;
    "connector-plugin display-last-updated") playground_connector_plugin_display_last_updated_command ;;
    "connector-plugin sourcecode") playground_connector_plugin_sourcecode_command ;;
    "connector") playground_connector_command ;;
    "connector status") playground_connector_status_command ;;
    "connector oracle-cdc-xstream") playground_connector_oracle_cdc_xstream_command ;;
    "connector oracle-cdc-xstream generate-report") playground_connector_oracle_cdc_xstream_generate_report_command ;;
    "connector oracle-cdc-xstream debug") playground_connector_oracle_cdc_xstream_debug_command ;;
    "connector offsets") playground_connector_offsets_command ;;
    "connector offsets get") playground_connector_offsets_get_command ;;
    "connector offsets reset") playground_connector_offsets_reset_command ;;
    "connector offsets alter") playground_connector_offsets_alter_command ;;
    "connector offsets get-offsets-request-status") playground_connector_offsets_get_offsets_request_status_command ;;
    "connector plugins") playground_connector_plugins_command ;;
    "connector pause") playground_connector_pause_command ;;
    "connector versions") playground_connector_versions_command ;;
    "connector sourcecode") playground_connector_sourcecode_command ;;
    "connector restart") playground_connector_restart_command ;;
    "connector stop") playground_connector_stop_command ;;
    "connector resume") playground_connector_resume_command ;;
    "connector delete") playground_connector_delete_command ;;
    "connector show-lag") playground_connector_show_lag_command ;;
    "connector show-config") playground_connector_show_config_command ;;
    "connector show-config-parameters") playground_connector_show_config_parameters_command ;;
    "connector select-config") playground_connector_select_config_command ;;
    "connector snippets") playground_connector_snippets_command ;;
    "connector open-docs") playground_connector_open_docs_command ;;
    "connector log-level") playground_connector_log_level_command ;;
    "connector logs") playground_connector_logs_command ;;
    "connector open-ccloud-connector-in-browser") playground_connector_open_ccloud_connector_in_browser_command ;;
    "connector connect-migration-utility") playground_connector_connect_migration_utility_command ;;
    "connector connect-migration-utility discovery") playground_connector_connect_migration_utility_discovery_command ;;
    "connector connect-migration-utility migrate") playground_connector_connect_migration_utility_migrate_command ;;
    "connector create-or-update") playground_connector_create_or_update_command ;;
    "connector update") playground_connector_update_command ;;
    "ec2") playground_ec2_command ;;
    "ec2 create") playground_ec2_create_command ;;
    "ec2 delete") playground_ec2_delete_command ;;
    "ec2 open") playground_ec2_open_command ;;
    "ec2 allow-my-ip") playground_ec2_allow_my_ip_command ;;
    "ec2 list") playground_ec2_list_command ;;
    "ec2 stop") playground_ec2_stop_command ;;
    "ec2 start") playground_ec2_start_command ;;
    "ec2 status") playground_ec2_status_command ;;
    "ec2 sync-repro-folder") playground_ec2_sync_repro_folder_command ;;
    "ec2 sync-repro-folder local-to-ec2") playground_ec2_sync_repro_folder_local_to_ec2_command ;;
    "ec2 sync-repro-folder ec2-to-local") playground_ec2_sync_repro_folder_ec2_to_local_command ;;
  esac
}

if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
  # :command.start
  command_line_args=("$@")
  initialize
  run "${command_line_args[@]}"
fi
