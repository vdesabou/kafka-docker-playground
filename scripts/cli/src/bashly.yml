name: playground
version: 1.0.0
dependencies:
  docker: visit $(blue_underlined https://docs.docker.com/get-docker) to install
help: |-
  ğŸ§  CLI for Kafka Docker Playground ğŸ³

  ğŸ‘‰ Check documentation https://kafka-docker-playground.io/#/cli
filters:
- docker_running
commands:

### private commands for completion
- name: get-connector-list
  help: Return some completion for connector list
  private: true

- name: get-ccloud-connector-list
  help: Return some completion for ccloud connector list
  private: true
  dependencies:
    confluent: visit $(blue_underlined https://docs.confluent.io/confluent-cli/current/overview.html) to install

- name: get-kafka-region-list
  help: Return some completion for confluent cloud kafka cluster region list
  private: true
  dependencies:
    confluent: visit $(blue_underlined https://docs.confluent.io/confluent-cli/current/overview.html) to install

- name: get-topic-list
  help: Return some completion for topic list
  private: true
  flags:
  - long: --skip-connect-internal-topics
    required: false

- name: get-examples-list-with-fzf
  help: Return some completion for examples list
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur
  flags:
  - long: --without-repro
    required: false
  - long: --sink-only
    required: false
  - long: --ccloud-only
    required: false

- name: get-zip-or-jar-with-fzf
  help: Return some completion for zip or jar list
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur
  flags:
  - long: --type
    required: false
    arg: type
    allowed: [zip, jar]

- name: get-any-file-with-fzf
  help: Return some completion for any files
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur

- name: get-predefined-schemas
  help: Return some completion for predefined schemas
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur

- name: bashly-reload
  private: true
  dependencies:
    bashly: visit $(blue_underlined https://bashly.dannyb.co/installation/) to install

- name: run
  group: Run
  catch_all:
    label: arguments
    help: |-
      Arguments to use by example script

      Most of examples support to get required options either by using arguments or environment variables.
      
      Example with Zendesk:

      playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME> <ZENDESK_PASSWORD>
    required: false
  dependencies:
    fzf: visit $(blue_underlined https://github.com/junegunn/fzf#installation) to install
  help: |-
    ğŸ•¹ï¸ Run any example, except for Confluent Cloud (in this case use run-ccloud command)

  flags:
  - long: --file
    short: -f
    required: true
    validate: file_exists_with_trick
    arg: file
    completions:
      - $(playground get-examples-list-with-fzf "$cur")
    help: |-
      ğŸ”– Example file to run

      â• It must be absolute full path

      ğŸ“ Tip: use <tab> completion to trigger fzf completion
  - long: --open
    short: -o
    help: ğŸ“– Opening example file with text editor set with config.ini (default is code)
  - &tag
    long: --tag
    arg: tag
    required: false
    validate: minimal_cp_version
    help: |-
      ğŸ¯ Confluent Platform (CP) version to use

      Must be greater or equal to 5.0.0
  - &connector-tag
    long: --connector-tag
    arg: connector_tag
    required: false
    help: |- 
      ğŸ”— Connector version to use

      By default, for each connector, the latest available version on Confluent Hub is used
    conflicts: [--connector-zip]
  - &connector-zip
    long: --connector-zip
    arg: connector_zip
    required: false
    validate: file_exists_with_trick
    completions:
      - $(playground get-zip-or-jar-with-fzf --type zip "$cur")
    conflicts: [--connector-tag]
    help: |- 
      ğŸ¤ Connector zip to use

      â• It must be absolute full path

      ğŸ“ Tip: use <tab> completion to trigger fzf completion 
              use folder_zip_or_jar (default: ~/Downloads) in config.ini file to configure where to search the files (current folder is always used)

  - &connector-jar
    long: --connector-jar
    arg: connector_jar
    required: false
    validate: file_exists_with_trick
    completions:
      - $(playground get-zip-or-jar-with-fzf --type jar "$cur")
    help: |-
      â™¨ï¸ Connector jar to use

      â• It must be absolute full path

      ğŸ“ Tip: use <tab> completion to trigger fzf completion 
              use folder_zip_or_jar (default: ~/Downloads) in config.ini file to configure where to search the files (current folder is always used)

  - &enable-ksqldb
    long: --enable-ksqldb
    required: false
    help: |-
      ğŸš€ Enable ksqlDB

      By default, ksqldb-server and ksqldb-cli containers are not started for every test
  - &enable-control-center
    long: --enable-control-center
    required: false
    help: |-
      ğŸ’  Enable Control Center

      By default, control-center container is not started for every test

      Control Center is reachable at http://127.0.0.1:9021
  - &enable-conduktor
    long: --enable-conduktor
    required: false
    help: |- 
      ğŸº Enable Conduktor Platform

      By default, Conduktor Platform container is not started for every test

      Conduktor is reachable at http://127.0.0.1:8080/console (admin/admin)
  - &enable-multiple-brokers
    long: --enable-multiple-brokers
    required: false
    help: |- 
      3ï¸âƒ£ Enable multiple brokers

      By default, there is only one broker node enabled
  - &enable-multiple-connect-workers
    long: --enable-multiple-connect-workers
    required: false
    help: |-
      ğŸ¥‰ Enable multiple connect node

      By default, there is only one connect node enabled

      It only works when plaintext environment is used
  - &enable-jmx-grafana
    long: --enable-jmx-grafana
    required: false
    help: |-
      Enable Grafana, Prometheus and Pyroscope

      ğŸ“Š Grafana is reachable at http://127.0.0.1:3000
      ğŸ›¡ï¸ Prometheus is reachable at http://127.0.0.1:9090
      ğŸ“› Pyroscope is reachable at http://127.0.0.1:4040
  - &enable-kcat
    long: --enable-kcat
    required: false
    help: |-
      ğŸˆâ€â¬› Enable kcat

      You can use it with:

      $ docker exec kcat kcat -b broker:9092 -L
  - &enable-sr-maven-plugin-app
    long: --enable-sr-maven-plugin-app
    required: false
    help: |- 
      ğŸ”° Enable Schema Registry Maven plugin App
  - &enable-sql-datagen
    long: --enable-sql-datagen
    required: false
    help: |-
      ğŸŒªï¸ Enable SQL Datagen injection

      This only works for Oracle, MySql, Postgres and Microsoft Sql Server source connector examples with JDBC and Debezium
  examples:
  - playground run -f zendesk-source<tab> --tag 7.2.1 --enable-control-center <ZENDESK_URL> <ZENDESK_USERNAME> <ZENDESK_PASSWORD>
  - playground run -f jdbc<tab> --connector-tag 10.6.0 --enable-jmx-grafana --open

- name: re-run
  group: Run
  help: |-
    âš¡ Simply re-run last example you ran with <playground run> or <playground run-ccloud>
  catch_all:
    label: arguments
    help: |-
      Arguments to use by example script

      Most of examples support to get required options either by using arguments or environment variables.
      
      Example with Zendesk:

      playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME> <ZENDESK_PASSWORD>
    required: false
  dependencies:
    fzf: visit $(blue_underlined https://github.com/junegunn/fzf#installation) to install
  flags:
    - *tag
    - *connector-tag
    - *connector-zip
    - *connector-jar
    - *enable-ksqldb
    - *enable-control-center
    - *enable-conduktor
    - *enable-multiple-brokers
    - *enable-multiple-connect-workers
    - *enable-jmx-grafana
    - *enable-kcat
    - *enable-sr-maven-plugin-app
    - *enable-sql-datagen
  examples:
  - playground re-run
  - playground re-run --tag=6.2.1

- name: run-ccloud
  group: Run
  catch_all:
    label: arguments
    help: |-
      Arguments to use by example script

      Most of examples support to get required options either by using arguments or environment variables.
      
      Example with Zendesk:

      playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME> <ZENDESK_PASSWORD>
    required: false
  dependencies:
    fzf: visit $(blue_underlined https://github.com/junegunn/fzf#installation) to install
    confluent: visit $(blue_underlined https://docs.confluent.io/confluent-cli/current/overview.html) to install
  help: |-
    â›… Run any Confluent Cloud (ccloud) example

    All you have to do is to be already logged in with confluent CLI.

    By default, a new Confluent Cloud environment with a Cluster will be created.

    You can configure the new cluster by setting:

    --cluster-cloud (or CLUSTER_CLOUD environment variable)
    --cluster-region (or CLUSTER_REGION environment variable)
    --cluster-environment (or ENVIRONMENT environment variable)

    In case you want to use your own existing cluster, you need to setup, in addition to previous ones:

    --cluster-name (or CLUSTER_NAME environment variable)
    --cluster-creds (or CLUSTER_CREDS environment variable)
    --cluster-schema-registry-creds (or SCHEMA_REGISTRY_CREDS environment variable)
    
  flags:
    - long: --file
      short: -f
      required: true
      validate: file_exists_with_trick
      arg: file
      completions:
        - $(playground get-examples-list-with-fzf --ccloud-only "$cur")
      help: |-
        ğŸ”– Example file to run

        â• It must be absolute full path

        ğŸ“ Tip: use <tab> completion to trigger fzf completion
    - long: --open
      short: -o
      help: ğŸ“– Opening example file with text editor set with config.ini (default is code)
    - *tag
    - *connector-tag
    - *connector-zip
    - *connector-jar
    - *enable-control-center
    - *enable-conduktor
    - *enable-kcat
    - &cluster-cloud
      long: --cluster-cloud
      required: false
      arg: cluster-cloud
      allowed: [aws, gcp, azure]
      help: |-
        ğŸŒ¤ The cloud provider: aws, gcp or azure. Default is aws

        ğŸ“ Tip: you can also use CLUSTER_CLOUD environment variable
    - &cluster-region
      long: --cluster-region
      required: false
      arg: cluster-region
      completions:
        - $(playground get-kafka-region-list)
      help: |-
        ğŸ—º The Cloud region. 
        
        ğŸ“ Tip: you can also use CLUSTER_REGION environment variable
    - &cluster-environment
      long: --cluster-environment
      required: false
      arg: cluster-environment
      validate: not_empty
      help: |-
        ğŸŒ The environment id where want your new cluster (example: env-xxxxx)

        â„¹ï¸ Optional, if not set, new environment will be created

        ğŸ“ Tip: you can also use ENVIRONMENT environment variable
    - &cluster-name
      long: --cluster-name
      required: false
      validate: not_empty
      arg: cluster-name
      help: |-
        ğŸ° The cluster name. 
        
        â£ï¸ Only required if you want to use your own existing cluster

        ğŸ“ Tip: you can also use CLUSTER_NAME environment variable
    - &cluster-creds
      long: --cluster-creds
      required: false
      validate: not_empty
      arg: cluster-creds
      help: |-
        ğŸ”’ The Kafka api key and secret to use, it should be separated with semi-colon (example: <API_KEY>:<API_KEY_SECRET>)

        â£ï¸ Only required if you want to use your own existing cluster

        ğŸ“ Tip: you can also use CLUSTER_CREDS environment variable
    - &cluster-schema-registry-creds
      long: --cluster-schema-registry-creds
      required: false
      validate: not_empty
      arg: cluster-schema-registry-creds
      help: |-
        ğŸ”’ The Schema Registry api key and secret to use, it should be separated with semi-colon (example: <SR_API_KEY>:<SR_API_KEY_SECRET>)

        â„¹ï¸ Optional, if not set, new credentials will be created

        â£ï¸ Only required if you want to use your own existing cluster
        
        ğŸ“ Tip: you can also use SCHEMA_REGISTRY_CREDS environment variable
  examples:
  - playground run-ccloud mqtt<tab> --cluster-cloud aws --cluster-region eu-west-3 --enable-control-center --connector-tag 1.2.3

- name: open
  group: Run
  dependencies:
    fzf: visit $(blue_underlined https://github.com/junegunn/fzf#installation) to install
  help: |-
    ğŸ‘ When --file is not provided, simply open last example you ran with <playground run> or <playground run-ccloud>

    Otherwise, open any file from the playground using --file.
  flags:
  - long: --file
    short: -f
    required: false
    validate: file_exists_with_trick
    arg: file
    completions:
      - $(playground get-any-file-with-fzf "$cur")
    help: |-
      ğŸ” Search any file and open it.
      
      â• It must be absolute full path

      ğŸ“ Tip: use <tab> completion to trigger fzf completion

- name: stop
  group: Run
  help: |-
    ğŸ›‘ Stop currently running example

- name: bootstrap-reproduction-model
  environment_variables:
  - name: OUTPUT_FOLDER 
    help: ğŸ“ Output folder where to generate bootstrapped files
    default: reproduction-models
  group: Bootstrap
  dependencies:
    fzf: visit $(blue_underlined https://github.com/junegunn/fzf#installation) to install
  help: |-
    ğŸ›   Bootstrap reproduction model
    
    ğŸ‘‰ Check documentation https://kafka-docker-playground.io/#/reusables?id=%f0%9f%9b%a0-bootstrap-reproduction-model
  catch_all:
    label: arguments
    help: |-
      Arguments to use by example script

      Most of examples support to get required options either by using arguments or environment variables.
      
      Example with Zendesk:

      playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME> <ZENDESK_PASSWORD>
    required: false
  flags:
  - *tag
  - *connector-tag
  - *connector-zip
  - *connector-jar
  - *enable-ksqldb
  - *enable-control-center
  - *enable-conduktor
  - *enable-multiple-brokers
  - *enable-multiple-connect-workers
  - *enable-jmx-grafana
  - *enable-kcat
  - *enable-sr-maven-plugin-app
  - *enable-sql-datagen
  - *cluster-region
  - *cluster-environment
  - *cluster-name
  - *cluster-creds
  - *cluster-schema-registry-creds

  - long: --file
    short: -f
    required: true
    validate: file_exists_with_trick
    arg: file
    completions:
      - $(playground get-examples-list-with-fzf --without-repro "$cur")
    help: |-
      ğŸ”– Example file to use as basis
      
      â• It must be absolute full path

      ğŸ“ Tip: use <tab> completion to trigger fzf completion

  - long: --description
    short: -d
    required: true
    validate: not_empty
    arg: description
    help: |-
      ğŸ’­ Description for the reproduction model

  - long: --producer
    short: -p
    arg: producer-type
    conflicts: [--pipeline]
    default: "none"
    allowed: 
      - none
      - avro
      - avro-with-key
      - protobuf
      - protobuf-with-key
      - json-schema
      - json-schema-with-key
    help: |-
      â™¨ï¸ Java producer type to use
      
      One of avro, avro-with-key, protobuf, protobuf-with-key, json-schema, json-schema-with-key

      ğŸ“ Tip: 'with-key' will also produce key with selected converter, otherwise LongConverter is used

  - long: --nb-producers
    short: -n
    arg: nb-producers
    validate: integer
    default: ""
    help: |-
      2ï¸âƒ£ Number of java producers to generate

  - long: --producer-schema-key
    required: false
    help: |-
      ğŸ”° Schema to use for the key

      âœ¨ Copy and paste the schema you want to use for the key, save and close the file to continue

  - long: --producer-schema-value
    required: false
    help: |-
      ğŸ”° Schema to use for the value

      âœ¨ Copy and paste the schema you want to use for the key, save and close the file to continue

  - long: --custom-smt
    help: |-
      âš™ï¸ Add a custom SMT (which is a no-op)

  - long: --pipeline
    required: false
    validate: file_exists_with_trick
    arg: sink_file
    conflicts: [--producer]
    completions:
      - $(playground get-examples-list-with-fzf --without-repro --sink-only "$cur")
    help: |-
      ğŸ”– Sink example file to use for creating a pipeline
      
      â• It must be absolute full path. 

      ğŸ“ Tip: use <tab> completion to trigger fzf completion

  examples:
  - playground bootstrap-reproduction-model -f hdfs2<tab> -d "simple test"
  - playground bootstrap-reproduction-model -f /full/path/hdfs2-sink.sh -d "testing with avro producer" --producer avro --producer-schema-value myschema<tab>
  - playground bootstrap-reproduction-model -f hdfs2<tab> -d "testing with 2 protobuf producers" --producer protobuf --nb-producers 2
  - playground bootstrap-reproduction-model -f hdfs2<tab> -d "testing custom smt" --custom-smt
  - playground bootstrap-reproduction-model -f debeziumpostgres<tab> -d "create pipeline" --pipeline jdbcsink<tab>

- name: get-properties
  group: Kafka
  help: |-
    ğŸ“ Get properties file from a container
    
    ğŸ‘‰ Check documentation https://kafka-docker-playground.io/#/how-to-use?id=%f0%9f%93%9d-see-properties-file

  flags:
  - &container
    long: --container
    short: -c
    required: false
    default: "connect"
    arg: container
    completions:
      - $(docker ps --format '{{.Names}}')
    help: |-
      ğŸ³ Container name

  examples:
  - playground get-properties
  - playground get-properties --container broker
  - playground get-properties -c broker

- name: get-all-schemas
  group: Kafka
  filters:
  - not_mdc_environment
  - schema_registry_running
  help: |-
    ğŸ”° Get all schemas versions for all subjects
  flags:
    - long: --open
      short: -o
      help: |- 
        ğŸ”– Save output to a file and open with text editor set with config.ini (default is code)

  examples:
  - playground get-all-schemas

- name: enable-remote-debugging
  group: Debug
  help: |-
    âœ¨ Enable java remote debugging for container
    
    ğŸ‘‰ Check documentation https://kafka-docker-playground.io/#/reusables?id=%e2%9c%a8-remote-debugging
  flags:
    - *container
  examples:
  - playground enable-remote-debugging
  - playground enable-remote-debugging --container broker
  - playground enable-remote-debugging -c broker

- name: log-level
  group: Debug
  help: |-
    ğŸ§¬ Set log level for any package
  filters:
  - connect_running
  commands:
  - name: get
    help: Get log levels
    flags:
    - long: --package
      short: -p
      required: false
      validate: not_empty
      arg: package
      help: |-
        Package name

  - name: set
    help: Set log level for specific logger
    flags:
    - long: --package
      short: -p
      required: true
      validate: not_empty
      arg: package
      help: |-
        ğŸ“¦ Package name

    - long: --level
      short: -l
      arg: level
      allowed: [INFO, WARN, DEBUG, TRACE]
      required: true
      help: |-
        â•Log level

  examples:
  - playground log-level get
  - playground log-level get -p io.confluent.connect.oracle.cdc
  - playground log-level get --package io.confluent.connect.oracle.cdc
  - playground log-level set -p io.confluent.connect.oracle.cdc.logging.LogUtils -l TRACE

- name: get-jmx-metrics
  group: Kafka
  help: |-
    ğŸ”¢ Get JMX metrics from a component
    
    ğŸ‘‰ Check documentation https://kafka-docker-playground.io/#/how-to-use?id=%f0%9f%94%a2-jmx-metrics
  dependencies:
    java: visit $(blue_underlined https://openjdk.org/install/) to install
  flags:
  - long: --component
    short: -c
    default: "connect"
    required: false
    arg: component
    allowed: [zookeeper, broker, connect, schema-registry]
    help: |-
      Component name
  - long: --open
    short: -o
    help: |- 
      ğŸ”– Save output to a file and open with text editor set with config.ini (default is code)

  - long: --domain
    short: -d
    required: false
    arg: domain
    help: |-
      Domain name

  examples:
  - playground get-jmx-metrics --component connect
  - playground get-jmx-metrics --component connect --domain "kafka.connect kafka.consumer kafka.producer"
  - playground get-jmx-metrics -c broker

- name: container
  expose: true
  group: Container
  help: |-
    ğŸ³ Container commands
  commands:

    - name: recreate
      group: Container
      help: |-
        ğŸ’« Recreate container(s)
        
        ğŸ‘‰ Check documentation https://kafka-docker-playground.io/#/how-to-use?id=%e2%99%bb%ef%b8%8f-re-create-containers

    - name: get-ip-addresses
      group: Container
      help: |-
        ğŸ–¥ï¸  Get ip address of running containers
      examples:
      - playground get-ip-address-container

    - name: kill-all
      group: Container
      help: |-
        ğŸ’€ Kill all containers

    - name: logs
      group: Container
      help: |-
        ğŸ•µï¸  Tail and follow container logs

      flags:
      - *container
      - long: --open
        short: -o
        help: |- 
          ğŸ”– Save output to a file and open with text editor set with config.ini (default is code)
        conflicts: [--wait-for-log]
      - long: --wait-for-log
        short: -w
        arg: log
        validate: not_empty
        help: |- 
          ğŸ˜´ Wait until log appears
        conflicts: [--open]
      - long: --max-wait
        short: -m
        arg: max_wait
        validate: integer
        default: "600"
        help: |- 
          â³ Max time in seconds to wait when using --wait-for-log (default 600s)
        conflicts: [--open]

      examples:
      - playground container logs --container connect
      - playground container logs -c connect --open
      - playground container logs -c connect --wait-for-log "StackOverflowError"

    - name: ssh
      group: Container
      help: |-
        ğŸ›¬ SSH into container

      flags:
      - *container

      - long: --shell
        short: -s
        required: false
        default: "bash"
        arg: shell
        allowed: 
          - bash
          - sh
          - ksh
          - zsh
        help: |-
          ğŸ’¾ Shell to use (default is bash)

      examples:
      - playground ssh -c connect
      - playground ssh -c connect -s sh
      - playground ssh --container connect --shell sh

    - name: exec
      group: Container
      help: |-
        ğŸª„  Execute command in a container

      flags:
      - *container

      - long: --command
        required: true
        validate: not_empty
        arg: command
        help: |-
          ğŸ“² Command to execute

      - long: --root
        help: |-
          ğŸ‘‘ Run command as root

      - long: --shell
        default: "bash"
        arg: shell
        allowed: 
          - bash
          - sh
          - ksh
          - zsh
        help: |-
          ğŸ’¾ Shell to use (default is bash)

      examples:
      - playground exec -c connect -d "date"
      - playground exec -c connect -d "whoami" --root
      - playground exec --container connect --command "whoami" --shell sh

    - name: restart
      group: Container
      help: |-
        ğŸ” Restart a container

      flags:
      - *container

    - name: pause
      group: Container
      help: |-
        â¸ï¸  Pause a container

      flags:
      - *container

    - name: resume
      group: Container
      help: |-
        â¯ï¸  Resume a container

      flags:
      - *container

    - name: kill
      group: Container
      help: |-
        ğŸ”« Kill a container

      flags:
      - *container

- name: topic
  expose: true
  group: Topic
  filters:
  - not_mdc_environment
  help: |-
    ğŸ—³ Topic commands
  commands:

    - name: get-number-records
      group: Topic
      help: |-
        ğŸ’¯ Get number of records in a topic
      flags:
      - &topic
        long: --topic
        short: -t
        required: false
        arg: topic
        completions:
          - $(playground get-topic-list)
        help: |-
          ğŸ—³ Topic name
      examples:
      - playground get-number-records --topic a-topic
      - playground get-number-records -t a-topic

    - name: display-consumer-offsets
      group: Topic
      help: |-
        ğŸ“­ Display content of __consumer_offsets topic

    - name: describe
      group: Topic
      help: |-
        ğŸ”¬ Describe topic
      flags:
      - *topic

    - name: consume
      filters:
      - schema_registry_running
      group: Topic
      help: |-
        ğŸ“¥ Consume topic from beginning
      flags:
      - *topic
      - long: --max-messages
        arg: max-messages
        validate: integer
        required: false
        default: "50"
        help: |-
          Max number of messages to display (default is 50)
      - long: --min-expected-messages
        arg: min-expected-messages
        validate: integer
        required: false
        default: ""
        help: |-
          Minimum expected number of messages to be present in topic, returns an error if this is not the case

          Note: --topic should be specified in this case.
      - long: --grep
        arg: grep
        required: false
        default: ""
        help: |-
          Verify that topic content contains record which contains specified string
      - long: --timeout
        arg: timeout
        validate: integer
        required: false
        default: "60"
        help: |-
          Max number of seconds to wait when --min-expected-messages is used.

          Default is 60 seconds

    - name: produce
      filters:
      - schema_registry_running
      group: Topic
      help: |-
         ğŸ“¤ Produce to a topic
      flags:
      - long: --input
        arg: input
        completions:
          - $(playground get-predefined-schemas "$cur")
        default: "-"
        required: false
        help: |- 
          ğŸ”¥ You can either:
          
          * Set your own schema (avro, json-schema, protobuf) with stdin (see example section). You can also use json or sql format as per https://github.com/MaterializeInc/datagen

          * Use completion to select predefined schemas

          * Use your own schema file. ğŸ“ Tip: use <tab> completion to trigger fzf completion

          * Directly set payload

      - long: --topic
        short: -t
        required: true
        arg: topic
        completions:
          - $(playground get-topic-list)
        help: |-
          ğŸ—³ Topic name
      - long: --nb-messages
        arg: nb-messages
        validate: integer
        required: false
        default: "3"
        help: |-
          Number of messages to produce (default is 3)
      - long: --nb-partitions
        arg: nb-partitions
        validate: integer
        required: false
        default: "1"
        help: |-
          Number of partitions for the topic. 
          
          Important: If topic is existing, it will be re-created before producing to topic.
      examples: |

        playground topic produce -t topic-json --nb-messages 10 << 'EOF'
        {
            "_meta": {
                "topic": "",
                "key": "",
                "relationships": []
            },
            "nested": {
                "phone": "faker.phone.imei()",
                "website": "faker.internet.domainName()"
            },
            "id": "iteration.index",
            "name": "faker.internet.userName()",
            "email": "faker.internet.exampleEmail()",
            "phone": "faker.phone.imei()",
            "website": "faker.internet.domainName()",
            "city": "faker.address.city()",
            "company": "faker.company.name()"
        }
        EOF

        playground topic produce -t topic-avro --nb-messages 10 << 'EOF'
        {
            "type": "record",
            "namespace": "com.github.vdesabou",
            "name": "Customer",
            "version": "1",
            "fields": [
                {
                    "name": "count",
                    "type": "long",
                    "doc": "count"
                },
                {
                    "name": "first_name",
                    "type": "string",
                    "doc": "First Name of Customer"
                },
                {
                    "name": "last_name",
                    "type": "string",
                    "doc": "Last Name of Customer"
                },
                {
                    "name": "address",
                    "type": "string",
                    "doc": "Address of Customer"
                }
            ]
        }
        EOF

        playground topic produce -t topic-json-schema --nb-messages 3 << 'EOF'
        {
          "$schema": "http://json-schema.org/draft-07/schema#",
          "additionalProperties": false,
          "$id": "http://lh.test/Customer.schema.json",
          "title": "Customer",
          "description": "Customer description",
          "type": "object",
          "properties": {
            "name": {
              "description": "Customer name",
              "type": "string",
              "maxLength": 25
            },
            "surname": {
              "description": "Customer surname",
              "type": "string",
              "minLength": 2
            },
            "email": {
              "description": "Email",
              "type": "string",
              "pattern": "^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$"
            }
          },
          "required": [
            "name",
            "surname"
          ]
        }
        EOF


        playground topic produce -t topic-proto --nb-messages 3 << 'EOF'
        syntax = "proto3";

        message Order {
          float         total = 1;
          repeated Item items = 2;

          message Item {
            string name  = 1;
            float  price = 2;
          }
        }
        EOF

        playground topic produce -t vincent-jsql --nb-messages 10 << 'EOF'
        CREATE TABLE "notused"."notused" (
          "id" int PRIMARY KEY,
          "name" varchar COMMENT 'faker.internet.userName()',
          "merchant_id" int NOT NULL COMMENT 'faker.datatype.number()',
          "price" int COMMENT 'faker.datatype.number()',
          "status" int COMMENT 'faker.datatype.boolean()',
          "created_at" datetime DEFAULT (now())
        );
        EOF

    - name: set-schema-compatibility
      filters:
      - schema_registry_running
      group: Topic
      help: |-
        ğŸ›¡ï¸ Change topic's schema compatibility
      flags:
      - *topic
      - long: --compatibility
        arg: compatibility
        allowed: 
          - BACKWARD
          - BACKWARD_TRANSITIVE
          - FORWARD
          - FORWARD_TRANSITIVE
          - FULL
          - FULL_TRANSITIVE
          - NONE
        required: true
        help: |-
          Schema Registry compatibility rule

    - name: display-schema-id-statistics
      group: Topic
      help: |-
        ğŸ§ Easily identify the usage of different schema versions within a topic.

        It makes use of https://github.com/EladLeev/schema-registry-statistics

        It only works when plaintext environment is used
      flags:
      - *topic

- name: ccloud-connector
  expose: true
  group: Connector
  filters:
  - ccloud_environment
  dependencies:
    confluent: visit $(blue_underlined https://docs.confluent.io/confluent-cli/current/overview.html) to install
  help: |-
    ğŸ”—â˜ï¸ Fully Managed Connector commands
  environment_variables:
  - name: CLOUD_API_KEY
    help: Cloud API key, see https://docs.confluent.io/cloud/current/access-management/authenticate/api-keys/api-keys.html#cloud-cloud-api-keys
    required: true
  - name: CLOUD_API_SECRET
    help: Cloud API secret, see https://docs.confluent.io/cloud/current/access-management/authenticate/api-keys/api-keys.html#cloud-cloud-api-keys
    required: true

  commands:
  - name: status
    help: ğŸ§© Show status of all connectors

  - name: plugins
    help: ğŸ¨ Show all plugins installed

  - name: pause
    help: â¸ï¸  Pause connector
    flags:
    - &ccloudconnector
      long: --connector
      short: -c
      required: false
      arg: connector
      completions:
        - $(playground get-ccloud-connector-list)
      help: |-
        ğŸ”— Connector name

        ğŸ“ Tip: If not specified, the command will apply to all connectors

  - name: resume
    help: â¯ï¸  Resume connector
    flags:
    - *ccloudconnector

  - name: delete
    help: ğŸ—‘ï¸  Delete connector
    flags:
    - *ccloudconnector

  - name: show-lag
    help: ğŸ¢ Show lag of sink connector
    flags:
    - *ccloudconnector

  - name: create-or-update
    help: ğŸ§‘â€ğŸ¨  Create or update connector
    args:
    - name: json
      
      # Set the default path value to -, which is the standard operator for stdin.
      default: "-"
      help: json (reads from stdin if empty)

    flags:
    - long: --connector
      short: -c
      required: true
      arg: connector
      completions:
        - $(playground get-ccloud-connector-list)
      help: |-
        ğŸ”— Connector name

    examples: |
      playground ccloud-connector create-or-update --connector HttpSink << EOF
      {
          "connector.class": "HttpSink",
          "name": "HttpSink",
          "kafka.auth.mode": "KAFKA_API_KEY",
          "kafka.api.key": "$CLOUD_KEY",
          "kafka.api.secret": "$CLOUD_SECRET",
          "topics": "http-topic",
          "input.data.format": "AVRO",
          "http.api.url": "http://httpstat.us/200/",
          "behavior.on.error": "fail",
          "tasks.max" : "1"
      }
      EOF

- name: connector
  expose: true
  group: Connector
  filters:
  - not_mdc_environment
  - connect_running
  help: |-
    ğŸ”— Connector commands

  commands:
  - name: status
    help: ğŸ§© Show status of all connectors

  - name: plugins
    help: ğŸ¨ Show all plugins installed

  - name: pause
    help: â¸ï¸  Pause connector
    flags:
    - &connector
      long: --connector
      short: -c
      required: false
      arg: connector
      completions:
        - $(playground get-connector-list)
      help: |-
        ğŸ”— Connector name

        ğŸ“ Tip: If not specified, the command will apply to all connectors

  - name: versions
    help:  ğŸ§ Get current and latest version available on Confluent Hub for connector(s) used in example

  - name: restart
    help: â™»ï¸  Restart connector
    flags:
    - *connector

  - name: resume
    help: â¯ï¸  Resume connector
    flags:
    - *connector

  - name: delete
    help: ğŸ—‘ï¸  Delete connector
    flags:
    - *connector

  - name: show-lag
    help: ğŸ¢ Show lag of sink connector
    flags:
    - *connector

  - name: log-level
    help: |-
      ğŸ§¬ Set connect log level
    flags:
    - *connector
    - long: --level
      short: -l
      help: Log level
      arg: level
      allowed: [INFO, WARN, DEBUG, TRACE]
      required: true

  - name: create-or-update
    help: ğŸ§‘â€ğŸ¨  Create or update connector
    args:
    - name: json
      
      # Set the default path value to -, which is the standard operator for stdin.
      default: "-"
      help: json (reads from stdin if empty)

    flags:
    - long: --connector
      short: -c
      required: true
      arg: connector
      completions:
        - $(playground get-connector-list)
      help: |-
        ğŸ”— Connector name

    examples: |
      playground connector create-or-update -c filestream-sink << EOF
      {
          "tasks.max": "1",
          "connector.class": "org.apache.kafka.connect.file.FileStreamSinkConnector",
          "topics": "filestream",
          "file": "/tmp/output.json",
          "key.converter": "org.apache.kafka.connect.storage.StringConverter",
          "value.converter": "org.apache.kafka.connect.json.JsonConverter",
          "value.converter.schemas.enable": "false"
      }
      EOF

  examples:
  - playground connector status
  - playground connector status --json
  - playground connector resume --connector <connector-name>
  - playground connector pause -c <connector-name>
  - playground connector delete -c <connector-name>
