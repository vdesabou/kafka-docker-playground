name: playground
version: 1.0.0
dependencies:
  docker: visit https://docs.docker.com/get-docker to install
help: |-
  ğŸ§  CLI for Kafka Docker Playground ğŸ³

  ğŸ‘‰ Check documentation https://kafka-docker-playground.io/#/cli
filters:
- docker_running

flags:
- long: --vvv
  short: -v
  help: |
    ğŸ› set verbose output (set -x)

    â— it can print sensitive information â—

- long: --output-level
  short: -o
  arg: level
  allowed: [INFO, WARN, ERROR]
  required: false
  help: |-
    â•Log level used by all commands

    Default is INFO (all INFO, WARN and ERROR will be printed in command output)

commands:

- name: help
  help: Show help about a command
  args:
  - name: command
    help: ğŸ†˜ Help command

- name: status
  help: ğŸ—ºï¸ Show a status

### private commands for completion
- name: get-docker-ports
  help: Return some completion for docker ports
  private: true

- name: get-connector-list
  help: Return some completion for connector list
  private: true

- name: get-zazkia-connection-list
  help: Return some completion for zazkia connections list
  private: true

- name: generate-fzf-find-files
  help: force call to generate_fzf_find_files
  private: true

- name: generate-tag-list
  help: generate the confluent platform tag list
  private: true

- name: generate-connector-plugin-list
  help: generate the confluent hub plugin list
  private: true

- name: generate-kafka-region-list
  help: generate the confluent kafka region list
  private: true
  dependencies:
    confluent: visit https://docs.confluent.io/confluent-cli/current/overview.html to install
    
- name: get-connector-plugin
  help: Return some completion for connector plugin
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur

- name: get-ccloud-environment-list
  help: Return some completion for ccloud environment
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur

- name: get-ccloud-cluster-list
  help: Return some completion for ccloud cluster
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur

- name: get-tag-list
  help: Return some completion for confluent platform tag
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur

- name: get-kafka-region-list
  help: Return some completion for confluent cloud kafka cluster region list
  private: true
  dependencies:
    confluent: visit https://docs.confluent.io/confluent-cli/current/overview.html to install
  args:
  - name: cur
    required: false
    help: correspond to completion $cur

- name: get-topic-list
  help: Return some completion for topic list
  private: true
  flags:
  - long: --skip-connect-internal-topics
    required: false

- name: get-subject-list
  help: Return some completion for subject list
  private: true
  flags:
  - long: --deleted
    required: false
    help: |-
      ğŸ§Ÿ Include soft deleted schemas

- name: get-examples-list-with-fzf
  help: Return some completion for examples list
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur
  flags:
  - long: --without-repro
    required: false
  - long: --sink-only
    required: false
  - long: --ccloud-only
    required: false
  - long: --connector-only
    required: false
  - long: --repro-only
    required: false
  - long: --environment-only
    required: false
  - long: --fully-managed-connector-only
    required: false
  - long: --ksql-only
    required: false
  - long: --schema-registry-only
    required: false
  - long: --rest-proxy-only
    required: false
  - long: --other-playgrounds-only
    required: false

- name: get-zip-or-jar-with-fzf
  help: Return some completion for zip or jar list
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur
  flags:
  - long: --type
    required: false
    arg: type
    allowed: [zip, jar]

- name: get-any-file-with-fzf
  help: Return some completion for any files
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur

- name: get-playground-repro-export-with-fzf
  help: Return some completion for export tgz files
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur

- name: get-predefined-schemas
  help: Return some completion for predefined schemas
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur

- name: update-readme
  private: true
  environment_variables:
  - name: GH_TOKEN 
    help: GH_TOKEN
  flags:
    - long: --tags
      required: false
      validate: not_empty
      arg: tags
      help: |-
        ğŸ’¯ list of tags
    - long: --generate-for-kb
      required: false

- name: bashly-reload
  private: true
  dependencies:
    bashly: visit https://bashly.dannyb.co/installation/ to install

- name: state
  private: true
  commands:
  - name: show
    private: true
    help: Show the entire playground.ini file

  - name: get
    help: Read a value from the playground.ini file
    private: true
    args:
    - name: key
      required: true
      help: playground.ini key
    examples:
    - playground state get hello
    - playground state get user.name

  - name: set
    help: Save a value in the playground.ini file
    private: true
    args:
    - name: key
      required: true
      help: playground.ini key
    - name: value
      required: true
      help: playground.ini value
    examples:
    - playground state set hello world
    - playground state set user.email me@example.com

  - name: del
    help: Remove a value from the playground.ini file
    private: true
    args:
    - name: key
      required: true
      help: playground.ini key
    examples:
    - playground state del hello
    - playground state del user.name


- name: config
  help: âš™ï¸ Configure CLI
  commands:
  - name: show
    private: true
    help: Show the entire playground_config.ini file

  - name: get
    private: true
    help: Read a value from the playground_config.ini file

    args:
    - name: key
      required: true
      help: Config key
    examples:
    - playground config get hello
    - playground config get user.name

  - name: set
    private: true
    help: Save a value in the playground_config.ini file
    args:
    - name: key
      required: true
      help: playground_config.ini key
    - name: value
      required: true
      help: playground_config.ini value
    examples:
    - playground config set hello world
    - playground config set user.email me@example.com

  - name: editor
    help: editor to use to open files
    args:
    - name: editor
      required: true
      help: editor
      validate: editor_exists
    examples:
    - playground config editor vi
    - playground config editor code

  - name: folder_zip_or_jar
    help: |- 
      ğŸ“‚ list of folders where to search for zip or jar
      current folder is always included

      default is ~ (home dir)
    args:
    - name: folder
      required: true
      help: folder
      unique: true
      repeatable: true
      validate: dir_exists
    examples:
    - playground config folder_zip_or_jar ~/Downloads ~/Documents/github/kafka-connect-*
    - playground config folder_zip_or_jar ~/Downloads

  - name: clipboard
    help: copy to clipboard connector config (only working on MacOS)
    args:
    - name: enabled
      required: false
      default: "true"
      help: editor
    examples:
    - playground config clipboard false
    - playground config clipboard true

- name: install-vscode-extension
  help: |-
    ğŸª„ Install a slightly modified version of "Shell Script Command Completion" Visual Studio Code extension (https://marketplace.visualstudio.com/items?itemName=tetradresearch.vscode-h2o)

    After installation, install "playground" command:

    * Go on a .sh file

    * Type Ctrl+Shift+P (or âŒ˜+â‡§+P on macOS) and choose "Shell Completion: Load Command Spec (experimental)"" and then type "playground"
    
    ğŸ‘‰ Check documentation https://kafka-docker-playground.io/#/cli?id=%f0%9f%aa%84-setup-shell-script-command-completion-visual-studio-code-extension
  examples:
  - playground install-vscode-extension
  dependencies:
    code: visit https://code.visualstudio.com/docs/setup/mac#_launching-from-the-command-line to install

- name: run
  group: Run
  dependencies:
    fzf: visit https://github.com/junegunn/fzf#installation to install
  help: |-
    ğŸ•¹ï¸ Run any example !

    ğŸ”¥ It start an interactive mode where you'll be fully guided !


    â›… When running Confluent Cloud (ccloud) example:

      All you have to do is to be already logged in with confluent CLI.

      By default, a new Confluent Cloud environment with a Cluster will be created.

      You can configure the new cluster by setting:
    
      --cluster-type (or CLUSTER_TYPE environment variable): The type of cluster (possible values: basic, standard and dedicated, default basic)
      --cluster-cloud (or CLUSTER_CLOUD environment variable): The Cloud provider (possible values: aws, gcp and azure, default aws)
      --cluster-region (or CLUSTER_REGION environment variable): The Cloud region (use confluent kafka region list to get the list, default eu-west-2 for aws, westeurope for azure and europe-west2 for gcp)
      --cluster-environment (or ENVIRONMENT environment variable) (optional): The environment id where want your new cluster (example: txxxxx) 

      In case you want to use your own existing cluster, you need to setup, in addition to previous ones:

      --cluster-name (or CLUSTER_NAME environment variable): The cluster name
      --cluster-creds (or CLUSTER_CREDS environment variable): The Kafka api key and secret to use, it should be separated with colon (example: <API_KEY>:<API_KEY_SECRET>)
      --cluster-schema-registry-creds (or SCHEMA_REGISTRY_CREDS environment variable) (optional, if not set, new one will be created): The Schema Registry api key and secret to use, it should be separated with colon (example: <SR_API_KEY>:<SR_API_KEY_SECRET>)

  flags:
  - &environment-run
    long: --environment
    required: false
    default: "plaintext"
    arg: environment
    allowed: [ccloud, plaintext, sasl-ssl, sasl-plain, 2way-ssl, sasl-scram, kraft-external-plaintext, kraft-plaintext, kerberos, ssl_kerberos, ldap-authorizer-sasl-plain, ldap-sasl-plain, rbac-sasl-plain]
    help: |-
      ğŸ” The environment to start when running a connector example 
      
      - plaintext
      - ccloud
      - 2way-ssl
      - kerberos
      - kraft-external-plaintext
      - kraft-plaintext
      - ldap-authorizer-sasl-plain
      - ldap-sasl-plain
      - rbac-sasl-plain
      - sasl-plain
      - sasl-scram
      - sasl-ssl
      - ssl_kerberos

      Default is plaintext.
      This is only supported when example is a connector example
  - long: --file
    short: -f
    required: false
    
    validate: file_exists_with_trick
    arg: file
    completions:
      - $(playground get-examples-list-with-fzf "$cur")
    help: |-
      ğŸ”– Example file to run

      â• It must be absolute full path

      ğŸ“ Tip: use <tab> completion to trigger fzf completion
  - long: --open
    
    short: -o
    help: ğŸ“– Opening example file with text editor set with playground config editor <editor> (default is code)
  - &tag
    long: --tag
    
    arg: tag
    required: false
    completions:
      - $(playground get-tag-list "$cur")
    help: |-
      ğŸ¯ Confluent Platform (CP) version to use

      Must be greater or equal to 5.3.0

      ğŸ“ Tip: use <tab> completion to trigger fzf completion
  - &connector-tag
    long: --connector-tag
    arg: connector_tag
    
    required: false
    help: |- 
      ğŸ”— Connector version to use

      By default, for each connector, the latest available version on Confluent Hub is used

      ğŸ“ Tip: set to " " in order to select the version dynamically

    conflicts: [--connector-zip]
  - &connector-zip
    long: --connector-zip
    arg: connector_zip
    
    required: false
    validate: file_exists_with_trick
    completions:
      - $(playground get-zip-or-jar-with-fzf --type zip "$cur")
    conflicts: [--connector-tag]
    help: |- 
      ğŸ¤ Connector zip to use

      â• It must be absolute full path

      ğŸ“ Tip: use <tab> completion to trigger fzf completion 
              use playground config folder_zip_or_jar <folder1> <folder2>... (default is home folder and current folder is always included) to configure where to search the files

  - &connector-jar
    long: --connector-jar
    arg: connector_jar
    
    required: false
    validate: file_exists_with_trick
    completions:
      - $(playground get-zip-or-jar-with-fzf --type jar "$cur")
    help: |-
      ğŸ¤ Connector jar to use

      â• It must be absolute full path

      ğŸ“ Tip: use <tab> completion to trigger fzf completion 
              use playground config folder_zip_or_jar <folder1> <folder2>... (default is home folder and current folder is always included) to configure where to search the files

  - &enable-ksqldb
    long: --enable-ksqldb
    required: false
    
    help: |-
      ğŸš€ Enable ksqlDB 
      
      â— not supported with ccloud examples

      By default, ksqldb-server and ksqldb-cli containers are not started for every test
  - &enable-rest-proxy
    long: --enable-rest-proxy
    required: false
    
    help: |-
      ğŸ§² Enable Rest Proxy

      â— not supported with ccloud examples

      By default, rest-proxy container is not started for every test
  - &enable-control-center
    long: --enable-control-center
    required: false
    
    help: |-
      ğŸ’  Enable Control Center

      By default, control-center container is not started for every test

      Control Center is reachable at http://127.0.0.1:9021
  - &enable-conduktor
    long: --enable-conduktor
    required: false
    
    help: |- 
      ğŸº Enable Conduktor Platform

      By default, Conduktor Platform container is not started for every test

      Conduktor is reachable at http://127.0.0.1:8080/console (admin/admin)
  - &enable-multiple-brokers
    long: --enable-multiple-brokers
    required: false
    
    help: |- 
      3ï¸âƒ£ Enable multiple brokers

      By default, there is only one broker node enabled
  - &enable-multiple-connect-workers
    long: --enable-multiple-connect-workers
    required: false
    
    help: |-
      ğŸ¥‰ Enable multiple connect worker node

      By default, there is only one connect worker node enabled
  - &enable-jmx-grafana
    long: --enable-jmx-grafana
    required: false
    
    help: |-
      Enable Grafana, Prometheus and Pyroscope

      ğŸ“Š Grafana is reachable at http://127.0.0.1:3000 (login/password is admin/password)

      ğŸ›¡ï¸ Prometheus is reachable at http://127.0.0.1:9090
      
      ğŸ“› Pyroscope is reachable at http://127.0.0.1:4040
  - &enable-kcat
    long: --enable-kcat
    required: false
    
    help: |-
      ğŸˆâ€â¬› Enable kcat

      You can use it with:

      $ docker exec kcat kcat -b broker:9092 -L
  - &enable-sql-datagen
    long: --enable-sql-datagen
    required: false
    
    help: |-
      ğŸŒªï¸ Enable SQL Datagen injection

      This only works for Oracle, MySql, Postgres and Microsoft Sql Server source connector examples with JDBC and Debezium

  - &cluster-cloud
    long: --cluster-cloud
    required: false
    
    arg: cluster-cloud
    allowed: [aws, gcp, azure]
    help: |-
      ğŸŒ¤ The cloud provider: aws, gcp or azure. Default is aws

      ğŸ“ Tip: you can also use CLUSTER_CLOUD environment variable
  - &cluster-type
    long: --cluster-type
    required: false
    
    arg: cluster-type
    allowed: [basic, standard, dedicated]
    help: |-
      ğŸ”‹ The cluster type: basic, standard or dedicated. Default is basic

      ğŸ“ Tip: you can also use CLUSTER_TYPE environment variable
  - &cluster-region
    long: --cluster-region
    required: false
    
    arg: cluster-region
    completions:
      - $(playground get-kafka-region-list "$cur")
    help: |-
      ğŸ—º The Cloud region. 
      
      ğŸ“ Tip: you can also use CLUSTER_REGION environment variable
      ğŸ“ Tip: use <tab> completion to trigger fzf completion

  - &cluster-environment
    long: --cluster-environment
    required: false
    
    arg: cluster-environment
    validate: not_empty
    completions:
      - $(playground get-ccloud-environment-list "$cur")
    help: |-
      ğŸŒ The environment id where want your new cluster (example: txxxxx)

      â„¹ï¸ Optional, if not set, new environment will be created

      ğŸ“ Tip: you can also use ENVIRONMENT environment variable
      ğŸ“ Tip: use <tab> completion to trigger fzf completion

  - &cluster-name
    long: --cluster-name
    required: false
    
    validate: not_empty
    completions:
      - $(playground get-ccloud-cluster-list "$cur")
    arg: cluster-name
    help: |-
      ğŸ° The cluster name. 
      
      â£ï¸ Only required if you want to use your own existing cluster

      ğŸ“ Tip: you can also use CLUSTER_NAME environment variable
      ğŸ“ Tip: use <tab> completion to trigger fzf completion
  - &cluster-creds
    long: --cluster-creds
    required: false
    
    validate: not_empty
    arg: cluster-creds
    help: |-
      ğŸ”’ The Kafka api key and secret to use, it should be separated with colon (example: <API_KEY>:<API_KEY_SECRET>)

      â£ï¸ Only required if you want to use your own existing cluster

      ğŸ“ Tip: you can also use CLUSTER_CREDS environment variable
  - &cluster-schema-registry-creds
    long: --cluster-schema-registry-creds
    required: false
    
    validate: not_empty
    arg: cluster-schema-registry-creds
    help: |-
      ğŸ”’ The Schema Registry api key and secret to use, it should be separated with colon (example: <SR_API_KEY>:<SR_API_KEY_SECRET>)

      â„¹ï¸ Optional, if not set, new credentials will be created

      â£ï¸ Only required if you want to use your own existing cluster
      
      ğŸ“ Tip: you can also use SCHEMA_REGISTRY_CREDS environment variable

  - long: --force-interactive-re-run
    required: false
    private: true
    help: |-
      Force interactive mode
  - long: --force-interactive-repro
    required: false
    private: true
    help: |-
      Force interactive mode
  examples:
  - playground run (interactive mode)

- name: re-run
  group: Run
  help: |-
    âš¡ Simply re-run last example you ran with <playground run>
  dependencies:
    fzf: visit https://github.com/junegunn/fzf#installation to install
  examples:
  - playground re-run (interactive mode)

- name: history
  group: Run
  help: |-
    ğŸ° Get an history of the examples which were run with run command and run it again
  dependencies:
    fzf: visit https://github.com/junegunn/fzf#installation to install

- name: start-environment
  private: true
  group: Run
  help: |-
    ğŸ” Simply start an environment listed in http://tinyurl.com/y4ybbw32:

    - ccloud
    - 2way-ssl
    - kerberos
    - kraft-external-plaintext
    - kraft-plaintext
    - ldap-authorizer-sasl-plain
    - ldap-sasl-plain
    - mdc-kerberos
    - mdc-plaintext
    - mdc-sasl-plain
    - plaintext
    - rbac-sasl-plain
    - sasl-plain
    - sasl-scram
    - sasl-ssl
    - ssl_kerberos

    Note: when running an example with <playground run>, it is already automatically done
  flags:
    - &environment
      long: --environment
      required: false
      default: "plaintext"
      arg: environment
      allowed: [ccloud, 2way-ssl, kerberos, kraft-external-plaintext, kraft-plaintext, ldap-authorizer-sasl-plain, ldap-sasl-plain, mdc-kerberos, mdc-plaintext, mdc-sasl-plain, plaintext, rbac-sasl-plain, sasl-plain, sasl-scram, sasl-ssl, ssl_kerberos]
      help: |-
        ğŸ” The environment to start . 
        
        - ccloud
        - 2way-ssl
        - kerberos
        - kraft-external-plaintext
        - kraft-plaintext
        - ldap-authorizer-sasl-plain
        - ldap-sasl-plain
        - mdc-kerberos
        - mdc-plaintext
        - mdc-sasl-plain
        - plaintext
        - rbac-sasl-plain
        - sasl-plain
        - sasl-scram
        - sasl-ssl
        - ssl_kerberos

        Default is plaintext
    - long: --wait-for-control-center
      help: |- 
        ğŸ˜´ Wait for control-center instead of connect
    - long: --docker-compose-override-file
      short: -f
      validate: file_exists
      arg: docker-compose-override-file
      help: |-
        ğŸ”– docker-compose override file

        â• It must be absolute full path
  examples:
  - playground start-environment
  - playground start-environment --environment rbac-sasl-plain

- name: switch-ccloud
  group: Run
  dependencies:
    confluent: visit https://docs.confluent.io/confluent-cli/current/overview.html to install
  help: |-
    ğŸŒ©ï¸  Switch to ccloud environment.
    
    It will bootstrap ccloud environment based on your previously ran ccloud example.

- name: switch-back
  group: Run
  help: |-
    ğŸ’º  Switch back from previous environment before switch-ccloud was called.

- name: update-version
  group: Run
  help: |-
    âœ¨ Update current confluent platform or connector(s) with new version(s)
  flags:
  - *tag
  - *connector-tag
  - *connector-zip
  - *connector-jar
  examples:
  - playground update-version (interactive mode)
  - playground update-version --tag 6.2.0 --connector-tag=2.5.12,10.5.7

- name: open
  group: Run
  dependencies:
    fzf: visit https://github.com/junegunn/fzf#installation to install
  help: |-
    ğŸ‘ When --file is not provided, simply open last example you ran with <playground run>

    Otherwise, open any file from the playground using --file.
  flags:
  - long: --file
    short: -f
    required: false
    validate: file_exists_with_trick
    arg: file
    completions:
      - $(playground get-any-file-with-fzf "$cur")
    help: |-
      ğŸ” Search any file and open it.
      
      â• It must be absolute full path

      ğŸ“ Tip: use <tab> completion to trigger fzf completion

- name: stop
  group: Run
  help: |-
    ğŸ›‘ Stop currently running example

- name: remove-all-docker-images
  group: Run
  help: |-
    ğŸ§¨ Remove all docker images (including docker volumes)

- name: open-docs
  group: Run
  help: |-
    ğŸ§‘â€ğŸ“ Open Confluent documentation of currently running example
  flags:
  - long: --only-show-url
    help: |-
      ğŸŒ Only show url

- name: cleanup-cloud-resources
  group: Run
  dependencies:
    confluent: visit https://docs.confluent.io/confluent-cli/current/overview.html to install
  environment_variables:
  - name: AZ_USER 
    help: Azure user
  - name: AZ_PASS 
    help: Azure password
  - name: GCP_PROJECT 
    help: GCP project
  - name: AWS_ACCESS_KEY_ID 
    help: AWS access key id
  - name: AWS_SECRET_ACCESS_KEY 
    help: AWS secret access key
  - name: GCP_KEYFILE_CONTENT 
    help: GCP keyfile (generated with "cat keyfile.json | jq -aRs .")
  help: |-
    ğŸ§¹ Cleanup cloud resources that were created by running examples from the playground

    â—it will remove all resources created by the playground, including topics, connectors, clusters, buckets, redshift cluster, etc...
  flags:
  - long: --force
    help: |-
      â˜¢ï¸ do not ask for confirmation

      â—use with caution
  - long: --user
    private: true
    arg: user
    help: |-
      â˜¢ï¸ force user
  - long: --resource
    arg: resource
    help: |-
      ğŸ› resource to cleanup

      If not provided, all of them are cleaned up

      ğŸ“ Tip: you can pass multiple resources by specifying --resource multiple times
    required: false
    repeatable: true
    unique: true
    default:
      - aws
      - gcp
      - azure
      - ccloud
      - salesforce
    allowed: 
      - aws
      - gcp
      - azure
      - ccloud
      - salesforce

- name: repro
  expose: always
  group: Repro
  help: |-
    ğŸ‘·â€â™‚ï¸ Reproduction model commands
  environment_variables:
  - name: OUTPUT_FOLDER 
    help: ğŸ“ Output folder where to generate bootstrapped files
    default: reproduction-models
  dependencies:
    fzf: visit https://github.com/junegunn/fzf#installation to install
  commands:

  - name: export
    help: |-
      ğŸ“¤ Export as tgz file uncommitted reproduction models from the folder of current reproduction model
    dependencies:
      git: visit https://git-scm.com/downloads to install
    flags:
      - long: --all
        required: false
        help: |-
          Export all uncommitted reproduction models

  - name: import
    help: |-
      ğŸ“¥ Import tgz file which was created with export command
    flags:
    - long: --file
      short: -f
      arg: file
      required: false
      validate: file_exists_with_trick
      completions:
        - $(playground get-playground-repro-export-with-fzf "$cur")
      help: |- 
        ğŸ¤ playground_repro_export.tgz file

        â• It must be absolute full path

        ğŸ“ Tip: use <tab> completion to trigger fzf completion 
                use playground config folder_zip_or_jar <folder1> <folder2>... (default is home folder and current folder is always included) to configure where to search the files

  - name: bootstrap
    help: |-
      ğŸ›   Bootstrap reproduction model, just run <playground repro bootstrap> !

      ğŸ”¥ HIGHLY RECOMMENDED: start in interactive mode by simple running <playground repro bootstrap> !
      
      ğŸ‘‰ Check documentation https://kafka-docker-playground.io/#/reusables?id=%f0%9f%9b%a0-bootstrap-reproduction-model
    flags:
    - long: --file
      short: -f
      required: false
      validate: file_exists_with_trick
      arg: file
      completions:
        - $(playground get-examples-list-with-fzf --without-repro "$cur")
      help: |-
        ğŸ”– Example file to use as basis, if not set, currently running example is used
        
        â• It must be absolute full path

        ğŸ“ Tip: use <tab> completion to trigger fzf completion

    - long: --description
      short: -d
      required: false
      validate: not_empty
      arg: description
      help: |-
        ğŸ’­ Description for the reproduction model

    - long: --producer
      private: true
      short: -p
      arg: producer-type
      conflicts: [--pipeline]
      default: "none"
      allowed: 
        - none
        - avro
        - avro-with-key
        - protobuf
        - protobuf-with-key
        - json-schema
        - json-schema-with-key
      help: |-
        ğŸ¤ Java producer type to use
        
        One of avro, avro-with-key, protobuf, protobuf-with-key, json-schema, json-schema-with-key

        ğŸ“ Tip: Most of times, it's much simpler to use 'playground topic produce'. Use java producer only if you have very specific requirements such as specifying record timestamp or to do perf testing (even though CLI is also good for that)

        ğŸ“ Tip: 'with-key' will also produce key with selected converter, otherwise LongConverter is used

    - long: --nb-producers
      private: true
      short: -n
      arg: nb-producers
      required: false
      help: |-
        2ï¸âƒ£ Number of java producers to generate

    - long: --producer-schema-key
      private: true
      required: false
      help: |-
        ğŸ”° Schema to use for the key

        âœ¨ Copy and paste the schema you want to use for the key, save and close the file to continue

    - long: --producer-schema-value
      private: true
      required: false
      help: |-
        ğŸ”° Schema to use for the value

        âœ¨ Copy and paste the schema you want to use for the key, save and close the file to continue

    - long: --custom-smt
      help: |-
        ğŸ”§ Add a custom SMT (which is a no-op)

    - long: --pipeline
      required: false
      validate: file_exists_with_trick
      arg: sink_file
      conflicts: [--producer]
      repeatable: true
      completions:
        - $(playground get-examples-list-with-fzf --without-repro --sink-only "$cur")
      help: |-
        ğŸ”– Sink example file to use for creating a pipeline. multiple --pipeline flags can be used to create a pipeline with multiple sinks.
        
        â• It must be absolute full path. 

        ğŸ“ Tip: use <tab> completion to trigger fzf completion

    examples:
    - playground repro bootstrap (interactive mode)

- name: get-docker-compose
  group: Kafka
  help: |-
    ğŸ‹ Get docker-compose

- name: schema
  expose: always
  group: Schema
  help: |-
     ğŸ”° Schema commands
  commands:

  - name: get
    group: Schema
    filters:
    - not_mdc_environment
    - schema_registry_running
    help: |-
      ğŸ”° Get all schemas versions for specified subject (if --subject is not specified, all subjects will be used)
    flags:
      - &subject
        long: --subject
        required: false
        arg: subject
        conflicts:
          - "id"
        completions:
          - $(playground get-subject-list)
        help: |-
          ğŸ“› Subject name

      - long: --id
        required: false
        validate: integer
        arg: id
        conflicts:
          - "subject"
          - "deleted"
        help: |-
           ğŸ’¯ Schema id

      - &verbose
        long: --verbose
        short: -v
        help: ğŸ Show command being ran.

      - long: --deleted
        required: false
        conflicts:
          - "id"
        help: |-
          ğŸ§Ÿ Include soft deleted subjects
    examples:
    - playground schema get
    - playground schema get --subject <SUBJECT>
    - playground schema get --deleted

  - name: register
    group: Schema
    filters:
    - not_mdc_environment
    - schema_registry_running
    help: |-
      âºï¸ Register a schema in specified subject
    flags:
      - &subject_required
        long: --subject
        required: true
        arg: subject
        completions:
          - $(playground get-subject-list)
        help: |-
          ğŸ“› Subject name
      - *verbose
      - long: --schema
        arg: schema
        completions:
          - $(playground get-predefined-schemas "$cur")
        default: "-"
        required: false
        help: |- 
          ğŸ”¥ You can either:
          
          * Set your own schema (avro, json-schema, protobuf) with stdin (see example section). 

          * Use completion to select predefined schemas (or use your own schema file) ğŸ“ Tip: use <tab> completion to trigger fzf completion
      - long: --id
        required: false
        validate: integer
        arg: id
        help: |-
          â˜¢ï¸ Force schema id

          â—it will replace any schema which already exists at given id

    examples: |
      playground schema register --subject test-protobuf << 'EOF'
      syntax = "proto3";
      
      package com.github.vdesabou;
      
      message Customer {
          int64 count = 1;
          string first_name = 2;
          string last_name = 3;
          string address = 4;
      }
      EOF

      playground schema register --subject test-avro << 'EOF'
      {
          "type": "record",
          "namespace": "com.github.vdesabou",
          "name": "Customer",
          "fields": [
              {
                  "name": "count",
                  "type": "long",
                  "doc": "count"
              },
              {
                  "name": "first_name",
                  "type": "string",
                  "doc": "First Name of Customer"
              },
              {
                  "name": "last_name",
                  "type": "string",
                  "doc": "Last Name of Customer"
              },
              {
                  "name": "address",
                  "type": "string",
                  "doc": "Address of Customer"
              }
          ]
      }
      EOF

  - name: get-compatibility
    filters:
    - not_mdc_environment
    - schema_registry_running
    group: Schema
    help: |-
      ğŸ›¡ï¸ Get subject-level compatibility
    flags:
    - *subject_required
    - *verbose

  - name: set-compatibility
    filters:
    - not_mdc_environment
    - schema_registry_running
    group: Schema
    help: |-
      ğŸ›¡ï¸ Set subject-level compatibility
    flags:
    - *subject_required
    - *verbose
    - &compatibility-required
      long: --compatibility
      arg: compatibility
      allowed: 
        - BACKWARD
        - BACKWARD_TRANSITIVE
        - FORWARD
        - FORWARD_TRANSITIVE
        - FULL
        - FULL_TRANSITIVE
        - NONE
      required: true
      help: |-
        Schema Registry compatibility rule

  - name: get-mode
    filters:
    - not_mdc_environment
    - schema_registry_running
    group: Schema
    help: |-
      ğŸ” Get subject-level mode
    flags:
    - *subject_required
    - *verbose

  - name: set-mode
    filters:
    - not_mdc_environment
    - schema_registry_running
    group: Schema
    help: |-
      ğŸ” Set subject-level mode

      To enable mode changes on a Schema Registry cluster, you must also set mode.mutability=true in the Schema Registry properties file before starting Schema Registry
    flags:
    - *subject_required
    - *verbose
    - long: --mode
      arg: mode
      allowed: 
        - IMPORT
        - READONLY
        - READWRITE
      required: true
      help: |-
        Schema Registry mode

  - name: delete
    filters:
    - not_mdc_environment
    - schema_registry_running
    group: Schema
    help: |-
      ğŸ§Ÿ Delete schema
    flags:
    - &subject_not_required
      long: --subject
      required: false
      arg: subject
      completions:
        - $(playground get-subject-list)
      help: |-
        ğŸ“› Subject name to delete:
          
          if --version is provided, only that version will be deleted. Otherwise the complete subject will be deleted
    - long: --version
      required: false
      validate: integer
      arg: version
      conflicts:
        - "--id"
      help: |-
        ğŸ”¢ Schema version of the provided subject to delete

        Can only be used when --subject is provided
    - long: --id
      required: false
      validate: integer
      arg: id
      conflicts:
        - "--version"
      help: |-
        ğŸ«µ Schema id

        Can only be used when --subject is provided
    - long: --permanent
      required: false
      help: |-
        ğŸ’€ Hard delete (default is soft delete)
    - *verbose


- name: tcp-proxy
  expose: always
  group: TCP Proxy
  help: |-
    ğŸš Zazkia TCP Proxy commands

    Simulate TCP connection issues (reset,delay,throttle,corrupt) using emicklei/zazkia (https://github.com/emicklei/zazkia) TCP proxy
  commands:

  - name: start
    help: |-
      ğŸ’— Start the TCP proxy and automatically replace connector config with zazkia hostname and port 49998
    flags:
      - long: --hostname
        arg: hostname
        required: true
        completions:
          - $(docker ps --format '{{.Names}}')
        help: |-
          Hostname used by the tcp proxy to forward request
      - long: --port
        arg: port
        validate: integer
        required: true
        completions:
          - $(playground get-docker-ports)
        help: |-
          Port used by the tcp proxy to forward request
      - &throttle-service-response
        long: --throttle-service-response
        arg: throttle-service-response
        validate: integer
        required: false
        default: "0"
        help: |-
          ğŸŒ Throttle service response. This is bytes per second.
      - long: --delay-service-response
        arg: delay-service-response
        validate: integer
        required: false
        default: "0"
        help: |-
          â²ï¸ Add milliseconds delay to service response. Default is 0 ms.
      - long: --break-service-response
        arg: break-service-response
        validate: percentage
        required: false
        default: "0"
        help: |-
          ğŸ’” Percentage of broken connections. Default is 0%.
      - &service-response-corrupt
        long: --service-response-corrupt
        required: false
        help: |-
          ğŸ¦¹â€â™‚ï¸ Corrupt service response with random mangled bytes. By default, there is no corruption.
      - long: --skip-automatic-connector-config
        required: false
        help: |-
          ğŸ¤– By default, script will attempt to modify automatically the running connector config to use Zazkia proxy.
          
          This flag allows to skip this automatic configuration (only useful if you want to manually update connector config with zazkia tcp proxy details)
    examples:
    - playground tcp-proxy start --hostname mysql --port 3306

  - name: get-connections
    help: |-
      ğŸ§² Get Zazkia active TCP connections config and stats
    flags:
      - &connection-id
        long: --connection-id
        completions:
          - $(playground get-zazkia-connection-list)
        arg: connection-id
        validate: integer
        required: false
        help: |-
          ğŸ§² Zazkia TCP connection id
                
  - name: delay
    help: |-
        â²ï¸ Add milliseconds delay to service response.
        Set it to 0 to remove the delay.
    flags:
      - long: --delay-service-response
        arg: delay-service-response
        validate: integer
        required: true
        help: |-
          â²ï¸ Add milliseconds delay to service response.
      - *connection-id

  - name: break
    help: |-
        ğŸ’” Break sending the response to the client.
        Set it to 0% to remove the delay.
    flags:
      - long: --break-service-response
        arg: break-service-response
        validate: percentage
        required: true
        help: |-
          ğŸ’” Percentage of broken connections.
      - *connection-id

  - name: close-connection
    help: |-
        âŒ Close the Zazkia active TCP connections
    flags:
      - *connection-id

  - name: close-all-connection-with-error
    help: |-
        ğŸ§¹ Close all Zazkia TCP connections which are in error state (close all with error button in Zazkia UI)

  - name: toggle-accept-connections
    help: |-
        ğŸ™…â€â™‚ï¸ Change whether new connections can be accepted

  - name: toggle-reads-client
    help: |-
        âœ… Change whether reading data from the client is enabled.

          See diagram in https://github.com/emicklei/zazkia#how-does-it-work- (or locally http://localhost:9191/help.html)
    flags:
      - *connection-id

  - name: toggle-reads-service
    help: |-
        âœ… Change whether reading data from the service is enabled.

          See diagram in https://github.com/emicklei/zazkia#how-does-it-work- (or locally http://localhost:9191/help.html)
    flags:
      - *connection-id

  - name: toggle-writes-client
    help: |-
        âœ… Change whether writing data to the client is enabled.

          See diagram in https://github.com/emicklei/zazkia#how-does-it-work- (or locally http://localhost:9191/help.html)
    flags:
      - *connection-id

  - name: toggle-writes-service
    help: |-
        âœ… Change whether reading data to the service is enabled.

          See diagram in https://github.com/emicklei/zazkia#how-does-it-work- (or locally http://localhost:9191/help.html)
    flags:
      - *connection-id

- name: debug
  expose: always
  group: Debug
  help: |-
    ğŸ Debug commands
  commands:

  - name: enable-remote-debugging
    help: |-
      âœ¨ Enable java remote debugging for container
      
      ğŸ‘‰ Check documentation https://kafka-docker-playground.io/#/reusables?id=%e2%9c%a8-remote-debugging
    flags:
      - &container
        long: --container
        short: -c
        required: false
        default: "connect"
        arg: container
        completions:
          - $(docker ps --format '{{.Names}}')
        help: |-
          ğŸ³ Container name
    examples:
    - playground debug enable-remote-debugging
    - playground debug enable-remote-debugging --container broker
    - playground debug enable-remote-debugging -c broker

  - name: testssl
    help: |-
      ğŸ” Testing TLS/SSL encryption using https://testssl.sh/

      testssl <URI>, where <URI> is:

      host|host:port|URL|URL:port   port 443 is default, URL can only contain HTTPS protocol
    args:
    - name: arguments
      help: arguments to pass to testssl, see https://testssl.sh for all options
      required: false
    examples:
    - playground debug testssl https://google.com
    - playground debug testssl pkc-xxxx.us-west-2.aws.confluent.cloud:9092

  - name: generate-diagnostics
    help: |-
      â›‘ï¸ Generate a diagnostic bundle with Diagnostics Bundle Tool

      âš ï¸ only connect and broker containers are supported for now

      see https://docs.confluent.io/platform/current/tools/diagnostics-tool.html#collect-diagnostics
    flags:
      - *container
    examples:
    - playground debug generate-diagnostics
    - playground debug generate-diagnostics --container broker

  - name: thread-dump
    help: |-
      ğŸ¯ Take a java thread dump

      ğŸ”– It will save output to a file and open with text editor set with playground config editor <editor> (default is code)
    flags:
      - *container
    examples:
    - playground debug thread-dump
    - playground debug thread-dump --container broker

  - name: heap-dump
    help: |-
      ğŸ‘» Take a heap dump

      ğŸ”– It will save output to a .hprof file. VisualVM (https://visualvm.github.io/) or MAT (https://www.eclipse.org/mat/) can be used to read the file.
    flags:
      - *container
    examples:
    - playground debug heap-dump
    - playground debug heap-dump --container broker

  - name: tcp-dump
    help: |-
      ğŸ•µï¸â€â™‚ï¸ Take a tcp dump (sniffing network)
    flags:
      - *container
      - long: --port
        arg: port
        validate: integer
        required: false
        completions:
          - $(playground get-docker-ports)
        help: |-
          Port on which tcp dump should be done, if not set sniffing is done on every port
      - long: --duration
        arg: duration
        validate: integer
        required: false
        default: "30"
        help: |-
          Duration of the dump (default is 30 seconds).
    examples:
    - playground debug tcp-dump --container control-center --port 9021 --duration 60

  - name: block-traffic
    help: |-
      ğŸš« Blocking traffic using iptables
    flags:
      - *container
      - long: --destination
        arg: destination
        required: true
        help: |-
          Destination: it could be an ip address, a container name or a hostname
      - long: --port
        arg: port
        validate: integer
        required: false
        completions:
          - $(playground get-docker-ports)
        help: |-
          Port on which tcp traffic should be blocked
      - &action
        long: --action
        allowed: [start, stop]
        arg: action
        required: true
        help: |-
          ğŸŸ¢ start or stop
    examples:
    - playground debug block-traffic --destination google.com --action start
    - playground debug block-traffic --container broker --destination zookeeper --action start

  - name: java-debug
    help: |-
      ğŸ¤ JVM arguments for SSL, Kerberos or Class Loading
    flags:
      - *container
      - long: --type
        arg: type
        allowed: [ssl_all, ssl_handshake, class_loading, kerberos]
        required: true
        help: |-
          - ssl_all: Enable all SSL debugging, i.e -Djavax.net.debug=all
          - ssl_handshake: Enable SSL handshake debugging, i.e -Djavax.net.debug=ssl:handshake
          - class_loading: Enable class loading debugging, i.e -verbose:class
          - kerberos: Enable Kerberos debugging, i.e -Dsun.security.krb5.debug=true
      - long: --action
        allowed: [enable, disable]
        arg: action
        required: false
        default: "enable"
        help: |-
          ğŸŸ¢ enable or disable
    examples:
    - playground debug java-debug --type class_loading
    - playground debug java-debug --container broker --action start

  - name: flight-recorder
    help: |-
      ğŸ›©ï¸ Record flight recorder

      Read more about it at https://www.baeldung.com/java-flight-recorder-monitoring

      Open the jfr file with JDK Mission Control JMC(https://jdk.java.net/jmc/)
    flags:
      - *container
      - *action
    examples:
    - playground debug flight-recorder --action start
    - playground debug flight-recorder --action stop

  - name: log-level
    help: |-
      ğŸ§¬ Set log level for any package
    filters:
    - connect_running
    commands:
    - name: get
      help: Get log levels
      flags:
      - &package
        long: --package
        short: -p
        required: false
        validate: not_empty
        arg: package
        help: |-
          Package name

    - name: set
      help: Set log level for specific logger
      flags:
      - long: --package
        short: -p
        required: true
        validate: not_empty
        arg: package
        help: |-
          ğŸ“¦ Package name

      - &level
        long: --level
        short: -l
        arg: level
        allowed: [INFO, WARN, DEBUG, TRACE]
        required: true
        help: |-
          â•Log level

    examples:
    - playground debug log-level get
    - playground debug log-level get -p io.confluent.connect.oracle.cdc
    - playground debug log-level get --package io.confluent.connect.oracle.cdc
    - playground debug log-level set -p io.confluent.connect.oracle.cdc.logging.LogUtils -l TRACE

- name: get-jmx-metrics
  group: Kafka
  help: |-
    ğŸ”¢ Get JMX metrics from a container
    
    ğŸ‘‰ Check documentation https://kafka-docker-playground.io/#/how-to-use?id=%f0%9f%94%a2-jmx-metrics
  dependencies:
    java: visit https://openjdk.org/install/ to install
  flags:
  - *container
  - long: --open
    short: -o
    help: |- 
      ğŸ”– Save output to a file and open with text editor set with playground config editor <editor> (default is code)

  - long: --domain
    short: -d
    required: false
    arg: domain
    help: |-
      Domain name

  examples:
  - playground get-jmx-metrics --container connect
  - playground get-jmx-metrics --container connect --domain "kafka.connect kafka.consumer kafka.producer"
  - playground get-jmx-metrics -c broker

- name: container
  expose: always
  group: Container
  help: |-
    ğŸ³ Container commands
  commands:

    - name: get-properties
      help: |-
        ğŸ“ Get properties file from a container
        
        ğŸ‘‰ Check documentation https://kafka-docker-playground.io/#/how-to-use?id=%f0%9f%93%9d-see-properties-file

      flags:
      - *container
      examples:
      - playground get-properties
      - playground get-properties --container broker
      - playground get-properties -c broker

    - name: recreate
      group: Container
      help: |-
        ğŸ’« Recreate container(s)
        
        ğŸ‘‰ Check documentation https://kafka-docker-playground.io/#/how-to-use?id=%e2%99%bb%ef%b8%8f-re-create-containers
      flags:
      - long: --ignore-current-versions
        required: false
        help: |-
          Ignore current confluent platform version

          By default, the current version is used

    - name: get-ip-addresses
      group: Container
      help: |-
        ğŸ–¥ï¸  Get ip address of running containers
      examples:
      - playground get-ip-address-container

    - name: kill-all
      group: Container
      help: |-
        ğŸ’€ Kill all containers

    - name: logs
      group: Container
      help: |-
        ğŸ•µï¸  Tail and follow container logs

      flags:
      - *container
      - &logsopen
        long: --open
        short: -o
        help: |- 
          ğŸ”– Save output to a file and open with text editor set with playground config editor <editor> (default is code)
        conflicts: [--wait-for-log]
      - &logswaitforlog
        long: --wait-for-log
        short: -w
        arg: log
        validate: not_empty
        help: |- 
          ğŸ˜´ Wait until log appears
        conflicts: [--open]
      - &logsmaxwait
        long: --max-wait
        short: -m
        arg: max_wait
        validate: integer
        default: "600"
        help: |- 
          â³ Max time in seconds to wait when using --wait-for-log (default 600s)
        conflicts: [--open]

      examples:
      - playground container logs --container connect
      - playground container logs -c connect --open
      - playground container logs -c connect --wait-for-log "StackOverflowError"

    - name: ssh
      group: Container
      help: |-
        ğŸ›¬ SSH into container

      flags:
      - *container

      - long: --shell
        short: -s
        required: false
        default: "bash"
        arg: shell
        allowed: 
          - bash
          - sh
          - ksh
          - zsh
        help: |-
          ğŸ’¾ Shell to use (default is bash)

      examples:
      - playground ssh -c connect
      - playground ssh -c connect -s sh
      - playground ssh --container connect --shell sh

    - name: change-jdk
      group: Container
      help: |-
        ğŸ¤ Change java JDK version using Azul JDK (https://www.azul.com/downloads/#downloads-table-zulu)

        PS: It works for UBI8 docker images only

      flags:
      - *container

      - long: --version
        required: true
        arg: version
        allowed: 
          - "8"
          - "11"
          - "17"
          - "21"
          - "22"
        help: |-
          ğŸ¤ JDK version to use

      examples:
      - playground change-jdk --container connect --version jdk17-lts

    - name: exec
      group: Container
      help: |-
        ğŸª„  Execute command in a container

      flags:
      - *container

      - long: --command
        required: true
        validate: not_empty
        arg: command
        help: |-
          ğŸ“² Command to execute

      - long: --root
        help: |-
          ğŸ‘‘ Run command as root

      - long: --shell
        default: "bash"
        arg: shell
        allowed: 
          - bash
          - sh
          - ksh
          - zsh
        help: |-
          ğŸ’¾ Shell to use (default is bash)

      examples:
      - playground exec -c connect -d "date"
      - playground exec -c connect -d "whoami" --root
      - playground exec --container connect --command "whoami" --shell sh

    - name: restart
      group: Container
      help: |-
        ğŸ” Restart a container

      flags:
      - *container

    - name: pause
      group: Container
      help: |-
        â¸ï¸  Pause a container

      flags:
      - *container

    - name: resume
      alias: unpause
      group: Container
      help: |-
        â¯ï¸  Resume a container

      flags:
      - *container

    - name: kill
      group: Container
      help: |-
        ğŸ”« Kill a container

      flags:
      - *container

- name: topic
  expose: always
  group: Topic
  filters:
  - not_mdc_environment
  help: |-
    ğŸ—³ Topic commands
  commands:

    - name: get-number-records
      group: Topic
      help: |-
        ğŸ’¯ Get number of records in a topic
      flags:
      - &topic
        long: --topic
        short: -t
        required: false
        arg: topic
        completions:
          - $(playground get-topic-list)
        help: |-
          ğŸ—³ Topic name
      examples:
      - playground get-number-records --topic a-topic
      - playground get-number-records -t a-topic

    - name: display-consumer-offsets
      group: Topic
      help: |-
        ğŸ“­ Display content of __consumer_offsets topic
      flags:
      - *verbose

    - name: list
      group: Topic
      help: |-
        ğŸ”˜ List topics

    - name: describe
      group: Topic
      help: |-
        ğŸ”¬ Describe topic
      flags:
      - *topic
      - *verbose

    - name: set-schema-compatibility
      filters:
      - schema_registry_running
      group: Topic
      help: |-
        ğŸ›¡ï¸ Change topic's schema compatibility
      flags:
      - *topic
      - *compatibility-required
      - *verbose

    - name: consume
      filters:
      - schema_registry_running
      group: Topic
      help: |-
        ğŸ“¥ Consume topic from beginning
      flags:
      - *verbose
      - *topic
      - long: --max-messages
        arg: max-messages
        validate: integer
        required: false
        default: "10"
        help: |-
          Max number of messages to display (default is 10)
      - long: --min-expected-messages
        arg: min-expected-messages
        validate: integer
        required: false
        default: "0"
        help: |-
          Minimum expected number of messages to be present in topic, returns an error if this is not the case

          Note: --topic should be specified in this case.
      - long: --grep
        arg: grep
        required: false
        default: ""
        help: |-
          Verify that topic content contains record which contains specified string
      - long: --timeout
        arg: timeout
        validate: integer
        required: false
        default: "60"
        help: |-
          Max number of seconds to wait when --min-expected-messages is used.

          Default is 60 seconds
      - long: --tail
        required: false
        help: |-
          Tail on logs.
        conflicts: [--min-expected-messages, --max-messages]

      - long: --plot-latencies-timestamp-field
        required: false
        arg: timestamp
        help: |-
          ğŸ—³ Timestamp field name that represents when record was created in source system

      - long: --key-subject
        required: false
        arg: key-subject
        completions:
          - $(playground get-subject-list)
        help: |-
          ğŸ“› Subject for key in schema-registry to use (useful when data was produced with --key-subject-name-strategy other than TopicNameStrategy)
          
          Note: --topic should be specified in this case.

      - long: --value-subject
        required: false
        arg: value-subject
        completions:
          - $(playground get-subject-list)
        help: |-
          ğŸ“› Subject for value in schema-registry to use (useful when data was produced with --value-subject-name-strategy other than TopicNameStrategy)
          
          Note: --topic should be specified in this case.

      - long: --max-characters
        arg: max-characters
        validate: integer
        required: false
        default: "3000"
        help: |-
          Max characters per message to display (default is 3000)

    - name: produce
      filters:
      - schema_registry_running
      group: Topic
      help: |-
         ğŸ“¤ Produce to a topic

         See video tutorial https://youtu.be/mbzHCewG_XE
      flags:

      - long: --key
        arg: key
        required: false
        completions:
          - $(playground get-predefined-schemas "$cur")
        help: |-
          ğŸ—ï¸ Key to use. If not set, no key is used.

          ğŸ”¥ You can either:
          
          * Set your own schema (avro, json-schema, protobuf) within single quotes (see examples) 
          
          * You can also generate json data using json or sql format using syntax from https://github.com/MaterializeInc/datagen

          * Use completion to select predefined schemas (or use your own schema file) ğŸ“ Tip: use <tab> completion to trigger fzf completion

          * Directly set payload ("%g" can be used to generate a counter)

          In case of 'raw' data (i.e not using schema):

          If the key contain a number, it will be used as starting point and incremented for each record. 
          
          Example: key1 will start with key1, then key2, etc..
          Example: mykey-10-suffix will start with mykey-10-suffix then mykey-11-suffix, etc..

          "%g" can also be used to generate a counter

          Example: key%g will start with key1, then key2, etc..

          Otherwise, the key will be same for all records.

      - long: --value
        arg: value
        completions:
          - $(playground get-predefined-schemas "$cur")
        default: "-"
        required: false
        help: |- 
          ğŸ”¥ You can either:
          
          * Set your own schema (avro, json-schema, protobuf) with stdin (see example section). 
          
          * You can also generate json data using json or sql format using syntax from https://github.com/MaterializeInc/datagen

          * Use completion to select predefined schemas (or use your own schema file) ğŸ“ Tip: use <tab> completion to trigger fzf completion

          * Directly set payload ("%g" can be used to generate a counter)

      - *verbose
      - long: --debug
        short: -d
        required: false
        private: true
        help: |-
          debug mode (internal)
      - long: --topic
        short: -t
        required: true
        arg: topic
        completions:
          - $(playground get-topic-list)
        help: |-
          ğŸ—³ Topic name
      - long: --nb-messages
        arg: nb-messages
        validate: integer
        required: false
        default: "1"
        help: |-
          ğŸ’¯ Number of messages to produce (default is 1)
             
          ğŸ“  - if > <value of --max-nb-messages-per-batch> (default 300000), messages will be sent in batches of <value of --max-nb-messages-per-batch> (default 300000) records
              - if you set it to -1, an infinite number of records will also be sent in batches
      - long: --max-nb-messages-per-batch
        arg: max-nb-messages-per-batch
        validate: integer
        required: false
        default: "300000"
        help: |-
          ğŸ”¼ Max number of messages to send per batch when --nb-messages > --max-nb-messages-per-batch
             if --nb-messages is set to -1, this is the number of messages sent per batch
             default is 300000
      - long: --sleep-time-between-batch
        arg: sleep-time-between-batch
        validate: integer
        required: false
        default: "0"
        help: |-
          ğŸ’¤ Sleep time in seconds between batches
             default is 0
      - long: --nb-partitions
        arg: nb-partitions
        validate: integer
        required: false
        default: "1"
        help: |-
          ğŸ”¢ Number of partitions for the topic. (default is 1)
          
          âŒ Important: If topic is existing, it will be re-created before producing to topic.
      - long: --compression-codec
        arg: compression-codec
        required: false
        allowed: 
          - gzip
          - snappy
          - lz4
          - zstd
        help: |-
          ğŸ¤ The compression codec: either 'gzip', 'snappy', 'lz4', or 'zstd'
          If not set, there is no compression

      - &compatibility
        long: --compatibility
        arg: compatibility
        allowed: 
          - BACKWARD
          - BACKWARD_TRANSITIVE
          - FORWARD
          - FORWARD_TRANSITIVE
          - FULL
          - FULL_TRANSITIVE
          - NONE
        help: |-
          Schema Registry compatibility rule

      - &key-subject-name-strategy
        long: --key-subject-name-strategy
        arg: key-subject-name-strategy
        allowed: 
          - TopicNameStrategy
          - RecordNameStrategy
          - TopicRecordNameStrategy
        help: |-
          Key Subject Name Strategy

      - &value-subject-name-strategy
        long: --value-subject-name-strategy
        arg: value-subject-name-strategy
        allowed: 
          - TopicNameStrategy
          - RecordNameStrategy
          - TopicRecordNameStrategy
        help: |-
          Value Subject Name Strategy

      - long: --headers
        arg: headers
        required: false
        help: |-
          ğŸš Headers to use for all records. If not set, no header is used.

          Example: --headers "header1:value1,header2:value2"

          Note: CP 7.2+ is required.
      - long: --forced-key
        arg: forced-key
        required: false
        help: |-
          â˜¢ï¸ Key to use for all records. 
          
          ğŸ“ Tip: use --generate-only first with avro, json-schema or protobuf to get skeleton of messages and then use --forced-key to send the message you need. 
      - long: --forced-value
        arg: forced-value
        required: false
        help: |-
          â˜¢ï¸ Value to use for all records. 
          
          ğŸ“ Tip: use --generate-only first with avro, json-schema or protobuf to get skeleton of messages and then use --forced-value to send the message you need. 
      - long: --generate-only
        required: false
        help: |-
          ğŸšª Only generate messages without sending to kafka topic.

          Used with --forced-value, this is a powerful way to send specific messages.
      - long: --tombstone
        required: false
        help: |-
          âš°ï¸ Generate tombstone (record with null value). 
          
          --key must be set when this flag is used.

          Note: CP 7.2+ is required.
      - long: --validate
        required: false
        help: |-
          â˜‘ï¸ Validate schema according to connect sink converter used

      - long: --no-null
        required: false
        help: |-
          ğŸª¹ Never generate null fields even for optional fields

          N.B: only work with avro and json-schema

      - long: --consume
        required: false
        help: |-
          ğŸ“¥ After producing, directly consume topic.

      - long: --delete-topic
        required: false
        help: |-
          âŒ Delete topic and associated schema/subject if applicable before producing data.

      - long: --reference
        arg: reference
        private: true
        help: |-
          ğŸ–‡ï¸ Schema reference
          
          See docs: https://docs.confluent.io/platform/7.6/schema-registry/fundamentals/serdes-develop/index.html#schema-references

          ğŸ“ Tip: you can pass multiple references by specifying --reference multiple times

          ğŸ”¥ You can either:
          
          * Set your own schema (avro, json-schema, protobuf) within single quotes (see examples) 
          
          * Use completion to select predefined schemas (or use your own schema file) ğŸ“ Tip: use <tab> completion to trigger fzf completion
        required: false
        repeatable: true
        completions:
          - $(playground get-predefined-schemas "$cur")

      - long: --validate-config
        arg: validate-config
        help: |-
          ğŸ”© Converter configuration parameters to use 
          
          See docs: https://docs.confluent.io/platform/current/schema-registry/connect.html#using-kconnect-long-with-sr

          ğŸ“ Tip: you can pass multiple parameters by specifying --validate-config multiple times
        required: false
        repeatable: true
        allowed: 
          - scrub.invalid.names=true
          - enhanced.avro.schema.support=true
          - connect.meta.data=false
          - object.additional.properties=false
          - use.optional.for.nonrequired=true
          - ignore.default.for.nullables=true
          - generalized.sum.type.support=true
          - enhanced.protobuf.schema.support=true
          - generate.index.for.unions=false
          - int.for.enums=true
          - optional.for.nullables=true
          - generate.struct.for.nulls=true
          - wrapper.for.nullables=true
          - wrapper.for.raw.primitives=false

      - long: --producer-property
        arg: producer-property
        help: |-
          ğŸ”© Producer configuration parameters to use 
          
          See docs: https://docs.confluent.io/platform/current/installation/configuration/producer-configs.html#cp-config-producer

          ğŸ“ Tip: you can pass multiple parameters by specifying --producer-property multiple times

          Example: --producer-property "max.request.size=990485760" --producer-property "client.id=myid"
        required: false
        repeatable: true

      - long: --record-size
        arg: record-size
        validate: integer
        required: false
        default: "0"
        help: |-
          ğŸ‹ï¸ Record size in bytes, eg. 1048576 for 1MB

          ğŸ“¢ If size is > 1Mb, --producer-property max.request.size and topic max.message.bytes will be automatically set to support the record size.

      - long: --value-schema-id
        arg: value-schema-id
        private: true
        validate: integer
        required: false
        help: |-
          ğŸ”° Do not auto register schema and specify schema id to use. 

          It sets --property value.schema.id=x --property auto.register=false --property use.latest.version=true

      examples: |

        playground topic produce --tombstone --topic a-topic --key mykey

        playground topic produce -t topic-json --nb-messages 10 << 'EOF'
        {
            "_meta": {
                "topic": "",
                "key": "",
                "relationships": []
            },
            "nested": {
                "phone": "faker.phone.imei()",
                "website": "faker.internet.domainName()"
            },
            "id": "iteration.index",
            "name": "faker.internet.userName()",
            "email": "faker.internet.exampleEmail()",
            "phone": "faker.phone.imei()",
            "website": "faker.internet.domainName()",
            "city": "faker.address.city()",
            "company": "faker.company.name()"
        }
        EOF

        playground topic produce -t topic-avro --nb-messages 10 << 'EOF'
        {
          "fields": [
            {
              "name": "count",
              "type": "long"
            },
            {
              "name": "first_name",
              "type": "string"
            },
            {
              "name": "last_name",
              "type": "string"
            },
            {
              "default": null,
              "name": "address",
              "type": [
                "null",
                "string"
              ]
            },
            {
              "name": "last_sale_date",
              "type": {
                "logicalType": "timestamp-millis",
                "type": "long"
              }
            },
            {
              "name": "last_sale_price",
              "type": {
                "logicalType": "decimal",
                "precision": 15,
                "scale": 2,
                "type": "bytes"
              }
            },
            {
              "name": "last_connection",
              "type": {
                "logicalType": "date",
                "type": "int"
              }
            }
          ],
          "name": "Customer",
          "namespace": "com.github.vdesabou",
          "type": "record"
        }
        EOF

        playground topic produce -t topic-json-schema --nb-messages 3 << 'EOF'
        {
          "$schema": "http://json-schema.org/draft-07/schema#",
          "additionalProperties": false,
          "$id": "http://lh.test/Customer.schema.json",
          "title": "Customer",
          "description": "Customer description",
          "type": "object",
          "properties": {
            "name": {
              "description": "Customer name",
              "type": "string",
              "maxLength": 25
            },
            "surname": {
              "description": "Customer surname",
              "type": "string",
              "minLength": 2
            },
            "email": {
              "description": "Email",
              "type": "string",
              "pattern": "^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$"
            }
          },
          "required": [
            "name",
            "surname"
          ]
        }
        EOF


        playground topic produce -t topic-proto --nb-messages 1 << 'EOF'
        syntax = "proto3";

        package com.github.vdesabou;

        message Customer {
            int64 count = 1;
            string first_name = 2;
            string last_name = 3;
            string address = 4;
        }
        EOF

        playground topic produce -t topic-jsql --nb-messages 10 << 'EOF'
        CREATE TABLE "notused"."notused" (
          "id" int PRIMARY KEY,
          "name" varchar COMMENT 'faker.internet.userName()',
          "merchant_id" int NOT NULL COMMENT 'faker.datatype.number()',
          "price" int COMMENT 'faker.datatype.number()',
          "status" int COMMENT 'faker.datatype.boolean()',
          "created_at" datetime DEFAULT (now())
        );
        EOF

        playground topic produce -t topic-json --nb-messages 1 --producer-property "max.request.size=990485760" < bigjson.json

        playground topic produce -t topic-string --nb-messages 5000 << 'EOF'
        Ad et ut pariatur officia eos.
        Nesciunt fugit nam libero ut qui itaque sed earum at itaque nesciunt eveniet atque.
        Quidem libero quis quod et illum excepturi voluptas et in perspiciatis iusto neque.
        Quibusdam commodi explicabo dolores molestiae qui delectus dolorum fugiat molestiae natus assumenda omnis expedita.
        Et sunt aut architecto suscipit fugiat qui voluptate iure vel doloremque eum culpa.
        Qui enim facilis eos similique aperiam totam eius et at dolor dolores.
        Ut sunt quia qui quia consectetur aut reiciendis.
        Modi adipisci iusto aut voluptatem dolores laudantium.
        Sequi sint quia quibusdam molestias minus et aliquid voluptatum aliquam.
        Rerum aut amet quo possimus nihil velit quisquam ut cumque.
        Pariatur ad officiis voluptatibus quia vel corporis ea fugit adipisci porro.
        EOF

        # key and headers
        # mykey1 %g can also be used
        playground topic produce -t topic-json-multiple-lines --nb-messages 10 --key "mykey1" --headers "header1:value1,header2:value2" << 'EOF'
        {"u_name": "scissors", "u_price": 2.75, "u_quantity": 3}
        {"u_name": "tape", "u_price": 0.99, "u_quantity": 10}
        {"u_name": "notebooks", "u_price": 1.99, "u_quantity": 5}
        EOF

        # avro key
        playground topic produce -t topic-avro-with-key --nb-messages 10 --key '
        {
          "fields": [
            {
              "name": "id",
              "type": "long"
            }
          ],
          "name": "Key",
          "namespace": "com.github.vdesabou",
          "type": "record"
        }
        ' << 'EOF'
        {
          "fields": [
            {
              "doc": "count",
              "name": "count",
              "type": "long"
            },
            {
              "doc": "First Name of Customer",
              "name": "first_name",
              "type": "string"
            },
            {
              "doc": "Last Name of Customer",
              "name": "last_name",
              "type": "string"
            }
          ],
          "name": "Customer",
          "namespace": "com.github.vdesabou",
          "type": "record"
        }
        EOF

        # tombstone
        playground topic produce -t topic-json-multiple-lines --tombstone --key "mykey1"

        # input file
        playground topic produce -t topic-avro-example3 < avro-schema.avsc

        # record-size
        playground topic produce -t topic-avro-example-big-size --nb-messages 3 --record-size 10000000 << 'EOF'
        {
          "fields": [
            {
              "doc": "count",
              "name": "count",
              "type": "long"
            },
            {
              "doc": "First Name of Customer",
              "name": "first_name",
              "type": "string"
            },
            {
              "doc": "Last Name of Customer",
              "name": "last_name",
              "type": "string"
            },
            {
              "doc": "Address of Customer",
              "name": "address",
              "type": "string"
            }
          ],
          "name": "Customer",
          "namespace": "com.github.vdesabou",
          "type": "record"
        }
        EOF

        # validate
        playground topic produce -t topic-json-schema-validate --nb-messages 3 --validate << 'EOF'
        {
          "$schema": "http://json-schema.org/draft-07/schema#",
          "additionalProperties": false,
          "$id": "http://lh.test/Customer.schema.json",
          "title": "Customer",
          "description": "Customer description",
          "type": "object",
          "properties": {
            "name": {
              "description": "Customer name",
              "type": "string",
              "maxLength": 25
            },
            "surname": {
              "description": "Customer surname",
              "type": "string",
              "minLength": 2
            },
            "email": {
              "description": "Email",
              "type": "string",
              "pattern": "^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$"
            },
            "holiday": {
              "oneOf": [
                {
                  "title": "Not included",
                  "type": "null"
                },
                {}
              ]
            },
            "f2": {}
          },
          "required": [
            "name",
            "surname"
          ]
        }
        EOF

        #  --value-subject-name-strategy
        playground topic produce -t topic-avro-example-value-subject-name-strategy --nb-messages 10 --value-subject-name-strategy TopicRecordNameStrategy << 'EOF'
        {
          "fields": [
            {
              "doc": "count",
              "name": "count",
              "type": "long"
            },
            {
              "doc": "First Name of Customer",
              "name": "first_name",
              "type": "string"
            },
            {
              "doc": "Last Name of Customer",
              "name": "last_name",
              "type": "string"
            },
            {
              "doc": "Address of Customer",
              "name": "address",
              "type": "string"
            }
          ],
          "name": "Customer",
          "namespace": "com.github.vdesabou",
          "type": "record"
        }
        EOF

        # --generate-only
        playground topic produce -t topic-avro-example-forced-value --nb-messages 10  --generate-only << 'EOF'
        {
          "fields": [
            {
              "doc": "count",
              "name": "count",
              "type": "long"
            },
            {
              "doc": "First Name of Customer",
              "name": "first_name",
              "type": "string"
            },
            {
              "doc": "Last Name of Customer",
              "name": "last_name",
              "type": "string"
            },
            {
              "doc": "Address of Customer",
              "name": "address",
              "type": "string"
            },
            {
              "name": "createdDate",
              "type": {
                "logicalType": "timestamp-millis",
                "type": "long"
              }
            },
            {
              "default": null,
              "name": "warranty_expiration",
              "type": [
                "null",
                {
                  "logicalType": "date",
                  "type": "int"
                }
              ]
            }
          ],
          "name": "Customer",
          "namespace": "com.github.vdesabou",
          "type": "record"
        }
        EOF

        # --forced-value
        playground topic produce -t topic-avro-example-forced-value --nb-messages 1 --forced-value '{"count":4,"first_name":"Vincent","last_name":"de Saboulin","address":"xxx","createdDate":1697852606000,"warranty_expiration":{"int":19653}}' << 'EOF'
        {
          "fields": [
            {
              "doc": "count",
              "name": "count",
              "type": "long"
            },
            {
              "doc": "First Name of Customer",
              "name": "first_name",
              "type": "string"
            },
            {
              "doc": "Last Name of Customer",
              "name": "last_name",
              "type": "string"
            },
            {
              "doc": "Address of Customer",
              "name": "address",
              "type": "string"
            },
            {
              "name": "createdDate",
              "type": {
                "logicalType": "timestamp-millis",
                "type": "long"
              }
            },
            {
              "default": null,
              "name": "warranty_expiration",
              "type": [
                "null",
                {
                  "logicalType": "date",
                  "type": "int"
                }
              ]
            }
          ],
          "name": "Customer",
          "namespace": "com.github.vdesabou",
          "type": "record"
        }
        EOF

        # json schema references
        playground topic produce --value /path/to/scripts/cli/predefined-schemas/json-schema/schema-reference/customer.json --reference /path/to/scripts/cli/predefined-schemas/json-schema/schema-reference/address.json --reference /path/to/scripts/cli/predefined-schemas/json-schema/schema-reference/email.json --topic customers
    - name: create
      group: Topic
      help: |-
        ğŸ†• Create topic
      flags:
      - *verbose
      - long: --topic
        short: -t
        required: true
        arg: topic
        help: |-
          ğŸ—³ Topic name
      - long: --nb-partitions
        arg: nb-partitions
        validate: integer
        required: false
        default: "1"
        help: |-
          Number of partitions for the topic. (default is 1)
      catch_all:
        label: arguments
        help: |-
          Any arguments to be used with kafka-topics --create
        required: false
      examples: |
        playground topic create --topic atopic
        playground topic create --topic atopic --nb-partitions 8 --config retention.ms=30000 --config cleanup.policy=compact
        
    - name: delete
      group: Topic
      help: |-
        âŒ Delete topic and associated schema/subject if applicable
      flags:
      - *verbose
      - long: --topic
        short: -t
        required: true
        arg: topic
        completions:
          - $(playground get-topic-list)
        help: |-
          ğŸ—³ Topic name
      - long: --skip-delete-schema
        required: false
        help: |-
          ğŸ”° Do not delete subject/schema

    - name: alter
      group: Topic
      help: |-
        ğŸª› Alter topic config
      flags:
      - *verbose
      - long: --topic
        short: -t
        required: true
        arg: topic
        completions:
          - $(playground get-topic-list)
        help: |-
          ğŸ—³ Topic name
      catch_all:
        label: arguments
        help: |-
          Any arguments to be used with kafka-configs --alter. If the topic does not exist, it is created first.
        required: false
      examples: |
        playground topic alter --topic atopic --add-config max.message.bytes=5242940

- name: connector-plugin
  expose: always
  group: Connector-Plugin
  help: |-
    ğŸ”Œ Connector-plugin commands

  commands:
  - name: search-jar
    help: â˜• List jars for a connector plugin from confluent hub https://www.confluent.io/hub/
          Search for specific class and display method signatures
    dependencies:
      javap: visit https://openjdk.org/install/ to install
    flags:
    - &connector-plugin
      long: --connector-plugin
      short: -c
      required: true
      arg: connector-plugin
      completions:
        - $(playground get-connector-plugin "$cur")
      help: |-
        ğŸ”Œ Connector plugin name

        ğŸ“ Tip: use <tab> completion to trigger fzf completion
    - *connector-tag
    - long: --class
      arg: class
      required: false
      help: |- 
        â˜• Java class name to search for in all jars
    examples: |
      playground connector-plugin search-jar --connector-plugin confluentinc/kafka-connect-s3 --class WebIdentityTokenCredentialsProvider

  - name: versions
    help: ğŸ’¯ List versions for a connector plugin from confluent hub https://www.confluent.io/hub/
    flags:
    - *connector-plugin
    - &force_refresh
      long: --force-refresh
      required: false
      help: |-
        â˜¢ï¸ Force refresh.
    - long: --last
      arg: last
      required: false
      validate: integer
      conflicts: [--all]
      help: |-
        ğŸ†• Number of last versions to show
    examples: |
      playground connector-plugin versions --connector-plugin confluentinc/kafka-connect-s3

- name: connector
  expose: always
  group: Connector
  filters:
  - not_mdc_environment
  help: |-
    ğŸ”— Connector commands

  commands:
  - name: status
    help: ğŸ§© Show status of all connectors
    flags:
    - *verbose
    - &connector
      long: --connector
      short: -c
      required: false
      arg: connector
      completions:
        - $(playground get-connector-list)
      help: |-
        ğŸ”— Connector name

        ğŸ“ Tip: If not specified, the command will apply to all connectors

  - name: offsets
    help: |
      ğŸ’ˆ Handle source and sink connectors offsets

        Note: First-class offsets (KIP-875) is only available if CP > 7.6
    commands:
    - name: get
      help: |
        ğŸ¹ Get current offsets for source and sink connectors

        âš ï¸ Available for ccloud source connectors as EA (see https://docs.confluent.io/cloud/current/connectors/offsets.html)
      flags:
      - *verbose
      - *connector
    - name: reset
      help: |
        ğŸ†• Reset offsets for source and sink connectors

        âš ï¸ Available for ccloud connectors as EA (see https://docs.confluent.io/cloud/current/connectors/offsets.html)
      flags:
      - *verbose
      - *connector
    - name: alter
      help: |
        â›ï¸ Alter offsets for source and sink connectors

        âš ï¸ Available for ccloud connectors as EA (see https://docs.confluent.io/cloud/current/connectors/offsets.html)
      flags:
      - *verbose
      - *connector

  - name: plugins
    help: ğŸ¨ Show all connector plugins installed. You can also display transforms, converters and predicates using --all flag
    flags:
    - *verbose
    - long: --all
      required: false
      help: |-
        ğŸŒ• Show also transforms, converters, predicates available

  - name: pause
    help: â¸ï¸  Pause connector
    flags:
    - *verbose
    - *connector

  - name: versions
    help:  |
      ğŸ§ Get current and latest versions available on Confluent Hub for connector(s) used in example

  - name: restart
    help: â™»ï¸  Restart connector
    flags:
    - *verbose
    - *connector

  - name: stop
    help: ğŸ›‘ Stop connector (only available if CP > 7.5 )
    flags:
    - *verbose
    - *connector

  - name: resume
    alias: unpause
    help: â¯ï¸  Resume connector
    flags:
    - *verbose
    - *connector

  - name: delete
    help: ğŸ—‘ï¸  Delete connector
    flags:
    - *verbose
    - *connector

  - name: show-lag
    help: |
      ğŸ¢ Show lag of sink connector

      It will run until all lag becomes 0 (press ctrl-c to exit)
    flags:
    - *verbose
    - *connector
    - long: --interval
      arg: interval
      validate: integer
      required: false
      default: "20"
      help: |-
        Interval between lag checks (default is 20 seconds).

  - name: show-config
    help:  |
      ğŸ§° Show current connector config that was applied
      
      use --force-rest-endpoint to get results with REST API /config endpoint (https://docs.confluent.io/platform/current/connect/references/restapi.html#get--connectors-(string-name)-config)
    flags:
    - *verbose
    - *connector
    - &noclipboard
      long: --no-clipboard
      required: false
      private: true
      help: |-
        do not copy to clipboard (internal)
    - long: --force-rest-endpoint
      required: false
      help: |-
        â˜¢ï¸ Force using REST API /config endpoint (https://docs.confluent.io/platform/current/connect/references/restapi.html#get--connectors-(string-name)-config)

  - name: show-config-parameters
    help: ğŸ”© Show all possible configuration parameters of connector
    flags:
    - *verbose
    - *connector
    - long: --open
      short: -o
      help: |- 
        ğŸ”– Save output to a file and open with text editor set with playground config editor <editor> (default is code)
    - *force_refresh
    -  &only_show_file_path
      long: --only-show-file-path
      required: false
      private: true
      help: |-
        ğŸ“‚ Only show the path of the file containing the configuration parameters
    - &only_show_json
      long: --only-show-json
      required: false
      help: |-
        ğŸ“— Only show list of all available parameters for connector (with default value when applicable)
    -  &only_show_json_file_path
      long: --only-show-json-file-path
      required: false
      private: true
      help: |-
        ğŸ“‚ Only show the path of the json file containing the configuration parameters

  - name: select-config
    help: |-
      ğŸ—œï¸ Easily select config from all possible configuration parameters of connector

      ğŸ“ Tip: use <tab> to select multiple config at once !
    dependencies:
      fzf: visit https://github.com/junegunn/fzf#installation to install
    flags:
    - *connector

  - name: snippets
    help: ğŸ”Œ useful snippets
    flags:
    - long: --converter
      required: false
      arg: converter
      allowed: 
        - avro
        - protobuf
        - json-schema
        - json
        - json-schema-enabled
        - string
        - bytearray
      help: |-
        ğŸ”Œ Converter
    - long: --dlq
      required: false
      help: |- 
        ğŸ’€ dlq
    examples: |
      playground connector snippets --converter avro --dlq

  - name: open-docs
    help: |-
      ğŸ§‘â€ğŸ“ Open connector documentation of currently running conector(s)
    flags:
    - long: --only-show-url
      help: |-
        ğŸŒ Only show url

  - name: log-level
    help: |-
      ğŸ§¬ Set connect log level

      ğŸ“ Tip: it will also set io.confluent.kafka.schemaregistry.client.rest.RestService (to see schema registry rest requests) and org.apache.kafka.connect.runtime.TransformationChain (to see records before and after SMTs)
              it will also set org.apache.kafka.connect.runtime.WorkerSinkTask for sink and org.apache.kafka.connect.runtime.WorkerSourceTask for source connectors.
    flags:
    - *connector
    - *level

  - name: logs
    group: Connect
    help: |-
      ğŸ•µï¸  Tail and follow connect logs

      This is basically a shortcut for "playground container logs --container connect"

      It does not work for Fully Managed connectors, except if you're a Confluent employee, this will open log in our internal tools (make sure to follow this first https://github.com/confluentinc/kafka-docker-playground-internal#how-to-use)

    flags:
    - *logsopen
    - *logswaitforlog
    - *logsmaxwait
    - long: --lcc-id
      required: false
      arg: lcc-id
      help: |-
        â˜ï¸ Fully Managed lcc id (only for Confluent employees)

  - name: open-in-confluent-cloud
    group: Connect
    help: |-
      ğŸ¤– Open Fully Managed connector in Confluent Cloud dashboard
    flags:
    - *connector

  - name: create-or-update
    help: ğŸ§‘â€ğŸ¨  Create or update connector
    args:
    - name: json
      
      # Set the default path value to -, which is the standard operator for stdin.
      default: "-"
      help: json (reads from stdin if empty)

    flags:
    - *verbose
    - *noclipboard
    - long: --connector
      short: -c
      required: true
      arg: connector
      completions:
        - $(playground get-connector-list)
      help: |-
        ğŸ”— Connector name
    - long: --level
      short: -l
      arg: level
      allowed: [INFO, WARN, DEBUG, TRACE]
      required: false
      help: |-
        â•Log level

        âš ï¸ Not available for ccloud connectors
    - *package
    - long: --wait-for-zero-lag
      help: |- 
        ğŸ˜´ Wait until lag becomes 0
    - long: --validate
      required: false
      help: |-
        âœ… Validate config using PUT /connector-plugins/(string:name)/config/validate (https://docs.confluent.io/platform/current/connect/references/restapi.html#put--connector-plugins-(string-name)-config-validate)
    - long: --skip-automatic-connector-config
      required: false
      help: |-
        ğŸ¤– If example is run (playground run) with --environment flag, automatic configuration to adapt to the environment is added. 
        
        This flag allows to skip this automatic configuration (only useful to reproduce issues)

    examples: |
      playground connector create-or-update -c filestream-sink << EOF
      {
          "tasks.max": "1",
          "connector.class": "org.apache.kafka.connect.file.FileStreamSinkConnector",
          "topics": "filestream",
          "file": "/tmp/output.json",
          "key.converter": "org.apache.kafka.connect.storage.StringConverter",
          "value.converter": "org.apache.kafka.connect.json.JsonConverter",
          "value.converter.schemas.enable": "false"
      }
      EOF

  - name: update
    help: ğŸ› ï¸ Update connector configuration by opening current connector config in text editor set with playground config editor <editor> (default is code). Once file is saved, the new configuration is updated.
    flags:
    - *connector
    examples: |
      playground connector update -c filestream-sink

  examples:
  - playground connector status
  - playground connector status --json
  - playground connector resume --connector <connector-name>
  - playground connector pause -c <connector-name>
  - playground connector delete -c <connector-name>
