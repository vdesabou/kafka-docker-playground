name: playground
version: 1.0.0
dependencies:
  docker: visit $(blue_underlined https://docs.docker.com/get-docker) to install
help: |-
  ğŸ§  CLI for Kafka Docker Playground ğŸ³

  ğŸ‘‰ Check documentation https://kafka-docker-playground.io/#/cli
filters:
- docker_running
commands:

- name: help
  help: Show help about a command
  args:
  - name: command
    help: ğŸ†˜ Help command

### private commands for completion
- name: get-connector-list
  help: Return some completion for connector list
  private: true

- name: get-ccloud-connector-list
  help: Return some completion for ccloud connector list
  private: true
  dependencies:
    confluent: visit $(blue_underlined https://docs.confluent.io/confluent-cli/current/overview.html) to install

- name: get-kafka-region-list
  help: Return some completion for confluent cloud kafka cluster region list
  private: true
  dependencies:
    confluent: visit $(blue_underlined https://docs.confluent.io/confluent-cli/current/overview.html) to install

- name: get-topic-list
  help: Return some completion for topic list
  private: true
  flags:
  - long: --skip-connect-internal-topics
    required: false

- name: get-subject-list
  help: Return some completion for subject list
  private: true
  flags:
  - long: --deleted
    required: false
    help: |-
      ğŸ§Ÿ Include soft deleted schemas

- name: get-examples-list-with-fzf
  help: Return some completion for examples list
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur
  flags:
  - long: --without-repro
    required: false
  - long: --sink-only
    required: false
  - long: --ccloud-only
    required: false

- name: get-zip-or-jar-with-fzf
  help: Return some completion for zip or jar list
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur
  flags:
  - long: --type
    required: false
    arg: type
    allowed: [zip, jar]

- name: get-any-file-with-fzf
  help: Return some completion for any files
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur

- name: get-playground-repro-export-with-fzf
  help: Return some completion for export tgz files
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur

- name: get-predefined-schemas
  help: Return some completion for predefined schemas
  private: true
  args:
  - name: cur
    required: false
    help: correspond to completion $cur

- name: bashly-reload
  private: true
  dependencies:
    bashly: visit $(blue_underlined https://bashly.dannyb.co/installation/) to install

- name: run
  group: Run
  catch_all:
    label: arguments
    help: |-
      Arguments to use by example script

      Most of examples support to get required options either by using arguments or environment variables.
      
      Example with Zendesk:

      playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME> <ZENDESK_PASSWORD>
    required: false
  dependencies:
    fzf: visit $(blue_underlined https://github.com/junegunn/fzf#installation) to install
  help: |-
    ğŸ•¹ï¸ Run any example, except for Confluent Cloud (in this case use run-ccloud command)

  flags:
  - long: --file
    short: -f
    required: true
    validate: file_exists_with_trick
    arg: file
    completions:
      - $(playground get-examples-list-with-fzf "$cur")
    help: |-
      ğŸ”– Example file to run

      â• It must be absolute full path

      ğŸ“ Tip: use <tab> completion to trigger fzf completion
  - long: --open
    short: -o
    help: ğŸ“– Opening example file with text editor set with config.ini (default is code)
  - &tag
    long: --tag
    arg: tag
    required: false
    validate: minimal_cp_version
    help: |-
      ğŸ¯ Confluent Platform (CP) version to use

      Must be greater or equal to 5.0.0
  - &connector-tag
    long: --connector-tag
    arg: connector_tag
    required: false
    help: |- 
      ğŸ”— Connector version to use

      By default, for each connector, the latest available version on Confluent Hub is used
    conflicts: [--connector-zip]
  - &connector-zip
    long: --connector-zip
    arg: connector_zip
    required: false
    validate: file_exists_with_trick
    completions:
      - $(playground get-zip-or-jar-with-fzf --type zip "$cur")
    conflicts: [--connector-tag]
    help: |- 
      ğŸ¤ Connector zip to use

      â• It must be absolute full path

      ğŸ“ Tip: use <tab> completion to trigger fzf completion 
              use folder_zip_or_jar (default: ~/Downloads) in config.ini file to configure where to search the files (current folder is always used)

  - &connector-jar
    long: --connector-jar
    arg: connector_jar
    required: false
    validate: file_exists_with_trick
    completions:
      - $(playground get-zip-or-jar-with-fzf --type jar "$cur")
    help: |-
      â™¨ï¸ Connector jar to use

      â• It must be absolute full path

      ğŸ“ Tip: use <tab> completion to trigger fzf completion 
              use folder_zip_or_jar (default: ~/Downloads) in config.ini file to configure where to search the files (current folder is always used)

  - &enable-ksqldb
    long: --enable-ksqldb
    required: false
    help: |-
      ğŸš€ Enable ksqlDB

      By default, ksqldb-server and ksqldb-cli containers are not started for every test
  - &enable-control-center
    long: --enable-control-center
    required: false
    help: |-
      ğŸ’  Enable Control Center

      By default, control-center container is not started for every test

      Control Center is reachable at http://127.0.0.1:9021
  - &enable-conduktor
    long: --enable-conduktor
    required: false
    help: |- 
      ğŸº Enable Conduktor Platform

      By default, Conduktor Platform container is not started for every test

      Conduktor is reachable at http://127.0.0.1:8080/console (admin/admin)
  - &enable-multiple-brokers
    long: --enable-multiple-brokers
    required: false
    help: |- 
      3ï¸âƒ£ Enable multiple brokers

      By default, there is only one broker node enabled
  - &enable-multiple-connect-workers
    long: --enable-multiple-connect-workers
    required: false
    help: |-
      ğŸ¥‰ Enable multiple connect node

      By default, there is only one connect node enabled

      It only works when plaintext environment is used
  - &enable-jmx-grafana
    long: --enable-jmx-grafana
    required: false
    help: |-
      Enable Grafana, Prometheus and Pyroscope

      ğŸ“Š Grafana is reachable at http://127.0.0.1:3000

      ğŸ›¡ï¸ Prometheus is reachable at http://127.0.0.1:9090
      
      ğŸ“› Pyroscope is reachable at http://127.0.0.1:4040
  - &enable-kcat
    long: --enable-kcat
    required: false
    help: |-
      ğŸˆâ€â¬› Enable kcat

      You can use it with:

      $ docker exec kcat kcat -b broker:9092 -L
  - &enable-sr-maven-plugin-app
    long: --enable-sr-maven-plugin-app
    required: false
    help: |- 
      ğŸ”° Enable Schema Registry Maven plugin App
  - &enable-sql-datagen
    long: --enable-sql-datagen
    required: false
    help: |-
      ğŸŒªï¸ Enable SQL Datagen injection

      This only works for Oracle, MySql, Postgres and Microsoft Sql Server source connector examples with JDBC and Debezium
  examples:
  - playground run -f zendesk-source<tab> --tag 7.2.1 --enable-control-center <ZENDESK_URL> <ZENDESK_USERNAME> <ZENDESK_PASSWORD>
  - playground run -f jdbc<tab> --connector-tag 10.6.0 --enable-jmx-grafana --open

- name: re-run
  group: Run
  help: |-
    âš¡ Simply re-run last example you ran with <playground run> or <playground run-ccloud>
  catch_all:
    label: arguments
    help: |-
      Arguments to use by example script

      Most of examples support to get required options either by using arguments or environment variables.
      
      Example with Zendesk:

      playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME> <ZENDESK_PASSWORD>
    required: false
  dependencies:
    fzf: visit $(blue_underlined https://github.com/junegunn/fzf#installation) to install
  flags:
    - long: --clear
      required: false
      help: |- 
        ğŸ§¼ Clear any previous flags
    - *tag
    - *connector-tag
    - *connector-zip
    - *connector-jar
    - *enable-ksqldb
    - *enable-control-center
    - *enable-conduktor
    - *enable-multiple-brokers
    - *enable-multiple-connect-workers
    - *enable-jmx-grafana
    - *enable-kcat
    - *enable-sr-maven-plugin-app
    - *enable-sql-datagen
  examples:
  - playground re-run
  - playground re-run --tag=6.2.1

- name: run-ccloud
  group: Run
  catch_all:
    label: arguments
    help: |-
      Arguments to use by example script

      Most of examples support to get required options either by using arguments or environment variables.
      
      Example with Zendesk:

      playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME> <ZENDESK_PASSWORD>
    required: false
  dependencies:
    fzf: visit $(blue_underlined https://github.com/junegunn/fzf#installation) to install
    confluent: visit $(blue_underlined https://docs.confluent.io/confluent-cli/current/overview.html) to install
  help: |-
    â›… Run any Confluent Cloud (ccloud) example

    All you have to do is to be already logged in with confluent CLI.

    By default, a new Confluent Cloud environment with a Cluster will be created.

    You can configure the new cluster by setting:

    --cluster-cloud (or CLUSTER_CLOUD environment variable)
    --cluster-region (or CLUSTER_REGION environment variable)
    --cluster-environment (or ENVIRONMENT environment variable)

    In case you want to use your own existing cluster, you need to setup, in addition to previous ones:

    --cluster-name (or CLUSTER_NAME environment variable)
    --cluster-creds (or CLUSTER_CREDS environment variable)
    --cluster-schema-registry-creds (or SCHEMA_REGISTRY_CREDS environment variable)
    
  flags:
    - long: --file
      short: -f
      required: true
      validate: file_exists_with_trick
      arg: file
      completions:
        - $(playground get-examples-list-with-fzf --ccloud-only "$cur")
      help: |-
        ğŸ”– Example file to run

        â• It must be absolute full path

        ğŸ“ Tip: use <tab> completion to trigger fzf completion
    - long: --open
      short: -o
      help: ğŸ“– Opening example file with text editor set with config.ini (default is code)
    - *tag
    - *connector-tag
    - *connector-zip
    - *connector-jar
    - *enable-control-center
    - *enable-conduktor
    - *enable-kcat
    - &cluster-cloud
      long: --cluster-cloud
      required: false
      arg: cluster-cloud
      allowed: [aws, gcp, azure]
      help: |-
        ğŸŒ¤ The cloud provider: aws, gcp or azure. Default is aws

        ğŸ“ Tip: you can also use CLUSTER_CLOUD environment variable
    - &cluster-region
      long: --cluster-region
      required: false
      arg: cluster-region
      completions:
        - $(playground get-kafka-region-list)
      help: |-
        ğŸ—º The Cloud region. 
        
        ğŸ“ Tip: you can also use CLUSTER_REGION environment variable
    - &cluster-environment
      long: --cluster-environment
      required: false
      arg: cluster-environment
      validate: not_empty
      help: |-
        ğŸŒ The environment id where want your new cluster (example: env-xxxxx)

        â„¹ï¸ Optional, if not set, new environment will be created

        ğŸ“ Tip: you can also use ENVIRONMENT environment variable
    - &cluster-name
      long: --cluster-name
      required: false
      validate: not_empty
      arg: cluster-name
      help: |-
        ğŸ° The cluster name. 
        
        â£ï¸ Only required if you want to use your own existing cluster

        ğŸ“ Tip: you can also use CLUSTER_NAME environment variable
    - &cluster-creds
      long: --cluster-creds
      required: false
      validate: not_empty
      arg: cluster-creds
      help: |-
        ğŸ”’ The Kafka api key and secret to use, it should be separated with semi-colon (example: <API_KEY>:<API_KEY_SECRET>)

        â£ï¸ Only required if you want to use your own existing cluster

        ğŸ“ Tip: you can also use CLUSTER_CREDS environment variable
    - &cluster-schema-registry-creds
      long: --cluster-schema-registry-creds
      required: false
      validate: not_empty
      arg: cluster-schema-registry-creds
      help: |-
        ğŸ”’ The Schema Registry api key and secret to use, it should be separated with semi-colon (example: <SR_API_KEY>:<SR_API_KEY_SECRET>)

        â„¹ï¸ Optional, if not set, new credentials will be created

        â£ï¸ Only required if you want to use your own existing cluster
        
        ğŸ“ Tip: you can also use SCHEMA_REGISTRY_CREDS environment variable
  examples:
  - playground run-ccloud mqtt<tab> --cluster-cloud aws --cluster-region eu-west-3 --enable-control-center --connector-tag 1.2.3

- name: open
  group: Run
  dependencies:
    fzf: visit $(blue_underlined https://github.com/junegunn/fzf#installation) to install
  help: |-
    ğŸ‘ When --file is not provided, simply open last example you ran with <playground run> or <playground run-ccloud>

    Otherwise, open any file from the playground using --file.
  flags:
  - long: --file
    short: -f
    required: false
    validate: file_exists_with_trick
    arg: file
    completions:
      - $(playground get-any-file-with-fzf "$cur")
    help: |-
      ğŸ” Search any file and open it.
      
      â• It must be absolute full path

      ğŸ“ Tip: use <tab> completion to trigger fzf completion

- name: stop
  group: Run
  help: |-
    ğŸ›‘ Stop currently running example

- name: open-docs
  group: Run
  help: |-
    ğŸ§‘â€ğŸ“ Open Confluent documentation of currently running example
  flags:
  - long: --only-show-url
    help: |-
      ğŸŒ Only show url

- name: repro
  expose: true
  group: Repro
  help: |-
    ğŸ‘·â€â™‚ï¸ Reproduction model commands
  environment_variables:
  - name: OUTPUT_FOLDER 
    help: ğŸ“ Output folder where to generate bootstrapped files
    default: reproduction-models
  dependencies:
    fzf: visit $(blue_underlined https://github.com/junegunn/fzf#installation) to install
  commands:

  - name: export
    help: |-
      ğŸ“¤ Export as tgz file uncommitted reproduction models from the folder of current reproduction model
    dependencies:
      git: visit $(blue_underlined https://git-scm.com/downloads) to install
    flags:
      - long: --all
        required: false
        help: |-
          Export all uncommitted reproduction models

  - name: import
    help: |-
      ğŸ“¥ Import tgz file which was created with export command
    flags:
    - long: --file
      short: -f
      arg: file
      required: false
      validate: file_exists_with_trick
      completions:
        - $(playground get-playground-repro-export-with-fzf "$cur")
      help: |- 
        ğŸ¤ playground_repro_export.tgz file

        â• It must be absolute full path

        ğŸ“ Tip: use <tab> completion to trigger fzf completion 
                use folder_zip_or_jar (default: ~/Downloads) in config.ini file to configure where to search the files (current folder is always used)

  - name: bootstrap
    help: |-
      ğŸ›   Bootstrap reproduction model
      
      ğŸ‘‰ Check documentation https://kafka-docker-playground.io/#/reusables?id=%f0%9f%9b%a0-bootstrap-reproduction-model
    catch_all:
      label: arguments
      help: |-
        Arguments to use by example script

        Most of examples support to get required options either by using arguments or environment variables.
        
        Example with Zendesk:

        playground run -f zendesk-source<tab> <ZENDESK_URL> <ZENDESK_USERNAME> <ZENDESK_PASSWORD>
      required: false
    flags:
    - *tag
    - *connector-tag
    - *connector-zip
    - *connector-jar
    - *enable-ksqldb
    - *enable-control-center
    - *enable-conduktor
    - *enable-multiple-brokers
    - *enable-multiple-connect-workers
    - *enable-jmx-grafana
    - *enable-kcat
    - *enable-sr-maven-plugin-app
    - *enable-sql-datagen
    - *cluster-region
    - *cluster-environment
    - *cluster-name
    - *cluster-creds
    - *cluster-schema-registry-creds

    - long: --file
      short: -f
      required: true
      validate: file_exists_with_trick
      arg: file
      completions:
        - $(playground get-examples-list-with-fzf --without-repro "$cur")
      help: |-
        ğŸ”– Example file to use as basis
        
        â• It must be absolute full path

        ğŸ“ Tip: use <tab> completion to trigger fzf completion

    - long: --description
      short: -d
      required: true
      validate: not_empty
      arg: description
      help: |-
        ğŸ’­ Description for the reproduction model

    - long: --producer
      short: -p
      arg: producer-type
      conflicts: [--pipeline]
      default: "none"
      allowed: 
        - none
        - avro
        - avro-with-key
        - protobuf
        - protobuf-with-key
        - json-schema
        - json-schema-with-key
      help: |-
        â™¨ï¸ Java producer type to use
        
        One of avro, avro-with-key, protobuf, protobuf-with-key, json-schema, json-schema-with-key

        ğŸ“ Tip: Most of times, it's much simpler to use 'playground topic produce'. Use java producer only if you have very specific requirements such as specifying record timestamp, use key with schema or to do perf testing

        ğŸ“ Tip: 'with-key' will also produce key with selected converter, otherwise LongConverter is used

    - long: --nb-producers
      short: -n
      arg: nb-producers
      validate: integer
      default: ""
      help: |-
        2ï¸âƒ£ Number of java producers to generate

    - long: --producer-schema-key
      required: false
      help: |-
        ğŸ”° Schema to use for the key

        âœ¨ Copy and paste the schema you want to use for the key, save and close the file to continue

    - long: --producer-schema-value
      required: false
      help: |-
        ğŸ”° Schema to use for the value

        âœ¨ Copy and paste the schema you want to use for the key, save and close the file to continue

    - long: --custom-smt
      help: |-
        âš™ï¸ Add a custom SMT (which is a no-op)

    - long: --pipeline
      required: false
      validate: file_exists_with_trick
      arg: sink_file
      conflicts: [--producer]
      completions:
        - $(playground get-examples-list-with-fzf --without-repro --sink-only "$cur")
      help: |-
        ğŸ”– Sink example file to use for creating a pipeline
        
        â• It must be absolute full path. 

        ğŸ“ Tip: use <tab> completion to trigger fzf completion

    examples:
    - playground repro bootstrap -f hdfs2<tab> -d "simple test"
    - playground repro bootstrap -f /full/path/hdfs2-sink.sh -d "testing with avro producer" --producer avro --producer-schema-value myschema<tab>
    - playground repro bootstrap -f hdfs2<tab> -d "testing with 2 protobuf producers" --producer protobuf --nb-producers 2
    - playground repro bootstrap -f hdfs2<tab> -d "testing custom smt" --custom-smt
    - playground repro bootstrap -f debeziumpostgres<tab> -d "create pipeline" --pipeline jdbcsink<tab>

- name: get-docker-compose
  group: Kafka
  help: |-
    ğŸ‹ Get docker-compose

- name: get-properties
  group: Kafka
  help: |-
    ğŸ“ Get properties file from a container
    
    ğŸ‘‰ Check documentation https://kafka-docker-playground.io/#/how-to-use?id=%f0%9f%93%9d-see-properties-file

  flags:
  - &container
    long: --container
    short: -c
    required: false
    default: "connect"
    arg: container
    completions:
      - $(docker ps --format '{{.Names}}')
    help: |-
      ğŸ³ Container name

  examples:
  - playground get-properties
  - playground get-properties --container broker
  - playground get-properties -c broker

- name: schema
  expose: true
  group: Schema
  help: |-
     ğŸ”° Schema commands
  commands:

  - name: get
    group: Schema
    filters:
    - not_mdc_environment
    - schema_registry_running
    help: |-
      ğŸ”° Get all schemas versions for specified subject (if --subject is not specified, all subjects will be used)
    flags:
      - &subject
        long: --subject
        required: false
        arg: subject
        completions:
          - $(playground get-subject-list)
        help: |-
          ğŸ“› Subject name

      - long: --deleted
        required: false
        help: |-
          ğŸ§Ÿ Include soft deleted subjects
    examples:
    - playground schema get
    - playground schema get --subject <SUBJECT>
    - playground schema get --deleted

  - name: register
    group: Schema
    filters:
    - not_mdc_environment
    - schema_registry_running
    help: |-
      âºï¸ Register a schema in specified subject
    flags:
      - &subject_required
        long: --subject
        required: true
        arg: subject
        completions:
          - $(playground get-subject-list)
        help: |-
          ğŸ“› Subject name
      - &verbose
        long: --verbose
        short: -v
        help: ğŸ Show command being ran.
      - long: --input
        arg: input
        completions:
          - $(playground get-predefined-schemas "$cur")
        default: "-"
        required: false
        help: |- 
          ğŸ”¥ You can either:
          
          * Set your own schema (avro, json-schema, protobuf) with stdin (see example section). 

          * Use completion to select predefined schemas (or use your own schema file) ğŸ“ Tip: use <tab> completion to trigger fzf completion

      - long: --replace
        required: false
        help: ğŸ’ª Force replace existing schema

    examples: |
      playground schema register --subject test-protobuf << 'EOF'
      syntax = "proto3";
      
      package com.github.vdesabou;
      
      message Customer {
          int64 count = 1;
          string first_name = 2;
          string last_name = 3;
          string address = 4;
      }
      EOF

      playground schema register --subject test-avro << 'EOF'
      {
          "type": "record",
          "namespace": "com.github.vdesabou",
          "name": "Customer",
          "fields": [
              {
                  "name": "count",
                  "type": "long",
                  "doc": "count"
              },
              {
                  "name": "first_name",
                  "type": "string",
                  "doc": "First Name of Customer"
              },
              {
                  "name": "last_name",
                  "type": "string",
                  "doc": "Last Name of Customer"
              },
              {
                  "name": "address",
                  "type": "string",
                  "doc": "Address of Customer"
              }
          ]
      }
      EOF

  - name: delete
    group: Schema
    help: |-
      ğŸ§Ÿ Delete schema
    flags:
    - &subject_not_required
      long: --subject
      required: false
      arg: subject
      completions:
        - $(playground get-subject-list)
      help: |-
        ğŸ“› Subject name to delete:
          
          if --version is provided, only that version will be deleted. Otherwise the complete subject will be deleted
    - long: --version
      required: false
      validate: integer
      arg: version
      help: |-
        ğŸ”¢ Schema version of the provided subject to delete

        Can only be used when --subject is provided
    - long: --permanent
      required: false
      help: |-
        ğŸ’€ Hard delete (default is soft delete)
        
- name: debug
  expose: true
  group: Debug
  help: |-
    ğŸ Debug commands
  commands:

  - name: install-vscode-extension
    help: |-
      ğŸª„ Install a slightly modified version of "Shell Script Command Completion" Visual Studio Code extension (https://marketplace.visualstudio.com/items?itemName=tetradresearch.vscode-h2o)

      After installation, install "playground" command:

      * Go on a .sh file

      * Type Ctrl+Shift+P (or âŒ˜+â‡§+P on macOS) and choose "Shell Completion: Load Command Spec (experimental)"" and then type "playground"
      
      ğŸ‘‰ Check documentation https://kafka-docker-playground.io/#/cli?id=%f0%9f%aa%84-setup-shell-script-command-completion-visual-studio-code-extension
    examples:
    - playground install-vscode-extension
    dependencies:
      code: visit $(blue_underlined https://code.visualstudio.com/docs/setup/mac#_launching-from-the-command-line) to install

  - name: enable-remote-debugging
    help: |-
      âœ¨ Enable java remote debugging for container
      
      ğŸ‘‰ Check documentation https://kafka-docker-playground.io/#/reusables?id=%e2%9c%a8-remote-debugging
    flags:
      - *container
    examples:
    - playground debug enable-remote-debugging
    - playground debug enable-remote-debugging --container broker
    - playground debug enable-remote-debugging -c broker

  - name: testssl
    help: |-
      ğŸ” Testing TLS/SSL encryption using https://testssl.sh/

      testssl <URI>, where <URI> is:

      host|host:port|URL|URL:port   port 443 is default, URL can only contain HTTPS protocol
    args:
    - name: arguments
      help: arguments to pass to testssl, see https://testssl.sh for all options
      required: false
    examples:
    - playground debug testssl https://google.com
    - playground debug testssl pkc-xxxx.us-west-2.aws.confluent.cloud:9092

  - name: generate-diagnostics
    help: |-
      â›‘ï¸ Generate a diagnostic bundle with Diagnostics Bundle Tool

      âš ï¸ only connect and broker containers are supported for now

      see https://docs.confluent.io/platform/current/tools/diagnostics-tool.html#collect-diagnostics
    flags:
      - *container
    examples:
    - playground debug generate-diagnostics
    - playground debug generate-diagnostics --container broker

  - name: thread-dump
    help: |-
      ğŸ¯ Take a java thread dump

      ğŸ”– It will save output to a file and open with text editor set with config.ini (default is code)
    flags:
      - *container
    examples:
    - playground debug thread-dump
    - playground debug thread-dump --container broker

  - name: heap-dump
    help: |-
      ğŸ‘» Take a heap dump

      ğŸ”– It will save output to a .hprof file. VisualVM (https://visualvm.github.io/) or MAT (https://www.eclipse.org/mat/) can be used to read the file.
    flags:
      - *container
    examples:
    - playground debug heap-dump
    - playground debug heap-dump --container broker

  - name: tcp-dump
    help: |-
      ğŸ•µï¸â€â™‚ï¸ Take a tcp dump (sniffing network)
    flags:
      - *container
      - long: --port
        arg: port
        validate: integer
        required: false
        help: |-
          Port on which tcp dump should be done, if not set sniffing is done on every port
      - long: --duration
        arg: duration
        validate: integer
        required: false
        default: "30"
        help: |-
          Duration of the dump (default is 30 seconds).
    examples:
    - playground debug tcp-dump --container control-center --port 9021 --duration 60

  - name: block-traffic
    help: |-
      ğŸš« Blocking traffic using iptables
    flags:
      - *container
      - long: --destination
        arg: destination
        required: true
        help: |-
          Destination: it could be an ip address, a container name or a hostname
      - long: --port
        arg: port
        validate: integer
        required: false
        help: |-
          Port on which tcp traffic should be blocked
      - &action
        long: --action
        allowed: [start, stop]
        arg: action
        required: true
        help: |-
          ğŸŸ¢ start or stop
    examples:
    - playground debug block-traffic --destination google.com --action start
    - playground debug block-traffic --container broker --destination zookeeper --action start

  - name: flight-recorder
    help: |-
      ğŸ›©ï¸ Record flight recorder

      Read more about it at https://www.baeldung.com/java-flight-recorder-monitoring

      Open the jfr file with JDK Mission Control JMC(https://jdk.java.net/jmc/)
    flags:
      - *container
      - *action
    examples:
    - playground debug flight-recorder --action start
    - playground debug flight-recorder --action stop

  - name: log-level
    help: |-
      ğŸ§¬ Set log level for any package
    filters:
    - connect_running
    commands:
    - name: get
      help: Get log levels
      flags:
      - &package
        long: --package
        short: -p
        required: false
        validate: not_empty
        arg: package
        help: |-
          Package name

    - name: set
      help: Set log level for specific logger
      flags:
      - long: --package
        short: -p
        required: true
        validate: not_empty
        arg: package
        help: |-
          ğŸ“¦ Package name

      - &level
        long: --level
        short: -l
        arg: level
        allowed: [INFO, WARN, DEBUG, TRACE]
        required: true
        help: |-
          â•Log level

    examples:
    - playground debug log-level get
    - playground debug log-level get -p io.confluent.connect.oracle.cdc
    - playground debug log-level get --package io.confluent.connect.oracle.cdc
    - playground debug log-level set -p io.confluent.connect.oracle.cdc.logging.LogUtils -l TRACE

- name: get-jmx-metrics
  group: Kafka
  help: |-
    ğŸ”¢ Get JMX metrics from a component
    
    ğŸ‘‰ Check documentation https://kafka-docker-playground.io/#/how-to-use?id=%f0%9f%94%a2-jmx-metrics
  dependencies:
    java: visit $(blue_underlined https://openjdk.org/install/) to install
  flags:
  - long: --component
    short: -c
    default: "connect"
    required: false
    arg: component
    allowed: [zookeeper, broker, connect, schema-registry]
    help: |-
      Component name
  - long: --open
    short: -o
    help: |- 
      ğŸ”– Save output to a file and open with text editor set with config.ini (default is code)

  - long: --domain
    short: -d
    required: false
    arg: domain
    help: |-
      Domain name

  examples:
  - playground get-jmx-metrics --component connect
  - playground get-jmx-metrics --component connect --domain "kafka.connect kafka.consumer kafka.producer"
  - playground get-jmx-metrics -c broker

- name: container
  expose: true
  group: Container
  help: |-
    ğŸ³ Container commands
  commands:

    - name: recreate
      group: Container
      help: |-
        ğŸ’« Recreate container(s)
        
        ğŸ‘‰ Check documentation https://kafka-docker-playground.io/#/how-to-use?id=%e2%99%bb%ef%b8%8f-re-create-containers

    - name: get-ip-addresses
      group: Container
      help: |-
        ğŸ–¥ï¸  Get ip address of running containers
      examples:
      - playground get-ip-address-container

    - name: kill-all
      group: Container
      help: |-
        ğŸ’€ Kill all containers

    - name: logs
      group: Container
      help: |-
        ğŸ•µï¸  Tail and follow container logs

      flags:
      - *container
      - long: --open
        short: -o
        help: |- 
          ğŸ”– Save output to a file and open with text editor set with config.ini (default is code)
        conflicts: [--wait-for-log]
      - long: --wait-for-log
        short: -w
        arg: log
        validate: not_empty
        help: |- 
          ğŸ˜´ Wait until log appears
        conflicts: [--open]
      - long: --max-wait
        short: -m
        arg: max_wait
        validate: integer
        default: "600"
        help: |- 
          â³ Max time in seconds to wait when using --wait-for-log (default 600s)
        conflicts: [--open]

      examples:
      - playground container logs --container connect
      - playground container logs -c connect --open
      - playground container logs -c connect --wait-for-log "StackOverflowError"

    - name: ssh
      group: Container
      help: |-
        ğŸ›¬ SSH into container

      flags:
      - *container

      - long: --shell
        short: -s
        required: false
        default: "bash"
        arg: shell
        allowed: 
          - bash
          - sh
          - ksh
          - zsh
        help: |-
          ğŸ’¾ Shell to use (default is bash)

      examples:
      - playground ssh -c connect
      - playground ssh -c connect -s sh
      - playground ssh --container connect --shell sh

    - name: exec
      group: Container
      help: |-
        ğŸª„  Execute command in a container

      flags:
      - *container

      - long: --command
        required: true
        validate: not_empty
        arg: command
        help: |-
          ğŸ“² Command to execute

      - long: --root
        help: |-
          ğŸ‘‘ Run command as root

      - long: --shell
        default: "bash"
        arg: shell
        allowed: 
          - bash
          - sh
          - ksh
          - zsh
        help: |-
          ğŸ’¾ Shell to use (default is bash)

      examples:
      - playground exec -c connect -d "date"
      - playground exec -c connect -d "whoami" --root
      - playground exec --container connect --command "whoami" --shell sh

    - name: restart
      group: Container
      help: |-
        ğŸ” Restart a container

      flags:
      - *container

    - name: pause
      group: Container
      help: |-
        â¸ï¸  Pause a container

      flags:
      - *container

    - name: resume
      group: Container
      help: |-
        â¯ï¸  Resume a container

      flags:
      - *container

    - name: kill
      group: Container
      help: |-
        ğŸ”« Kill a container

      flags:
      - *container

- name: topic
  expose: true
  group: Topic
  filters:
  - not_mdc_environment
  help: |-
    ğŸ—³ Topic commands
  commands:

    - name: get-number-records
      group: Topic
      help: |-
        ğŸ’¯ Get number of records in a topic
      flags:
      - &topic
        long: --topic
        short: -t
        required: false
        arg: topic
        completions:
          - $(playground get-topic-list)
        help: |-
          ğŸ—³ Topic name
      examples:
      - playground get-number-records --topic a-topic
      - playground get-number-records -t a-topic

    - name: display-consumer-offsets
      group: Topic
      help: |-
        ğŸ“­ Display content of __consumer_offsets topic

    - name: list
      group: Topic
      help: |-
        ğŸ”˜ List topics

    - name: describe
      group: Topic
      help: |-
        ğŸ”¬ Describe topic
      flags:
      - *topic

    - name: set-schema-compatibility
      filters:
      - schema_registry_running
      group: Topic
      help: |-
        ğŸ›¡ï¸ Change topic's schema compatibility
      flags:
      - *topic
      - long: --compatibility
        arg: compatibility
        allowed: 
          - BACKWARD
          - BACKWARD_TRANSITIVE
          - FORWARD
          - FORWARD_TRANSITIVE
          - FULL
          - FULL_TRANSITIVE
          - NONE
        required: true
        help: |-
          Schema Registry compatibility rule
          
    - name: consume
      filters:
      - schema_registry_running
      group: Topic
      help: |-
        ğŸ“¥ Consume topic from beginning
      flags:
      - *verbose
      - *topic
      - long: --max-messages
        arg: max-messages
        validate: integer
        required: false
        default: "10"
        help: |-
          Max number of messages to display (default is 10)
      - long: --min-expected-messages
        arg: min-expected-messages
        validate: integer
        required: false
        default: ""
        help: |-
          Minimum expected number of messages to be present in topic, returns an error if this is not the case

          Note: --topic should be specified in this case.
      - long: --grep
        arg: grep
        required: false
        default: ""
        help: |-
          Verify that topic content contains record which contains specified string
      - long: --timeout
        arg: timeout
        validate: integer
        required: false
        default: "60"
        help: |-
          Max number of seconds to wait when --min-expected-messages is used.

          Default is 60 seconds
      - long: --tail
        required: false
        help: |-
          Tail on logs.
        conflicts: [--min-expected-messages, --max-messages]

      - long: --plot-latencies-timestamp-field
        required: false
        arg: timestamp
        help: |-
          ğŸ—³ Timestamp field name that represents when record was created in source system

      - long: --subject
        required: false
        arg: subject
        completions:
          - $(playground get-subject-list)
        help: |-
          ğŸ“› Subject for value in schema-registry to use (useful when data was produced with --value-subject-name-strategy other than TopicNameStrategy)
          
          Note: --topic should be specified in this case.

      - long: --max-characters
        arg: max-characters
        validate: integer
        required: false
        default: "2500"
        help: |-
          Max characters per message to display (default is 2500)

    - name: produce
      filters:
      - schema_registry_running
      group: Topic
      help: |-
         ğŸ“¤ Produce to a topic
      flags:
      - long: --input
        arg: input
        completions:
          - $(playground get-predefined-schemas "$cur")
        default: "-"
        required: false
        help: |- 
          ğŸ”¥ You can either:
          
          * Set your own schema (avro, json-schema, protobuf) with stdin (see example section). 
          
          * You can also generate json data using json or sql format using syntax from https://github.com/MaterializeInc/datagen

          * Use completion to select predefined schemas (or use your own schema file) ğŸ“ Tip: use <tab> completion to trigger fzf completion

          * Directly set payload ("%g" can be used to generate a counter)

      - *verbose
      - long: --topic
        short: -t
        required: true
        arg: topic
        completions:
          - $(playground get-topic-list)
        help: |-
          ğŸ—³ Topic name
      - long: --nb-messages
        arg: nb-messages
        validate: integer
        required: false
        default: "1"
        help: |-
          ğŸ’¯ Number of messages to produce (default is 1)
      - long: --nb-partitions
        arg: nb-partitions
        validate: integer
        required: false
        default: ""
        help: |-
          ğŸ”¢ Number of partitions for the topic. (default is 1)
          
          âŒ Important: If topic is existing, it will be re-created before producing to topic.
      - &compatibility
        long: --compatibility
        arg: compatibility
        allowed: 
          - BACKWARD
          - BACKWARD_TRANSITIVE
          - FORWARD
          - FORWARD_TRANSITIVE
          - FULL
          - FULL_TRANSITIVE
          - NONE
        help: |-
          Schema Registry compatibility rule

      - &value-subject-name-strategy
        long: --value-subject-name-strategy
        arg: value-subject-name-strategy
        allowed: 
          - TopicNameStrategy
          - RecordNameStrategy
          - TopicRecordNameStrategy
        help: |-
          Value Subject Name Strategy
      - long: --key
        arg: key
        required: false
        help: |-
          ğŸ—ï¸ Key to use. If not set, no key is used.

          If the key contain a number, it will be used as starting point and incremented for each record. 
          
          Example: key1 will start with key1, then key2, etc..
          Example: mykey-10-suffix will start with mykey-10-suffix then mykey-11-suffix, etc..

          "%g" can also be used to generate a counter

          Example: key%g will start with key1, then key2, etc..

          Otherwise, the key will be same for all records.
          
      - long: --headers
        arg: headers
        required: false
        help: |-
          ğŸš Headers to use for all records. If not set, no header is used.

          Example: --headers "header1:value1,header2:value2"

          Note: CP 7.2+ is required.
      - long: --forced-value
        arg: forced-value
        required: false
        help: |-
          â˜¢ï¸ Value to use for all records. 
          
          ğŸ“ Tip: use --generate-only first with avro, json-schema or protobuf to get skeleton of messages and then use --forced-value to send the message you need. 
      - long: --generate-only
        required: false
        help: |-
          ğŸšª Only generate messages without sending to kafka topic.

          Used with --forced-value, this is a powerful way to send specific messages.
      - long: --tombstone
        required: false
        help: |-
          âš°ï¸ Generate tombstone (record with null value). 
          
          --key must be set when this flag is used.

          Note: CP 7.2+ is required.
      - long: --validate
        required: false
        help: |-
          â˜‘ï¸ Validate schema according to connect sink converter used

      - long: --validate-config
        arg: validate-config
        help: |-
          ğŸ”© Converter configuration parameters to use 
          
          See docs: https://docs.confluent.io/platform/current/schema-registry/connect.html#using-kconnect-long-with-sr

          ğŸ“ Tip: you can pass multiple parameters by specifying --validate-config multiple times
        required: false
        repeatable: true
        allowed: 
          - scrub.invalid.names=true
          - enhanced.avro.schema.support=true
          - connect.meta.data=false
          - object.additional.properties=false
          - use.optional.for.nonrequired=true
          - ignore.default.for.nullables=true
          - generalized.sum.type.support=true
          - enhanced.protobuf.schema.support=true
          - generate.index.for.unions=false
          - int.for.enums=true
          - optional.for.nullables=true
          - generate.struct.for.nulls=true
          - wrapper.for.nullables=true
          - wrapper.for.raw.primitives=false

      - long: --producer-property
        arg: producer-property
        help: |-
          ğŸ”© Producer configuration parameters to use 
          
          See docs: https://docs.confluent.io/platform/current/installation/configuration/producer-configs.html#cp-config-producer

          ğŸ“ Tip: you can pass multiple parameters by specifying --producer-property multiple times

          Example: --producer-property "max.request.size=990485760" --producer-property "client.id=myid"
        required: false
        repeatable: true

      - long: --record-size
        arg: record-size
        validate: integer
        required: false
        default: "0"
        help: |-
          ğŸ‹ï¸ Record size in bytes, eg. 1048576 for 1MB

          ğŸ“¢ If size is > 1Mb, --producer-property max.request.size and topic max.message.bytes will be automatically set to support the record size.

      examples: |

        playground topic produce --tombstone --topic a-topic --key mykey

        playground topic produce -t topic-json --nb-messages 10 << 'EOF'
        {
            "_meta": {
                "topic": "",
                "key": "",
                "relationships": []
            },
            "nested": {
                "phone": "faker.phone.imei()",
                "website": "faker.internet.domainName()"
            },
            "id": "iteration.index",
            "name": "faker.internet.userName()",
            "email": "faker.internet.exampleEmail()",
            "phone": "faker.phone.imei()",
            "website": "faker.internet.domainName()",
            "city": "faker.address.city()",
            "company": "faker.company.name()"
        }
        EOF

        playground topic produce -t topic-avro --nb-messages 10 << 'EOF'
        {
            "type": "record",
            "namespace": "com.github.vdesabou",
            "name": "Customer",
            "fields": [
                {
                    "name": "count",
                    "type": "long",
                    "doc": "count"
                },
                {
                    "name": "first_name",
                    "type": "string",
                    "doc": "First Name of Customer"
                },
                {
                    "name": "last_name",
                    "type": "string",
                    "doc": "Last Name of Customer"
                },
                {
                    "name": "address",
                    "type": "string",
                    "doc": "Address of Customer"
                }
            ]
        }
        EOF

        playground topic produce -t topic-json-schema --nb-messages 3 << 'EOF'
        {
          "$schema": "http://json-schema.org/draft-07/schema#",
          "additionalProperties": false,
          "$id": "http://lh.test/Customer.schema.json",
          "title": "Customer",
          "description": "Customer description",
          "type": "object",
          "properties": {
            "name": {
              "description": "Customer name",
              "type": "string",
              "maxLength": 25
            },
            "surname": {
              "description": "Customer surname",
              "type": "string",
              "minLength": 2
            },
            "email": {
              "description": "Email",
              "type": "string",
              "pattern": "^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$"
            }
          },
          "required": [
            "name",
            "surname"
          ]
        }
        EOF


        playground topic produce -t topic-proto --nb-messages 1 << 'EOF'
        syntax = "proto3";

        package com.github.vdesabou;

        message Customer {
            int64 count = 1;
            string first_name = 2;
            string last_name = 3;
            string address = 4;
        }
        EOF

        playground topic produce -t topic-jsql --nb-messages 10 << 'EOF'
        CREATE TABLE "notused"."notused" (
          "id" int PRIMARY KEY,
          "name" varchar COMMENT 'faker.internet.userName()',
          "merchant_id" int NOT NULL COMMENT 'faker.datatype.number()',
          "price" int COMMENT 'faker.datatype.number()',
          "status" int COMMENT 'faker.datatype.boolean()',
          "created_at" datetime DEFAULT (now())
        );
        EOF

        playground topic produce -t topic-json --nb-messages 1 --producer-property "max.request.size=990485760" < bigjson.json

    - name: create
      group: Topic
      help: |-
        ğŸ†• Create topic
      flags:
      - long: --topic
        short: -t
        required: true
        arg: topic
        help: |-
          ğŸ—³ Topic name
      - long: --nb-partitions
        arg: nb-partitions
        validate: integer
        required: false
        default: ""
        help: |-
          Number of partitions for the topic. (default is 1)
      catch_all:
        label: arguments
        help: |-
          Any arguments to be used with kafka-topics --create
        required: false
      examples: |
        playground topic create --topic atopic
        playground topic create --topic atopic --nb-partitions 8 --config retention.ms=30000
        
    - name: delete
      group: Topic
      help: |-
        âŒ Delete topic
      flags:
      - long: --topic
        short: -t
        required: true
        arg: topic
        completions:
          - $(playground get-topic-list)
        help: |-
          ğŸ—³ Topic name

    - name: alter
      group: Topic
      help: |-
        ğŸª› Alter topic config
      flags:
      - long: --topic
        short: -t
        required: true
        arg: topic
        completions:
          - $(playground get-topic-list)
        help: |-
          ğŸ—³ Topic name
      catch_all:
        label: arguments
        help: |-
          Any arguments to be used with kafka-configs --alter. If the topic does not exist, it is created first.
        required: false
      examples: |
        playground topic alter --topic atopic --add-config max.message.bytes=5242940

- name: ccloud-connector
  expose: true
  group: Connector
  filters:
  - ccloud_environment
  dependencies:
    confluent: visit $(blue_underlined https://docs.confluent.io/confluent-cli/current/overview.html) to install
  help: |-
    ğŸ”—â˜ï¸ Fully Managed Connector commands
  environment_variables:
  - name: CLOUD_API_KEY
    help: Cloud API key, see https://docs.confluent.io/cloud/current/access-management/authenticate/api-keys/api-keys.html#cloud-cloud-api-keys
    required: true
  - name: CLOUD_API_SECRET
    help: Cloud API secret, see https://docs.confluent.io/cloud/current/access-management/authenticate/api-keys/api-keys.html#cloud-cloud-api-keys
    required: true

  commands:
  - name: status
    help: ğŸ§© Show status of all connectors
    flags:
    - &ccloudconnector
      long: --connector
      short: -c
      required: false
      arg: connector
      completions:
        - $(playground get-ccloud-connector-list)
      help: |-
        ğŸ”— Connector name

        ğŸ“ Tip: If not specified, the command will apply to all connectors

  - name: plugins
    help: ğŸ¨ Show all plugins installed

  - name: pause
    help: â¸ï¸  Pause connector
    flags:
    - *ccloudconnector

  - name: resume
    help: â¯ï¸  Resume connector
    flags:
    - *ccloudconnector

  - name: delete
    help: ğŸ—‘ï¸  Delete connector
    flags:
    - *ccloudconnector

  - name: show-lag
    help: ğŸ¢ Show lag of sink connector
    flags:
    - *ccloudconnector
    - &waitforzerolag
      long: --wait-for-zero-lag
      help: |- 
        ğŸ˜´ Wait until lag becomes 0

  - name: show-config
    help:  ğŸ§° Show current connector config
    flags:
    - *ccloudconnector

  - name: show-config-parameters
    help: ğŸ”© Show all possible configuration parameters of connector
    flags:
    - *ccloudconnector
    - long: --open
      short: -o
      help: |- 
        ğŸ”– Save output to a file and open with text editor set with config.ini (default is code)
    - long: --force-refresh
      required: false
      help: |-
        â˜¢ï¸ Force refresh.

  - name: create-or-update
    help: ğŸ§‘â€ğŸ¨  Create or update connector
    args:
    - name: json
      
      # Set the default path value to -, which is the standard operator for stdin.
      default: "-"
      help: json (reads from stdin if empty)

    flags:
    - long: --connector
      short: -c
      required: true
      arg: connector
      completions:
        - $(playground get-ccloud-connector-list)
      help: |-
        ğŸ”— Connector name

    examples: |
      playground ccloud-connector create-or-update --connector HttpSink << EOF
      {
          "connector.class": "HttpSink",
          "name": "HttpSink",
          "kafka.auth.mode": "KAFKA_API_KEY",
          "kafka.api.key": "$CLOUD_KEY",
          "kafka.api.secret": "$CLOUD_SECRET",
          "topics": "http-topic",
          "input.data.format": "AVRO",
          "http.api.url": "http://httpstat.us/200/",
          "behavior.on.error": "fail",
          "tasks.max" : "1"
      }
      EOF

- name: connector
  expose: true
  group: Connector
  filters:
  - not_mdc_environment
  - connect_running
  help: |-
    ğŸ”— Connector commands

  commands:
  - name: status
    help: ğŸ§© Show status of all connectors
    flags:
    - &connector
      long: --connector
      short: -c
      required: false
      arg: connector
      completions:
        - $(playground get-connector-list)
      help: |-
        ğŸ”— Connector name

        ğŸ“ Tip: If not specified, the command will apply to all connectors

  - name: plugins
    help: ğŸ¨ Show all plugins installed

  - name: pause
    help: â¸ï¸  Pause connector
    flags:
    - *connector

  - name: versions
    help:  ğŸ§ Get current and latest version available on Confluent Hub for connector(s) used in example

  - name: restart
    help: â™»ï¸  Restart connector
    flags:
    - *connector

  - name: resume
    help: â¯ï¸  Resume connector
    flags:
    - *connector

  - name: delete
    help: ğŸ—‘ï¸  Delete connector
    flags:
    - *connector

  - name: show-lag
    help: ğŸ¢ Show lag of sink connector
    flags:
    - *connector
    - *waitforzerolag

  - name: show-config
    help:  ğŸ§° Show current connector config
    flags:
    - *connector

  - name: show-config-parameters
    help: ğŸ”© Show all possible configuration parameters of connector
    flags:
    - *connector
    - long: --open
      short: -o
      help: |- 
        ğŸ”– Save output to a file and open with text editor set with config.ini (default is code)
    - long: --force-refresh
      required: false
      help: |-
        â˜¢ï¸ Force refresh.

  - name: log-level
    help: |-
      ğŸ§¬ Set connect log level
    flags:
    - *connector
    - *level

  - name: create-or-update
    help: ğŸ§‘â€ğŸ¨  Create or update connector
    args:
    - name: json
      
      # Set the default path value to -, which is the standard operator for stdin.
      default: "-"
      help: json (reads from stdin if empty)

    flags:
    - long: --connector
      short: -c
      required: true
      arg: connector
      completions:
        - $(playground get-connector-list)
      help: |-
        ğŸ”— Connector name
    - long: --level
      short: -l
      arg: level
      allowed: [INFO, WARN, DEBUG, TRACE]
      required: false
      help: |-
        â•Log level
    - *package
    examples: |
      playground connector create-or-update -c filestream-sink << EOF
      {
          "tasks.max": "1",
          "connector.class": "org.apache.kafka.connect.file.FileStreamSinkConnector",
          "topics": "filestream",
          "file": "/tmp/output.json",
          "key.converter": "org.apache.kafka.connect.storage.StringConverter",
          "value.converter": "org.apache.kafka.connect.json.JsonConverter",
          "value.converter.schemas.enable": "false"
      }
      EOF

  examples:
  - playground connector status
  - playground connector status --json
  - playground connector resume --connector <connector-name>
  - playground connector pause -c <connector-name>
  - playground connector delete -c <connector-name>
